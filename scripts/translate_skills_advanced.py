#!/usr/bin/env python3
"""
Oh My Skills - æ™ºèƒ½ç¿»è¯‘è„šæœ¬
æ¥å…¥ Google Translate (deep-translator) å®ç°é«˜è´¨é‡å†…å®¹çš„æœ¬åœ°ç¿»è¯‘
"""

import json
import time
import re
from pathlib import Path
from deep_translator import GoogleTranslator

# é…ç½®
# ==========
BATCH_SIZE = 5      # æ¯æ‰¹å¤„ç†çš„æ•°é‡ï¼Œé¿å…è¿‡å¿«
DELAY = 1.0         # æ¯æ¬¡ API è°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰
MAX_RETRIES = 3     # é‡è¯•æ¬¡æ•°

INPUT_FILE = Path(__file__).parent.parent / "public" / "data" / "skills_raw.json"
OUTPUT_FILE = Path(__file__).parent.parent / "public" / "data" / "skills.json"

# ç¼“å­˜æ–‡ä»¶ï¼Œé¿å…é‡å¤ç¿»è¯‘
CACHE_FILE = Path(__file__).parent / "translation_cache.json"

# åˆå§‹åŒ–ç¿»è¯‘å™¨
translator = GoogleTranslator(source='auto', target='zh-CN')

# å›ºå®šçš„ä¸“ä¸šæœ¯è¯­æ˜ å°„ï¼ˆæœ‰äº›è¯ Google ç¿»è¯‘å¯èƒ½ä¸å‡†ï¼Œå¼ºåˆ¶è¦†ç›–ï¼‰
TERM_MAPPING = {
    "Artifacts": "Artifacts",
    "Claude": "Claude",
    "React": "React",
    "Expo": "Expo",
    "Vercel": "Vercel",
    "Markdown": "Markdown",
    "p5.js": "p5.js",
    "TypeScript": "TypeScript",
    "JavaScript": "JavaScript",
    "Python": "Python",
    "MCP": "MCP",
    "LLM": "LLM",
    "AI": "AI",
    "Agent": "æ™ºèƒ½ä½“",
}

CATEGORY_TRANSLATIONS = {
    "development": "å¼€å‘å·¥å…·",
    "workflow": "å·¥ä½œæµ",
    "testing": "æµ‹è¯•",
    "documentation": "æ–‡æ¡£",
    "backend": "åç«¯",
    "frontend": "å‰ç«¯",
    "data": "æ•°æ®",
    "security": "å®‰å…¨",
    "devops": "DevOps",
    "tools": "å·¥å…·",
    "design": "è®¾è®¡",
    "productivity": "ç”Ÿäº§åŠ›",
}

# åŠ è½½ç¼“å­˜
cache = {}
if CACHE_FILE.exists():
    try:
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            cache = json.load(f)
    except:
        pass

def save_cache():
    """ä¿å­˜ç¿»è¯‘ç¼“å­˜"""
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)

def smart_translate(text: str) -> str:
    """è°ƒç”¨ Google ç¿»è¯‘ï¼Œå¸¦ç¼“å­˜å’Œé‡è¯•"""
    if not text or not text.strip():
        return text
    
    # æ£€æŸ¥ç¼“å­˜
    if text in cache:
        return cache[text]
    
    # å°è¯•ç¿»è¯‘
    for i in range(MAX_RETRIES):
        try:
            # é™åˆ¶æ–‡æœ¬é•¿åº¦ï¼Œé¿å…è¶…å‡º URL é™åˆ¶ (Google å…è´¹æ¥å£é™åˆ¶çº¦ 5000 å­—ç¬¦)
            if len(text) > 4000:
                print(f"âš ï¸ æ–‡æœ¬è¿‡é•¿ ({len(text)} å­—ç¬¦)ï¼Œå°†è¢«æˆªæ–­ç¿»è¯‘...")
                translated = translator.translate(text[:4000]) + "..."
            else:
                translated = translator.translate(text)
            
            # åº”ç”¨æœ¯è¯­ä¿®æ­£
            for term, replacement in TERM_MAPPING.items():
                translated = translated.replace(term, replacement)
                # ä¿®å¤å¯èƒ½è¢«ç¿»è¯‘çš„æœ¯è¯­ï¼ˆä¾‹å¦‚ React -> ååº”ï¼‰
                # è¿™é‡Œç®€å•å¤„ç†ï¼Œä¿æŒæŸäº›ä¸“æœ‰åè¯å¤§å†™
            
            # å†™å…¥ç¼“å­˜
            cache[text] = translated
            save_cache() # å®æ—¶ä¿å­˜é˜²æ­¢ä¸­æ–­
            
            time.sleep(DELAY) # ç¤¼è²Œå»¶æ—¶
            return translated
        except Exception as e:
            print(f"   âš ï¸ ç¿»è¯‘å¤±è´¥ (é‡è¯• {i+1}/{MAX_RETRIES}): {e}")
            time.sleep(2)
    
    print(f"   âŒ æœ€ç»ˆç¿»è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡")
    return text

def translate_markdown_body(body: str) -> str:
    """
    æ™ºèƒ½ç¿»è¯‘ Markdown æ­£æ–‡
    ç­–ç•¥ï¼šæŒ‰æ®µè½æ‹†åˆ†ï¼Œåˆ†åˆ«ç¿»è¯‘ï¼Œä¿ç•™ä»£ç å—
    """
    if not body:
        return ""
        
    # 1. ä¿æŠ¤ä»£ç å— (```...```) ä¸è¢«ç¿»è¯‘
    code_blocks = []
    def save_code_block(match):
        code_blocks.append(match.group(0))
        return f"__CODE_BLOCK_{len(code_blocks)-1}__"
    
    # å°†ä»£ç å—æ›¿æ¢ä¸ºå ä½ç¬¦
    text_safe = re.sub(r'```[\s\S]*?```', save_code_block, body)
    
    # 2. ä¿æŠ¤è¡Œå†…ä»£ç  (`...`) 
    inline_codes = []
    def save_inline_code(match):
        inline_codes.append(match.group(0))
        return f"__INLINE_CODE_{len(inline_codes)-1}__"
    
    text_safe = re.sub(r'`[^`\n]+`', save_inline_code, text_safe)
    
    # 3. æŒ‰è¡Œæ‹†åˆ†ç¿»è¯‘ï¼ˆä¿ç•™ Markdown ç»“æ„ï¼‰
    lines = text_safe.split('\n')
    translated_lines = []
    
    buffer_text = ""
    buffer_indices = []
    
    for idx, line in enumerate(lines):
        line = line.strip()
        
        # è·³è¿‡ç©ºè¡Œã€åªæœ‰ç¬¦å·çš„è¡Œ
        if not line or re.match(r'^[-=*_#\s]+$', line):
            translated_lines.append(line) # ä¿æŒåŸæ ·
            continue
            
        # è¯†åˆ«æ ‡é¢˜
        header_match = re.match(r'^(#+)\s+(.*)', line)
        if header_match:
            level = header_match.group(1)
            content = header_match.group(2)
            trans = smart_translate(content)
            translated_lines.append(f"{level} {trans}")
            continue
            
        # è¯†åˆ«åˆ—è¡¨é¡¹
        list_match = re.match(r'^([-*]|\d+\.)\s+(.*)', line)
        if list_match:
            marker = list_match.group(1)
            content = list_match.group(2)
            trans = smart_translate(content)
            translated_lines.append(f"{marker} {trans}")
            continue
            
        # æ™®é€šæ–‡æœ¬æ®µè½
        trans = smart_translate(line)
        translated_lines.append(trans)
    
    # é‡æ–°ç»„åˆ
    result = '\n'.join(translated_lines)
    
    # 4. è¿˜åŸè¡Œå†…ä»£ç 
    for i, code in enumerate(inline_codes):
        result = result.replace(f"__INLINE_CODE_{i}__", code)
        
    # 5. è¿˜åŸä»£ç å—
    for i, block in enumerate(code_blocks):
        result = result.replace(f"__CODE_BLOCK_{i}__", block)
        
    return result

def translate_skill_full(skill: dict, index: int, total: int) -> dict:
    """å®Œæ•´ç¿»è¯‘å•ä¸ªæŠ€èƒ½"""
    print(f"[{index+1}/{total}] å¤„ç†æŠ€èƒ½: {skill.get('name')}...")
    
    translated = skill.copy()
    
    # 1. ç¿»è¯‘åç§°
    # åç§°é€šå¸¸è¾ƒçŸ­ï¼Œå¯ä»¥ç›´æ¥ç¿»è¯‘ï¼Œæˆ–è€…ä¿æŒè‹±æ–‡ (å¾ˆå¤šæŠ€æœ¯åè¯ä¿ç•™è‹±æ–‡æ›´å¥½)
    # è¿™é‡Œæˆ‘ä»¬ç­–ç•¥æ˜¯ï¼šå¦‚æœç¿»è¯‘åå·®åˆ«å¾ˆå¤§ä¸”ä¸å…¨æ˜¯ ASCIIï¼Œåˆ™ä¿ç•™ï¼›
    # æˆ–è€…å¯¹äºç‰¹å®šè¯æ±‡ä½¿ç”¨æ˜ å°„
    name = skill.get("name", "")
    # å°è¯•ç¿»è¯‘åç§°ï¼Œä½†å¦‚æœæ˜¯ä¸“æœ‰åè¯å¯èƒ½ä¸éœ€è¦
    # translated["name_zh"] = smart_translate(name) 
    # ä¿æŒæ··åˆæ¨¡å¼ï¼šä½¿ç”¨ä¹‹å‰çš„å›ºå®šæ˜ å°„ä¼˜å…ˆï¼Œæ²¡æœ‰çš„å† API ç¿»è¯‘
    # ä¸ºäº†æ¼”ç¤ºæ•ˆæœï¼Œæˆ‘ä»¬å¯¹åç§°ä¹Ÿå°è¯• API ç¿»è¯‘ï¼Œå¦‚æœä¸æ»¡æ„å¯ä»¥æ‰‹åŠ¨æ”¹
    name_zh = smart_translate(name)
    # å¦‚æœç¿»è¯‘åŒ…å«è‹±æ–‡ï¼Œå°½é‡ä¿ç•™è‹±æ–‡åŸæ–‡ä½œä¸ºä¸»ï¼Œè¿™é‡Œåªå­˜ä¸­æ–‡éƒ¨åˆ†
    translated["name_zh"] = name_zh
    
    # 2. ç¿»è¯‘æè¿° (Description)
    desc = skill.get("description", "")
    if desc:
        print(f"   - ç¿»è¯‘æè¿°...")
        translated["description_zh"] = smart_translate(desc)
    
    # 3. ç¿»è¯‘åˆ†ç±»
    cat = skill.get("category", "").lower()
    translated["category_zh"] = CATEGORY_TRANSLATIONS.get(cat, skill.get("category"))
    
    # 4. ç¿»è¯‘æ­£æ–‡ (Markdown Body)
    # è¿™æ˜¯æœ€è€—æ—¶çš„éƒ¨åˆ†
    body = skill.get("body", "")
    if body:
        print(f"   - ç¿»è¯‘è¯¦ç»†è¯´æ˜ ({len(body)} å­—ç¬¦)...")
        translated["body_zh"] = translate_markdown_body(body)
    
    return translated

def main():
    print("ğŸŒ Oh My Skills - å¯åŠ¨ Google æ™ºèƒ½ç¿»è¯‘")
    print("========================================")
    
    if not INPUT_FILE.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {INPUT_FILE}")
        return
        
    try:
        with open(INPUT_FILE, "r", encoding="utf-8") as f:
            skills = json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å– JSON å¤±è´¥: {e}")
        return

    total_skills = len(skills)
    translated_skills = []
    
    # åªå¤„ç†å‰ N ä¸ªæˆ–è€…å…¨éƒ¨ï¼Œè¿™é‡Œæ˜¯å…¨éƒ¨
    # å»ºè®®å…ˆæµ‹è¯•å‰ 3 ä¸ª: skills[:3]
    # ä½†ç”¨æˆ·è¦æ±‚ç”Ÿæˆé«˜è´¨é‡ jsonï¼Œæ‰€ä»¥æˆ‘ä»¬è·‘å…¨é‡ (å¯èƒ½ä¼šèŠ±å‡ åˆ†é’Ÿ)
    
    try:
        for i, skill in enumerate(skills):
            translated_skill = translate_skill_full(skill, i, total_skills)
            translated_skills.append(translated_skill)
            
            # å®šæœŸä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼Œé˜²æ­¢ä¸­é€” crash
            if (i + 1) % 5 == 0:
                with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
                    json.dump(translated_skills + skills[i+1:], f, ensure_ascii=False, indent=2)
                print(f"   ğŸ’¾ è¿›åº¦å·²ä¿å­˜ ({i+1}/{total_skills})")
                
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œä¿å­˜å·²ç¿»è¯‘å†…å®¹...")
    
    # æœ€ç»ˆä¿å­˜
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(translated_skills, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼")
    print(f"   å·²ç”Ÿæˆé«˜è´¨é‡ç¿»è¯‘æ–‡ä»¶: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
