[
  {
    "name": "algorithmic-art",
    "description": "Creating algorithmic art using p5.js with seeded randomness and interactive parameter exploration. Use when users request creating art using code, generative art, algorithmic art, flow fields, or particle systems.",
    "body": "# Algorithmic Art\n\nCreate generative art with code using p5.js, featuring seeded randomness for reproducibility.\n\n## Core Concepts\n\n### Seeded Randomness\n```javascript\n// Use seed for reproducible results\nfunction setup() {\n  randomSeed(42);\n  noiseSeed(42);\n}\n```\n\n### Noise Functions\n```javascript\n// Perlin noise for organic patterns\nlet x = noise(frameCount * 0.01) * width;\nlet y = noise(frameCount * 0.01 + 1000) * height;\n```\n\n## Common Patterns\n\n### Flow Fields\n```javascript\nlet cols, rows, scale = 20;\nlet particles = [];\nlet flowfield;\n\nfunction setup() {\n  createCanvas(800, 800);\n  cols = floor(width / scale);\n  rows = floor(height / scale);\n  flowfield = new Array(cols * rows);\n\n  for (let i = 0; i < 1000; i++) {\n    particles.push(new Particle());\n  }\n}\n\nfunction draw() {\n  let yoff = 0;\n  for (let y = 0; y < rows; y++) {\n    let xoff = 0;\n    for (let x = 0; x < cols; x++) {\n      let angle = noise(xoff, yoff) * TWO_PI * 2;\n      let v = p5.Vector.fromAngle(angle);\n      flowfield[x + y * cols] = v;\n      xoff += 0.1;\n    }\n    yoff += 0.1;\n  }\n\n  particles.forEach(p => {\n    p.follow(flowfield);\n    p.update();\n    p.show();\n  });\n}\n```\n\n### Recursive Trees\n```javascript\nfunction branch(len) {\n  line(0, 0, 0, -len);\n  translate(0, -len);\n\n  if (len > 4) {\n    push();\n    rotate(PI / 6);\n    branch(len * 0.67);\n    pop();\n\n    push();\n    rotate(-PI / 6);\n    branch(len * 0.67);\n    pop();\n  }\n}\n```\n\n### Particle Systems\n```javascript\nclass Particle {\n  constructor() {\n    this.pos = createVector(random(width), random(height));\n    this.vel = createVector(0, 0);\n    this.acc = createVector(0, 0);\n    this.maxSpeed = 4;\n  }\n\n  follow(flowfield) {\n    let x = floor(this.pos.x / scale);\n    let y = floor(this.pos.y / scale);\n    let force = flowfield[x + y * cols];\n    this.acc.add(force);\n  }\n\n  update() {\n    this.vel.add(this.acc);\n    this.vel.limit(this.maxSpeed);\n    this.pos.add(this.vel);\n    this.acc.mult(0);\n  }\n\n  show() {\n    stroke(255, 5);\n    point(this.pos.x, this.pos.y);\n  }\n}\n```\n\n## Color Palettes\n\n```javascript\n// Define palette\nconst palette = ['#264653', '#2a9d8f', '#e9c46a', '#f4a261', '#e76f51'];\n\n// Random from palette\nfill(random(palette));\n```\n\n## Best Practices\n\n- Use `noLoop()` for static pieces, save with `save('art.png')`\n- Experiment with blend modes: `blendMode(ADD)`\n- Layer transparency for depth\n- Use frameCount for animation",
    "id": "algorithmic-art",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/algorithmic-art",
    "name_zh": "ÁÆóÊ≥ïËâ∫ÊúØ",
    "description_zh": "ÂàõÂª∫ ÁÆóÊ≥ïËâ∫ÊúØ using p5.js ‰ΩøÁî®ÁßçÂ≠êÈöèÊú∫ÊÄß and ‰∫§‰∫íÂºèÂèÇÊï∞Êé¢Á¥¢. ÈÄÇÁî®‰∫é Áî®Êà∑ËØ∑Ê±Ç creating art ‰ΩøÁî®‰ª£Á†Å, ÁîüÊàêËâ∫ÊúØ, ÁÆóÊ≥ïËâ∫ÊúØ, ÊµÅÂú∫, or Á≤íÂ≠êÁ≥ªÁªü.",
    "body_zh": "# Algorithmic Art\n\nCreate generative art with code using p5.js, featuring seeded randomness for reproducibility.\n\n## Core Concepts\n\n### Seeded Randomness\n```javascript\n// Use seed for reproducible results\nfunction setup() {\n  randomSeed(42);\n  noiseSeed(42);\n}\n```\n\n### Noise Functions\n```javascript\n// Perlin noise for organic patterns\nlet x = noise(frameCount * 0.01) * width;\nlet y = noise(frameCount * 0.01 + 1000) * height;\n```\n\n## Common Patterns\n\n### Flow Fields\n```javascript\nlet cols, rows, scale = 20;\nlet particles = [];\nlet flowfield;\n\nfunction setup() {\n  createCanvas(800, 800);\n  cols = floor(width / scale);\n  rows = floor(height / scale);\n  flowfield = new Array(cols * rows);\n\n  for (let i = 0; i < 1000; i++) {\n    particles.push(new Particle());\n  }\n}\n\nfunction draw() {\n  let yoff = 0;\n  for (let y = 0; y < rows; y++) {\n    let xoff = 0;\n    for (let x = 0; x < cols; x++) {\n      let angle = noise(xoff, yoff) * TWO_PI * 2;\n      let v = p5.Vector.fromAngle(angle);\n      flowfield[x + y * cols] = v;\n      xoff += 0.1;\n    }\n    yoff += 0.1;\n  }\n\n  particles.forEach(p => {\n    p.follow(flowfield);\n    p.update();\n    p.show();\n  });\n}\n```\n\n### Recursive Trees\n```javascript\nfunction branch(len) {\n  line(0, 0, 0, -len);\n  translate(0, -len);\n\n  if (len > 4) {\n    push();\n    rotate(PI / 6);\n    branch(len * 0.67);\n    pop();\n\n    push();\n    rotate(-PI / 6);\n    branch(len * 0.67);\n    pop();\n  }\n}\n```\n\n### Particle Systems\n```javascript\nclass Particle {\n  constructor() {\n    this.pos = createVector(random(width), random(height));\n    this.vel = createVector(0, 0);\n    this.acc = createVector(0, 0);\n    this.maxSpeed = 4;\n  }\n\n  follow(flowfield) {\n    let x = floor(this.pos.x / scale);\n    let y = floor(this.pos.y / scale);\n    let force = flowfield[x + y * cols];\n    this.acc.add(force);\n  }\n\n  update() {\n    this.vel.add(this.acc);\n    this.vel.limit(this.maxSpeed);\n    this.pos.add(this.vel);\n    this.acc.mult(0);\n  }\n\n  show() {\n    stroke(255, 5);\n    point(this.pos.x, this.pos.y);\n  }\n}\n```\n\n## Color Palettes\n\n```javascript\n// Define palette\nconst palette = ['#264653', '#2a9d8f', '#e9c46a', '#f4a261', '#e76f51'];\n\n// Random from palette\nfill(random(palette));\n```\n\n## Best Practices\n\n- Use `noLoop()` for static pieces, save with `save('art.png')`\n- Experiment with blend modes: `blendMode(ADD)`\n- Layer transparency for depth\n- Use frameCount for animation"
  },
  {
    "name": "artifacts-builder",
    "description": "Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui). Use for complex artifacts requiring state management, routing, or shadcn/ui components - not for simple single-file HTML/JSX artifacts.",
    "body": "# Artifacts Builder\n\nTo build powerful frontend claude.ai artifacts, follow these steps:\n1. Initialize the frontend repo using `scripts/init-artifact.sh`\n2. Develop your artifact by editing the generated code\n3. Bundle all code into a single HTML file using `scripts/bundle-artifact.sh`\n4. Display artifact to user\n5. (Optional) Test the artifact\n\n**Stack**: React 18 + TypeScript + Vite + Parcel (bundling) + Tailwind CSS + shadcn/ui\n\n## Design & Style Guidelines\n\nVERY IMPORTANT: To avoid what is often referred to as \"AI slop\", avoid using excessive centered layouts, purple gradients, uniform rounded corners, and Inter font.\n\n## Quick Start\n\n### Step 1: Initialize Project\n\nRun the initialization script to create a new React project:\n```bash\nbash scripts/init-artifact.sh <project-name>\ncd <project-name>\n```\n\nThis creates a fully configured project with:\n- ‚úÖ React + TypeScript (via Vite)\n- ‚úÖ Tailwind CSS 3.4.1 with shadcn/ui theming system\n- ‚úÖ Path aliases (`@/`) configured\n- ‚úÖ 40+ shadcn/ui components pre-installed\n- ‚úÖ All Radix UI dependencies included\n- ‚úÖ Parcel configured for bundling (via .parcelrc)\n- ‚úÖ Node 18+ compatibility (auto-detects and pins Vite version)\n\n### Step 2: Develop Your Artifact\n\nTo build the artifact, edit the generated files. See **Common Development Tasks** below for guidance.\n\n### Step 3: Bundle to Single HTML File\n\nTo bundle the React app into a single HTML artifact:\n```bash\nbash scripts/bundle-artifact.sh\n```\n\nThis creates `bundle.html` - a self-contained artifact with all JavaScript, CSS, and dependencies inlined. This file can be directly shared in Claude conversations as an artifact.\n\n**Requirements**: Your project must have an `index.html` in the root directory.\n\n**What the script does**:\n- Installs bundling dependencies (parcel, @parcel/config-default, parcel-resolver-tspaths, html-inline)\n- Creates `.parcelrc` config with path alias support\n- Builds with Parcel (no source maps)\n- Inlines all assets into single HTML using html-inline\n\n### Step 4: Share Artifact with User\n\nFinally, share the bundled HTML file in conversation with the user so they can view it as an artifact.\n\n### Step 5: Testing/Visualizing the Artifact (Optional)\n\nNote: This is a completely optional step. Only perform if necessary or requested.\n\nTo test/visualize the artifact, use available tools (including other Skills or built-in tools like Playwright or Puppeteer). In general, avoid testing the artifact upfront as it adds latency between the request and when the finished artifact can be seen. Test later, after presenting the artifact, if requested or if issues arise.\n\n## Reference\n\n- **shadcn/ui components**: https://ui.shadcn.com/docs/components",
    "id": "artifacts-builder",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/artifacts-builder",
    "name_zh": "Artifacts ÊûÑÂª∫Âô®",
    "description_zh": "Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui). Use for complex artifacts requiring state management, routing, or shadcn/ui components - not for simple single-file HTML/JSX artifacts.",
    "body_zh": "# Artifacts Builder\n\nTo build powerful frontend claude.ai artifacts, follow these steps:\n1. Initialize the frontend repo using `scripts/init-artifact.sh`\n2. Develop your artifact by editing the generated code\n3. Bundle all code into a single HTML file using `scripts/bundle-artifact.sh`\n4. Display artifact to user\n5. (Optional) Test the artifact\n\n**Stack**: React 18 + TypeScript + Vite + Parcel (bundling) + Tailwind CSS + shadcn/ui\n\n## Design & Style Guidelines\n\nVERY IMPORTANT: To avoid what is often referred to as \"AI slop\", avoid using excessive centered layouts, purple gradients, uniform rounded corners, and Inter font.\n\n## Quick Start\n\n### Step 1: Initialize Project\n\nRun the initialization script to create a new React project:\n```bash\nbash scripts/init-artifact.sh <project-name>\ncd <project-name>\n```\n\nThis creates a fully configured project with:\n- ‚úÖ React + TypeScript (via Vite)\n- ‚úÖ Tailwind CSS 3.4.1 with shadcn/ui theming system\n- ‚úÖ Path aliases (`@/`) configured\n- ‚úÖ 40+ shadcn/ui components pre-installed\n- ‚úÖ All Radix UI dependencies included\n- ‚úÖ Parcel configured for bundling (via .parcelrc)\n- ‚úÖ Node 18+ compatibility (auto-detects and pins Vite version)\n\n### Step 2: Develop Your Artifact\n\nTo build the artifact, edit the generated files. See **Common Development Tasks** below for guidance.\n\n### Step 3: Bundle to Single HTML File\n\nTo bundle the React app into a single HTML artifact:\n```bash\nbash scripts/bundle-artifact.sh\n```\n\nThis creates `bundle.html` - a self-contained artifact with all JavaScript, CSS, and dependencies inlined. This file can be directly shared in Claude conversations as an artifact.\n\n**Requirements**: Your project must have an `index.html` in the root directory.\n\n**What the script does**:\n- Installs bundling dependencies (parcel, @parcel/config-default, parcel-resolver-tspaths, html-inline)\n- Creates `.parcelrc` config with path alias support\n- Builds with Parcel (no source maps)\n- Inlines all assets into single HTML using html-inline\n\n### Step 4: Share Artifact with User\n\nFinally, share the bundled HTML file in conversation with the user so they can view it as an artifact.\n\n### Step 5: Testing/Visualizing the Artifact (Optional)\n\nNote: This is a completely optional step. Only perform if necessary or requested.\n\nTo test/visualize the artifact, use available tools (including other Skills or built-in tools like Playwright or Puppeteer). In general, avoid testing the artifact upfront as it adds latency between the request and when the finished artifact can be seen. Test later, after presenting the artifact, if requested or if issues arise.\n\n## Reference\n\n- **shadcn/ui components**: https://ui.shadcn.com/docs/components"
  },
  {
    "name": "ask-questions-if-underspecified",
    "description": "Clarify requirements before implementing. Do not use automatically, only when invoked explicitly.",
    "body": "# Ask Questions If Underspecified\n\n## Goal\n\nAsk the minimum set of clarifying questions needed to avoid wrong work; do not start implementing until the must-have questions are answered (or the user explicitly approves proceeding with stated assumptions).\n\n## Workflow\n\n### 1) Decide whether the request is underspecified\n\nTreat a request as underspecified if after exploring how to perform the work, some or all of the following are not clear:\n- Define the objective (what should change vs stay the same)\n- Define \"done\" (acceptance criteria, examples, edge cases)\n- Define scope (which files/components/users are in/out)\n- Define constraints (compatibility, performance, style, deps, time)\n- Identify environment (language/runtime versions, OS, build/test runner)\n- Clarify safety/reversibility (data migration, rollout/rollback, risk)\n\nIf multiple plausible interpretations exist, assume it is underspecified.\n\n### 2) Ask must-have questions first (keep it small)\n\nAsk 1-5 questions in the first pass. Prefer questions that eliminate whole branches of work.\n\nMake questions easy to answer:\n- Optimize for scannability (short, numbered questions; avoid paragraphs)\n- Offer multiple-choice options when possible\n- Suggest reasonable defaults when appropriate (mark them clearly as the default/recommended choice; bold the recommended choice in the list, or if you present options in a code block, put a bold \"Recommended\" line immediately above the block and also tag defaults inside the block)\n- Include a fast-path response (e.g., reply `defaults` to accept all recommended/default choices)\n- Include a low-friction \"not sure\" option when helpful (e.g., \"Not sure - use default\")\n- Separate \"Need to know\" from \"Nice to know\" if that reduces friction\n- Structure options so the user can respond with compact decisions (e.g., `1b 2a 3c`); restate the chosen options in plain language to confirm\n\n### 3) Pause before acting\n\nUntil must-have answers arrive:\n- Do not run commands, edit files, or produce a detailed plan that depends on unknowns\n- Do perform a clearly labeled, low-risk discovery step only if it does not commit you to a direction (e.g., inspect repo structure, read relevant config files)\n\nIf the user explicitly asks you to proceed without answers:\n- State your assumptions as a short numbered list\n- Ask for confirmation; proceed only after they confirm or correct them\n\n### 4) Confirm interpretation, then proceed\n\nOnce you have answers, restate the requirements in 1-3 sentences (including key constraints and what success looks like), then start work.\n\n## Question templates\n\n- \"Before I start, I need: (1) ..., (2) ..., (3) .... If you don't care about (2), I will assume ....\"\n- \"Which of these should it be? A) ... B) ... C) ... (pick one)\"\n- \"What would you consider 'done'? For example: ...\"\n- \"Any constraints I must follow (versions, performance, style, deps)? If none, I will target the existing project defaults.\"\n- Use numbered questions with lettered options and a clear reply format\n\n```text\n1) Scope?\na) Minimal change (default)\nb) Refactor while touching the area\nc) Not sure - use default\n2) Compatibility target?\na) Current project defaults (default)\nb) Also support older versions: <specify>\nc) Not sure - use default\n\nReply with: defaults (or 1a 2a)\n```\n\n## Anti-patterns\n\n- Don't ask questions you can answer with a quick, low-risk discovery read (e.g., configs, existing patterns, docs).\n- Don't ask open-ended questions if a tight multiple-choice or yes/no would eliminate ambiguity faster.\n\n---\n\n*Originally created by [@thsottiaux](https://x.com/thsottiaux)*",
    "id": "ask-questions-if-underspecified",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/ask-questions-if-underspecified",
    "name_zh": "Ëá™Âä®ËøΩÈóÆÊæÑÊ∏Ö",
    "description_zh": "Clarify requirements before implementing. Do not use automatically, only when invoked explicitly.",
    "body_zh": "# Ask Questions If Underspecified\n\n## Goal\n\nAsk the minimum set of clarifying questions needed to avoid wrong work; do not start implementing until the must-have questions are answered (or the user explicitly approves proceeding with stated assumptions).\n\n## Workflow\n\n### 1) Decide whether the request is underspecified\n\nTreat a request as underspecified if after exploring how to perform the work, some or all of the following are not clear:\n- Define the objective (what should change vs stay the same)\n- Define \"done\" (acceptance criteria, examples, edge cases)\n- Define scope (which files/components/users are in/out)\n- Define constraints (compatibility, performance, style, deps, time)\n- Identify environment (language/runtime versions, OS, build/test runner)\n- Clarify safety/reversibility (data migration, rollout/rollback, risk)\n\nIf multiple plausible interpretations exist, assume it is underspecified.\n\n### 2) Ask must-have questions first (keep it small)\n\nAsk 1-5 questions in the first pass. Prefer questions that eliminate whole branches of work.\n\nMake questions easy to answer:\n- Optimize for scannability (short, numbered questions; avoid paragraphs)\n- Offer multiple-choice options when possible\n- Suggest reasonable defaults when appropriate (mark them clearly as the default/recommended choice; bold the recommended choice in the list, or if you present options in a code block, put a bold \"Recommended\" line immediately above the block and also tag defaults inside the block)\n- Include a fast-path response (e.g., reply `defaults` to accept all recommended/default choices)\n- Include a low-friction \"not sure\" option when helpful (e.g., \"Not sure - use default\")\n- Separate \"Need to know\" from \"Nice to know\" if that reduces friction\n- Structure options so the user can respond with compact decisions (e.g., `1b 2a 3c`); restate the chosen options in plain language to confirm\n\n### 3) Pause before acting\n\nUntil must-have answers arrive:\n- Do not run commands, edit files, or produce a detailed plan that depends on unknowns\n- Do perform a clearly labeled, low-risk discovery step only if it does not commit you to a direction (e.g., inspect repo structure, read relevant config files)\n\nIf the user explicitly asks you to proceed without answers:\n- State your assumptions as a short numbered list\n- Ask for confirmation; proceed only after they confirm or correct them\n\n### 4) Confirm interpretation, then proceed\n\nOnce you have answers, restate the requirements in 1-3 sentences (including key constraints and what success looks like), then start work.\n\n## Question templates\n\n- \"Before I start, I need: (1) ..., (2) ..., (3) .... If you don't care about (2), I will assume ....\"\n- \"Which of these should it be? A) ... B) ... C) ... (pick one)\"\n- \"What would you consider 'done'? For example: ...\"\n- \"Any constraints I must follow (versions, performance, style, deps)? If none, I will target the existing project defaults.\"\n- Use numbered questions with lettered options and a clear reply format\n\n```text\n1) Scope?\na) Minimal change (default)\nb) Refactor while touching the area\nc) Not sure - use default\n2) Compatibility target?\na) Current project defaults (default)\nb) Also support older versions: <specify>\nc) Not sure - use default\n\nReply with: defaults (or 1a 2a)\n```\n\n## Anti-patterns\n\n- Don't ask questions you can answer with a quick, low-risk discovery read (e.g., configs, existing patterns, docs).\n- Don't ask open-ended questions if a tight multiple-choice or yes/no would eliminate ambiguity faster.\n\n---\n\n*Originally created by [@thsottiaux](https://x.com/thsottiaux)*"
  },
  {
    "name": "backend-development",
    "description": "Backend API design, database architecture, microservices patterns, and test-driven development. Use for designing APIs, database schemas, or backend system architecture.",
    "body": "# Backend Development\n\n## API Design\n\n### RESTful Conventions\n```\nGET    /users          # List users\nPOST   /users          # Create user\nGET    /users/:id      # Get user\nPUT    /users/:id      # Update user (full)\nPATCH  /users/:id      # Update user (partial)\nDELETE /users/:id      # Delete user\n\nGET    /users/:id/posts  # List user's posts\nPOST   /users/:id/posts  # Create post for user\n```\n\n### Response Format\n```json\n{\n  \"data\": { ... },\n  \"meta\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"total\": 100\n  }\n}\n```\n\n### Error Format\n```json\n{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid input\",\n    \"details\": [\n      { \"field\": \"email\", \"message\": \"Invalid format\" }\n    ]\n  }\n}\n```\n\n## Database Patterns\n\n### Schema Design\n```sql\n-- Use UUIDs for public IDs\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  public_id UUID DEFAULT gen_random_uuid() UNIQUE,\n  email VARCHAR(255) UNIQUE NOT NULL,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  updated_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Soft deletes\nALTER TABLE users ADD COLUMN deleted_at TIMESTAMPTZ;\n\n-- Indexes\nCREATE INDEX idx_users_email ON users(email);\nCREATE INDEX idx_users_created ON users(created_at DESC);\n```\n\n### Query Patterns\n```sql\n-- Pagination with cursor\nSELECT * FROM posts\nWHERE created_at < $cursor\nORDER BY created_at DESC\nLIMIT 20;\n\n-- Efficient counting\nSELECT reltuples::bigint AS estimate\nFROM pg_class WHERE relname = 'users';\n```\n\n## Authentication\n\n### JWT Pattern\n```typescript\ninterface TokenPayload {\n  sub: string;      // User ID\n  iat: number;      // Issued at\n  exp: number;      // Expiration\n  scope: string[];  // Permissions\n}\n\nfunction verifyToken(token: string): TokenPayload {\n  return jwt.verify(token, SECRET) as TokenPayload;\n}\n```\n\n### Middleware\n```typescript\nasync function authenticate(req: Request, res: Response, next: Next) {\n  const token = req.headers.authorization?.replace('Bearer ', '');\n  if (!token) {\n    return res.status(401).json({ error: 'Unauthorized' });\n  }\n\n  try {\n    req.user = verifyToken(token);\n    next();\n  } catch {\n    res.status(401).json({ error: 'Invalid token' });\n  }\n}\n```\n\n## Caching Strategy\n\n```typescript\n// Cache-aside pattern\nasync function getUser(id: string): Promise<User> {\n  const cached = await redis.get(`user:${id}`);\n  if (cached) return JSON.parse(cached);\n\n  const user = await db.users.findById(id);\n  await redis.setex(`user:${id}`, 3600, JSON.stringify(user));\n  return user;\n}\n\n// Cache invalidation\nasync function updateUser(id: string, data: Partial<User>) {\n  await db.users.update(id, data);\n  await redis.del(`user:${id}`);\n}\n```\n\n## Rate Limiting\n\n```typescript\nconst limiter = rateLimit({\n  windowMs: 60 * 1000,  // 1 minute\n  max: 100,             // 100 requests per window\n  keyGenerator: (req) => req.ip,\n  handler: (req, res) => {\n    res.status(429).json({ error: 'Too many requests' });\n  }\n});\n```\n\n## Observability\n\n- **Logging**: Structured JSON logs with request IDs\n- **Metrics**: Request latency, error rates, queue depths\n- **Tracing**: Distributed tracing with correlation IDs\n- **Health checks**: `/health` and `/ready` endpoints",
    "id": "backend-development",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/backend-development",
    "name_zh": "ÂêéÁ´ØÂºÄÂèë",
    "description_zh": "Backend API design, database architecture, microservices patterns, and test-driven development. Use for designing APIs, database schemas, or backend system architecture.",
    "body_zh": "# Backend Development\n\n## API Design\n\n### RESTful Conventions\n```\nGET    /users          # List users\nPOST   /users          # Create user\nGET    /users/:id      # Get user\nPUT    /users/:id      # Update user (full)\nPATCH  /users/:id      # Update user (partial)\nDELETE /users/:id      # Delete user\n\nGET    /users/:id/posts  # List user's posts\nPOST   /users/:id/posts  # Create post for user\n```\n\n### Response Format\n```json\n{\n  \"data\": { ... },\n  \"meta\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"total\": 100\n  }\n}\n```\n\n### Error Format\n```json\n{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid input\",\n    \"details\": [\n      { \"field\": \"email\", \"message\": \"Invalid format\" }\n    ]\n  }\n}\n```\n\n## Database Patterns\n\n### Schema Design\n```sql\n-- Use UUIDs for public IDs\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  public_id UUID DEFAULT gen_random_uuid() UNIQUE,\n  email VARCHAR(255) UNIQUE NOT NULL,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  updated_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Soft deletes\nALTER TABLE users ADD COLUMN deleted_at TIMESTAMPTZ;\n\n-- Indexes\nCREATE INDEX idx_users_email ON users(email);\nCREATE INDEX idx_users_created ON users(created_at DESC);\n```\n\n### Query Patterns\n```sql\n-- Pagination with cursor\nSELECT * FROM posts\nWHERE created_at < $cursor\nORDER BY created_at DESC\nLIMIT 20;\n\n-- Efficient counting\nSELECT reltuples::bigint AS estimate\nFROM pg_class WHERE relname = 'users';\n```\n\n## Authentication\n\n### JWT Pattern\n```typescript\ninterface TokenPayload {\n  sub: string;      // User ID\n  iat: number;      // Issued at\n  exp: number;      // Expiration\n  scope: string[];  // Permissions\n}\n\nfunction verifyToken(token: string): TokenPayload {\n  return jwt.verify(token, SECRET) as TokenPayload;\n}\n```\n\n### Middleware\n```typescript\nasync function authenticate(req: Request, res: Response, next: Next) {\n  const token = req.headers.authorization?.replace('Bearer ', '');\n  if (!token) {\n    return res.status(401).json({ error: 'Unauthorized' });\n  }\n\n  try {\n    req.user = verifyToken(token);\n    next();\n  } catch {\n    res.status(401).json({ error: 'Invalid token' });\n  }\n}\n```\n\n## Caching Strategy\n\n```typescript\n// Cache-aside pattern\nasync function getUser(id: string): Promise<User> {\n  const cached = await redis.get(`user:${id}`);\n  if (cached) return JSON.parse(cached);\n\n  const user = await db.users.findById(id);\n  await redis.setex(`user:${id}`, 3600, JSON.stringify(user));\n  return user;\n}\n\n// Cache invalidation\nasync function updateUser(id: string, data: Partial<User>) {\n  await db.users.update(id, data);\n  await redis.del(`user:${id}`);\n}\n```\n\n## Rate Limiting\n\n```typescript\nconst limiter = rateLimit({\n  windowMs: 60 * 1000,  // 1 minute\n  max: 100,             // 100 requests per window\n  keyGenerator: (req) => req.ip,\n  handler: (req, res) => {\n    res.status(429).json({ error: 'Too many requests' });\n  }\n});\n```\n\n## Observability\n\n- **Logging**: Structured JSON logs with request IDs\n- **Metrics**: Request latency, error rates, queue depths\n- **Tracing**: Distributed tracing with correlation IDs\n- **Health checks**: `/health` and `/ready` endpoints"
  },
  {
    "name": "brand-guidelines",
    "description": "Apply brand colors and typography to artifacts. Use when brand colors, style guidelines, visual formatting, or company design standards apply. Ensures consistency across branded content.",
    "body": "# Brand Guidelines Application\n\n## Purpose\n\nApply consistent brand styling to any artifact: documents, presentations, web pages, or marketing materials.\n\n## Core Brand Elements\n\n### Colors\nDefine your brand palette with CSS variables:\n\n```css\n:root {\n  --brand-primary: #1a73e8;\n  --brand-secondary: #34a853;\n  --brand-accent: #ea4335;\n  --brand-dark: #202124;\n  --brand-light: #f8f9fa;\n  --brand-text: #3c4043;\n  --brand-text-muted: #5f6368;\n}\n```\n\n### Typography\n```css\n/* Primary font for headings */\n--font-display: 'Product Sans', 'Google Sans', system-ui;\n\n/* Body font */\n--font-body: 'Roboto', 'Inter', -apple-system, sans-serif;\n\n/* Monospace for code */\n--font-mono: 'Roboto Mono', 'Fira Code', monospace;\n\n/* Type scale */\n--text-xs: 0.75rem;\n--text-sm: 0.875rem;\n--text-base: 1rem;\n--text-lg: 1.125rem;\n--text-xl: 1.25rem;\n--text-2xl: 1.5rem;\n--text-3xl: 1.875rem;\n--text-4xl: 2.25rem;\n```\n\n### Spacing\n```css\n--space-1: 0.25rem;\n--space-2: 0.5rem;\n--space-3: 0.75rem;\n--space-4: 1rem;\n--space-6: 1.5rem;\n--space-8: 2rem;\n--space-12: 3rem;\n--space-16: 4rem;\n```\n\n## Application Examples\n\n### Buttons\n```css\n.btn-primary {\n  background: var(--brand-primary);\n  color: white;\n  padding: var(--space-2) var(--space-4);\n  border-radius: 4px;\n  font-family: var(--font-body);\n  font-weight: 500;\n}\n```\n\n### Cards\n```css\n.card {\n  background: white;\n  border: 1px solid var(--brand-light);\n  border-radius: 8px;\n  padding: var(--space-6);\n  box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n}\n```\n\n### Headers\n```css\nh1 {\n  font-family: var(--font-display);\n  font-size: var(--text-4xl);\n  color: var(--brand-dark);\n  font-weight: 500;\n}\n```\n\n## Document Templates\n\n### Google Docs\n- Heading 1: Display font, 24pt, Brand Dark\n- Heading 2: Display font, 18pt, Brand Primary\n- Body: Body font, 11pt, Brand Text\n- Links: Brand Primary, underlined\n\n### Presentations\n- Title slides: White text on Brand Primary background\n- Content slides: Brand Dark text on white\n- Accent elements: Brand Secondary or Accent\n\n## Best Practices\n\n1. **Consistency**: Use exact brand colors, never approximate\n2. **Contrast**: Ensure 4.5:1 minimum for text readability\n3. **Hierarchy**: Use size and weight to establish importance\n4. **Whitespace**: Generous spacing feels premium\n5. **Logo usage**: Maintain clear space around logo",
    "id": "brand-guidelines",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/brand-guidelines",
    "name_zh": "ÂìÅÁâåÊåáÂçó",
    "description_zh": "Apply brand colors and typography to artifacts. ÈÄÇÁî®‰∫é brand colors, style guidelines, visual formatting, or company design standards apply. Ensures consistency across branded content.",
    "body_zh": "# Brand Guidelines Application\n\n## Purpose\n\nApply consistent brand styling to any artifact: documents, presentations, web pages, or marketing materials.\n\n## Core Brand Elements\n\n### Colors\nDefine your brand palette with CSS variables:\n\n```css\n:root {\n  --brand-primary: #1a73e8;\n  --brand-secondary: #34a853;\n  --brand-accent: #ea4335;\n  --brand-dark: #202124;\n  --brand-light: #f8f9fa;\n  --brand-text: #3c4043;\n  --brand-text-muted: #5f6368;\n}\n```\n\n### Typography\n```css\n/* Primary font for headings */\n--font-display: 'Product Sans', 'Google Sans', system-ui;\n\n/* Body font */\n--font-body: 'Roboto', 'Inter', -apple-system, sans-serif;\n\n/* Monospace for code */\n--font-mono: 'Roboto Mono', 'Fira Code', monospace;\n\n/* Type scale */\n--text-xs: 0.75rem;\n--text-sm: 0.875rem;\n--text-base: 1rem;\n--text-lg: 1.125rem;\n--text-xl: 1.25rem;\n--text-2xl: 1.5rem;\n--text-3xl: 1.875rem;\n--text-4xl: 2.25rem;\n```\n\n### Spacing\n```css\n--space-1: 0.25rem;\n--space-2: 0.5rem;\n--space-3: 0.75rem;\n--space-4: 1rem;\n--space-6: 1.5rem;\n--space-8: 2rem;\n--space-12: 3rem;\n--space-16: 4rem;\n```\n\n## Application Examples\n\n### Buttons\n```css\n.btn-primary {\n  background: var(--brand-primary);\n  color: white;\n  padding: var(--space-2) var(--space-4);\n  border-radius: 4px;\n  font-family: var(--font-body);\n  font-weight: 500;\n}\n```\n\n### Cards\n```css\n.card {\n  background: white;\n  border: 1px solid var(--brand-light);\n  border-radius: 8px;\n  padding: var(--space-6);\n  box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n}\n```\n\n### Headers\n```css\nh1 {\n  font-family: var(--font-display);\n  font-size: var(--text-4xl);\n  color: var(--brand-dark);\n  font-weight: 500;\n}\n```\n\n## Document Templates\n\n### Google Docs\n- Heading 1: Display font, 24pt, Brand Dark\n- Heading 2: Display font, 18pt, Brand Primary\n- Body: Body font, 11pt, Brand Text\n- Links: Brand Primary, underlined\n\n### Presentations\n- Title slides: White text on Brand Primary background\n- Content slides: Brand Dark text on white\n- Accent elements: Brand Secondary or Accent\n\n## Best Practices\n\n1. **Consistency**: Use exact brand colors, never approximate\n2. **Contrast**: Ensure 4.5:1 minimum for text readability\n3. **Hierarchy**: Use size and weight to establish importance\n4. **Whitespace**: Generous spacing feels premium\n5. **Logo usage**: Maintain clear space around logo"
  },
  {
    "name": "canvas-design",
    "description": "Create beautiful visual art in .png and .pdf documents using design philosophy. Use when the user asks to create a poster, piece of art, design, or other static visual piece. Creates original visual designs.",
    "body": "# Canvas Design\n\nCreate visually striking static designs using HTML Canvas or Python imaging libraries.\n\n## Design Principles\n\n### Composition\n- **Rule of Thirds**: Place key elements along grid lines\n- **Visual Hierarchy**: Size, color, and position indicate importance\n- **White Space**: Embrace negative space for elegance\n- **Balance**: Symmetrical for formal, asymmetrical for dynamic\n\n### Color Theory\n- **Complementary**: Colors opposite on wheel (high contrast)\n- **Analogous**: Adjacent colors (harmonious)\n- **Triadic**: Three equidistant colors (vibrant)\n- Limit palette to 3-5 colors\n\n### Typography\n- Pair one display font with one body font\n- Maintain consistent hierarchy\n- Ensure readability (contrast, size)\n\n## Python Canvas (Pillow + Cairo)\n\n```python\nfrom PIL import Image, ImageDraw, ImageFont\nimport cairo\n\n# Create canvas\nwidth, height = 1200, 800\nsurface = cairo.ImageSurface(cairo.FORMAT_ARGB32, width, height)\nctx = cairo.Context(surface)\n\n# Background gradient\npattern = cairo.LinearGradient(0, 0, 0, height)\npattern.add_color_stop_rgb(0, 0.1, 0.1, 0.2)\npattern.add_color_stop_rgb(1, 0.05, 0.05, 0.1)\nctx.set_source(pattern)\nctx.paint()\n\n# Draw shapes\nctx.set_source_rgba(1, 0.3, 0.3, 0.8)\nctx.arc(600, 400, 150, 0, 2 * 3.14159)\nctx.fill()\n\n# Add text\nctx.set_source_rgb(1, 1, 1)\nctx.select_font_face(\"Sans\", cairo.FONT_SLANT_NORMAL, cairo.FONT_WEIGHT_BOLD)\nctx.set_font_size(48)\nctx.move_to(400, 600)\nctx.show_text(\"Hello Design\")\n\n# Save\nsurface.write_to_png(\"design.png\")\n```\n\n## HTML Canvas to Image\n\n```javascript\nconst canvas = document.createElement('canvas');\ncanvas.width = 1200;\ncanvas.height = 800;\nconst ctx = canvas.getContext('2d');\n\n// Draw\nctx.fillStyle = '#1a1a2e';\nctx.fillRect(0, 0, 1200, 800);\n\nctx.fillStyle = '#e94560';\nctx.beginPath();\nctx.arc(600, 400, 150, 0, Math.PI * 2);\nctx.fill();\n\n// Export\nconst dataUrl = canvas.toDataURL('image/png');\n```\n\n## Design Styles\n\n- **Minimalist**: Limited colors, lots of whitespace, clean lines\n- **Brutalist**: Raw, bold typography, stark contrasts\n- **Glassmorphism**: Frosted glass effects, subtle borders\n- **Retro/Vintage**: Muted colors, textures, classic typography\n- **Abstract**: Geometric shapes, gradients, artistic composition",
    "id": "canvas-design",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/canvas-design",
    "name_zh": "Canvas ËÆæËÆ°",
    "description_zh": "Create beautiful visual art in .png and .pdf documents using design philosophy. ÈÄÇÁî®‰∫é the user asks to create a poster, piece of art, design, or other static visual piece. Creates original visual designs.",
    "body_zh": "# Canvas Design\n\nCreate visually striking static designs using HTML Canvas or Python imaging libraries.\n\n## Design Principles\n\n### Composition\n- **Rule of Thirds**: Place key elements along grid lines\n- **Visual Hierarchy**: Size, color, and position indicate importance\n- **White Space**: Embrace negative space for elegance\n- **Balance**: Symmetrical for formal, asymmetrical for dynamic\n\n### Color Theory\n- **Complementary**: Colors opposite on wheel (high contrast)\n- **Analogous**: Adjacent colors (harmonious)\n- **Triadic**: Three equidistant colors (vibrant)\n- Limit palette to 3-5 colors\n\n### Typography\n- Pair one display font with one body font\n- Maintain consistent hierarchy\n- Ensure readability (contrast, size)\n\n## Python Canvas (Pillow + Cairo)\n\n```python\nfrom PIL import Image, ImageDraw, ImageFont\nimport cairo\n\n# Create canvas\nwidth, height = 1200, 800\nsurface = cairo.ImageSurface(cairo.FORMAT_ARGB32, width, height)\nctx = cairo.Context(surface)\n\n# Background gradient\npattern = cairo.LinearGradient(0, 0, 0, height)\npattern.add_color_stop_rgb(0, 0.1, 0.1, 0.2)\npattern.add_color_stop_rgb(1, 0.05, 0.05, 0.1)\nctx.set_source(pattern)\nctx.paint()\n\n# Draw shapes\nctx.set_source_rgba(1, 0.3, 0.3, 0.8)\nctx.arc(600, 400, 150, 0, 2 * 3.14159)\nctx.fill()\n\n# Add text\nctx.set_source_rgb(1, 1, 1)\nctx.select_font_face(\"Sans\", cairo.FONT_SLANT_NORMAL, cairo.FONT_WEIGHT_BOLD)\nctx.set_font_size(48)\nctx.move_to(400, 600)\nctx.show_text(\"Hello Design\")\n\n# Save\nsurface.write_to_png(\"design.png\")\n```\n\n## HTML Canvas to Image\n\n```javascript\nconst canvas = document.createElement('canvas');\ncanvas.width = 1200;\ncanvas.height = 800;\nconst ctx = canvas.getContext('2d');\n\n// Draw\nctx.fillStyle = '#1a1a2e';\nctx.fillRect(0, 0, 1200, 800);\n\nctx.fillStyle = '#e94560';\nctx.beginPath();\nctx.arc(600, 400, 150, 0, Math.PI * 2);\nctx.fill();\n\n// Export\nconst dataUrl = canvas.toDataURL('image/png');\n```\n\n## Design Styles\n\n- **Minimalist**: Limited colors, lots of whitespace, clean lines\n- **Brutalist**: Raw, bold typography, stark contrasts\n- **Glassmorphism**: Frosted glass effects, subtle borders\n- **Retro/Vintage**: Muted colors, textures, classic typography\n- **Abstract**: Geometric shapes, gradients, artistic composition"
  },
  {
    "name": "changelog-generator",
    "description": "Automatically creates user-facing changelogs from git commits by analyzing commit history, categorizing changes, and transforming technical commits into clear, customer-friendly release notes. Turns hours of manual changelog writing into minutes of automated generation.",
    "body": "# Changelog Generator\n\nThis skill transforms technical git commits into polished, user-friendly changelogs that your customers and users will actually understand and appreciate.\n\n## When to Use This Skill\n\n- Preparing release notes for a new version\n- Creating weekly or monthly product update summaries\n- Documenting changes for customers\n- Writing changelog entries for app store submissions\n- Generating update notifications\n- Creating internal release documentation\n- Maintaining a public changelog/product updates page\n\n## What This Skill Does\n\n1. **Scans Git History**: Analyzes commits from a specific time period or between versions\n2. **Categorizes Changes**: Groups commits into logical categories (features, improvements, bug fixes, breaking changes, security)\n3. **Translates Technical ‚Üí User-Friendly**: Converts developer commits into customer language\n4. **Formats Professionally**: Creates clean, structured changelog entries\n5. **Filters Noise**: Excludes internal commits (refactoring, tests, etc.)\n6. **Follows Best Practices**: Applies changelog guidelines and your brand voice\n\n## How to Use\n\n### Basic Usage\n\nFrom your project repository:\n\n```\nCreate a changelog from commits since last release\n```\n\n```\nGenerate changelog for all commits from the past week\n```\n\n```\nCreate release notes for version 2.5.0\n```\n\n### With Specific Date Range\n\n```\nCreate a changelog for all commits between March 1 and March 15\n```\n\n### With Custom Guidelines\n\n```\nCreate a changelog for commits since v2.4.0, using my changelog \nguidelines from CHANGELOG_STYLE.md\n```\n\n## Example\n\n**User**: \"Create a changelog for commits from the past 7 days\"\n\n**Output**:\n```markdown\n# Updates - Week of March 10, 2024\n\n## ‚ú® New Features\n\n- **Team Workspaces**: Create separate workspaces for different \n  projects. Invite team members and keep everything organized.\n\n- **Keyboard Shortcuts**: Press ? to see all available shortcuts. \n  Navigate faster without touching your mouse.\n\n## üîß Improvements\n\n- **Faster Sync**: Files now sync 2x faster across devices\n- **Better Search**: Search now includes file contents, not just titles\n\n## üêõ Fixes\n\n- Fixed issue where large images wouldn't upload\n- Resolved timezone confusion in scheduled posts\n- Corrected notification badge count\n```\n\n**Inspired by:** Manik Aggarwal's use case from Lenny's Newsletter\n\n## Tips\n\n- Run from your git repository root\n- Specify date ranges for focused changelogs\n- Use your CHANGELOG_STYLE.md for consistent formatting\n- Review and adjust the generated changelog before publishing\n- Save output directly to CHANGELOG.md\n\n## Related Use Cases\n\n- Creating GitHub release notes\n- Writing app store update descriptions\n- Generating email updates for users\n- Creating social media announcement posts",
    "id": "changelog-generator",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/changelog-generator",
    "name_zh": "Êõ¥Êñ∞Êó•ÂøóÁîüÊàêÂô®",
    "description_zh": "Automatically creates user-facing changelogs from git commits by analyzing commit history, categorizing changes, and transforming technical commits into clear, customer-friendly release notes. Turns hours of manual changelog writing into minutes of automated generation.",
    "body_zh": "# Changelog Generator\n\nThis skill transforms technical git commits into polished, user-friendly changelogs that your customers and users will actually understand and appreciate.\n\n## When to Use This Skill\n\n- Preparing release notes for a new version\n- Creating weekly or monthly product update summaries\n- Documenting changes for customers\n- Writing changelog entries for app store submissions\n- Generating update notifications\n- Creating internal release documentation\n- Maintaining a public changelog/product updates page\n\n## What This Skill Does\n\n1. **Scans Git History**: Analyzes commits from a specific time period or between versions\n2. **Categorizes Changes**: Groups commits into logical categories (features, improvements, bug fixes, breaking changes, security)\n3. **Translates Technical ‚Üí User-Friendly**: Converts developer commits into customer language\n4. **Formats Professionally**: Creates clean, structured changelog entries\n5. **Filters Noise**: Excludes internal commits (refactoring, tests, etc.)\n6. **Follows Best Practices**: Applies changelog guidelines and your brand voice\n\n## How to Use\n\n### Basic Usage\n\nFrom your project repository:\n\n```\nCreate a changelog from commits since last release\n```\n\n```\nGenerate changelog for all commits from the past week\n```\n\n```\nCreate release notes for version 2.5.0\n```\n\n### With Specific Date Range\n\n```\nCreate a changelog for all commits between March 1 and March 15\n```\n\n### With Custom Guidelines\n\n```\nCreate a changelog for commits since v2.4.0, using my changelog \nguidelines from CHANGELOG_STYLE.md\n```\n\n## Example\n\n**User**: \"Create a changelog for commits from the past 7 days\"\n\n**Output**:\n```markdown\n# Updates - Week of March 10, 2024\n\n## ‚ú® New Features\n\n- **Team Workspaces**: Create separate workspaces for different \n  projects. Invite team members and keep everything organized.\n\n- **Keyboard Shortcuts**: Press ? to see all available shortcuts. \n  Navigate faster without touching your mouse.\n\n## üîß Improvements\n\n- **Faster Sync**: Files now sync 2x faster across devices\n- **Better Search**: Search now includes file contents, not just titles\n\n## üêõ Fixes\n\n- Fixed issue where large images wouldn't upload\n- Resolved timezone confusion in scheduled posts\n- Corrected notification badge count\n```\n\n**Inspired by:** Manik Aggarwal's use case from Lenny's Newsletter\n\n## Tips\n\n- Run from your git repository root\n- Specify date ranges for focused changelogs\n- Use your CHANGELOG_STYLE.md for consistent formatting\n- Review and adjust the generated changelog before publishing\n- Save output directly to CHANGELOG.md\n\n## Related Use Cases\n\n- Creating GitHub release notes\n- Writing app store update descriptions\n- Generating email updates for users\n- Creating social media announcement posts"
  },
  {
    "name": "code-documentation",
    "description": "Writing effective code documentation - API docs, README files, inline comments, and technical guides. Use for documenting codebases, APIs, or writing developer guides.",
    "body": "# Code Documentation\n\n## README Structure\n\n### Standard README Template\n```markdown\n# Project Name\n\nBrief description of what this project does.\n\n## Quick Start\n\n\\`\\`\\`bash\nnpm install\nnpm run dev\n\\`\\`\\`\n\n## Installation\n\nDetailed installation instructions...\n\n## Usage\n\n\\`\\`\\`typescript\nimport { something } from 'project';\n\n// Example usage\nconst result = something.doThing();\n\\`\\`\\`\n\n## API Reference\n\n### `functionName(param: Type): ReturnType`\n\nDescription of what the function does.\n\n**Parameters:**\n- `param` - Description of parameter\n\n**Returns:** Description of return value\n\n**Example:**\n\\`\\`\\`typescript\nconst result = functionName('value');\n\\`\\`\\`\n\n## Configuration\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `option1` | `string` | `'default'` | What it does |\n\n## Contributing\n\nHow to contribute...\n\n## License\n\nMIT\n```\n\n## API Documentation\n\n### JSDoc/TSDoc Style\n```typescript\n/**\n * Creates a new user account.\n *\n * @param userData - The user data for account creation\n * @param options - Optional configuration\n * @returns The created user object\n * @throws {ValidationError} If email is invalid\n * @example\n * ```ts\n * const user = await createUser({\n *   email: 'user@example.com',\n *   name: 'John'\n * });\n * ```\n */\nasync function createUser(\n  userData: UserInput,\n  options?: CreateOptions\n): Promise<User> {\n  // Implementation\n}\n\n/**\n * Configuration options for the API client.\n */\ninterface ClientConfig {\n  /** The API base URL */\n  baseUrl: string;\n  /** Request timeout in milliseconds @default 5000 */\n  timeout?: number;\n  /** Custom headers to include in requests */\n  headers?: Record<string, string>;\n}\n```\n\n### OpenAPI/Swagger\n```yaml\nopenapi: 3.0.0\ninfo:\n  title: My API\n  version: 1.0.0\n\npaths:\n  /users:\n    post:\n      summary: Create a user\n      description: Creates a new user account\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/UserInput'\n      responses:\n        '201':\n          description: User created successfully\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/User'\n        '400':\n          description: Invalid input\n\ncomponents:\n  schemas:\n    UserInput:\n      type: object\n      required:\n        - email\n        - name\n      properties:\n        email:\n          type: string\n          format: email\n        name:\n          type: string\n    User:\n      type: object\n      properties:\n        id:\n          type: string\n        email:\n          type: string\n        name:\n          type: string\n        createdAt:\n          type: string\n          format: date-time\n```\n\n## Inline Comments\n\n### When to Comment\n```typescript\n// GOOD: Explain WHY, not WHAT\n\n// Use binary search because the list is always sorted and\n// can contain millions of items - O(log n) vs O(n)\nconst index = binarySearch(items, target);\n\n// GOOD: Explain complex business logic\n// Users get 20% discount if they've been members for 2+ years\n// AND have made 10+ purchases (per marketing team decision Q4 2024)\nif (user.memberYears >= 2 && user.purchaseCount >= 10) {\n  applyDiscount(0.2);\n}\n\n// GOOD: Document workarounds\n// HACK: Safari doesn't support this API, fallback to polling\n// TODO: Remove when Safari adds support (tracking: webkit.org/b/12345)\nif (!window.IntersectionObserver) {\n  startPolling();\n}\n```\n\n### When NOT to Comment\n```typescript\n// BAD: Stating the obvious\n// Increment counter by 1\ncounter++;\n\n// BAD: Explaining clear code\n// Check if user is admin\nif (user.role === 'admin') { ... }\n\n// BAD: Outdated comments (worse than no comment)\n// Returns the user's full name  <-- Actually returns email now!\nfunction getUserIdentifier(user) {\n  return user.email;\n}\n```\n\n## Architecture Documentation\n\n### ADR (Architecture Decision Record)\n```markdown\n# ADR-001: Use PostgreSQL for Primary Database\n\n## Status\nAccepted\n\n## Context\nWe need a database for storing user data and transactions.\nOptions considered: PostgreSQL, MySQL, MongoDB, DynamoDB.\n\n## Decision\nUse PostgreSQL with Supabase hosting.\n\n## Rationale\n- Strong ACID compliance needed for financial data\n- Team has PostgreSQL experience\n- Supabase provides auth and realtime features\n- pgvector extension for future AI features\n\n## Consequences\n- Need to manage schema migrations\n- May need read replicas for scale\n- Team needs to learn Supabase-specific features\n```\n\n### Component Documentation\n```markdown\n## Authentication Module\n\n### Overview\nHandles user authentication using JWT tokens with refresh rotation.\n\n### Flow\n1. User submits credentials to `/auth/login`\n2. Server validates and returns access + refresh tokens\n3. Access token used for API requests (15min expiry)\n4. Refresh token used to get new access token (7d expiry)\n\n### Dependencies\n- `jsonwebtoken` - Token generation/validation\n- `bcrypt` - Password hashing\n- `redis` - Refresh token storage\n\n### Configuration\n- `JWT_SECRET` - Secret for signing tokens\n- `ACCESS_TOKEN_EXPIRY` - Access token lifetime\n- `REFRESH_TOKEN_EXPIRY` - Refresh token lifetime\n```\n\n## Documentation Principles\n\n1. **Write for your audience** - New devs vs API consumers\n2. **Keep it close to code** - Docs in same repo, near relevant code\n3. **Update with code** - Stale docs are worse than none\n4. **Examples over explanations** - Show, don't just tell\n5. **Progressive disclosure** - Quick start first, details later",
    "id": "code-documentation",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/code-documentation",
    "name_zh": "‰ª£Á†ÅÊñáÊ°£",
    "description_zh": "Writing effective code documentation - API docs, README files, inline comments, and technical guides. Use for documenting codebases, APIs, or writing developer guides.",
    "body_zh": "# Code Documentation\n\n## README Structure\n\n### Standard README Template\n```markdown\n# Project Name\n\nBrief description of what this project does.\n\n## Quick Start\n\n\\`\\`\\`bash\nnpm install\nnpm run dev\n\\`\\`\\`\n\n## Installation\n\nDetailed installation instructions...\n\n## Usage\n\n\\`\\`\\`typescript\nimport { something } from 'project';\n\n// Example usage\nconst result = something.doThing();\n\\`\\`\\`\n\n## API Reference\n\n### `functionName(param: Type): ReturnType`\n\nDescription of what the function does.\n\n**Parameters:**\n- `param` - Description of parameter\n\n**Returns:** Description of return value\n\n**Example:**\n\\`\\`\\`typescript\nconst result = functionName('value');\n\\`\\`\\`\n\n## Configuration\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `option1` | `string` | `'default'` | What it does |\n\n## Contributing\n\nHow to contribute...\n\n## License\n\nMIT\n```\n\n## API Documentation\n\n### JSDoc/TSDoc Style\n```typescript\n/**\n * Creates a new user account.\n *\n * @param userData - The user data for account creation\n * @param options - Optional configuration\n * @returns The created user object\n * @throws {ValidationError} If email is invalid\n * @example\n * ```ts\n * const user = await createUser({\n *   email: 'user@example.com',\n *   name: 'John'\n * });\n * ```\n */\nasync function createUser(\n  userData: UserInput,\n  options?: CreateOptions\n): Promise<User> {\n  // Implementation\n}\n\n/**\n * Configuration options for the API client.\n */\ninterface ClientConfig {\n  /** The API base URL */\n  baseUrl: string;\n  /** Request timeout in milliseconds @default 5000 */\n  timeout?: number;\n  /** Custom headers to include in requests */\n  headers?: Record<string, string>;\n}\n```\n\n### OpenAPI/Swagger\n```yaml\nopenapi: 3.0.0\ninfo:\n  title: My API\n  version: 1.0.0\n\npaths:\n  /users:\n    post:\n      summary: Create a user\n      description: Creates a new user account\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/UserInput'\n      responses:\n        '201':\n          description: User created successfully\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/User'\n        '400':\n          description: Invalid input\n\ncomponents:\n  schemas:\n    UserInput:\n      type: object\n      required:\n        - email\n        - name\n      properties:\n        email:\n          type: string\n          format: email\n        name:\n          type: string\n    User:\n      type: object\n      properties:\n        id:\n          type: string\n        email:\n          type: string\n        name:\n          type: string\n        createdAt:\n          type: string\n          format: date-time\n```\n\n## Inline Comments\n\n### When to Comment\n```typescript\n// GOOD: Explain WHY, not WHAT\n\n// Use binary search because the list is always sorted and\n// can contain millions of items - O(log n) vs O(n)\nconst index = binarySearch(items, target);\n\n// GOOD: Explain complex business logic\n// Users get 20% discount if they've been members for 2+ years\n// AND have made 10+ purchases (per marketing team decision Q4 2024)\nif (user.memberYears >= 2 && user.purchaseCount >= 10) {\n  applyDiscount(0.2);\n}\n\n// GOOD: Document workarounds\n// HACK: Safari doesn't support this API, fallback to polling\n// TODO: Remove when Safari adds support (tracking: webkit.org/b/12345)\nif (!window.IntersectionObserver) {\n  startPolling();\n}\n```\n\n### When NOT to Comment\n```typescript\n// BAD: Stating the obvious\n// Increment counter by 1\ncounter++;\n\n// BAD: Explaining clear code\n// Check if user is admin\nif (user.role === 'admin') { ... }\n\n// BAD: Outdated comments (worse than no comment)\n// Returns the user's full name  <-- Actually returns email now!\nfunction getUserIdentifier(user) {\n  return user.email;\n}\n```\n\n## Architecture Documentation\n\n### ADR (Architecture Decision Record)\n```markdown\n# ADR-001: Use PostgreSQL for Primary Database\n\n## Status\nAccepted\n\n## Context\nWe need a database for storing user data and transactions.\nOptions considered: PostgreSQL, MySQL, MongoDB, DynamoDB.\n\n## Decision\nUse PostgreSQL with Supabase hosting.\n\n## Rationale\n- Strong ACID compliance needed for financial data\n- Team has PostgreSQL experience\n- Supabase provides auth and realtime features\n- pgvector extension for future AI features\n\n## Consequences\n- Need to manage schema migrations\n- May need read replicas for scale\n- Team needs to learn Supabase-specific features\n```\n\n### Component Documentation\n```markdown\n## Authentication Module\n\n### Overview\nHandles user authentication using JWT tokens with refresh rotation.\n\n### Flow\n1. User submits credentials to `/auth/login`\n2. Server validates and returns access + refresh tokens\n3. Access token used for API requests (15min expiry)\n4. Refresh token used to get new access token (7d expiry)\n\n### Dependencies\n- `jsonwebtoken` - Token generation/validation\n- `bcrypt` - Password hashing\n- `redis` - Refresh token storage\n\n### Configuration\n- `JWT_SECRET` - Secret for signing tokens\n- `ACCESS_TOKEN_EXPIRY` - Access token lifetime\n- `REFRESH_TOKEN_EXPIRY` - Refresh token lifetime\n```\n\n## Documentation Principles\n\n1. **Write for your audience** - New devs vs API consumers\n2. **Keep it close to code** - Docs in same repo, near relevant code\n3. **Update with code** - Stale docs are worse than none\n4. **Examples over explanations** - Show, don't just tell\n5. **Progressive disclosure** - Quick start first, details later"
  },
  {
    "name": "code-refactoring",
    "description": "Code refactoring patterns and techniques for improving code quality without changing behavior. Use for cleaning up legacy code, reducing complexity, or improving maintainability.",
    "body": "# Code Refactoring\n\n## Refactoring Principles\n\n### When to Refactor\n- Before adding new features (make change easy, then make easy change)\n- After getting tests passing (red-green-refactor)\n- When you see code smells\n- During code review feedback\n\n### When NOT to Refactor\n- Without tests covering the code\n- Under tight deadlines with no safety net\n- Code that will be replaced soon\n- When you don't understand what the code does\n\n## Common Code Smells\n\n### Long Methods\n```typescript\n// BEFORE: Method doing too much\nfunction processOrder(order: Order) {\n  // 100 lines of validation, calculation, notification, logging...\n}\n\n// AFTER: Extract into focused methods\nfunction processOrder(order: Order) {\n  validateOrder(order);\n  const total = calculateTotal(order);\n  saveOrder(order, total);\n  notifyCustomer(order);\n}\n```\n\n### Deeply Nested Conditionals\n```typescript\n// BEFORE: Arrow code\nfunction getDiscount(user: User, order: Order) {\n  if (user) {\n    if (user.isPremium) {\n      if (order.total > 100) {\n        if (order.items.length > 5) {\n          return 0.2;\n        }\n      }\n    }\n  }\n  return 0;\n}\n\n// AFTER: Early returns (guard clauses)\nfunction getDiscount(user: User, order: Order) {\n  if (!user) return 0;\n  if (!user.isPremium) return 0;\n  if (order.total <= 100) return 0;\n  if (order.items.length <= 5) return 0;\n  return 0.2;\n}\n```\n\n### Primitive Obsession\n```typescript\n// BEFORE: Primitives everywhere\nfunction createUser(name: string, email: string, phone: string) {\n  if (!email.includes('@')) throw new Error('Invalid email');\n  // more validation...\n}\n\n// AFTER: Value objects\nclass Email {\n  constructor(private value: string) {\n    if (!value.includes('@')) throw new Error('Invalid email');\n  }\n  toString() { return this.value; }\n}\n\nfunction createUser(name: string, email: Email, phone: Phone) {\n  // Email is already validated\n}\n```\n\n### Feature Envy\n```typescript\n// BEFORE: Method uses another object's data extensively\nfunction calculateShipping(order: Order) {\n  const address = order.customer.address;\n  const weight = order.items.reduce((sum, i) => sum + i.weight, 0);\n  const distance = calculateDistance(address.zip);\n  return weight * distance * 0.01;\n}\n\n// AFTER: Move method to where the data is\nclass Order {\n  calculateShipping() {\n    return this.totalWeight * this.customer.shippingDistance * 0.01;\n  }\n}\n```\n\n## Refactoring Techniques\n\n### Extract Method\n```typescript\n// Identify a code block that does one thing\n// Move it to a new method with a descriptive name\n// Replace original code with method call\n\nfunction printReport(data: ReportData) {\n  // Extract this block...\n  const header = `Report: ${data.title}\\nDate: ${data.date}\\n${'='.repeat(40)}`;\n  console.log(header);\n\n  // ...into a method\n  printHeader(data);\n}\n```\n\n### Replace Conditional with Polymorphism\n```typescript\n// BEFORE: Switch on type\nfunction getArea(shape: Shape) {\n  switch (shape.type) {\n    case 'circle': return Math.PI * shape.radius ** 2;\n    case 'rectangle': return shape.width * shape.height;\n    case 'triangle': return shape.base * shape.height / 2;\n  }\n}\n\n// AFTER: Polymorphic classes\ninterface Shape {\n  getArea(): number;\n}\n\nclass Circle implements Shape {\n  constructor(private radius: number) {}\n  getArea() { return Math.PI * this.radius ** 2; }\n}\n\nclass Rectangle implements Shape {\n  constructor(private width: number, private height: number) {}\n  getArea() { return this.width * this.height; }\n}\n```\n\n### Introduce Parameter Object\n```typescript\n// BEFORE: Too many parameters\nfunction searchProducts(\n  query: string,\n  minPrice: number,\n  maxPrice: number,\n  category: string,\n  inStock: boolean,\n  sortBy: string,\n  sortOrder: string\n) { ... }\n\n// AFTER: Parameter object\ninterface SearchParams {\n  query: string;\n  priceRange: { min: number; max: number };\n  category?: string;\n  inStock?: boolean;\n  sort?: { by: string; order: 'asc' | 'desc' };\n}\n\nfunction searchProducts(params: SearchParams) { ... }\n```\n\n### Replace Magic Numbers with Constants\n```typescript\n// BEFORE\nif (user.age >= 18 && order.total >= 50) {\n  applyDiscount(order, 0.1);\n}\n\n// AFTER\nconst MINIMUM_AGE = 18;\nconst DISCOUNT_THRESHOLD = 50;\nconst STANDARD_DISCOUNT = 0.1;\n\nif (user.age >= MINIMUM_AGE && order.total >= DISCOUNT_THRESHOLD) {\n  applyDiscount(order, STANDARD_DISCOUNT);\n}\n```\n\n## Safe Refactoring Process\n\n1. **Ensure tests exist** - Write tests if they don't\n2. **Make small changes** - One refactoring at a time\n3. **Run tests after each change** - Catch regressions immediately\n4. **Commit frequently** - Easy to revert if something breaks\n5. **Review the diff** - Make sure behavior hasn't changed\n\n## Refactoring Checklist\n\n- [ ] Tests pass before starting\n- [ ] Each change is small and focused\n- [ ] Tests pass after each change\n- [ ] No behavior changes (only structure)\n- [ ] Code is more readable than before\n- [ ] Commit message explains the refactoring",
    "id": "code-refactoring",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/code-refactoring",
    "name_zh": "‰ª£Á†ÅÈáçÊûÑ",
    "description_zh": "Code refactoring patterns and techniques for improving code quality without changing behavior. Use for cleaning up legacy code, reducing complexity, or improving maintainability.",
    "body_zh": "# Code Refactoring\n\n## Refactoring Principles\n\n### When to Refactor\n- Before adding new features (make change easy, then make easy change)\n- After getting tests passing (red-green-refactor)\n- When you see code smells\n- During code review feedback\n\n### When NOT to Refactor\n- Without tests covering the code\n- Under tight deadlines with no safety net\n- Code that will be replaced soon\n- When you don't understand what the code does\n\n## Common Code Smells\n\n### Long Methods\n```typescript\n// BEFORE: Method doing too much\nfunction processOrder(order: Order) {\n  // 100 lines of validation, calculation, notification, logging...\n}\n\n// AFTER: Extract into focused methods\nfunction processOrder(order: Order) {\n  validateOrder(order);\n  const total = calculateTotal(order);\n  saveOrder(order, total);\n  notifyCustomer(order);\n}\n```\n\n### Deeply Nested Conditionals\n```typescript\n// BEFORE: Arrow code\nfunction getDiscount(user: User, order: Order) {\n  if (user) {\n    if (user.isPremium) {\n      if (order.total > 100) {\n        if (order.items.length > 5) {\n          return 0.2;\n        }\n      }\n    }\n  }\n  return 0;\n}\n\n// AFTER: Early returns (guard clauses)\nfunction getDiscount(user: User, order: Order) {\n  if (!user) return 0;\n  if (!user.isPremium) return 0;\n  if (order.total <= 100) return 0;\n  if (order.items.length <= 5) return 0;\n  return 0.2;\n}\n```\n\n### Primitive Obsession\n```typescript\n// BEFORE: Primitives everywhere\nfunction createUser(name: string, email: string, phone: string) {\n  if (!email.includes('@')) throw new Error('Invalid email');\n  // more validation...\n}\n\n// AFTER: Value objects\nclass Email {\n  constructor(private value: string) {\n    if (!value.includes('@')) throw new Error('Invalid email');\n  }\n  toString() { return this.value; }\n}\n\nfunction createUser(name: string, email: Email, phone: Phone) {\n  // Email is already validated\n}\n```\n\n### Feature Envy\n```typescript\n// BEFORE: Method uses another object's data extensively\nfunction calculateShipping(order: Order) {\n  const address = order.customer.address;\n  const weight = order.items.reduce((sum, i) => sum + i.weight, 0);\n  const distance = calculateDistance(address.zip);\n  return weight * distance * 0.01;\n}\n\n// AFTER: Move method to where the data is\nclass Order {\n  calculateShipping() {\n    return this.totalWeight * this.customer.shippingDistance * 0.01;\n  }\n}\n```\n\n## Refactoring Techniques\n\n### Extract Method\n```typescript\n// Identify a code block that does one thing\n// Move it to a new method with a descriptive name\n// Replace original code with method call\n\nfunction printReport(data: ReportData) {\n  // Extract this block...\n  const header = `Report: ${data.title}\\nDate: ${data.date}\\n${'='.repeat(40)}`;\n  console.log(header);\n\n  // ...into a method\n  printHeader(data);\n}\n```\n\n### Replace Conditional with Polymorphism\n```typescript\n// BEFORE: Switch on type\nfunction getArea(shape: Shape) {\n  switch (shape.type) {\n    case 'circle': return Math.PI * shape.radius ** 2;\n    case 'rectangle': return shape.width * shape.height;\n    case 'triangle': return shape.base * shape.height / 2;\n  }\n}\n\n// AFTER: Polymorphic classes\ninterface Shape {\n  getArea(): number;\n}\n\nclass Circle implements Shape {\n  constructor(private radius: number) {}\n  getArea() { return Math.PI * this.radius ** 2; }\n}\n\nclass Rectangle implements Shape {\n  constructor(private width: number, private height: number) {}\n  getArea() { return this.width * this.height; }\n}\n```\n\n### Introduce Parameter Object\n```typescript\n// BEFORE: Too many parameters\nfunction searchProducts(\n  query: string,\n  minPrice: number,\n  maxPrice: number,\n  category: string,\n  inStock: boolean,\n  sortBy: string,\n  sortOrder: string\n) { ... }\n\n// AFTER: Parameter object\ninterface SearchParams {\n  query: string;\n  priceRange: { min: number; max: number };\n  category?: string;\n  inStock?: boolean;\n  sort?: { by: string; order: 'asc' | 'desc' };\n}\n\nfunction searchProducts(params: SearchParams) { ... }\n```\n\n### Replace Magic Numbers with Constants\n```typescript\n// BEFORE\nif (user.age >= 18 && order.total >= 50) {\n  applyDiscount(order, 0.1);\n}\n\n// AFTER\nconst MINIMUM_AGE = 18;\nconst DISCOUNT_THRESHOLD = 50;\nconst STANDARD_DISCOUNT = 0.1;\n\nif (user.age >= MINIMUM_AGE && order.total >= DISCOUNT_THRESHOLD) {\n  applyDiscount(order, STANDARD_DISCOUNT);\n}\n```\n\n## Safe Refactoring Process\n\n1. **Ensure tests exist** - Write tests if they don't\n2. **Make small changes** - One refactoring at a time\n3. **Run tests after each change** - Catch regressions immediately\n4. **Commit frequently** - Easy to revert if something breaks\n5. **Review the diff** - Make sure behavior hasn't changed\n\n## Refactoring Checklist\n\n- [ ] Tests pass before starting\n- [ ] Each change is small and focused\n- [ ] Tests pass after each change\n- [ ] No behavior changes (only structure)\n- [ ] Code is more readable than before\n- [ ] Commit message explains the refactoring"
  },
  {
    "name": "code-review",
    "description": "Automated code review for pull requests using specialized review patterns. Analyzes code for quality, security, performance, and best practices. Use when reviewing code changes, PRs, or doing code audits.",
    "body": "# Code Review\n\n## Review Categories\n\n### 1. Security Review\nCheck for:\n- SQL injection vulnerabilities\n- XSS (Cross-Site Scripting)\n- Command injection\n- Insecure deserialization\n- Hardcoded secrets/credentials\n- Improper authentication/authorization\n- Insecure direct object references\n\n### 2. Performance Review\nCheck for:\n- N+1 queries\n- Missing database indexes\n- Unnecessary re-renders (React)\n- Memory leaks\n- Blocking operations in async code\n- Missing caching opportunities\n- Large bundle sizes\n\n### 3. Code Quality Review\nCheck for:\n- Code duplication (DRY violations)\n- Functions doing too much (SRP violations)\n- Deep nesting / complex conditionals\n- Magic numbers/strings\n- Poor naming\n- Missing error handling\n- Incomplete type coverage\n\n### 4. Testing Review\nCheck for:\n- Missing test coverage for new code\n- Tests that don't test behavior\n- Flaky test patterns\n- Missing edge cases\n- Mocked external dependencies\n\n## Review Output Format\n\n```markdown\n## Code Review Summary\n\n### üî¥ Critical (Must Fix)\n- **[File:Line]** [Issue description]\n  - **Why:** [Explanation]\n  - **Fix:** [Suggested fix]\n\n### üü° Suggestions (Should Consider)\n- **[File:Line]** [Issue description]\n  - **Why:** [Explanation]\n  - **Fix:** [Suggested fix]\n\n### üü¢ Nits (Optional)\n- **[File:Line]** [Minor suggestion]\n\n### ‚úÖ What's Good\n- [Positive feedback on good patterns]\n```\n\n## Common Patterns to Flag\n\n### Security\n```javascript\n// BAD: SQL injection\nconst query = `SELECT * FROM users WHERE id = ${userId}`;\n\n// GOOD: Parameterized query\nconst query = 'SELECT * FROM users WHERE id = $1';\nawait db.query(query, [userId]);\n```\n\n### Performance\n```javascript\n// BAD: N+1 query\nusers.forEach(async user => {\n  const posts = await getPosts(user.id);\n});\n\n// GOOD: Batch query\nconst userIds = users.map(u => u.id);\nconst posts = await getPostsForUsers(userIds);\n```\n\n### Error Handling\n```javascript\n// BAD: Swallowing errors\ntry {\n  await riskyOperation();\n} catch (e) {}\n\n// GOOD: Handle or propagate\ntry {\n  await riskyOperation();\n} catch (e) {\n  logger.error('Operation failed', { error: e });\n  throw new AppError('Operation failed', { cause: e });\n}\n```\n\n## Review Checklist\n\n- [ ] No hardcoded secrets\n- [ ] Input validation present\n- [ ] Error handling complete\n- [ ] Types/interfaces defined\n- [ ] Tests added for new code\n- [ ] No obvious performance issues\n- [ ] Code is readable and documented\n- [ ] Breaking changes documented",
    "id": "code-review",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/code-review",
    "name_zh": "‰ª£Á†ÅÂÆ°Êü•",
    "description_zh": "Ëá™Âä®Âåñd code review for pull requests using specialized review patterns. Analyzes code for quality, security, performance, and best practices. ÈÄÇÁî®‰∫é reviewing code changes, PRs, or doing code audits.",
    "body_zh": "# Code Review\n\n## Review Categories\n\n### 1. Security Review\nCheck for:\n- SQL injection vulnerabilities\n- XSS (Cross-Site Scripting)\n- Command injection\n- Insecure deserialization\n- Hardcoded secrets/credentials\n- Improper authentication/authorization\n- Insecure direct object references\n\n### 2. Performance Review\nCheck for:\n- N+1 queries\n- Missing database indexes\n- Unnecessary re-renders (React)\n- Memory leaks\n- Blocking operations in async code\n- Missing caching opportunities\n- Large bundle sizes\n\n### 3. Code Quality Review\nCheck for:\n- Code duplication (DRY violations)\n- Functions doing too much (SRP violations)\n- Deep nesting / complex conditionals\n- Magic numbers/strings\n- Poor naming\n- Missing error handling\n- Incomplete type coverage\n\n### 4. Testing Review\nCheck for:\n- Missing test coverage for new code\n- Tests that don't test behavior\n- Flaky test patterns\n- Missing edge cases\n- Mocked external dependencies\n\n## Review Output Format\n\n```markdown\n## Code Review Summary\n\n### üî¥ Critical (Must Fix)\n- **[File:Line]** [Issue description]\n  - **Why:** [Explanation]\n  - **Fix:** [Suggested fix]\n\n### üü° Suggestions (Should Consider)\n- **[File:Line]** [Issue description]\n  - **Why:** [Explanation]\n  - **Fix:** [Suggested fix]\n\n### üü¢ Nits (Optional)\n- **[File:Line]** [Minor suggestion]\n\n### ‚úÖ What's Good\n- [Positive feedback on good patterns]\n```\n\n## Common Patterns to Flag\n\n### Security\n```javascript\n// BAD: SQL injection\nconst query = `SELECT * FROM users WHERE id = ${userId}`;\n\n// GOOD: Parameterized query\nconst query = 'SELECT * FROM users WHERE id = $1';\nawait db.query(query, [userId]);\n```\n\n### Performance\n```javascript\n// BAD: N+1 query\nusers.forEach(async user => {\n  const posts = await getPosts(user.id);\n});\n\n// GOOD: Batch query\nconst userIds = users.map(u => u.id);\nconst posts = await getPostsForUsers(userIds);\n```\n\n### Error Handling\n```javascript\n// BAD: Swallowing errors\ntry {\n  await riskyOperation();\n} catch (e) {}\n\n// GOOD: Handle or propagate\ntry {\n  await riskyOperation();\n} catch (e) {\n  logger.error('Operation failed', { error: e });\n  throw new AppError('Operation failed', { cause: e });\n}\n```\n\n## Review Checklist\n\n- [ ] No hardcoded secrets\n- [ ] Input validation present\n- [ ] Error handling complete\n- [ ] Types/interfaces defined\n- [ ] Tests added for new code\n- [ ] No obvious performance issues\n- [ ] Code is readable and documented\n- [ ] Breaking changes documented"
  },
  {
    "name": "competitive-ads-extractor",
    "description": "Extracts and analyzes competitors' ads from ad libraries (Facebook, LinkedIn, etc.) to understand what messaging, problems, and creative approaches are working. Helps inspire and improve your own ad campaigns.",
    "body": "# Competitive Ads Extractor\n\nThis skill extracts your competitors' ads from ad libraries and analyzes what's working‚Äîthe problems they're highlighting, use cases they're targeting, and copy/creative that's resonating.\n\n## When to Use This Skill\n\n- Researching competitor ad strategies\n- Finding inspiration for your own ads\n- Understanding market positioning\n- Identifying successful ad patterns\n- Analyzing messaging that works\n- Discovering new use cases or pain points\n- Planning ad campaigns with proven concepts\n\n## What This Skill Does\n\n1. **Extracts Ads**: Scrapes ads from Facebook Ad Library, LinkedIn, etc.\n2. **Captures Screenshots**: Saves visual copies of all ads\n3. **Analyzes Messaging**: Identifies problems, use cases, and value props\n4. **Categorizes Ads**: Groups by theme, audience, or format\n5. **Identifies Patterns**: Finds common successful approaches\n6. **Provides Insights**: Explains why certain ads likely perform well\n\n## How to Use\n\n### Basic Extraction\n\n```\nExtract all current ads from [Competitor Name] on Facebook Ad Library\n```\n\n```\nScrape ads from [Company] and analyze their messaging\n```\n\n### Specific Analysis\n\n```\nGet all ads from [Competitor] focusing on their messaging \nabout [specific problem]. What pain points are they highlighting?\n```\n\n### Competitive Set\n\n```\nExtract ads from these 5 competitors: [list]. \nCompare their approaches and tell me what's working.\n```\n\n### Specific Platform\n\n```\nGet LinkedIn ads from [Competitor] and analyze their \nB2B positioning strategy\n```\n\n## Example\n\n**User**: \"Extract ads from Notion on Facebook Ad Library and tell me what messaging is working for them.\"\n\n**Process**:\n```\nAccessing Facebook Ad Library...\nSearching for: Notion\nFound: 23 active ads\n\nExtracting screenshots...\n[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%\n\nSaved to: competitor-ads/notion/\n- ad-001-collaboration.png\n- ad-002-productivity.png\n- ad-003-templates.png\n...\n\nAnalyzing messaging...\n```\n\n**Output**:\n```\n# Notion Ad Analysis\n\n## Overview\n- Total Ads: 23 active\n- Primary Themes: Productivity (35%), Collaboration (30%), \n  Templates (20%), AI Features (15%)\n- Ad Formats: Static images (60%), Video (40%)\n- CTA Patterns: \"Try for free\", \"Get started\"\n\n## Key Problems They're Highlighting\n\n1. **Scattered Information** (8 ads)\n   Copy: \"Stop switching between 10 different tools\"\n   Why it works: Direct pain point many teams face\n\n2. **Meeting Overload** (5 ads)\n   Copy: \"Replace unnecessary meetings with async updates\"\n   Why it works: Post-COVID remote work pain point\n\n3. **Lost Documentation** (4 ads)\n   Copy: \"Never ask 'where is that doc?' again\"\n   Why it works: Universal workplace frustration\n\n## Successful Creative Patterns\n\n### Pattern 1: Before/After Split\n- Shows chaotic tool landscape ‚Üí Clean Notion workspace\n- Used in 6 high-performing ads\n- Visual metaphor is immediately clear\n\n### Pattern 2: Feature Showcase\n- GIF of actual product usage\n- Shows specific feature in 5 seconds\n- Used for new features (AI, templates)\n\n### Pattern 3: Social Proof\n- \"Join 20M users\" messaging\n- Customer logos\n- Used in 4 ads targeting enterprise\n\n## Copy That's Working\n\nBest Headlines:\n1. \"Your team's knowledge, finally in one place\"\n   ‚Üí Benefit-focused, addresses pain directly\n   \n2. \"The all-in-one workspace\"\n   ‚Üí Clear positioning, broad appeal\n   \n3. \"AI that actually helps you work\"\n   ‚Üí Addresses AI skepticism, practical angle\n\nBest Body Copy Patterns:\n- Short sentences (under 10 words)\n- Focus on outcomes not features\n- Include specific numbers (\"Cut meetings by 50%\")\n\n## Audience Targeting Insights\n\nBased on ad variations:\n- Startup founders: Solo productivity angle\n- Team leads: Collaboration and alignment\n- Enterprise: Security and compliance mentions\n- Students: Free plan, templates, organization\n\n## Recommendations for Your Ads\n\n1. **Test the \"tool sprawl\" pain point**\n   ‚Üí Strong resonance based on their ad frequency\n\n2. **Use product screenshots over abstract visuals**\n   ‚Üí All their top ads show actual UI\n\n3. **Lead with the problem, not the solution**\n   ‚Üí \"Tired of X?\" performs better than \"Introducing Y\"\n\n4. **Keep copy under 100 characters**\n   ‚Üí Their shortest ads seem most frequent\n\n5. **Test before/after visual formats**\n   ‚Üí Proven pattern in their creative\n\n## Files Saved\n- All ads: ~/competitor-ads/notion/\n- Analysis: ~/competitor-ads/notion/analysis.md\n- Best performers: ~/competitor-ads/notion/top-10/\n```\n\n**Inspired by:** Sumant Subrahmanya's use case from Lenny's Newsletter\n\n## What You Can Learn\n\n### Messaging Analysis\n- What problems they emphasize\n- How they position against competition\n- Value propositions that resonate\n- Target audience segments\n\n### Creative Patterns\n- Visual styles that work\n- Video vs. static image performance\n- Color schemes and branding\n- Layout patterns\n\n### Copy Formulas\n- Headline structures\n- Call-to-action patterns\n- Length and tone\n- Emotional triggers\n\n### Campaign Strategy\n- Seasonal campaigns\n- Product launch approaches\n- Feature announcement tactics\n- Retargeting patterns\n\n## Best Practices\n\n### Legal & Ethical\n‚úì Only use for research and inspiration\n‚úì Don't copy ads directly\n‚úì Respect intellectual property\n‚úì Use insights to inform original creative\n‚úó Don't plagiarize copy or steal designs\n\n### Analysis Tips\n1. **Look for patterns**: What themes repeat?\n2. **Track over time**: Save ads monthly to see evolution\n3. **Test hypotheses**: Adapt successful patterns for your brand\n4. **Segment by audience**: Different messages for different targets\n5. **Compare platforms**: LinkedIn vs Facebook messaging differs\n\n## Advanced Features\n\n### Trend Tracking\n```\nCompare [Competitor]'s ads from Q1 vs Q2. \nWhat messaging has changed?\n```\n\n### Multi-Competitor Analysis\n```\nExtract ads from [Company A], [Company B], [Company C]. \nWhat are the common patterns? Where do they differ?\n```\n\n### Industry Benchmarks\n```\nShow me ad patterns across the top 10 project management \ntools. What problems do they all focus on?\n```\n\n### Format Analysis\n```\nAnalyze video ads vs static image ads from [Competitor]. \nWhich gets more engagement? (if data available)\n```\n\n## Common Workflows\n\n### Ad Campaign Planning\n1. Extract competitor ads\n2. Identify successful patterns\n3. Note gaps in their messaging\n4. Brainstorm unique angles\n5. Draft test ad variations\n\n### Positioning Research\n1. Get ads from 5 competitors\n2. Map their positioning\n3. Find underserved angles\n4. Develop differentiated messaging\n5. Test against their approaches\n\n### Creative Inspiration\n1. Extract ads by theme\n2. Analyze visual patterns\n3. Note color and layout trends\n4. Adapt successful patterns\n5. Create original variations\n\n## Tips for Success\n\n1. **Regular Monitoring**: Check monthly for changes\n2. **Broad Research**: Look at adjacent competitors too\n3. **Save Everything**: Build a reference library\n4. **Test Insights**: Run your own experiments\n5. **Track Performance**: A/B test inspired concepts\n6. **Stay Original**: Use for inspiration, not copying\n7. **Multiple Platforms**: Compare Facebook, LinkedIn, TikTok, etc.\n\n## Output Formats\n\n- **Screenshots**: All ads saved as images\n- **Analysis Report**: Markdown summary of insights\n- **Spreadsheet**: CSV with ad copy, CTAs, themes\n- **Presentation**: Visual deck of top performers\n- **Pattern Library**: Categorized by approach\n\n## Related Use Cases\n\n- Writing better ad copy for your campaigns\n- Understanding market positioning\n- Finding content gaps in your messaging\n- Discovering new use cases for your product\n- Planning product marketing strategy\n- Inspiring social media content",
    "id": "competitive-ads-extractor",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/competitive-ads-extractor",
    "name_zh": "Á´ûÂìÅÂπøÂëäÊèêÂèñÂô®",
    "description_zh": "Extracts and analyzes competitors' ads from ad libraries (Facebook, LinkedIn, etc.) to understand what messaging, problems, and creative approaches are working. Helps inspire and improve your own ad campaigns.",
    "body_zh": "# Competitive Ads Extractor\n\nThis skill extracts your competitors' ads from ad libraries and analyzes what's working‚Äîthe problems they're highlighting, use cases they're targeting, and copy/creative that's resonating.\n\n## When to Use This Skill\n\n- Researching competitor ad strategies\n- Finding inspiration for your own ads\n- Understanding market positioning\n- Identifying successful ad patterns\n- Analyzing messaging that works\n- Discovering new use cases or pain points\n- Planning ad campaigns with proven concepts\n\n## What This Skill Does\n\n1. **Extracts Ads**: Scrapes ads from Facebook Ad Library, LinkedIn, etc.\n2. **Captures Screenshots**: Saves visual copies of all ads\n3. **Analyzes Messaging**: Identifies problems, use cases, and value props\n4. **Categorizes Ads**: Groups by theme, audience, or format\n5. **Identifies Patterns**: Finds common successful approaches\n6. **Provides Insights**: Explains why certain ads likely perform well\n\n## How to Use\n\n### Basic Extraction\n\n```\nExtract all current ads from [Competitor Name] on Facebook Ad Library\n```\n\n```\nScrape ads from [Company] and analyze their messaging\n```\n\n### Specific Analysis\n\n```\nGet all ads from [Competitor] focusing on their messaging \nabout [specific problem]. What pain points are they highlighting?\n```\n\n### Competitive Set\n\n```\nExtract ads from these 5 competitors: [list]. \nCompare their approaches and tell me what's working.\n```\n\n### Specific Platform\n\n```\nGet LinkedIn ads from [Competitor] and analyze their \nB2B positioning strategy\n```\n\n## Example\n\n**User**: \"Extract ads from Notion on Facebook Ad Library and tell me what messaging is working for them.\"\n\n**Process**:\n```\nAccessing Facebook Ad Library...\nSearching for: Notion\nFound: 23 active ads\n\nExtracting screenshots...\n[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%\n\nSaved to: competitor-ads/notion/\n- ad-001-collaboration.png\n- ad-002-productivity.png\n- ad-003-templates.png\n...\n\nAnalyzing messaging...\n```\n\n**Output**:\n```\n# Notion Ad Analysis\n\n## Overview\n- Total Ads: 23 active\n- Primary Themes: Productivity (35%), Collaboration (30%), \n  Templates (20%), AI Features (15%)\n- Ad Formats: Static images (60%), Video (40%)\n- CTA Patterns: \"Try for free\", \"Get started\"\n\n## Key Problems They're Highlighting\n\n1. **Scattered Information** (8 ads)\n   Copy: \"Stop switching between 10 different tools\"\n   Why it works: Direct pain point many teams face\n\n2. **Meeting Overload** (5 ads)\n   Copy: \"Replace unnecessary meetings with async updates\"\n   Why it works: Post-COVID remote work pain point\n\n3. **Lost Documentation** (4 ads)\n   Copy: \"Never ask 'where is that doc?' again\"\n   Why it works: Universal workplace frustration\n\n## Successful Creative Patterns\n\n### Pattern 1: Before/After Split\n- Shows chaotic tool landscape ‚Üí Clean Notion workspace\n- Used in 6 high-performing ads\n- Visual metaphor is immediately clear\n\n### Pattern 2: Feature Showcase\n- GIF of actual product usage\n- Shows specific feature in 5 seconds\n- Used for new features (AI, templates)\n\n### Pattern 3: Social Proof\n- \"Join 20M users\" messaging\n- Customer logos\n- Used in 4 ads targeting enterprise\n\n## Copy That's Working\n\nBest Headlines:\n1. \"Your team's knowledge, finally in one place\"\n   ‚Üí Benefit-focused, addresses pain directly\n   \n2. \"The all-in-one workspace\"\n   ‚Üí Clear positioning, broad appeal\n   \n3. \"AI that actually helps you work\"\n   ‚Üí Addresses AI skepticism, practical angle\n\nBest Body Copy Patterns:\n- Short sentences (under 10 words)\n- Focus on outcomes not features\n- Include specific numbers (\"Cut meetings by 50%\")\n\n## Audience Targeting Insights\n\nBased on ad variations:\n- Startup founders: Solo productivity angle\n- Team leads: Collaboration and alignment\n- Enterprise: Security and compliance mentions\n- Students: Free plan, templates, organization\n\n## Recommendations for Your Ads\n\n1. **Test the \"tool sprawl\" pain point**\n   ‚Üí Strong resonance based on their ad frequency\n\n2. **Use product screenshots over abstract visuals**\n   ‚Üí All their top ads show actual UI\n\n3. **Lead with the problem, not the solution**\n   ‚Üí \"Tired of X?\" performs better than \"Introducing Y\"\n\n4. **Keep copy under 100 characters**\n   ‚Üí Their shortest ads seem most frequent\n\n5. **Test before/after visual formats**\n   ‚Üí Proven pattern in their creative\n\n## Files Saved\n- All ads: ~/competitor-ads/notion/\n- Analysis: ~/competitor-ads/notion/analysis.md\n- Best performers: ~/competitor-ads/notion/top-10/\n```\n\n**Inspired by:** Sumant Subrahmanya's use case from Lenny's Newsletter\n\n## What You Can Learn\n\n### Messaging Analysis\n- What problems they emphasize\n- How they position against competition\n- Value propositions that resonate\n- Target audience segments\n\n### Creative Patterns\n- Visual styles that work\n- Video vs. static image performance\n- Color schemes and branding\n- Layout patterns\n\n### Copy Formulas\n- Headline structures\n- Call-to-action patterns\n- Length and tone\n- Emotional triggers\n\n### Campaign Strategy\n- Seasonal campaigns\n- Product launch approaches\n- Feature announcement tactics\n- Retargeting patterns\n\n## Best Practices\n\n### Legal & Ethical\n‚úì Only use for research and inspiration\n‚úì Don't copy ads directly\n‚úì Respect intellectual property\n‚úì Use insights to inform original creative\n‚úó Don't plagiarize copy or steal designs\n\n### Analysis Tips\n1. **Look for patterns**: What themes repeat?\n2. **Track over time**: Save ads monthly to see evolution\n3. **Test hypotheses**: Adapt successful patterns for your brand\n4. **Segment by audience**: Different messages for different targets\n5. **Compare platforms**: LinkedIn vs Facebook messaging differs\n\n## Advanced Features\n\n### Trend Tracking\n```\nCompare [Competitor]'s ads from Q1 vs Q2. \nWhat messaging has changed?\n```\n\n### Multi-Competitor Analysis\n```\nExtract ads from [Company A], [Company B], [Company C]. \nWhat are the common patterns? Where do they differ?\n```\n\n### Industry Benchmarks\n```\nShow me ad patterns across the top 10 project management \ntools. What problems do they all focus on?\n```\n\n### Format Analysis\n```\nAnalyze video ads vs static image ads from [Competitor]. \nWhich gets more engagement? (if data available)\n```\n\n## Common Workflows\n\n### Ad Campaign Planning\n1. Extract competitor ads\n2. Identify successful patterns\n3. Note gaps in their messaging\n4. Brainstorm unique angles\n5. Draft test ad variations\n\n### Positioning Research\n1. Get ads from 5 competitors\n2. Map their positioning\n3. Find underserved angles\n4. Develop differentiated messaging\n5. Test against their approaches\n\n### Creative Inspiration\n1. Extract ads by theme\n2. Analyze visual patterns\n3. Note color and layout trends\n4. Adapt successful patterns\n5. Create original variations\n\n## Tips for Success\n\n1. **Regular Monitoring**: Check monthly for changes\n2. **Broad Research**: Look at adjacent competitors too\n3. **Save Everything**: Build a reference library\n4. **Test Insights**: Run your own experiments\n5. **Track Performance**: A/B test inspired concepts\n6. **Stay Original**: Use for inspiration, not copying\n7. **Multiple Platforms**: Compare Facebook, LinkedIn, TikTok, etc.\n\n## Output Formats\n\n- **Screenshots**: All ads saved as images\n- **Analysis Report**: Markdown summary of insights\n- **Spreadsheet**: CSV with ad copy, CTAs, themes\n- **Presentation**: Visual deck of top performers\n- **Pattern Library**: Categorized by approach\n\n## Related Use Cases\n\n- Writing better ad copy for your campaigns\n- Understanding market positioning\n- Finding content gaps in your messaging\n- Discovering new use cases for your product\n- Planning product marketing strategy\n- Inspiring social media content"
  },
  {
    "name": "content-research-writer",
    "description": "Assists in writing high-quality content by conducting research, adding citations, improving hooks, iterating on outlines, and providing real-time feedback on each section. Transforms your writing process from solo effort to collaborative partnership.",
    "body": "# Content Research Writer\n\nThis skill acts as your writing partner, helping you research, outline, draft, and refine content while maintaining your unique voice and style.\n\n## When to Use This Skill\n\n- Writing blog posts, articles, or newsletters\n- Creating educational content or tutorials\n- Drafting thought leadership pieces\n- Researching and writing case studies\n- Producing technical documentation with sources\n- Writing with proper citations and references\n- Improving hooks and introductions\n- Getting section-by-section feedback while writing\n\n## What This Skill Does\n\n1. **Collaborative Outlining**: Helps you structure ideas into coherent outlines\n2. **Research Assistance**: Finds relevant information and adds citations\n3. **Hook Improvement**: Strengthens your opening to capture attention\n4. **Section Feedback**: Reviews each section as you write\n5. **Voice Preservation**: Maintains your writing style and tone\n6. **Citation Management**: Adds and formats references properly\n7. **Iterative Refinement**: Helps you improve through multiple drafts\n\n## How to Use\n\n### Setup Your Writing Environment\n\nCreate a dedicated folder for your article:\n```\nmkdir ~/writing/my-article-title\ncd ~/writing/my-article-title\n```\n\nCreate your draft file:\n```\ntouch article-draft.md\n```\n\nOpen Claude Code from this directory and start writing.\n\n### Basic Workflow\n\n1. **Start with an outline**:\n```\nHelp me create an outline for an article about [topic]\n```\n\n2. **Research and add citations**:\n```\nResearch [specific topic] and add citations to my outline\n```\n\n3. **Improve the hook**:\n```\nHere's my introduction. Help me make the hook more compelling.\n```\n\n4. **Get section feedback**:\n```\nI just finished the \"Why This Matters\" section. Review it and give feedback.\n```\n\n5. **Refine and polish**:\n```\nReview the full draft for flow, clarity, and consistency.\n```\n\n## Instructions\n\nWhen a user requests writing assistance:\n\n1. **Understand the Writing Project**\n   \n   Ask clarifying questions:\n   - What's the topic and main argument?\n   - Who's the target audience?\n   - What's the desired length/format?\n   - What's your goal? (educate, persuade, entertain, explain)\n   - Any existing research or sources to include?\n   - What's your writing style? (formal, conversational, technical)\n\n2. **Collaborative Outlining**\n   \n   Help structure the content:\n   \n   ```markdown\n   # Article Outline: [Title]\n   \n   ## Hook\n   - [Opening line/story/statistic]\n   - [Why reader should care]\n   \n   ## Introduction\n   - Context and background\n   - Problem statement\n   - What this article covers\n   \n   ## Main Sections\n   \n   ### Section 1: [Title]\n   - Key point A\n   - Key point B\n   - Example/evidence\n   - [Research needed: specific topic]\n   \n   ### Section 2: [Title]\n   - Key point C\n   - Key point D\n   - Data/citation needed\n   \n   ### Section 3: [Title]\n   - Key point E\n   - Counter-arguments\n   - Resolution\n   \n   ## Conclusion\n   - Summary of main points\n   - Call to action\n   - Final thought\n   \n   ## Research To-Do\n   - [ ] Find data on [topic]\n   - [ ] Get examples of [concept]\n   - [ ] Source citation for [claim]\n   ```\n   \n   **Iterate on outline**:\n   - Adjust based on feedback\n   - Ensure logical flow\n   - Identify research gaps\n   - Mark sections for deep dives\n\n3. **Conduct Research**\n   \n   When user requests research on a topic:\n   \n   - Search for relevant information\n   - Find credible sources\n   - Extract key facts, quotes, and data\n   - Add citations in requested format\n   \n   Example output:\n   ```markdown\n   ## Research: AI Impact on Productivity\n   \n   Key Findings:\n   \n   1. **Productivity Gains**: Studies show 40% time savings for \n      content creation tasks [1]\n   \n   2. **Adoption Rates**: 67% of knowledge workers use AI tools \n      weekly [2]\n   \n   3. **Expert Quote**: \"AI augments rather than replaces human \n      creativity\" - Dr. Jane Smith, MIT [3]\n   \n   Citations:\n   [1] McKinsey Global Institute. (2024). \"The Economic Potential \n       of Generative AI\"\n   [2] Stack Overflow Developer Survey (2024)\n   [3] Smith, J. (2024). MIT Technology Review interview\n   \n   Added to outline under Section 2.\n   ```\n\n4. **Improve Hooks**\n   \n   When user shares an introduction, analyze and strengthen:\n   \n   **Current Hook Analysis**:\n   - What works: [positive elements]\n   - What could be stronger: [areas for improvement]\n   - Emotional impact: [current vs. potential]\n   \n   **Suggested Alternatives**:\n   \n   Option 1: [Bold statement]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   Option 2: [Personal story]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   Option 3: [Surprising data]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   **Questions to hook**:\n   - Does it create curiosity?\n   - Does it promise value?\n   - Is it specific enough?\n   - Does it match the audience?\n\n5. **Provide Section-by-Section Feedback**\n   \n   As user writes each section, review for:\n   \n   ```markdown\n   # Feedback: [Section Name]\n   \n   ## What Works Well ‚úì\n   - [Strength 1]\n   - [Strength 2]\n   - [Strength 3]\n   \n   ## Suggestions for Improvement\n   \n   ### Clarity\n   - [Specific issue] ‚Üí [Suggested fix]\n   - [Complex sentence] ‚Üí [Simpler alternative]\n   \n   ### Flow\n   - [Transition issue] ‚Üí [Better connection]\n   - [Paragraph order] ‚Üí [Suggested reordering]\n   \n   ### Evidence\n   - [Claim needing support] ‚Üí [Add citation or example]\n   - [Generic statement] ‚Üí [Make more specific]\n   \n   ### Style\n   - [Tone inconsistency] ‚Üí [Match your voice better]\n   - [Word choice] ‚Üí [Stronger alternative]\n   \n   ## Specific Line Edits\n   \n   Original:\n   > [Exact quote from draft]\n   \n   Suggested:\n   > [Improved version]\n   \n   Why: [Explanation]\n   \n   ## Questions to Consider\n   - [Thought-provoking question 1]\n   - [Thought-provoking question 2]\n   \n   Ready to move to next section!\n   ```\n\n6. **Preserve Writer's Voice**\n   \n   Important principles:\n   \n   - **Learn their style**: Read existing writing samples\n   - **Suggest, don't replace**: Offer options, not directives\n   - **Match tone**: Formal, casual, technical, friendly\n   - **Respect choices**: If they prefer their version, support it\n   - **Enhance, don't override**: Make their writing better, not different\n   \n   Ask periodically:\n   - \"Does this sound like you?\"\n   - \"Is this the right tone?\"\n   - \"Should I be more/less [formal/casual/technical]?\"\n\n7. **Citation Management**\n   \n   Handle references based on user preference:\n   \n   **Inline Citations**:\n   ```markdown\n   Studies show 40% productivity improvement (McKinsey, 2024).\n   ```\n   \n   **Numbered References**:\n   ```markdown\n   Studies show 40% productivity improvement [1].\n   \n   [1] McKinsey Global Institute. (2024)...\n   ```\n   \n   **Footnote Style**:\n   ```markdown\n   Studies show 40% productivity improvement^1\n   \n   ^1: McKinsey Global Institute. (2024)...\n   ```\n   \n   Maintain a running citations list:\n   ```markdown\n   ## References\n   \n   1. Author. (Year). \"Title\". Publication.\n   2. Author. (Year). \"Title\". Publication.\n   ...\n   ```\n\n8. **Final Review and Polish**\n   \n   When draft is complete, provide comprehensive feedback:\n   \n   ```markdown\n   # Full Draft Review\n   \n   ## Overall Assessment\n   \n   **Strengths**:\n   - [Major strength 1]\n   - [Major strength 2]\n   - [Major strength 3]\n   \n   **Impact**: [Overall effectiveness assessment]\n   \n   ## Structure & Flow\n   - [Comments on organization]\n   - [Transition quality]\n   - [Pacing assessment]\n   \n   ## Content Quality\n   - [Argument strength]\n   - [Evidence sufficiency]\n   - [Example effectiveness]\n   \n   ## Technical Quality\n   - Grammar and mechanics: [assessment]\n   - Consistency: [assessment]\n   - Citations: [completeness check]\n   \n   ## Readability\n   - Clarity score: [evaluation]\n   - Sentence variety: [evaluation]\n   - Paragraph length: [evaluation]\n   \n   ## Final Polish Suggestions\n   \n   1. **Introduction**: [Specific improvements]\n   2. **Body**: [Specific improvements]\n   3. **Conclusion**: [Specific improvements]\n   4. **Title**: [Options if needed]\n   \n   ## Pre-Publish Checklist\n   - [ ] All claims sourced\n   - [ ] Citations formatted\n   - [ ] Examples clear\n   - [ ] Transitions smooth\n   - [ ] Call to action present\n   - [ ] Proofread for typos\n   \n   Ready to publish! üöÄ\n   ```\n\n## Examples\n\n### Example 1: Teresa Torres's Workflow\n\n**User**: \"I'm writing an article about continuous discovery. Help me create an outline.\"\n\n**Process**:\n1. Collaborates on outline structure\n2. Identifies research needs\n3. User starts writing introduction\n4. Reviews and improves the hook\n5. User writes each section\n6. Provides feedback after each section\n7. Conducts research and adds citations\n8. Final review of complete draft\n9. Polish and prep for publishing\n\n**Result**: Well-researched, properly cited article written in Teresa's voice with strong structure and flow.\n\n### Example 2: Research-Heavy Article\n\n**User**: \"I'm writing about AI's impact on product management. Help me find current data and examples.\"\n\n**Output**:\n```markdown\n## Research Compiled\n\n### Recent Data\n- Gartner: 80% of PMs will use AI tools by 2025 [1]\n- Survey: 45% report faster feature shipping [2]\n- Case study: Airbnb's AI-assisted prioritization [3]\n\n### Expert Quotes\n- \"AI amplifies PM judgment, not replaces it\" - Marty Cagan\n- [Additional quotes with citations]\n\n### Real Examples\n1. **Company A**: Used AI for user research synthesis\n   - Result: 60% time savings\n   - Source: [citation]\n\n2. **Company B**: AI-powered roadmap analysis\n   - Result: Better stakeholder alignment\n   - Source: [citation]\n\nAll added to your outline with proper citations.\n```\n\n### Example 3: Hook Improvement\n\n**User's Original Hook**:\n> \"Product management is changing because of AI. In this article, I'll discuss some ways AI affects product managers.\"\n\n**Improved Options**:\n\n**Option 1 (Data-driven)**:\n> \"Last month, I asked AI to analyze 500 customer interviews. It took 30 minutes instead of 3 weeks. Product management will never be the same.\"\n\n**Option 2 (Question)**:\n> \"What if you could talk to every customer, read every review, and analyze every support ticket‚Äîall before your morning coffee?\"\n\n**Option 3 (Story)**:\n> \"Sarah spent two weeks building the wrong feature. Not because she didn't understand her users, but because she couldn't process the hundreds of interviews fast enough to spot the pattern.\"\n\n### Example 4: Section Feedback\n\n**User**: \"Just finished my 'Common Mistakes' section. Thoughts?\"\n\n**Response**:\n```markdown\n# Feedback: Common Mistakes Section\n\n## What Works Well ‚úì\n- Strong examples (the Slack notification story)\n- Clear structure (3 mistakes, clean layout)\n- Practical advice for each mistake\n\n## Suggestions\n\n### Make It More Specific\nYour second point says \"Bad prioritization\" but could be stronger:\n\nCurrent:\n> \"Many teams prioritize badly by focusing on features instead of outcomes.\"\n\nSuggested:\n> \"I've watched teams ship 14 features in a quarter yet move none of their key metrics. They prioritized activity over progress.\"\n\n### Add Data\nThe third mistake would benefit from evidence:\n> \"[Add citation]: Studies show teams without regular user contact are 3x more likely to build unused features [needs source]\"\n\n### Flow Improvement\nConsider reordering: Mistake 3 ‚Üí Mistake 2 ‚Üí Mistake 1\nThis builds from small to big impact.\n\nReady for the next section!\n```\n\n## Writing Workflows\n\n### Blog Post Workflow\n1. Outline together\n2. Research key points\n3. Write introduction ‚Üí get feedback\n4. Write body sections ‚Üí feedback each\n5. Write conclusion ‚Üí final review\n6. Polish and edit\n\n### Newsletter Workflow\n1. Discuss hook ideas\n2. Quick outline (shorter format)\n3. Draft in one session\n4. Review for clarity and links\n5. Quick polish\n\n### Technical Tutorial Workflow\n1. Outline steps\n2. Write code examples\n3. Add explanations\n4. Test instructions\n5. Add troubleshooting section\n6. Final review for accuracy\n\n### Thought Leadership Workflow\n1. Brainstorm unique angle\n2. Research existing perspectives\n3. Develop your thesis\n4. Write with strong POV\n5. Add supporting evidence\n6. Craft compelling conclusion\n\n## Pro Tips\n\n1. **Work in VS Code**: Better than web Claude for long-form writing\n2. **One section at a time**: Get feedback incrementally\n3. **Save research separately**: Keep a research.md file\n4. **Version your drafts**: article-v1.md, article-v2.md, etc.\n5. **Read aloud**: Use feedback to identify clunky sentences\n6. **Set deadlines**: \"I want to finish the draft today\"\n7. **Take breaks**: Write, get feedback, pause, revise\n\n## File Organization\n\nRecommended structure for writing projects:\n\n```\n~/writing/article-name/\n‚îú‚îÄ‚îÄ outline.md          # Your outline\n‚îú‚îÄ‚îÄ research.md         # All research and citations\n‚îú‚îÄ‚îÄ draft-v1.md         # First draft\n‚îú‚îÄ‚îÄ draft-v2.md         # Revised draft\n‚îú‚îÄ‚îÄ final.md            # Publication-ready\n‚îú‚îÄ‚îÄ feedback.md         # Collected feedback\n‚îî‚îÄ‚îÄ sources/            # Reference materials\n    ‚îú‚îÄ‚îÄ study1.pdf\n    ‚îî‚îÄ‚îÄ article2.md\n```\n\n## Best Practices\n\n### For Research\n- Verify sources before citing\n- Use recent data when possible\n- Balance different perspectives\n- Link to original sources\n\n### For Feedback\n- Be specific about what you want: \"Is this too technical?\"\n- Share your concerns: \"I'm worried this section drags\"\n- Ask questions: \"Does this flow logically?\"\n- Request alternatives: \"What's another way to explain this?\"\n\n### For Voice\n- Share examples of your writing\n- Specify tone preferences\n- Point out good matches: \"That sounds like me!\"\n- Flag mismatches: \"Too formal for my style\"\n\n## Related Use Cases\n\n- Creating social media posts from articles\n- Adapting content for different audiences\n- Writing email newsletters\n- Drafting technical documentation\n- Creating presentation content\n- Writing case studies\n- Developing course outlines",
    "id": "content-research-writer",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/content-research-writer",
    "name_zh": "ÂÜÖÂÆπÁ†îÁ©∂ÂÜô‰Ωú",
    "description_zh": "Assists in writing high-quality content by conducting research, adding citations, improving hooks, iterating on outlines, and providing real-time feedback on each section. Transforms your writing process from solo effort to collaborative partnership.",
    "body_zh": "# Content Research Writer\n\nThis skill acts as your writing partner, helping you research, outline, draft, and refine content while maintaining your unique voice and style.\n\n## When to Use This Skill\n\n- Writing blog posts, articles, or newsletters\n- Creating educational content or tutorials\n- Drafting thought leadership pieces\n- Researching and writing case studies\n- Producing technical documentation with sources\n- Writing with proper citations and references\n- Improving hooks and introductions\n- Getting section-by-section feedback while writing\n\n## What This Skill Does\n\n1. **Collaborative Outlining**: Helps you structure ideas into coherent outlines\n2. **Research Assistance**: Finds relevant information and adds citations\n3. **Hook Improvement**: Strengthens your opening to capture attention\n4. **Section Feedback**: Reviews each section as you write\n5. **Voice Preservation**: Maintains your writing style and tone\n6. **Citation Management**: Adds and formats references properly\n7. **Iterative Refinement**: Helps you improve through multiple drafts\n\n## How to Use\n\n### Setup Your Writing Environment\n\nCreate a dedicated folder for your article:\n```\nmkdir ~/writing/my-article-title\ncd ~/writing/my-article-title\n```\n\nCreate your draft file:\n```\ntouch article-draft.md\n```\n\nOpen Claude Code from this directory and start writing.\n\n### Basic Workflow\n\n1. **Start with an outline**:\n```\nHelp me create an outline for an article about [topic]\n```\n\n2. **Research and add citations**:\n```\nResearch [specific topic] and add citations to my outline\n```\n\n3. **Improve the hook**:\n```\nHere's my introduction. Help me make the hook more compelling.\n```\n\n4. **Get section feedback**:\n```\nI just finished the \"Why This Matters\" section. Review it and give feedback.\n```\n\n5. **Refine and polish**:\n```\nReview the full draft for flow, clarity, and consistency.\n```\n\n## Instructions\n\nWhen a user requests writing assistance:\n\n1. **Understand the Writing Project**\n   \n   Ask clarifying questions:\n   - What's the topic and main argument?\n   - Who's the target audience?\n   - What's the desired length/format?\n   - What's your goal? (educate, persuade, entertain, explain)\n   - Any existing research or sources to include?\n   - What's your writing style? (formal, conversational, technical)\n\n2. **Collaborative Outlining**\n   \n   Help structure the content:\n   \n   ```markdown\n   # Article Outline: [Title]\n   \n   ## Hook\n   - [Opening line/story/statistic]\n   - [Why reader should care]\n   \n   ## Introduction\n   - Context and background\n   - Problem statement\n   - What this article covers\n   \n   ## Main Sections\n   \n   ### Section 1: [Title]\n   - Key point A\n   - Key point B\n   - Example/evidence\n   - [Research needed: specific topic]\n   \n   ### Section 2: [Title]\n   - Key point C\n   - Key point D\n   - Data/citation needed\n   \n   ### Section 3: [Title]\n   - Key point E\n   - Counter-arguments\n   - Resolution\n   \n   ## Conclusion\n   - Summary of main points\n   - Call to action\n   - Final thought\n   \n   ## Research To-Do\n   - [ ] Find data on [topic]\n   - [ ] Get examples of [concept]\n   - [ ] Source citation for [claim]\n   ```\n   \n   **Iterate on outline**:\n   - Adjust based on feedback\n   - Ensure logical flow\n   - Identify research gaps\n   - Mark sections for deep dives\n\n3. **Conduct Research**\n   \n   When user requests research on a topic:\n   \n   - Search for relevant information\n   - Find credible sources\n   - Extract key facts, quotes, and data\n   - Add citations in requested format\n   \n   Example output:\n   ```markdown\n   ## Research: AI Impact on Productivity\n   \n   Key Findings:\n   \n   1. **Productivity Gains**: Studies show 40% time savings for \n      content creation tasks [1]\n   \n   2. **Adoption Rates**: 67% of knowledge workers use AI tools \n      weekly [2]\n   \n   3. **Expert Quote**: \"AI augments rather than replaces human \n      creativity\" - Dr. Jane Smith, MIT [3]\n   \n   Citations:\n   [1] McKinsey Global Institute. (2024). \"The Economic Potential \n       of Generative AI\"\n   [2] Stack Overflow Developer Survey (2024)\n   [3] Smith, J. (2024). MIT Technology Review interview\n   \n   Added to outline under Section 2.\n   ```\n\n4. **Improve Hooks**\n   \n   When user shares an introduction, analyze and strengthen:\n   \n   **Current Hook Analysis**:\n   - What works: [positive elements]\n   - What could be stronger: [areas for improvement]\n   - Emotional impact: [current vs. potential]\n   \n   **Suggested Alternatives**:\n   \n   Option 1: [Bold statement]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   Option 2: [Personal story]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   Option 3: [Surprising data]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   **Questions to hook**:\n   - Does it create curiosity?\n   - Does it promise value?\n   - Is it specific enough?\n   - Does it match the audience?\n\n5. **Provide Section-by-Section Feedback**\n   \n   As user writes each section, review for:\n   \n   ```markdown\n   # Feedback: [Section Name]\n   \n   ## What Works Well ‚úì\n   - [Strength 1]\n   - [Strength 2]\n   - [Strength 3]\n   \n   ## Suggestions for Improvement\n   \n   ### Clarity\n   - [Specific issue] ‚Üí [Suggested fix]\n   - [Complex sentence] ‚Üí [Simpler alternative]\n   \n   ### Flow\n   - [Transition issue] ‚Üí [Better connection]\n   - [Paragraph order] ‚Üí [Suggested reordering]\n   \n   ### Evidence\n   - [Claim needing support] ‚Üí [Add citation or example]\n   - [Generic statement] ‚Üí [Make more specific]\n   \n   ### Style\n   - [Tone inconsistency] ‚Üí [Match your voice better]\n   - [Word choice] ‚Üí [Stronger alternative]\n   \n   ## Specific Line Edits\n   \n   Original:\n   > [Exact quote from draft]\n   \n   Suggested:\n   > [Improved version]\n   \n   Why: [Explanation]\n   \n   ## Questions to Consider\n   - [Thought-provoking question 1]\n   - [Thought-provoking question 2]\n   \n   Ready to move to next section!\n   ```\n\n6. **Preserve Writer's Voice**\n   \n   Important principles:\n   \n   - **Learn their style**: Read existing writing samples\n   - **Suggest, don't replace**: Offer options, not directives\n   - **Match tone**: Formal, casual, technical, friendly\n   - **Respect choices**: If they prefer their version, support it\n   - **Enhance, don't override**: Make their writing better, not different\n   \n   Ask periodically:\n   - \"Does this sound like you?\"\n   - \"Is this the right tone?\"\n   - \"Should I be more/less [formal/casual/technical]?\"\n\n7. **Citation Management**\n   \n   Handle references based on user preference:\n   \n   **Inline Citations**:\n   ```markdown\n   Studies show 40% productivity improvement (McKinsey, 2024).\n   ```\n   \n   **Numbered References**:\n   ```markdown\n   Studies show 40% productivity improvement [1].\n   \n   [1] McKinsey Global Institute. (2024)...\n   ```\n   \n   **Footnote Style**:\n   ```markdown\n   Studies show 40% productivity improvement^1\n   \n   ^1: McKinsey Global Institute. (2024)...\n   ```\n   \n   Maintain a running citations list:\n   ```markdown\n   ## References\n   \n   1. Author. (Year). \"Title\". Publication.\n   2. Author. (Year). \"Title\". Publication.\n   ...\n   ```\n\n8. **Final Review and Polish**\n   \n   When draft is complete, provide comprehensive feedback:\n   \n   ```markdown\n   # Full Draft Review\n   \n   ## Overall Assessment\n   \n   **Strengths**:\n   - [Major strength 1]\n   - [Major strength 2]\n   - [Major strength 3]\n   \n   **Impact**: [Overall effectiveness assessment]\n   \n   ## Structure & Flow\n   - [Comments on organization]\n   - [Transition quality]\n   - [Pacing assessment]\n   \n   ## Content Quality\n   - [Argument strength]\n   - [Evidence sufficiency]\n   - [Example effectiveness]\n   \n   ## Technical Quality\n   - Grammar and mechanics: [assessment]\n   - Consistency: [assessment]\n   - Citations: [completeness check]\n   \n   ## Readability\n   - Clarity score: [evaluation]\n   - Sentence variety: [evaluation]\n   - Paragraph length: [evaluation]\n   \n   ## Final Polish Suggestions\n   \n   1. **Introduction**: [Specific improvements]\n   2. **Body**: [Specific improvements]\n   3. **Conclusion**: [Specific improvements]\n   4. **Title**: [Options if needed]\n   \n   ## Pre-Publish Checklist\n   - [ ] All claims sourced\n   - [ ] Citations formatted\n   - [ ] Examples clear\n   - [ ] Transitions smooth\n   - [ ] Call to action present\n   - [ ] Proofread for typos\n   \n   Ready to publish! üöÄ\n   ```\n\n## Examples\n\n### Example 1: Teresa Torres's Workflow\n\n**User**: \"I'm writing an article about continuous discovery. Help me create an outline.\"\n\n**Process**:\n1. Collaborates on outline structure\n2. Identifies research needs\n3. User starts writing introduction\n4. Reviews and improves the hook\n5. User writes each section\n6. Provides feedback after each section\n7. Conducts research and adds citations\n8. Final review of complete draft\n9. Polish and prep for publishing\n\n**Result**: Well-researched, properly cited article written in Teresa's voice with strong structure and flow.\n\n### Example 2: Research-Heavy Article\n\n**User**: \"I'm writing about AI's impact on product management. Help me find current data and examples.\"\n\n**Output**:\n```markdown\n## Research Compiled\n\n### Recent Data\n- Gartner: 80% of PMs will use AI tools by 2025 [1]\n- Survey: 45% report faster feature shipping [2]\n- Case study: Airbnb's AI-assisted prioritization [3]\n\n### Expert Quotes\n- \"AI amplifies PM judgment, not replaces it\" - Marty Cagan\n- [Additional quotes with citations]\n\n### Real Examples\n1. **Company A**: Used AI for user research synthesis\n   - Result: 60% time savings\n   - Source: [citation]\n\n2. **Company B**: AI-powered roadmap analysis\n   - Result: Better stakeholder alignment\n   - Source: [citation]\n\nAll added to your outline with proper citations.\n```\n\n### Example 3: Hook Improvement\n\n**User's Original Hook**:\n> \"Product management is changing because of AI. In this article, I'll discuss some ways AI affects product managers.\"\n\n**Improved Options**:\n\n**Option 1 (Data-driven)**:\n> \"Last month, I asked AI to analyze 500 customer interviews. It took 30 minutes instead of 3 weeks. Product management will never be the same.\"\n\n**Option 2 (Question)**:\n> \"What if you could talk to every customer, read every review, and analyze every support ticket‚Äîall before your morning coffee?\"\n\n**Option 3 (Story)**:\n> \"Sarah spent two weeks building the wrong feature. Not because she didn't understand her users, but because she couldn't process the hundreds of interviews fast enough to spot the pattern.\"\n\n### Example 4: Section Feedback\n\n**User**: \"Just finished my 'Common Mistakes' section. Thoughts?\"\n\n**Response**:\n```markdown\n# Feedback: Common Mistakes Section\n\n## What Works Well ‚úì\n- Strong examples (the Slack notification story)\n- Clear structure (3 mistakes, clean layout)\n- Practical advice for each mistake\n\n## Suggestions\n\n### Make It More Specific\nYour second point says \"Bad prioritization\" but could be stronger:\n\nCurrent:\n> \"Many teams prioritize badly by focusing on features instead of outcomes.\"\n\nSuggested:\n> \"I've watched teams ship 14 features in a quarter yet move none of their key metrics. They prioritized activity over progress.\"\n\n### Add Data\nThe third mistake would benefit from evidence:\n> \"[Add citation]: Studies show teams without regular user contact are 3x more likely to build unused features [needs source]\"\n\n### Flow Improvement\nConsider reordering: Mistake 3 ‚Üí Mistake 2 ‚Üí Mistake 1\nThis builds from small to big impact.\n\nReady for the next section!\n```\n\n## Writing Workflows\n\n### Blog Post Workflow\n1. Outline together\n2. Research key points\n3. Write introduction ‚Üí get feedback\n4. Write body sections ‚Üí feedback each\n5. Write conclusion ‚Üí final review\n6. Polish and edit\n\n### Newsletter Workflow\n1. Discuss hook ideas\n2. Quick outline (shorter format)\n3. Draft in one session\n4. Review for clarity and links\n5. Quick polish\n\n### Technical Tutorial Workflow\n1. Outline steps\n2. Write code examples\n3. Add explanations\n4. Test instructions\n5. Add troubleshooting section\n6. Final review for accuracy\n\n### Thought Leadership Workflow\n1. Brainstorm unique angle\n2. Research existing perspectives\n3. Develop your thesis\n4. Write with strong POV\n5. Add supporting evidence\n6. Craft compelling conclusion\n\n## Pro Tips\n\n1. **Work in VS Code**: Better than web Claude for long-form writing\n2. **One section at a time**: Get feedback incrementally\n3. **Save research separately**: Keep a research.md file\n4. **Version your drafts**: article-v1.md, article-v2.md, etc.\n5. **Read aloud**: Use feedback to identify clunky sentences\n6. **Set deadlines**: \"I want to finish the draft today\"\n7. **Take breaks**: Write, get feedback, pause, revise\n\n## File Organization\n\nRecommended structure for writing projects:\n\n```\n~/writing/article-name/\n‚îú‚îÄ‚îÄ outline.md          # Your outline\n‚îú‚îÄ‚îÄ research.md         # All research and citations\n‚îú‚îÄ‚îÄ draft-v1.md         # First draft\n‚îú‚îÄ‚îÄ draft-v2.md         # Revised draft\n‚îú‚îÄ‚îÄ final.md            # Publication-ready\n‚îú‚îÄ‚îÄ feedback.md         # Collected feedback\n‚îî‚îÄ‚îÄ sources/            # Reference materials\n    ‚îú‚îÄ‚îÄ study1.pdf\n    ‚îî‚îÄ‚îÄ article2.md\n```\n\n## Best Practices\n\n### For Research\n- Verify sources before citing\n- Use recent data when possible\n- Balance different perspectives\n- Link to original sources\n\n### For Feedback\n- Be specific about what you want: \"Is this too technical?\"\n- Share your concerns: \"I'm worried this section drags\"\n- Ask questions: \"Does this flow logically?\"\n- Request alternatives: \"What's another way to explain this?\"\n\n### For Voice\n- Share examples of your writing\n- Specify tone preferences\n- Point out good matches: \"That sounds like me!\"\n- Flag mismatches: \"Too formal for my style\"\n\n## Related Use Cases\n\n- Creating social media posts from articles\n- Adapting content for different audiences\n- Writing email newsletters\n- Drafting technical documentation\n- Creating presentation content\n- Writing case studies\n- Developing course outlines"
  },
  {
    "name": "database-design",
    "description": "Database schema design, optimization, and migration patterns for PostgreSQL, MySQL, and NoSQL databases. Use for designing schemas, writing migrations, or optimizing queries.",
    "body": "# Database Design\n\n## Schema Design Principles\n\n### Normalization Guidelines\n```sql\n-- 1NF: Atomic values, no repeating groups\n-- 2NF: No partial dependencies on composite keys\n-- 3NF: No transitive dependencies\n\n-- Users table (normalized)\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  email VARCHAR(255) UNIQUE NOT NULL,\n  created_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Addresses table (separate entity)\nCREATE TABLE addresses (\n  id SERIAL PRIMARY KEY,\n  user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,\n  street VARCHAR(255),\n  city VARCHAR(100),\n  country VARCHAR(100),\n  is_primary BOOLEAN DEFAULT false\n);\n```\n\n### Denormalization for Performance\n```sql\n-- When read performance matters more than write consistency\nCREATE TABLE order_summaries (\n  id SERIAL PRIMARY KEY,\n  order_id INTEGER REFERENCES orders(id),\n  customer_name VARCHAR(255),  -- Denormalized from customers\n  total_amount DECIMAL(10,2),\n  item_count INTEGER,\n  last_updated TIMESTAMPTZ DEFAULT NOW()\n);\n```\n\n## Index Design\n\n### Common Index Patterns\n```sql\n-- B-tree (default) for equality and range queries\nCREATE INDEX idx_users_email ON users(email);\n\n-- Composite index (order matters!)\nCREATE INDEX idx_orders_user_date ON orders(user_id, created_at DESC);\n\n-- Partial index for specific conditions\nCREATE INDEX idx_active_users ON users(email) WHERE deleted_at IS NULL;\n\n-- GIN index for array/JSONB columns\nCREATE INDEX idx_posts_tags ON posts USING GIN(tags);\n\n-- Covering index (includes additional columns)\nCREATE INDEX idx_orders_covering ON orders(user_id) INCLUDE (total, status);\n```\n\n### Index Analysis\n```sql\n-- Check index usage\nSELECT\n  schemaname, tablename, indexname,\n  idx_scan, idx_tup_read, idx_tup_fetch\nFROM pg_stat_user_indexes\nORDER BY idx_scan DESC;\n\n-- Find missing indexes\nSELECT\n  relname, seq_scan, seq_tup_read,\n  idx_scan, idx_tup_fetch\nFROM pg_stat_user_tables\nWHERE seq_scan > idx_scan\nORDER BY seq_tup_read DESC;\n```\n\n## Migration Patterns\n\n### Safe Migration Template\n```sql\n-- Always use transactions\nBEGIN;\n\n-- Add column with default (non-blocking in PG 11+)\nALTER TABLE users ADD COLUMN status VARCHAR(20) DEFAULT 'active';\n\n-- Create index concurrently (doesn't lock table)\nCREATE INDEX CONCURRENTLY idx_users_status ON users(status);\n\n-- Backfill data in batches\nUPDATE users SET status = 'active' WHERE status IS NULL AND id BETWEEN 1 AND 10000;\n\nCOMMIT;\n```\n\n### Zero-Downtime Migrations\n```\n1. Add new column (nullable)\n2. Deploy code that writes to both columns\n3. Backfill old data\n4. Deploy code that reads from new column\n5. Remove old column\n```\n\n## Query Optimization\n\n### EXPLAIN Analysis\n```sql\n-- Always use EXPLAIN ANALYZE\nEXPLAIN (ANALYZE, BUFFERS, FORMAT TEXT)\nSELECT * FROM orders WHERE user_id = 123 AND status = 'pending';\n\n-- Key metrics to watch:\n-- - Seq Scan vs Index Scan\n-- - Actual rows vs Estimated rows\n-- - Buffers: shared hit vs read\n```\n\n### Common Optimizations\n```sql\n-- Use EXISTS instead of IN for large sets\nSELECT * FROM users u\nWHERE EXISTS (SELECT 1 FROM orders o WHERE o.user_id = u.id);\n\n-- Pagination with keyset (cursor) instead of OFFSET\nSELECT * FROM posts\nWHERE created_at < '2024-01-01'\nORDER BY created_at DESC\nLIMIT 20;\n\n-- Use CTEs for complex queries\nWITH active_users AS (\n  SELECT id FROM users WHERE last_login > NOW() - INTERVAL '30 days'\n)\nSELECT * FROM orders WHERE user_id IN (SELECT id FROM active_users);\n```\n\n## Constraints & Data Integrity\n\n```sql\n-- Primary key\nALTER TABLE users ADD PRIMARY KEY (id);\n\n-- Foreign key with cascade\nALTER TABLE orders ADD CONSTRAINT fk_orders_user\n  FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE;\n\n-- Check constraint\nALTER TABLE products ADD CONSTRAINT chk_price_positive\n  CHECK (price >= 0);\n\n-- Unique constraint\nALTER TABLE users ADD CONSTRAINT uniq_users_email UNIQUE (email);\n\n-- Exclusion constraint (no overlapping ranges)\nALTER TABLE reservations ADD CONSTRAINT excl_no_overlap\n  EXCLUDE USING gist (room_id WITH =, tsrange(start_time, end_time) WITH &&);\n```\n\n## Best Practices\n\n- Use UUIDs for public-facing IDs, SERIAL/BIGSERIAL for internal\n- Always add `created_at` and `updated_at` timestamps\n- Use soft deletes (`deleted_at`) for important data\n- Design for eventual consistency in distributed systems\n- Document schema decisions in migration files\n- Test migrations on production-size data before deploying",
    "id": "database-design",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/database-design",
    "name_zh": "Êï∞ÊçÆÂ∫ìËÆæËÆ°",
    "description_zh": "Database schema design, optimization, and migration patterns for PostgreSQL, MySQL, and NoSQL databases. Use for designing schemas, writing migrations, or optimizing queries.",
    "body_zh": "# Database Design\n\n## Schema Design Principles\n\n### Normalization Guidelines\n```sql\n-- 1NF: Atomic values, no repeating groups\n-- 2NF: No partial dependencies on composite keys\n-- 3NF: No transitive dependencies\n\n-- Users table (normalized)\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  email VARCHAR(255) UNIQUE NOT NULL,\n  created_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Addresses table (separate entity)\nCREATE TABLE addresses (\n  id SERIAL PRIMARY KEY,\n  user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,\n  street VARCHAR(255),\n  city VARCHAR(100),\n  country VARCHAR(100),\n  is_primary BOOLEAN DEFAULT false\n);\n```\n\n### Denormalization for Performance\n```sql\n-- When read performance matters more than write consistency\nCREATE TABLE order_summaries (\n  id SERIAL PRIMARY KEY,\n  order_id INTEGER REFERENCES orders(id),\n  customer_name VARCHAR(255),  -- Denormalized from customers\n  total_amount DECIMAL(10,2),\n  item_count INTEGER,\n  last_updated TIMESTAMPTZ DEFAULT NOW()\n);\n```\n\n## Index Design\n\n### Common Index Patterns\n```sql\n-- B-tree (default) for equality and range queries\nCREATE INDEX idx_users_email ON users(email);\n\n-- Composite index (order matters!)\nCREATE INDEX idx_orders_user_date ON orders(user_id, created_at DESC);\n\n-- Partial index for specific conditions\nCREATE INDEX idx_active_users ON users(email) WHERE deleted_at IS NULL;\n\n-- GIN index for array/JSONB columns\nCREATE INDEX idx_posts_tags ON posts USING GIN(tags);\n\n-- Covering index (includes additional columns)\nCREATE INDEX idx_orders_covering ON orders(user_id) INCLUDE (total, status);\n```\n\n### Index Analysis\n```sql\n-- Check index usage\nSELECT\n  schemaname, tablename, indexname,\n  idx_scan, idx_tup_read, idx_tup_fetch\nFROM pg_stat_user_indexes\nORDER BY idx_scan DESC;\n\n-- Find missing indexes\nSELECT\n  relname, seq_scan, seq_tup_read,\n  idx_scan, idx_tup_fetch\nFROM pg_stat_user_tables\nWHERE seq_scan > idx_scan\nORDER BY seq_tup_read DESC;\n```\n\n## Migration Patterns\n\n### Safe Migration Template\n```sql\n-- Always use transactions\nBEGIN;\n\n-- Add column with default (non-blocking in PG 11+)\nALTER TABLE users ADD COLUMN status VARCHAR(20) DEFAULT 'active';\n\n-- Create index concurrently (doesn't lock table)\nCREATE INDEX CONCURRENTLY idx_users_status ON users(status);\n\n-- Backfill data in batches\nUPDATE users SET status = 'active' WHERE status IS NULL AND id BETWEEN 1 AND 10000;\n\nCOMMIT;\n```\n\n### Zero-Downtime Migrations\n```\n1. Add new column (nullable)\n2. Deploy code that writes to both columns\n3. Backfill old data\n4. Deploy code that reads from new column\n5. Remove old column\n```\n\n## Query Optimization\n\n### EXPLAIN Analysis\n```sql\n-- Always use EXPLAIN ANALYZE\nEXPLAIN (ANALYZE, BUFFERS, FORMAT TEXT)\nSELECT * FROM orders WHERE user_id = 123 AND status = 'pending';\n\n-- Key metrics to watch:\n-- - Seq Scan vs Index Scan\n-- - Actual rows vs Estimated rows\n-- - Buffers: shared hit vs read\n```\n\n### Common Optimizations\n```sql\n-- Use EXISTS instead of IN for large sets\nSELECT * FROM users u\nWHERE EXISTS (SELECT 1 FROM orders o WHERE o.user_id = u.id);\n\n-- Pagination with keyset (cursor) instead of OFFSET\nSELECT * FROM posts\nWHERE created_at < '2024-01-01'\nORDER BY created_at DESC\nLIMIT 20;\n\n-- Use CTEs for complex queries\nWITH active_users AS (\n  SELECT id FROM users WHERE last_login > NOW() - INTERVAL '30 days'\n)\nSELECT * FROM orders WHERE user_id IN (SELECT id FROM active_users);\n```\n\n## Constraints & Data Integrity\n\n```sql\n-- Primary key\nALTER TABLE users ADD PRIMARY KEY (id);\n\n-- Foreign key with cascade\nALTER TABLE orders ADD CONSTRAINT fk_orders_user\n  FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE;\n\n-- Check constraint\nALTER TABLE products ADD CONSTRAINT chk_price_positive\n  CHECK (price >= 0);\n\n-- Unique constraint\nALTER TABLE users ADD CONSTRAINT uniq_users_email UNIQUE (email);\n\n-- Exclusion constraint (no overlapping ranges)\nALTER TABLE reservations ADD CONSTRAINT excl_no_overlap\n  EXCLUDE USING gist (room_id WITH =, tsrange(start_time, end_time) WITH &&);\n```\n\n## Best Practices\n\n- Use UUIDs for public-facing IDs, SERIAL/BIGSERIAL for internal\n- Always add `created_at` and `updated_at` timestamps\n- Use soft deletes (`deleted_at`) for important data\n- Design for eventual consistency in distributed systems\n- Document schema decisions in migration files\n- Test migrations on production-size data before deploying"
  },
  {
    "name": "developer-growth-analysis",
    "description": "Analyzes your recent Claude Code chat history to identify coding patterns, development gaps, and areas for improvement, curates relevant learning resources from HackerNews, and automatically sends a personalized growth report to your Slack DMs.",
    "body": "# Developer Growth Analysis\n\nThis skill provides personalized feedback on your recent coding work by analyzing your Claude Code chat interactions and identifying patterns that reveal strengths and areas for growth.\n\n## When to Use This Skill\n\nUse this skill when you want to:\n- Understand your development patterns and habits from recent work\n- Identify specific technical gaps or recurring challenges\n- Discover which topics would benefit from deeper study\n- Get curated learning resources tailored to your actual work patterns\n- Track improvement areas across your recent projects\n- Find high-quality articles that directly address the skills you're developing\n\nThis skill is ideal for developers who want structured feedback on their growth without waiting for code reviews, and who prefer data-driven insights from their own work history.\n\n## What This Skill Does\n\nThis skill performs a six-step analysis of your development work:\n\n1. **Reads Your Chat History**: Accesses your local Claude Code chat history from the past 24-48 hours to understand what you've been working on.\n\n2. **Identifies Development Patterns**: Analyzes the types of problems you're solving, technologies you're using, challenges you encounter, and how you approach different kinds of tasks.\n\n3. **Detects Improvement Areas**: Recognizes patterns that suggest skill gaps, repeated struggles, inefficient approaches, or areas where you might benefit from deeper knowledge.\n\n4. **Generates a Personalized Report**: Creates a comprehensive report showing your work summary, identified improvement areas, and specific recommendations for growth.\n\n5. **Finds Learning Resources**: Uses HackerNews to curate high-quality articles and discussions directly relevant to your improvement areas, providing you with a reading list tailored to your actual development work.\n\n6. **Sends to Your Slack DMs**: Automatically delivers the complete report to your own Slack direct messages so you can reference it anytime, anywhere.\n\n## How to Use\n\nAsk Claude to analyze your recent coding work:\n\n```\nAnalyze my developer growth from my recent chats\n```\n\nOr be more specific about which time period:\n\n```\nAnalyze my work from today and suggest areas for improvement\n```\n\nThe skill will generate a formatted report with:\n- Overview of your recent work\n- Key improvement areas identified\n- Specific recommendations for each area\n- Curated learning resources from HackerNews\n- Action items you can focus on\n\n## Instructions\n\nWhen a user requests analysis of their developer growth or coding patterns from recent work:\n\n1. **Access Chat History**\n\n   Read the chat history from `~/.claude/history.jsonl`. This file is a JSONL format where each line contains:\n   - `display`: The user's message/request\n   - `project`: The project being worked on\n   - `timestamp`: Unix timestamp (in milliseconds)\n   - `pastedContents`: Any code or content pasted\n\n   Filter for entries from the past 24-48 hours based on the current timestamp.\n\n2. **Analyze Work Patterns**\n\n   Extract and analyze the following from the filtered chats:\n   - **Projects and Domains**: What types of projects was the user working on? (e.g., backend, frontend, DevOps, data, etc.)\n   - **Technologies Used**: What languages, frameworks, and tools appear in the conversations?\n   - **Problem Types**: What categories of problems are being solved? (e.g., performance optimization, debugging, feature implementation, refactoring, setup/configuration)\n   - **Challenges Encountered**: What problems did the user struggle with? Look for:\n     - Repeated questions about similar topics\n     - Problems that took multiple attempts to solve\n     - Questions indicating knowledge gaps\n     - Complex architectural decisions\n   - **Approach Patterns**: How does the user solve problems? (e.g., methodical, exploratory, experimental)\n\n3. **Identify Improvement Areas**\n\n   Based on the analysis, identify 3-5 specific areas where the user could improve. These should be:\n   - **Specific** (not vague like \"improve coding skills\")\n   - **Evidence-based** (grounded in actual chat history)\n   - **Actionable** (practical improvements that can be made)\n   - **Prioritized** (most impactful first)\n\n   Examples of good improvement areas:\n   - \"Advanced TypeScript patterns (generics, utility types, type guards) - you struggled with type safety in [specific project]\"\n   - \"Error handling and validation - I noticed you patched several bugs related to missing null checks\"\n   - \"Async/await patterns - your recent work shows some race conditions and timing issues\"\n   - \"Database query optimization - you rewrote the same query multiple times\"\n\n4. **Generate Report**\n\n   Create a comprehensive report with this structure:\n\n   ```markdown\n   # Your Developer Growth Report\n\n   **Report Period**: [Yesterday / Today / [Custom Date Range]]\n   **Last Updated**: [Current Date and Time]\n\n   ## Work Summary\n\n   [2-3 paragraphs summarizing what the user worked on, projects touched, technologies used, and overall focus areas]\n\n   Example:\n   \"Over the past 24 hours, you focused primarily on backend development with three distinct projects. Your work involved TypeScript, React, and deployment infrastructure. You tackled a mix of feature implementation, debugging, and architectural decisions, with a particular focus on API design and database optimization.\"\n\n   ## Improvement Areas (Prioritized)\n\n   ### 1. [Area Name]\n\n   **Why This Matters**: [Explanation of why this skill is important for the user's work]\n\n   **What I Observed**: [Specific evidence from chat history showing this gap]\n\n   **Recommendation**: [Concrete step(s) to improve in this area]\n\n   **Time to Skill Up**: [Brief estimate of effort required]\n\n   ---\n\n   [Repeat for 2-4 additional areas]\n\n   ## Strengths Observed\n\n   [2-3 bullet points highlighting things you're doing well - things to continue doing]\n\n   ## Action Items\n\n   Priority order:\n   1. [Action item derived from highest priority improvement area]\n   2. [Action item from next area]\n   3. [Action item from next area]\n\n   ## Learning Resources\n\n   [Will be populated in next step]\n   ```\n\n5. **Search for Learning Resources**\n\n   Use Rube MCP to search HackerNews for articles related to each improvement area:\n\n   - For each improvement area, construct a search query targeting high-quality resources\n   - Search HackerNews using RUBE_SEARCH_TOOLS with queries like:\n     - \"Learn [Technology/Pattern] best practices\"\n     - \"[Technology] advanced patterns and techniques\"\n     - \"Debugging [specific problem type] in [language]\"\n   - Prioritize posts with high engagement (comments, upvotes)\n   - For each area, include 2-3 most relevant articles with:\n     - Article title\n     - Publication date\n     - Brief description of why it's relevant\n     - Link to the article\n\n   Add this section to the report:\n\n   ```markdown\n   ## Curated Learning Resources\n\n   ### For: [Improvement Area]\n\n   1. **[Article Title]** - [Date]\n      [Description of what it covers and why it's relevant to your improvement area]\n      [Link]\n\n   2. **[Article Title]** - [Date]\n      [Description]\n      [Link]\n\n   [Repeat for other improvement areas]\n   ```\n\n6. **Present the Complete Report**\n\n   Deliver the report in a clean, readable format that the user can:\n   - Quickly scan for key takeaways\n   - Use for focused learning planning\n   - Reference over the next week as they work on improvements\n   - Share with mentors if they want external feedback\n\n7. **Send Report to Slack DMs**\n\n   Use Rube MCP to send the complete report to the user's own Slack DMs:\n\n   - Check if Slack connection is active via RUBE_SEARCH_TOOLS\n   - If not connected, use RUBE_MANAGE_CONNECTIONS to initiate Slack auth\n   - Use RUBE_MULTI_EXECUTE_TOOL to send the report as a formatted message:\n     - Send the report title and period as the first message\n     - Break the report into logical sections (Summary, Improvements, Strengths, Actions, Resources)\n     - Format each section as a well-structured Slack message with proper markdown\n     - Include clickable links for the learning resources\n   - Confirm delivery in the CLI output\n\n   This ensures the user has the report in a place they check regularly and can reference it throughout the week.\n\n## Example Usage\n\n### Input\n\n```\nAnalyze my developer growth from my recent chats\n```\n\n### Output\n\n```markdown\n# Your Developer Growth Report\n\n**Report Period**: November 9-10, 2024\n**Last Updated**: November 10, 2024, 9:15 PM UTC\n\n## Work Summary\n\nOver the past two days, you focused on backend infrastructure and API development. Your primary project was an open-source showcase application, where you made significant progress on connections management, UI improvements, and deployment configuration. You worked with TypeScript, React, and Node.js, tackling challenges ranging from data security to responsive design. Your work shows a balance between implementing features and addressing technical debt.\n\n## Improvement Areas (Prioritized)\n\n### 1. Advanced TypeScript Patterns and Type Safety\n\n**Why This Matters**: TypeScript is central to your work, but leveraging its advanced features (generics, utility types, conditional types, type guards) can significantly improve code reliability and reduce runtime errors. Better type safety catches bugs at compile time rather than in production.\n\n**What I Observed**: In your recent chats, you were working with connection data structures and struggled a few times with typing auth configurations properly. You also had to iterate on union types for different connection states. There's an opportunity to use discriminated unions and type guards more effectively.\n\n**Recommendation**: Study TypeScript's advanced type system, particularly utility types (Omit, Pick, Record), conditional types, and discriminated unions. Apply these patterns to your connection configuration handling and auth state management.\n\n**Time to Skill Up**: 5-8 hours of focused learning and practice\n\n### 2. Secure Data Handling and Information Hiding in UI\n\n**Why This Matters**: You identified and fixed a security concern where sensitive connection data was being displayed in your console. Preventing information leakage is critical for applications handling user credentials and API keys. Good practices here prevent security incidents and user trust violations.\n\n**What I Observed**: You caught that your \"Your Apps\" page was showing full connection data including auth configs. This shows good security instincts, and the next step is building this into your default thinking when handling sensitive information.\n\n**Recommendation**: Review security best practices for handling sensitive data in frontend applications. Create reusable patterns for filtering/masking sensitive information before displaying it. Consider implementing a secure data layer that explicitly whitelist what can be shown in the UI.\n\n**Time to Skill Up**: 3-4 hours\n\n### 3. Component Architecture and Responsive UI Patterns\n\n**Why This Matters**: You're designing UIs that need to work across different screen sizes and user interactions. Strong component architecture makes it easier to build complex UIs without bugs and improves maintainability.\n\n**What I Observed**: You worked on the \"Marketplace\" UI (formerly Browse Tools), recreating it from a design image. You also identified and fixed scrolling issues where content was overflowing containers. There's an opportunity to strengthen your understanding of layout containment and responsive design patterns.\n\n**Recommendation**: Study React component composition patterns and CSS layout best practices (especially flexbox and grid). Focus on container queries and responsive patterns that prevent overflow issues. Look into component composition libraries and design system approaches.\n\n**Time to Skill Up**: 6-10 hours (depending on depth)\n\n## Strengths Observed\n\n- **Security Awareness**: You proactively identified data leakage issues before they became problems\n- **Iterative Refinement**: You worked through UI requirements methodically, asking clarifying questions and improving designs\n- **Full-Stack Capability**: You comfortably work across backend APIs, frontend UI, and deployment concerns\n- **Problem-Solving Approach**: You break down complex tasks into manageable steps\n\n## Action Items\n\nPriority order:\n1. Spend 1-2 hours learning TypeScript utility types and discriminated unions; apply to your connection data structures\n2. Document security patterns for your project (what data is safe to display, filtering/masking functions)\n3. Study one article on advanced React patterns and apply one pattern to your current UI work\n4. Set up a code review checklist focused on type safety and data security for future PRs\n\n## Curated Learning Resources\n\n### For: Advanced TypeScript Patterns\n\n1. **TypeScript's Advanced Types: Generics, Utility Types, and Conditional Types** - HackerNews, October 2024\n   Deep dive into TypeScript's type system with practical examples and real-world applications. Covers discriminated unions, type guards, and patterns for ensuring compile-time safety in complex applications.\n   [Link to discussion]\n\n2. **Building Type-Safe APIs in TypeScript** - HackerNews, September 2024\n   Practical guide to designing APIs with TypeScript that catch errors early. Particularly relevant for your connection configuration work.\n   [Link to discussion]\n\n### For: Secure Data Handling in Frontend\n\n1. **Preventing Information Leakage in Web Applications** - HackerNews, August 2024\n   Comprehensive guide to data security in frontend applications, including filtering sensitive information, secure logging, and audit trails.\n   [Link to discussion]\n\n2. **OAuth and API Key Management Best Practices** - HackerNews, July 2024\n   How to safely handle authentication tokens and API keys in applications, with examples for different frameworks.\n   [Link to discussion]\n\n### For: Component Architecture and Responsive Design\n\n1. **Advanced React Patterns: Composition Over Configuration** - HackerNews\n   Explores component composition strategies that scale, with examples using modern React patterns.\n   [Link to discussion]\n\n2. **CSS Layout Mastery: Flexbox, Grid, and Container Queries** - HackerNews, October 2024\n   Learn responsive design patterns that prevent overflow issues and work across all screen sizes.\n   [Link to discussion]\n```\n\n## Tips and Best Practices\n\n- Run this analysis once a week to track your improvement trajectory over time\n- Pick one improvement area at a time and focus on it for a few days before moving to the next\n- Use the learning resources as a study guide; work through the recommended materials and practice applying the patterns\n- Revisit this report after focusing on an area for a week to see how your work patterns change\n- The learning resources are intentionally curated for your actual work, not generic topics, so they'll be highly relevant to what you're building\n\n## How Accuracy and Quality Are Maintained\n\nThis skill:\n- Analyzes your actual work patterns from timestamped chat history\n- Generates evidence-based recommendations grounded in real projects\n- Curates learning resources that directly address your identified gaps\n- Focuses on actionable improvements, not vague feedback\n- Provides specific time estimates based on complexity\n- Prioritizes areas that will have the most impact on your development velocity",
    "id": "developer-growth-analysis",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/developer-growth-analysis",
    "name_zh": "ÂºÄÂèëËÄÖÂ¢ûÈïøÂàÜÊûê",
    "description_zh": "Analyzes your recent Claude Code chat history to identify coding patterns, development gaps, and areas for improvement, curates relevant learning resources from HackerNews, and automatically sends a personalized growth report to your Slack DMs.",
    "body_zh": "# Developer Growth Analysis\n\nThis skill provides personalized feedback on your recent coding work by analyzing your Claude Code chat interactions and identifying patterns that reveal strengths and areas for growth.\n\n## When to Use This Skill\n\nUse this skill when you want to:\n- Understand your development patterns and habits from recent work\n- Identify specific technical gaps or recurring challenges\n- Discover which topics would benefit from deeper study\n- Get curated learning resources tailored to your actual work patterns\n- Track improvement areas across your recent projects\n- Find high-quality articles that directly address the skills you're developing\n\nThis skill is ideal for developers who want structured feedback on their growth without waiting for code reviews, and who prefer data-driven insights from their own work history.\n\n## What This Skill Does\n\nThis skill performs a six-step analysis of your development work:\n\n1. **Reads Your Chat History**: Accesses your local Claude Code chat history from the past 24-48 hours to understand what you've been working on.\n\n2. **Identifies Development Patterns**: Analyzes the types of problems you're solving, technologies you're using, challenges you encounter, and how you approach different kinds of tasks.\n\n3. **Detects Improvement Areas**: Recognizes patterns that suggest skill gaps, repeated struggles, inefficient approaches, or areas where you might benefit from deeper knowledge.\n\n4. **Generates a Personalized Report**: Creates a comprehensive report showing your work summary, identified improvement areas, and specific recommendations for growth.\n\n5. **Finds Learning Resources**: Uses HackerNews to curate high-quality articles and discussions directly relevant to your improvement areas, providing you with a reading list tailored to your actual development work.\n\n6. **Sends to Your Slack DMs**: Automatically delivers the complete report to your own Slack direct messages so you can reference it anytime, anywhere.\n\n## How to Use\n\nAsk Claude to analyze your recent coding work:\n\n```\nAnalyze my developer growth from my recent chats\n```\n\nOr be more specific about which time period:\n\n```\nAnalyze my work from today and suggest areas for improvement\n```\n\nThe skill will generate a formatted report with:\n- Overview of your recent work\n- Key improvement areas identified\n- Specific recommendations for each area\n- Curated learning resources from HackerNews\n- Action items you can focus on\n\n## Instructions\n\nWhen a user requests analysis of their developer growth or coding patterns from recent work:\n\n1. **Access Chat History**\n\n   Read the chat history from `~/.claude/history.jsonl`. This file is a JSONL format where each line contains:\n   - `display`: The user's message/request\n   - `project`: The project being worked on\n   - `timestamp`: Unix timestamp (in milliseconds)\n   - `pastedContents`: Any code or content pasted\n\n   Filter for entries from the past 24-48 hours based on the current timestamp.\n\n2. **Analyze Work Patterns**\n\n   Extract and analyze the following from the filtered chats:\n   - **Projects and Domains**: What types of projects was the user working on? (e.g., backend, frontend, DevOps, data, etc.)\n   - **Technologies Used**: What languages, frameworks, and tools appear in the conversations?\n   - **Problem Types**: What categories of problems are being solved? (e.g., performance optimization, debugging, feature implementation, refactoring, setup/configuration)\n   - **Challenges Encountered**: What problems did the user struggle with? Look for:\n     - Repeated questions about similar topics\n     - Problems that took multiple attempts to solve\n     - Questions indicating knowledge gaps\n     - Complex architectural decisions\n   - **Approach Patterns**: How does the user solve problems? (e.g., methodical, exploratory, experimental)\n\n3. **Identify Improvement Areas**\n\n   Based on the analysis, identify 3-5 specific areas where the user could improve. These should be:\n   - **Specific** (not vague like \"improve coding skills\")\n   - **Evidence-based** (grounded in actual chat history)\n   - **Actionable** (practical improvements that can be made)\n   - **Prioritized** (most impactful first)\n\n   Examples of good improvement areas:\n   - \"Advanced TypeScript patterns (generics, utility types, type guards) - you struggled with type safety in [specific project]\"\n   - \"Error handling and validation - I noticed you patched several bugs related to missing null checks\"\n   - \"Async/await patterns - your recent work shows some race conditions and timing issues\"\n   - \"Database query optimization - you rewrote the same query multiple times\"\n\n4. **Generate Report**\n\n   Create a comprehensive report with this structure:\n\n   ```markdown\n   # Your Developer Growth Report\n\n   **Report Period**: [Yesterday / Today / [Custom Date Range]]\n   **Last Updated**: [Current Date and Time]\n\n   ## Work Summary\n\n   [2-3 paragraphs summarizing what the user worked on, projects touched, technologies used, and overall focus areas]\n\n   Example:\n   \"Over the past 24 hours, you focused primarily on backend development with three distinct projects. Your work involved TypeScript, React, and deployment infrastructure. You tackled a mix of feature implementation, debugging, and architectural decisions, with a particular focus on API design and database optimization.\"\n\n   ## Improvement Areas (Prioritized)\n\n   ### 1. [Area Name]\n\n   **Why This Matters**: [Explanation of why this skill is important for the user's work]\n\n   **What I Observed**: [Specific evidence from chat history showing this gap]\n\n   **Recommendation**: [Concrete step(s) to improve in this area]\n\n   **Time to Skill Up**: [Brief estimate of effort required]\n\n   ---\n\n   [Repeat for 2-4 additional areas]\n\n   ## Strengths Observed\n\n   [2-3 bullet points highlighting things you're doing well - things to continue doing]\n\n   ## Action Items\n\n   Priority order:\n   1. [Action item derived from highest priority improvement area]\n   2. [Action item from next area]\n   3. [Action item from next area]\n\n   ## Learning Resources\n\n   [Will be populated in next step]\n   ```\n\n5. **Search for Learning Resources**\n\n   Use Rube MCP to search HackerNews for articles related to each improvement area:\n\n   - For each improvement area, construct a search query targeting high-quality resources\n   - Search HackerNews using RUBE_SEARCH_TOOLS with queries like:\n     - \"Learn [Technology/Pattern] best practices\"\n     - \"[Technology] advanced patterns and techniques\"\n     - \"Debugging [specific problem type] in [language]\"\n   - Prioritize posts with high engagement (comments, upvotes)\n   - For each area, include 2-3 most relevant articles with:\n     - Article title\n     - Publication date\n     - Brief description of why it's relevant\n     - Link to the article\n\n   Add this section to the report:\n\n   ```markdown\n   ## Curated Learning Resources\n\n   ### For: [Improvement Area]\n\n   1. **[Article Title]** - [Date]\n      [Description of what it covers and why it's relevant to your improvement area]\n      [Link]\n\n   2. **[Article Title]** - [Date]\n      [Description]\n      [Link]\n\n   [Repeat for other improvement areas]\n   ```\n\n6. **Present the Complete Report**\n\n   Deliver the report in a clean, readable format that the user can:\n   - Quickly scan for key takeaways\n   - Use for focused learning planning\n   - Reference over the next week as they work on improvements\n   - Share with mentors if they want external feedback\n\n7. **Send Report to Slack DMs**\n\n   Use Rube MCP to send the complete report to the user's own Slack DMs:\n\n   - Check if Slack connection is active via RUBE_SEARCH_TOOLS\n   - If not connected, use RUBE_MANAGE_CONNECTIONS to initiate Slack auth\n   - Use RUBE_MULTI_EXECUTE_TOOL to send the report as a formatted message:\n     - Send the report title and period as the first message\n     - Break the report into logical sections (Summary, Improvements, Strengths, Actions, Resources)\n     - Format each section as a well-structured Slack message with proper markdown\n     - Include clickable links for the learning resources\n   - Confirm delivery in the CLI output\n\n   This ensures the user has the report in a place they check regularly and can reference it throughout the week.\n\n## Example Usage\n\n### Input\n\n```\nAnalyze my developer growth from my recent chats\n```\n\n### Output\n\n```markdown\n# Your Developer Growth Report\n\n**Report Period**: November 9-10, 2024\n**Last Updated**: November 10, 2024, 9:15 PM UTC\n\n## Work Summary\n\nOver the past two days, you focused on backend infrastructure and API development. Your primary project was an open-source showcase application, where you made significant progress on connections management, UI improvements, and deployment configuration. You worked with TypeScript, React, and Node.js, tackling challenges ranging from data security to responsive design. Your work shows a balance between implementing features and addressing technical debt.\n\n## Improvement Areas (Prioritized)\n\n### 1. Advanced TypeScript Patterns and Type Safety\n\n**Why This Matters**: TypeScript is central to your work, but leveraging its advanced features (generics, utility types, conditional types, type guards) can significantly improve code reliability and reduce runtime errors. Better type safety catches bugs at compile time rather than in production.\n\n**What I Observed**: In your recent chats, you were working with connection data structures and struggled a few times with typing auth configurations properly. You also had to iterate on union types for different connection states. There's an opportunity to use discriminated unions and type guards more effectively.\n\n**Recommendation**: Study TypeScript's advanced type system, particularly utility types (Omit, Pick, Record), conditional types, and discriminated unions. Apply these patterns to your connection configuration handling and auth state management.\n\n**Time to Skill Up**: 5-8 hours of focused learning and practice\n\n### 2. Secure Data Handling and Information Hiding in UI\n\n**Why This Matters**: You identified and fixed a security concern where sensitive connection data was being displayed in your console. Preventing information leakage is critical for applications handling user credentials and API keys. Good practices here prevent security incidents and user trust violations.\n\n**What I Observed**: You caught that your \"Your Apps\" page was showing full connection data including auth configs. This shows good security instincts, and the next step is building this into your default thinking when handling sensitive information.\n\n**Recommendation**: Review security best practices for handling sensitive data in frontend applications. Create reusable patterns for filtering/masking sensitive information before displaying it. Consider implementing a secure data layer that explicitly whitelist what can be shown in the UI.\n\n**Time to Skill Up**: 3-4 hours\n\n### 3. Component Architecture and Responsive UI Patterns\n\n**Why This Matters**: You're designing UIs that need to work across different screen sizes and user interactions. Strong component architecture makes it easier to build complex UIs without bugs and improves maintainability.\n\n**What I Observed**: You worked on the \"Marketplace\" UI (formerly Browse Tools), recreating it from a design image. You also identified and fixed scrolling issues where content was overflowing containers. There's an opportunity to strengthen your understanding of layout containment and responsive design patterns.\n\n**Recommendation**: Study React component composition patterns and CSS layout best practices (especially flexbox and grid). Focus on container queries and responsive patterns that prevent overflow issues. Look into component composition libraries and design system approaches.\n\n**Time to Skill Up**: 6-10 hours (depending on depth)\n\n## Strengths Observed\n\n- **Security Awareness**: You proactively identified data leakage issues before they became problems\n- **Iterative Refinement**: You worked through UI requirements methodically, asking clarifying questions and improving designs\n- **Full-Stack Capability**: You comfortably work across backend APIs, frontend UI, and deployment concerns\n- **Problem-Solving Approach**: You break down complex tasks into manageable steps\n\n## Action Items\n\nPriority order:\n1. Spend 1-2 hours learning TypeScript utility types and discriminated unions; apply to your connection data structures\n2. Document security patterns for your project (what data is safe to display, filtering/masking functions)\n3. Study one article on advanced React patterns and apply one pattern to your current UI work\n4. Set up a code review checklist focused on type safety and data security for future PRs\n\n## Curated Learning Resources\n\n### For: Advanced TypeScript Patterns\n\n1. **TypeScript's Advanced Types: Generics, Utility Types, and Conditional Types** - HackerNews, October 2024\n   Deep dive into TypeScript's type system with practical examples and real-world applications. Covers discriminated unions, type guards, and patterns for ensuring compile-time safety in complex applications.\n   [Link to discussion]\n\n2. **Building Type-Safe APIs in TypeScript** - HackerNews, September 2024\n   Practical guide to designing APIs with TypeScript that catch errors early. Particularly relevant for your connection configuration work.\n   [Link to discussion]\n\n### For: Secure Data Handling in Frontend\n\n1. **Preventing Information Leakage in Web Applications** - HackerNews, August 2024\n   Comprehensive guide to data security in frontend applications, including filtering sensitive information, secure logging, and audit trails.\n   [Link to discussion]\n\n2. **OAuth and API Key Management Best Practices** - HackerNews, July 2024\n   How to safely handle authentication tokens and API keys in applications, with examples for different frameworks.\n   [Link to discussion]\n\n### For: Component Architecture and Responsive Design\n\n1. **Advanced React Patterns: Composition Over Configuration** - HackerNews\n   Explores component composition strategies that scale, with examples using modern React patterns.\n   [Link to discussion]\n\n2. **CSS Layout Mastery: Flexbox, Grid, and Container Queries** - HackerNews, October 2024\n   Learn responsive design patterns that prevent overflow issues and work across all screen sizes.\n   [Link to discussion]\n```\n\n## Tips and Best Practices\n\n- Run this analysis once a week to track your improvement trajectory over time\n- Pick one improvement area at a time and focus on it for a few days before moving to the next\n- Use the learning resources as a study guide; work through the recommended materials and practice applying the patterns\n- Revisit this report after focusing on an area for a week to see how your work patterns change\n- The learning resources are intentionally curated for your actual work, not generic topics, so they'll be highly relevant to what you're building\n\n## How Accuracy and Quality Are Maintained\n\nThis skill:\n- Analyzes your actual work patterns from timestamped chat history\n- Generates evidence-based recommendations grounded in real projects\n- Curates learning resources that directly address your identified gaps\n- Focuses on actionable improvements, not vague feedback\n- Provides specific time estimates based on complexity\n- Prioritizes areas that will have the most impact on your development velocity"
  },
  {
    "name": "doc-coauthoring",
    "description": "Guide users through a structured workflow for co-authoring documentation. Use when user wants to write documentation, proposals, technical specs, decision docs, or similar structured content. This workflow helps users efficiently transfer context, refine content through iteration, and verify the doc works for readers. Trigger when user mentions writing docs, creating proposals, drafting specs, or similar documentation tasks.",
    "body": "# Doc Co-Authoring Workflow\n\nThis skill provides a structured workflow for guiding users through collaborative document creation. Act as an active guide, walking users through three stages: Context Gathering, Refinement & Structure, and Reader Testing.\n\n## When to Offer This Workflow\n\n**Trigger conditions:**\n- User mentions writing documentation: \"write a doc\", \"draft a proposal\", \"create a spec\", \"write up\"\n- User mentions specific doc types: \"PRD\", \"design doc\", \"decision doc\", \"RFC\"\n- User seems to be starting a substantial writing task\n\n**Initial offer:**\nOffer the user a structured workflow for co-authoring the document. Explain the three stages:\n\n1. **Context Gathering**: User provides all relevant context while Claude asks clarifying questions\n2. **Refinement & Structure**: Iteratively build each section through brainstorming and editing\n3. **Reader Testing**: Test the doc with a fresh Claude (no context) to catch blind spots before others read it\n\nExplain that this approach helps ensure the doc works well when others read it (including when they paste it into Claude). Ask if they want to try this workflow or prefer to work freeform.\n\nIf user declines, work freeform. If user accepts, proceed to Stage 1.\n\n## Stage 1: Context Gathering\n\n**Goal:** Close the gap between what the user knows and what Claude knows, enabling smart guidance later.\n\n### Initial Questions\n\nStart by asking the user for meta-context about the document:\n\n1. What type of document is this? (e.g., technical spec, decision doc, proposal)\n2. Who's the primary audience?\n3. What's the desired impact when someone reads this?\n4. Is there a template or specific format to follow?\n5. Any other constraints or context to know?\n\nInform them they can answer in shorthand or dump information however works best for them.\n\n**If user provides a template or mentions a doc type:**\n- Ask if they have a template document to share\n- If they provide a link to a shared document, use the appropriate integration to fetch it\n- If they provide a file, read it\n\n**If user mentions editing an existing shared document:**\n- Use the appropriate integration to read the current state\n- Check for images without alt-text\n- If images exist without alt-text, explain that when others use Claude to understand the doc, Claude won't be able to see them. Ask if they want alt-text generated. If so, request they paste each image into chat for descriptive alt-text generation.\n\n### Info Dumping\n\nOnce initial questions are answered, encourage the user to dump all the context they have. Request information such as:\n- Background on the project/problem\n- Related team discussions or shared documents\n- Why alternative solutions aren't being used\n- Organizational context (team dynamics, past incidents, politics)\n- Timeline pressures or constraints\n- Technical architecture or dependencies\n- Stakeholder concerns\n\nAdvise them not to worry about organizing it - just get it all out. Offer multiple ways to provide context:\n- Info dump stream-of-consciousness\n- Point to team channels or threads to read\n- Link to shared documents\n\n**If integrations are available** (e.g., Slack, Teams, Google Drive, SharePoint, or other MCP servers), mention that these can be used to pull in context directly.\n\n**If no integrations are detected and in Claude.ai or Claude app:** Suggest they can enable connectors in their Claude settings to allow pulling context from messaging apps and document storage directly.\n\nInform them clarifying questions will be asked once they've done their initial dump.\n\n**During context gathering:**\n\n- If user mentions team channels or shared documents:\n  - If integrations available: Inform them the content will be read now, then use the appropriate integration\n  - If integrations not available: Explain lack of access. Suggest they enable connectors in Claude settings, or paste the relevant content directly.\n\n- If user mentions entities/projects that are unknown:\n  - Ask if connected tools should be searched to learn more\n  - Wait for user confirmation before searching\n\n- As user provides context, track what's being learned and what's still unclear\n\n**Asking clarifying questions:**\n\nWhen user signals they've done their initial dump (or after substantial context provided), ask clarifying questions to ensure understanding:\n\nGenerate 5-10 numbered questions based on gaps in the context.\n\nInform them they can use shorthand to answer (e.g., \"1: yes, 2: see #channel, 3: no because backwards compat\"), link to more docs, point to channels to read, or just keep info-dumping. Whatever's most efficient for them.\n\n**Exit condition:**\nSufficient context has been gathered when questions show understanding - when edge cases and trade-offs can be asked about without needing basics explained.\n\n**Transition:**\nAsk if there's any more context they want to provide at this stage, or if it's time to move on to drafting the document.\n\nIf user wants to add more, let them. When ready, proceed to Stage 2.\n\n## Stage 2: Refinement & Structure\n\n**Goal:** Build the document section by section through brainstorming, curation, and iterative refinement.\n\n**Instructions to user:**\nExplain that the document will be built section by section. For each section:\n1. Clarifying questions will be asked about what to include\n2. 5-20 options will be brainstormed\n3. User will indicate what to keep/remove/combine\n4. The section will be drafted\n5. It will be refined through surgical edits\n\nStart with whichever section has the most unknowns (usually the core decision/proposal), then work through the rest.\n\n**Section ordering:**\n\nIf the document structure is clear:\nAsk which section they'd like to start with.\n\nSuggest starting with whichever section has the most unknowns. For decision docs, that's usually the core proposal. For specs, it's typically the technical approach. Summary sections are best left for last.\n\nIf user doesn't know what sections they need:\nBased on the type of document and template, suggest 3-5 sections appropriate for the doc type.\n\nAsk if this structure works, or if they want to adjust it.\n\n**Once structure is agreed:**\n\nCreate the initial document structure with placeholder text for all sections.\n\n**If access to artifacts is available:**\nUse `create_file` to create an artifact. This gives both Claude and the user a scaffold to work from.\n\nInform them that the initial structure with placeholders for all sections will be created.\n\nCreate artifact with all section headers and brief placeholder text like \"[To be written]\" or \"[Content here]\".\n\nProvide the scaffold link and indicate it's time to fill in each section.\n\n**If no access to artifacts:**\nCreate a markdown file in the working directory. Name it appropriately (e.g., `decision-doc.md`, `technical-spec.md`).\n\nInform them that the initial structure with placeholders for all sections will be created.\n\nCreate file with all section headers and placeholder text.\n\nConfirm the filename has been created and indicate it's time to fill in each section.\n\n**For each section:**\n\n### Step 1: Clarifying Questions\n\nAnnounce work will begin on the [SECTION NAME] section. Ask 5-10 clarifying questions about what should be included:\n\nGenerate 5-10 specific questions based on context and section purpose.\n\nInform them they can answer in shorthand or just indicate what's important to cover.\n\n### Step 2: Brainstorming\n\nFor the [SECTION NAME] section, brainstorm [5-20] things that might be included, depending on the section's complexity. Look for:\n- Context shared that might have been forgotten\n- Angles or considerations not yet mentioned\n\nGenerate 5-20 numbered options based on section complexity. At the end, offer to brainstorm more if they want additional options.\n\n### Step 3: Curation\n\nAsk which points should be kept, removed, or combined. Request brief justifications to help learn priorities for the next sections.\n\nProvide examples:\n- \"Keep 1,4,7,9\"\n- \"Remove 3 (duplicates 1)\"\n- \"Remove 6 (audience already knows this)\"\n- \"Combine 11 and 12\"\n\n**If user gives freeform feedback** (e.g., \"looks good\" or \"I like most of it but...\") instead of numbered selections, extract their preferences and proceed. Parse what they want kept/removed/changed and apply it.\n\n### Step 4: Gap Check\n\nBased on what they've selected, ask if there's anything important missing for the [SECTION NAME] section.\n\n### Step 5: Drafting\n\nUse `str_replace` to replace the placeholder text for this section with the actual drafted content.\n\nAnnounce the [SECTION NAME] section will be drafted now based on what they've selected.\n\n**If using artifacts:**\nAfter drafting, provide a link to the artifact.\n\nAsk them to read through it and indicate what to change. Note that being specific helps learning for the next sections.\n\n**If using a file (no artifacts):**\nAfter drafting, confirm completion.\n\nInform them the [SECTION NAME] section has been drafted in [filename]. Ask them to read through it and indicate what to change. Note that being specific helps learning for the next sections.\n\n**Key instruction for user (include when drafting the first section):**\nProvide a note: Instead of editing the doc directly, ask them to indicate what to change. This helps learning of their style for future sections. For example: \"Remove the X bullet - already covered by Y\" or \"Make the third paragraph more concise\".\n\n### Step 6: Iterative Refinement\n\nAs user provides feedback:\n- Use `str_replace` to make edits (never reprint the whole doc)\n- **If using artifacts:** Provide link to artifact after each edit\n- **If using files:** Just confirm edits are complete\n- If user edits doc directly and asks to read it: mentally note the changes they made and keep them in mind for future sections (this shows their preferences)\n\n**Continue iterating** until user is satisfied with the section.\n\n### Quality Checking\n\nAfter 3 consecutive iterations with no substantial changes, ask if anything can be removed without losing important information.\n\nWhen section is done, confirm [SECTION NAME] is complete. Ask if ready to move to the next section.\n\n**Repeat for all sections.**\n\n### Near Completion\n\nAs approaching completion (80%+ of sections done), announce intention to re-read the entire document and check for:\n- Flow and consistency across sections\n- Redundancy or contradictions\n- Anything that feels like \"slop\" or generic filler\n- Whether every sentence carries weight\n\nRead entire document and provide feedback.\n\n**When all sections are drafted and refined:**\nAnnounce all sections are drafted. Indicate intention to review the complete document one more time.\n\nReview for overall coherence, flow, completeness.\n\nProvide any final suggestions.\n\nAsk if ready to move to Reader Testing, or if they want to refine anything else.\n\n## Stage 3: Reader Testing\n\n**Goal:** Test the document with a fresh Claude (no context bleed) to verify it works for readers.\n\n**Instructions to user:**\nExplain that testing will now occur to see if the document actually works for readers. This catches blind spots - things that make sense to the authors but might confuse others.\n\n### Testing Approach\n\n**If access to sub-agents is available (e.g., in Claude Code):**\n\nPerform the testing directly without user involvement.\n\n### Step 1: Predict Reader Questions\n\nAnnounce intention to predict what questions readers might ask when trying to discover this document.\n\nGenerate 5-10 questions that readers would realistically ask.\n\n### Step 2: Test with Sub-Agent\n\nAnnounce that these questions will be tested with a fresh Claude instance (no context from this conversation).\n\nFor each question, invoke a sub-agent with just the document content and the question.\n\nSummarize what Reader Claude got right/wrong for each question.\n\n### Step 3: Run Additional Checks\n\nAnnounce additional checks will be performed.\n\nInvoke sub-agent to check for ambiguity, false assumptions, contradictions.\n\nSummarize any issues found.\n\n### Step 4: Report and Fix\n\nIf issues found:\nReport that Reader Claude struggled with specific issues.\n\nList the specific issues.\n\nIndicate intention to fix these gaps.\n\nLoop back to refinement for problematic sections.\n\n---\n\n**If no access to sub-agents (e.g., claude.ai web interface):**\n\nThe user will need to do the testing manually.\n\n### Step 1: Predict Reader Questions\n\nAsk what questions people might ask when trying to discover this document. What would they type into Claude.ai?\n\nGenerate 5-10 questions that readers would realistically ask.\n\n### Step 2: Setup Testing\n\nProvide testing instructions:\n1. Open a fresh Claude conversation: https://claude.ai\n2. Paste or share the document content (if using a shared doc platform with connectors enabled, provide the link)\n3. Ask Reader Claude the generated questions\n\nFor each question, instruct Reader Claude to provide:\n- The answer\n- Whether anything was ambiguous or unclear\n- What knowledge/context the doc assumes is already known\n\nCheck if Reader Claude gives correct answers or misinterprets anything.\n\n### Step 3: Additional Checks\n\nAlso ask Reader Claude:\n- \"What in this doc might be ambiguous or unclear to readers?\"\n- \"What knowledge or context does this doc assume readers already have?\"\n- \"Are there any internal contradictions or inconsistencies?\"\n\n### Step 4: Iterate Based on Results\n\nAsk what Reader Claude got wrong or struggled with. Indicate intention to fix those gaps.\n\nLoop back to refinement for any problematic sections.\n\n---\n\n### Exit Condition (Both Approaches)\n\nWhen Reader Claude consistently answers questions correctly and doesn't surface new gaps or ambiguities, the doc is ready.\n\n## Final Review\n\nWhen Reader Testing passes:\nAnnounce the doc has passed Reader Claude testing. Before completion:\n\n1. Recommend they do a final read-through themselves - they own this document and are responsible for its quality\n2. Suggest double-checking any facts, links, or technical details\n3. Ask them to verify it achieves the impact they wanted\n\nAsk if they want one more review, or if the work is done.\n\n**If user wants final review, provide it. Otherwise:**\nAnnounce document completion. Provide a few final tips:\n- Consider linking this conversation in an appendix so readers can see how the doc was developed\n- Use appendices to provide depth without bloating the main doc\n- Update the doc as feedback is received from real readers\n\n## Tips for Effective Guidance\n\n**Tone:**\n- Be direct and procedural\n- Explain rationale briefly when it affects user behavior\n- Don't try to \"sell\" the approach - just execute it\n\n**Handling Deviations:**\n- If user wants to skip a stage: Ask if they want to skip this and write freeform\n- If user seems frustrated: Acknowledge this is taking longer than expected. Suggest ways to move faster\n- Always give user agency to adjust the process\n\n**Context Management:**\n- Throughout, if context is missing on something mentioned, proactively ask\n- Don't let gaps accumulate - address them as they come up\n\n**Artifact Management:**\n- Use `create_file` for drafting full sections\n- Use `str_replace` for all edits\n- Provide artifact link after every change\n- Never use artifacts for brainstorming lists - that's just conversation\n\n**Quality over Speed:**\n- Don't rush through stages\n- Each iteration should make meaningful improvements\n- The goal is a document that actually works for readers",
    "id": "doc-coauthoring",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/doc-coauthoring",
    "name_zh": "ÊñáÊ°£Âçè‰Ωú",
    "description_zh": "Guide users through a structured workflow for co-authoring documentation. ÈÄÇÁî®‰∫é user wants to write documentation, proposals, technical specs, decision docs, or similar structured content. This workflow helps users efficiently transfer context, refine content through iteration, and verify the doc works for readers. Trigger when user mentions writing docs, creating proposals, drafting specs, or similar documentation tasks.",
    "body_zh": "# Doc Co-Authoring Workflow\n\nThis skill provides a structured workflow for guiding users through collaborative document creation. Act as an active guide, walking users through three stages: Context Gathering, Refinement & Structure, and Reader Testing.\n\n## When to Offer This Workflow\n\n**Trigger conditions:**\n- User mentions writing documentation: \"write a doc\", \"draft a proposal\", \"create a spec\", \"write up\"\n- User mentions specific doc types: \"PRD\", \"design doc\", \"decision doc\", \"RFC\"\n- User seems to be starting a substantial writing task\n\n**Initial offer:**\nOffer the user a structured workflow for co-authoring the document. Explain the three stages:\n\n1. **Context Gathering**: User provides all relevant context while Claude asks clarifying questions\n2. **Refinement & Structure**: Iteratively build each section through brainstorming and editing\n3. **Reader Testing**: Test the doc with a fresh Claude (no context) to catch blind spots before others read it\n\nExplain that this approach helps ensure the doc works well when others read it (including when they paste it into Claude). Ask if they want to try this workflow or prefer to work freeform.\n\nIf user declines, work freeform. If user accepts, proceed to Stage 1.\n\n## Stage 1: Context Gathering\n\n**Goal:** Close the gap between what the user knows and what Claude knows, enabling smart guidance later.\n\n### Initial Questions\n\nStart by asking the user for meta-context about the document:\n\n1. What type of document is this? (e.g., technical spec, decision doc, proposal)\n2. Who's the primary audience?\n3. What's the desired impact when someone reads this?\n4. Is there a template or specific format to follow?\n5. Any other constraints or context to know?\n\nInform them they can answer in shorthand or dump information however works best for them.\n\n**If user provides a template or mentions a doc type:**\n- Ask if they have a template document to share\n- If they provide a link to a shared document, use the appropriate integration to fetch it\n- If they provide a file, read it\n\n**If user mentions editing an existing shared document:**\n- Use the appropriate integration to read the current state\n- Check for images without alt-text\n- If images exist without alt-text, explain that when others use Claude to understand the doc, Claude won't be able to see them. Ask if they want alt-text generated. If so, request they paste each image into chat for descriptive alt-text generation.\n\n### Info Dumping\n\nOnce initial questions are answered, encourage the user to dump all the context they have. Request information such as:\n- Background on the project/problem\n- Related team discussions or shared documents\n- Why alternative solutions aren't being used\n- Organizational context (team dynamics, past incidents, politics)\n- Timeline pressures or constraints\n- Technical architecture or dependencies\n- Stakeholder concerns\n\nAdvise them not to worry about organizing it - just get it all out. Offer multiple ways to provide context:\n- Info dump stream-of-consciousness\n- Point to team channels or threads to read\n- Link to shared documents\n\n**If integrations are available** (e.g., Slack, Teams, Google Drive, SharePoint, or other MCP servers), mention that these can be used to pull in context directly.\n\n**If no integrations are detected and in Claude.ai or Claude app:** Suggest they can enable connectors in their Claude settings to allow pulling context from messaging apps and document storage directly.\n\nInform them clarifying questions will be asked once they've done their initial dump.\n\n**During context gathering:**\n\n- If user mentions team channels or shared documents:\n  - If integrations available: Inform them the content will be read now, then use the appropriate integration\n  - If integrations not available: Explain lack of access. Suggest they enable connectors in Claude settings, or paste the relevant content directly.\n\n- If user mentions entities/projects that are unknown:\n  - Ask if connected tools should be searched to learn more\n  - Wait for user confirmation before searching\n\n- As user provides context, track what's being learned and what's still unclear\n\n**Asking clarifying questions:**\n\nWhen user signals they've done their initial dump (or after substantial context provided), ask clarifying questions to ensure understanding:\n\nGenerate 5-10 numbered questions based on gaps in the context.\n\nInform them they can use shorthand to answer (e.g., \"1: yes, 2: see #channel, 3: no because backwards compat\"), link to more docs, point to channels to read, or just keep info-dumping. Whatever's most efficient for them.\n\n**Exit condition:**\nSufficient context has been gathered when questions show understanding - when edge cases and trade-offs can be asked about without needing basics explained.\n\n**Transition:**\nAsk if there's any more context they want to provide at this stage, or if it's time to move on to drafting the document.\n\nIf user wants to add more, let them. When ready, proceed to Stage 2.\n\n## Stage 2: Refinement & Structure\n\n**Goal:** Build the document section by section through brainstorming, curation, and iterative refinement.\n\n**Instructions to user:**\nExplain that the document will be built section by section. For each section:\n1. Clarifying questions will be asked about what to include\n2. 5-20 options will be brainstormed\n3. User will indicate what to keep/remove/combine\n4. The section will be drafted\n5. It will be refined through surgical edits\n\nStart with whichever section has the most unknowns (usually the core decision/proposal), then work through the rest.\n\n**Section ordering:**\n\nIf the document structure is clear:\nAsk which section they'd like to start with.\n\nSuggest starting with whichever section has the most unknowns. For decision docs, that's usually the core proposal. For specs, it's typically the technical approach. Summary sections are best left for last.\n\nIf user doesn't know what sections they need:\nBased on the type of document and template, suggest 3-5 sections appropriate for the doc type.\n\nAsk if this structure works, or if they want to adjust it.\n\n**Once structure is agreed:**\n\nCreate the initial document structure with placeholder text for all sections.\n\n**If access to artifacts is available:**\nUse `create_file` to create an artifact. This gives both Claude and the user a scaffold to work from.\n\nInform them that the initial structure with placeholders for all sections will be created.\n\nCreate artifact with all section headers and brief placeholder text like \"[To be written]\" or \"[Content here]\".\n\nProvide the scaffold link and indicate it's time to fill in each section.\n\n**If no access to artifacts:**\nCreate a markdown file in the working directory. Name it appropriately (e.g., `decision-doc.md`, `technical-spec.md`).\n\nInform them that the initial structure with placeholders for all sections will be created.\n\nCreate file with all section headers and placeholder text.\n\nConfirm the filename has been created and indicate it's time to fill in each section.\n\n**For each section:**\n\n### Step 1: Clarifying Questions\n\nAnnounce work will begin on the [SECTION NAME] section. Ask 5-10 clarifying questions about what should be included:\n\nGenerate 5-10 specific questions based on context and section purpose.\n\nInform them they can answer in shorthand or just indicate what's important to cover.\n\n### Step 2: Brainstorming\n\nFor the [SECTION NAME] section, brainstorm [5-20] things that might be included, depending on the section's complexity. Look for:\n- Context shared that might have been forgotten\n- Angles or considerations not yet mentioned\n\nGenerate 5-20 numbered options based on section complexity. At the end, offer to brainstorm more if they want additional options.\n\n### Step 3: Curation\n\nAsk which points should be kept, removed, or combined. Request brief justifications to help learn priorities for the next sections.\n\nProvide examples:\n- \"Keep 1,4,7,9\"\n- \"Remove 3 (duplicates 1)\"\n- \"Remove 6 (audience already knows this)\"\n- \"Combine 11 and 12\"\n\n**If user gives freeform feedback** (e.g., \"looks good\" or \"I like most of it but...\") instead of numbered selections, extract their preferences and proceed. Parse what they want kept/removed/changed and apply it.\n\n### Step 4: Gap Check\n\nBased on what they've selected, ask if there's anything important missing for the [SECTION NAME] section.\n\n### Step 5: Drafting\n\nUse `str_replace` to replace the placeholder text for this section with the actual drafted content.\n\nAnnounce the [SECTION NAME] section will be drafted now based on what they've selected.\n\n**If using artifacts:**\nAfter drafting, provide a link to the artifact.\n\nAsk them to read through it and indicate what to change. Note that being specific helps learning for the next sections.\n\n**If using a file (no artifacts):**\nAfter drafting, confirm completion.\n\nInform them the [SECTION NAME] section has been drafted in [filename]. Ask them to read through it and indicate what to change. Note that being specific helps learning for the next sections.\n\n**Key instruction for user (include when drafting the first section):**\nProvide a note: Instead of editing the doc directly, ask them to indicate what to change. This helps learning of their style for future sections. For example: \"Remove the X bullet - already covered by Y\" or \"Make the third paragraph more concise\".\n\n### Step 6: Iterative Refinement\n\nAs user provides feedback:\n- Use `str_replace` to make edits (never reprint the whole doc)\n- **If using artifacts:** Provide link to artifact after each edit\n- **If using files:** Just confirm edits are complete\n- If user edits doc directly and asks to read it: mentally note the changes they made and keep them in mind for future sections (this shows their preferences)\n\n**Continue iterating** until user is satisfied with the section.\n\n### Quality Checking\n\nAfter 3 consecutive iterations with no substantial changes, ask if anything can be removed without losing important information.\n\nWhen section is done, confirm [SECTION NAME] is complete. Ask if ready to move to the next section.\n\n**Repeat for all sections.**\n\n### Near Completion\n\nAs approaching completion (80%+ of sections done), announce intention to re-read the entire document and check for:\n- Flow and consistency across sections\n- Redundancy or contradictions\n- Anything that feels like \"slop\" or generic filler\n- Whether every sentence carries weight\n\nRead entire document and provide feedback.\n\n**When all sections are drafted and refined:**\nAnnounce all sections are drafted. Indicate intention to review the complete document one more time.\n\nReview for overall coherence, flow, completeness.\n\nProvide any final suggestions.\n\nAsk if ready to move to Reader Testing, or if they want to refine anything else.\n\n## Stage 3: Reader Testing\n\n**Goal:** Test the document with a fresh Claude (no context bleed) to verify it works for readers.\n\n**Instructions to user:**\nExplain that testing will now occur to see if the document actually works for readers. This catches blind spots - things that make sense to the authors but might confuse others.\n\n### Testing Approach\n\n**If access to sub-agents is available (e.g., in Claude Code):**\n\nPerform the testing directly without user involvement.\n\n### Step 1: Predict Reader Questions\n\nAnnounce intention to predict what questions readers might ask when trying to discover this document.\n\nGenerate 5-10 questions that readers would realistically ask.\n\n### Step 2: Test with Sub-Agent\n\nAnnounce that these questions will be tested with a fresh Claude instance (no context from this conversation).\n\nFor each question, invoke a sub-agent with just the document content and the question.\n\nSummarize what Reader Claude got right/wrong for each question.\n\n### Step 3: Run Additional Checks\n\nAnnounce additional checks will be performed.\n\nInvoke sub-agent to check for ambiguity, false assumptions, contradictions.\n\nSummarize any issues found.\n\n### Step 4: Report and Fix\n\nIf issues found:\nReport that Reader Claude struggled with specific issues.\n\nList the specific issues.\n\nIndicate intention to fix these gaps.\n\nLoop back to refinement for problematic sections.\n\n---\n\n**If no access to sub-agents (e.g., claude.ai web interface):**\n\nThe user will need to do the testing manually.\n\n### Step 1: Predict Reader Questions\n\nAsk what questions people might ask when trying to discover this document. What would they type into Claude.ai?\n\nGenerate 5-10 questions that readers would realistically ask.\n\n### Step 2: Setup Testing\n\nProvide testing instructions:\n1. Open a fresh Claude conversation: https://claude.ai\n2. Paste or share the document content (if using a shared doc platform with connectors enabled, provide the link)\n3. Ask Reader Claude the generated questions\n\nFor each question, instruct Reader Claude to provide:\n- The answer\n- Whether anything was ambiguous or unclear\n- What knowledge/context the doc assumes is already known\n\nCheck if Reader Claude gives correct answers or misinterprets anything.\n\n### Step 3: Additional Checks\n\nAlso ask Reader Claude:\n- \"What in this doc might be ambiguous or unclear to readers?\"\n- \"What knowledge or context does this doc assume readers already have?\"\n- \"Are there any internal contradictions or inconsistencies?\"\n\n### Step 4: Iterate Based on Results\n\nAsk what Reader Claude got wrong or struggled with. Indicate intention to fix those gaps.\n\nLoop back to refinement for any problematic sections.\n\n---\n\n### Exit Condition (Both Approaches)\n\nWhen Reader Claude consistently answers questions correctly and doesn't surface new gaps or ambiguities, the doc is ready.\n\n## Final Review\n\nWhen Reader Testing passes:\nAnnounce the doc has passed Reader Claude testing. Before completion:\n\n1. Recommend they do a final read-through themselves - they own this document and are responsible for its quality\n2. Suggest double-checking any facts, links, or technical details\n3. Ask them to verify it achieves the impact they wanted\n\nAsk if they want one more review, or if the work is done.\n\n**If user wants final review, provide it. Otherwise:**\nAnnounce document completion. Provide a few final tips:\n- Consider linking this conversation in an appendix so readers can see how the doc was developed\n- Use appendices to provide depth without bloating the main doc\n- Update the doc as feedback is received from real readers\n\n## Tips for Effective Guidance\n\n**Tone:**\n- Be direct and procedural\n- Explain rationale briefly when it affects user behavior\n- Don't try to \"sell\" the approach - just execute it\n\n**Handling Deviations:**\n- If user wants to skip a stage: Ask if they want to skip this and write freeform\n- If user seems frustrated: Acknowledge this is taking longer than expected. Suggest ways to move faster\n- Always give user agency to adjust the process\n\n**Context Management:**\n- Throughout, if context is missing on something mentioned, proactively ask\n- Don't let gaps accumulate - address them as they come up\n\n**Artifact Management:**\n- Use `create_file` for drafting full sections\n- Use `str_replace` for all edits\n- Provide artifact link after every change\n- Never use artifacts for brainstorming lists - that's just conversation\n\n**Quality over Speed:**\n- Don't rush through stages\n- Each iteration should make meaningful improvements\n- The goal is a document that actually works for readers"
  },
  {
    "name": "docx",
    "description": "Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. When Claude needs to work with professional documents (.docx files) for creating new documents, modifying content, working with tracked changes, or adding comments.",
    "body": "# DOCX Processing\n\n## Workflow Decision Tree\n\n- **Reading/Analyzing**: Use text extraction or raw XML access\n- **Creating New Document**: Use docx-js (JavaScript)\n- **Editing Existing**: Use OOXML editing or redlining workflow\n\n## Reading Content\n\n### Text Extraction with Pandoc\n```bash\n# Convert to markdown with tracked changes\npandoc --track-changes=all file.docx -o output.md\n```\n\n### Raw XML Access\n```bash\n# Unpack document\nunzip document.docx -d unpacked/\n# Key files:\n# word/document.xml - Main content\n# word/comments.xml - Comments\n# word/media/ - Images\n```\n\n## Creating New Documents (docx-js)\n\n```javascript\nimport { Document, Paragraph, TextRun, Packer } from 'docx';\nimport fs from 'fs';\n\nconst doc = new Document({\n  sections: [{\n    children: [\n      new Paragraph({\n        children: [\n          new TextRun({ text: \"Hello \", bold: true }),\n          new TextRun({ text: \"World\", italics: true })\n        ]\n      })\n    ]\n  }]\n});\n\nconst buffer = await Packer.toBuffer(doc);\nfs.writeFileSync('document.docx', buffer);\n```\n\n## Editing Existing Documents\n\n### Simple Edits\n1. Unpack: `unzip doc.docx -d unpacked/`\n2. Edit `word/document.xml`\n3. Repack: `cd unpacked && zip -r ../edited.docx .`\n\n### Tracked Changes (Redlining)\nFor professional documents, use tracked changes:\n\n```xml\n<!-- Deletion -->\n<w:del w:author=\"Author\" w:date=\"2025-01-01T00:00:00Z\">\n  <w:r><w:delText>old text</w:delText></w:r>\n</w:del>\n\n<!-- Insertion -->\n<w:ins w:author=\"Author\" w:date=\"2025-01-01T00:00:00Z\">\n  <w:r><w:t>new text</w:t></w:r>\n</w:ins>\n```\n\n## Converting to Images\n\n```bash\n# DOCX to PDF\nsoffice --headless --convert-to pdf document.docx\n\n# PDF to images\npdftoppm -jpeg -r 150 document.pdf page\n```\n\n## Best Practices\n\n- Use Pandoc for text extraction\n- Use docx-js for creating new documents\n- For legal/business docs, always use tracked changes\n- Preserve original RSIDs when editing",
    "id": "docx",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/docx",
    "name_zh": "Word ÊñáÊ°£Â§ÑÁêÜ",
    "description_zh": "Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. When Claude needs to work with professional documents (.docx files) for creating new documents, modifying content, working with tracked changes, or adding comments.",
    "body_zh": "# DOCX Processing\n\n## Workflow Decision Tree\n\n- **Reading/Analyzing**: Use text extraction or raw XML access\n- **Creating New Document**: Use docx-js (JavaScript)\n- **Editing Existing**: Use OOXML editing or redlining workflow\n\n## Reading Content\n\n### Text Extraction with Pandoc\n```bash\n# Convert to markdown with tracked changes\npandoc --track-changes=all file.docx -o output.md\n```\n\n### Raw XML Access\n```bash\n# Unpack document\nunzip document.docx -d unpacked/\n# Key files:\n# word/document.xml - Main content\n# word/comments.xml - Comments\n# word/media/ - Images\n```\n\n## Creating New Documents (docx-js)\n\n```javascript\nimport { Document, Paragraph, TextRun, Packer } from 'docx';\nimport fs from 'fs';\n\nconst doc = new Document({\n  sections: [{\n    children: [\n      new Paragraph({\n        children: [\n          new TextRun({ text: \"Hello \", bold: true }),\n          new TextRun({ text: \"World\", italics: true })\n        ]\n      })\n    ]\n  }]\n});\n\nconst buffer = await Packer.toBuffer(doc);\nfs.writeFileSync('document.docx', buffer);\n```\n\n## Editing Existing Documents\n\n### Simple Edits\n1. Unpack: `unzip doc.docx -d unpacked/`\n2. Edit `word/document.xml`\n3. Repack: `cd unpacked && zip -r ../edited.docx .`\n\n### Tracked Changes (Redlining)\nFor professional documents, use tracked changes:\n\n```xml\n<!-- Deletion -->\n<w:del w:author=\"Author\" w:date=\"2025-01-01T00:00:00Z\">\n  <w:r><w:delText>old text</w:delText></w:r>\n</w:del>\n\n<!-- Insertion -->\n<w:ins w:author=\"Author\" w:date=\"2025-01-01T00:00:00Z\">\n  <w:r><w:t>new text</w:t></w:r>\n</w:ins>\n```\n\n## Converting to Images\n\n```bash\n# DOCX to PDF\nsoffice --headless --convert-to pdf document.docx\n\n# PDF to images\npdftoppm -jpeg -r 150 document.pdf page\n```\n\n## Best Practices\n\n- Use Pandoc for text extraction\n- Use docx-js for creating new documents\n- For legal/business docs, always use tracked changes\n- Preserve original RSIDs when editing"
  },
  {
    "name": "domain-name-brainstormer",
    "description": "Generates creative domain name ideas for your project and checks availability across multiple TLDs (.com, .io, .dev, .ai, etc.). Saves hours of brainstorming and manual checking.",
    "body": "# Domain Name Brainstormer\n\nThis skill helps you find the perfect domain name for your project by generating creative options and checking what's actually available to register.\n\n## When to Use This Skill\n\n- Starting a new project or company\n- Launching a product or service\n- Creating a personal brand or portfolio site\n- Rebranding an existing project\n- Registering a domain for a side project\n- Finding available alternatives when your first choice is taken\n\n## What This Skill Does\n\n1. **Understands Your Project**: Analyzes what you're building and who it's for\n2. **Generates Creative Names**: Creates relevant, memorable domain options\n3. **Checks Availability**: Verifies which domains are actually available across multiple TLDs\n4. **Multiple Extensions**: Suggests .com, .io, .dev, .ai, .app, and more\n5. **Provides Alternatives**: Offers variations if top choices are taken\n6. **Branding Insights**: Explains why certain names work well\n\n## How to Use\n\n### Basic Brainstorming\n\n```\nI'm building a project management tool for remote teams. \nSuggest domain names.\n```\n\n```\nHelp me brainstorm domain names for a personal finance app\n```\n\n### Specific Preferences\n\n```\nI need a domain name for my AI writing assistant. \nPrefer short names with .ai or .io extension.\n```\n\n### With Keywords\n\n```\nSuggest domain names using the words \"pixel\" or \"studio\" \nfor my design agency\n```\n\n## Example\n\n**User**: \"I'm building a tool for developers to share code snippets. Suggest creative domain names.\"\n\n**Output**:\n```\nAnalyzing your project...\nTarget audience: Developers\nKey features: Code sharing, snippets, collaboration\n\nüéØ Domain Name Suggestions\n\n## Available (.com)\n1. ‚úì snippetbox.com - Clear, memorable, available!\n   Why: Directly describes the product, easy to remember\n\n2. ‚úì codeclip.com - Short and snappy\n   Why: Implies quick code sharing, only 8 characters\n\n3. ‚úì devpaste.com - Developer-focused\n   Why: Familiar to devs (like pastebin), clear purpose\n\n## Available (Alternative TLDs)\n4. ‚úì snippet.dev - Perfect extension for developers\n   Why: .dev extension signals developer tool\n\n5. ‚úì codebox.io - Tech-forward\n   Why: .io popular with tech startups, clean name\n\n6. ‚úì sharecode.app - Descriptive\n   Why: .app extension, clearly states the action\n\n## Premium/Taken (.com)\n- codeshare.com (Taken, est. $2,500)\n- snippets.com (Taken, premium domain)\n\n## Recommendations\n\nüèÜ Top Pick: snippet.dev\n- Perfect for developer audience\n- Short and memorable  \n- .dev extension adds credibility\n- Available now!\n\nü•à Runner-up: snippetbox.com\n- .com is universally recognized\n- Slightly longer but descriptive\n- Great brandability\n\nNext steps:\n1. Register your favorite before someone else does!\n2. Want me to check more variations?\n3. Need help with logo ideas for these names?\n```\n\n**Inspired by:** Ben Aiad's use case from Lenny's Newsletter\n\n## Domain Naming Tips\n\n### What Makes a Good Domain\n\n‚úì **Short**: Under 15 characters ideal\n‚úì **Memorable**: Easy to recall and spell\n‚úì **Pronounceable**: Can be said in conversation\n‚úì **Descriptive**: Hints at what you do\n‚úì **Brandable**: Unique enough to stand out\n‚úì **No hyphens**: Easier to share verbally\n\n### TLD Guide\n\n- **.com**: Universal, trusted, great for businesses\n- **.io**: Tech startups, developer tools\n- **.dev**: Developer-focused products\n- **.ai**: AI/ML products\n- **.app**: Mobile or web applications\n- **.co**: Alternative to .com\n- **.xyz**: Modern, creative projects\n- **.design**: Creative/design agencies\n- **.tech**: Technology companies\n\n## Advanced Features\n\n### Check Similar Variations\n\n```\nCheck availability for \"codebase\" and similar variations \nacross .com, .io, .dev\n```\n\n### Industry-Specific\n\n```\nSuggest domain names for a sustainable fashion brand, \nchecking .eco and .fashion TLDs\n```\n\n### Multilingual Options\n\n```\nBrainstorm domain names in English and Spanish for \na language learning app\n```\n\n### Competitor Analysis\n\n```\nShow me domain patterns used by successful project \nmanagement tools, then suggest similar available ones\n```\n\n## Example Workflows\n\n### Startup Launch\n1. Describe your startup idea\n2. Get 10-15 domain suggestions across TLDs\n3. Review availability and pricing\n4. Pick top 3 favorites\n5. Register immediately\n\n### Personal Brand\n1. Share your name and profession\n2. Get variations (firstname.com, firstnamelastname.dev, etc.)\n3. Check social media handle availability too\n4. Register consistent brand across platforms\n\n### Product Naming\n1. Describe product and target market\n2. Get creative, brandable names\n3. Check trademark conflicts\n4. Verify domain and social availability\n5. Test names with target audience\n\n## Tips for Success\n\n1. **Act Fast**: Good domains get taken quickly\n2. **Register Variations**: Get .com and .io to protect brand\n3. **Avoid Numbers**: Hard to communicate verbally\n4. **Check Social Media**: Make sure @username is available too\n5. **Say It Out Loud**: Test if it's easy to pronounce\n6. **Check Trademarks**: Ensure no legal conflicts\n7. **Think Long-term**: Will it still make sense in 5 years?\n\n## Pricing Context\n\nWhen suggesting domains, I'll note:\n- Standard domains: ~$10-15/year\n- Premium TLDs (.io, .ai): ~$30-50/year\n- Taken domains: Market price if listed\n- Premium domains: $hundreds to $thousands\n\n## Related Tools\n\nAfter picking a domain:\n- Check logo design options\n- Verify social media handles\n- Research trademark availability\n- Plan brand identity colors/fonts",
    "id": "domain-name-brainstormer",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/domain-name-brainstormer",
    "name_zh": "ÂüüÂêçÂ§¥ËÑëÈ£éÊö¥",
    "description_zh": "ÁîüÊàês creative domain name ideas for your project and checks availability across multiple TLDs (.com, .io, .dev, .ai, etc.). Saves hours of brainstorming and manual checking.",
    "body_zh": "# Domain Name Brainstormer\n\nThis skill helps you find the perfect domain name for your project by generating creative options and checking what's actually available to register.\n\n## When to Use This Skill\n\n- Starting a new project or company\n- Launching a product or service\n- Creating a personal brand or portfolio site\n- Rebranding an existing project\n- Registering a domain for a side project\n- Finding available alternatives when your first choice is taken\n\n## What This Skill Does\n\n1. **Understands Your Project**: Analyzes what you're building and who it's for\n2. **Generates Creative Names**: Creates relevant, memorable domain options\n3. **Checks Availability**: Verifies which domains are actually available across multiple TLDs\n4. **Multiple Extensions**: Suggests .com, .io, .dev, .ai, .app, and more\n5. **Provides Alternatives**: Offers variations if top choices are taken\n6. **Branding Insights**: Explains why certain names work well\n\n## How to Use\n\n### Basic Brainstorming\n\n```\nI'm building a project management tool for remote teams. \nSuggest domain names.\n```\n\n```\nHelp me brainstorm domain names for a personal finance app\n```\n\n### Specific Preferences\n\n```\nI need a domain name for my AI writing assistant. \nPrefer short names with .ai or .io extension.\n```\n\n### With Keywords\n\n```\nSuggest domain names using the words \"pixel\" or \"studio\" \nfor my design agency\n```\n\n## Example\n\n**User**: \"I'm building a tool for developers to share code snippets. Suggest creative domain names.\"\n\n**Output**:\n```\nAnalyzing your project...\nTarget audience: Developers\nKey features: Code sharing, snippets, collaboration\n\nüéØ Domain Name Suggestions\n\n## Available (.com)\n1. ‚úì snippetbox.com - Clear, memorable, available!\n   Why: Directly describes the product, easy to remember\n\n2. ‚úì codeclip.com - Short and snappy\n   Why: Implies quick code sharing, only 8 characters\n\n3. ‚úì devpaste.com - Developer-focused\n   Why: Familiar to devs (like pastebin), clear purpose\n\n## Available (Alternative TLDs)\n4. ‚úì snippet.dev - Perfect extension for developers\n   Why: .dev extension signals developer tool\n\n5. ‚úì codebox.io - Tech-forward\n   Why: .io popular with tech startups, clean name\n\n6. ‚úì sharecode.app - Descriptive\n   Why: .app extension, clearly states the action\n\n## Premium/Taken (.com)\n- codeshare.com (Taken, est. $2,500)\n- snippets.com (Taken, premium domain)\n\n## Recommendations\n\nüèÜ Top Pick: snippet.dev\n- Perfect for developer audience\n- Short and memorable  \n- .dev extension adds credibility\n- Available now!\n\nü•à Runner-up: snippetbox.com\n- .com is universally recognized\n- Slightly longer but descriptive\n- Great brandability\n\nNext steps:\n1. Register your favorite before someone else does!\n2. Want me to check more variations?\n3. Need help with logo ideas for these names?\n```\n\n**Inspired by:** Ben Aiad's use case from Lenny's Newsletter\n\n## Domain Naming Tips\n\n### What Makes a Good Domain\n\n‚úì **Short**: Under 15 characters ideal\n‚úì **Memorable**: Easy to recall and spell\n‚úì **Pronounceable**: Can be said in conversation\n‚úì **Descriptive**: Hints at what you do\n‚úì **Brandable**: Unique enough to stand out\n‚úì **No hyphens**: Easier to share verbally\n\n### TLD Guide\n\n- **.com**: Universal, trusted, great for businesses\n- **.io**: Tech startups, developer tools\n- **.dev**: Developer-focused products\n- **.ai**: AI/ML products\n- **.app**: Mobile or web applications\n- **.co**: Alternative to .com\n- **.xyz**: Modern, creative projects\n- **.design**: Creative/design agencies\n- **.tech**: Technology companies\n\n## Advanced Features\n\n### Check Similar Variations\n\n```\nCheck availability for \"codebase\" and similar variations \nacross .com, .io, .dev\n```\n\n### Industry-Specific\n\n```\nSuggest domain names for a sustainable fashion brand, \nchecking .eco and .fashion TLDs\n```\n\n### Multilingual Options\n\n```\nBrainstorm domain names in English and Spanish for \na language learning app\n```\n\n### Competitor Analysis\n\n```\nShow me domain patterns used by successful project \nmanagement tools, then suggest similar available ones\n```\n\n## Example Workflows\n\n### Startup Launch\n1. Describe your startup idea\n2. Get 10-15 domain suggestions across TLDs\n3. Review availability and pricing\n4. Pick top 3 favorites\n5. Register immediately\n\n### Personal Brand\n1. Share your name and profession\n2. Get variations (firstname.com, firstnamelastname.dev, etc.)\n3. Check social media handle availability too\n4. Register consistent brand across platforms\n\n### Product Naming\n1. Describe product and target market\n2. Get creative, brandable names\n3. Check trademark conflicts\n4. Verify domain and social availability\n5. Test names with target audience\n\n## Tips for Success\n\n1. **Act Fast**: Good domains get taken quickly\n2. **Register Variations**: Get .com and .io to protect brand\n3. **Avoid Numbers**: Hard to communicate verbally\n4. **Check Social Media**: Make sure @username is available too\n5. **Say It Out Loud**: Test if it's easy to pronounce\n6. **Check Trademarks**: Ensure no legal conflicts\n7. **Think Long-term**: Will it still make sense in 5 years?\n\n## Pricing Context\n\nWhen suggesting domains, I'll note:\n- Standard domains: ~$10-15/year\n- Premium TLDs (.io, .ai): ~$30-50/year\n- Taken domains: Market price if listed\n- Premium domains: $hundreds to $thousands\n\n## Related Tools\n\nAfter picking a domain:\n- Check logo design options\n- Verify social media handles\n- Research trademark availability\n- Plan brand identity colors/fonts"
  },
  {
    "name": "expo-app-design",
    "description": "Build beautiful cross-platform mobile apps with Expo Router, NativeWind, and React Native.",
    "body": "# Expo App Design\n\nBuild beautiful cross-platform mobile apps with Expo Router, NativeWind, and React Native.\n\n## When to Use\n\n- Building mobile apps with Expo\n- Navigation with Expo Router\n- Styling with NativeWind/Tailwind\n- Native tabs and animations\n\n## Source\n\nThis skill references patterns from [Expo's skills](https://github.com/expo/skills).",
    "id": "expo-app-design",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/expo-app-design",
    "name_zh": "Expo Â∫îÁî®ËÆæËÆ°",
    "description_zh": "ÊûÑÂª∫ beautiful cross-platform mobile apps with Expo Router, NativeWind, and React Native.",
    "body_zh": "# Expo App Design\n\nBuild beautiful cross-platform mobile apps with Expo Router, NativeWind, and React Native.\n\n## When to Use\n\n- Building mobile apps with Expo\n- Navigation with Expo Router\n- Styling with NativeWind/Tailwind\n- Native tabs and animations\n\n## Source\n\nThis skill references patterns from [Expo's skills](https://github.com/expo/skills)."
  },
  {
    "name": "expo-deployment",
    "description": "Deploy Expo apps to iOS App Store, Android Play Store, and web.",
    "body": "# Expo Deployment\n\nDeploy Expo apps to iOS App Store, Android Play Store, and web.\n\n## When to Use\n\n- Publishing to App Store / Play Store\n- EAS Build configuration\n- OTA updates\n- CI/CD workflows for mobile\n\n## Source\n\nThis skill references patterns from [Expo's skills](https://github.com/expo/skills).",
    "id": "expo-deployment",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/expo-deployment",
    "name_zh": "Expo ÈÉ®ÁΩ≤",
    "description_zh": "Deploy Expo apps to iOS App Store, Android Play Store, and web.",
    "body_zh": "# Expo Deployment\n\nDeploy Expo apps to iOS App Store, Android Play Store, and web.\n\n## When to Use\n\n- Publishing to App Store / Play Store\n- EAS Build configuration\n- OTA updates\n- CI/CD workflows for mobile\n\n## Source\n\nThis skill references patterns from [Expo's skills](https://github.com/expo/skills)."
  },
  {
    "name": "file-organizer",
    "description": "Intelligently organizes your files and folders across your computer by understanding context, finding duplicates, suggesting better structures, and automating cleanup tasks. Reduces cognitive load and keeps your digital workspace tidy without manual effort.",
    "body": "# File Organizer\n\nThis skill acts as your personal organization assistant, helping you maintain a clean, logical file structure across your computer without the mental overhead of constant manual organization.\n\n## When to Use This Skill\n\n- Your Downloads folder is a chaotic mess\n- You can't find files because they're scattered everywhere\n- You have duplicate files taking up space\n- Your folder structure doesn't make sense anymore\n- You want to establish better organization habits\n- You're starting a new project and need a good structure\n- You're cleaning up before archiving old projects\n\n## What This Skill Does\n\n1. **Analyzes Current Structure**: Reviews your folders and files to understand what you have\n2. **Finds Duplicates**: Identifies duplicate files across your system\n3. **Suggests Organization**: Proposes logical folder structures based on your content\n4. **Automates Cleanup**: Moves, renames, and organizes files with your approval\n5. **Maintains Context**: Makes smart decisions based on file types, dates, and content\n6. **Reduces Clutter**: Identifies old files you probably don't need anymore\n\n## How to Use\n\n### From Your Home Directory\n\n```\ncd ~\n```\n\nThen run Claude Code and ask for help:\n\n```\nHelp me organize my Downloads folder\n```\n\n```\nFind duplicate files in my Documents folder\n```\n\n```\nReview my project directories and suggest improvements\n```\n\n### Specific Organization Tasks\n\n```\nOrganize these downloads into proper folders based on what they are\n```\n\n```\nFind duplicate files and help me decide which to keep\n```\n\n```\nClean up old files I haven't touched in 6+ months\n```\n\n```\nCreate a better folder structure for my [work/projects/photos/etc]\n```\n\n## Instructions\n\nWhen a user requests file organization help:\n\n1. **Understand the Scope**\n   \n   Ask clarifying questions:\n   - Which directory needs organization? (Downloads, Documents, entire home folder?)\n   - What's the main problem? (Can't find things, duplicates, too messy, no structure?)\n   - Any files or folders to avoid? (Current projects, sensitive data?)\n   - How aggressively to organize? (Conservative vs. comprehensive cleanup)\n\n2. **Analyze Current State**\n   \n   Review the target directory:\n   ```bash\n   # Get overview of current structure\n   ls -la [target_directory]\n   \n   # Check file types and sizes\n   find [target_directory] -type f -exec file {} \\; | head -20\n   \n   # Identify largest files\n   du -sh [target_directory]/* | sort -rh | head -20\n   \n   # Count file types\n   find [target_directory] -type f | sed 's/.*\\.//' | sort | uniq -c | sort -rn\n   ```\n   \n   Summarize findings:\n   - Total files and folders\n   - File type breakdown\n   - Size distribution\n   - Date ranges\n   - Obvious organization issues\n\n3. **Identify Organization Patterns**\n   \n   Based on the files, determine logical groupings:\n   \n   **By Type**:\n   - Documents (PDFs, DOCX, TXT)\n   - Images (JPG, PNG, SVG)\n   - Videos (MP4, MOV)\n   - Archives (ZIP, TAR, DMG)\n   - Code/Projects (directories with code)\n   - Spreadsheets (XLSX, CSV)\n   - Presentations (PPTX, KEY)\n   \n   **By Purpose**:\n   - Work vs. Personal\n   - Active vs. Archive\n   - Project-specific\n   - Reference materials\n   - Temporary/scratch files\n   \n   **By Date**:\n   - Current year/month\n   - Previous years\n   - Very old (archive candidates)\n\n4. **Find Duplicates**\n   \n   When requested, search for duplicates:\n   ```bash\n   # Find exact duplicates by hash\n   find [directory] -type f -exec md5 {} \\; | sort | uniq -d\n   \n   # Find files with same name\n   find [directory] -type f -printf '%f\\n' | sort | uniq -d\n   \n   # Find similar-sized files\n   find [directory] -type f -printf '%s %p\\n' | sort -n\n   ```\n   \n   For each set of duplicates:\n   - Show all file paths\n   - Display sizes and modification dates\n   - Recommend which to keep (usually newest or best-named)\n   - **Important**: Always ask for confirmation before deleting\n\n5. **Propose Organization Plan**\n   \n   Present a clear plan before making changes:\n   \n   ```markdown\n   # Organization Plan for [Directory]\n   \n   ## Current State\n   - X files across Y folders\n   - [Size] total\n   - File types: [breakdown]\n   - Issues: [list problems]\n   \n   ## Proposed Structure\n   \n   ```\n   [Directory]/\n   ‚îú‚îÄ‚îÄ Work/\n   ‚îÇ   ‚îú‚îÄ‚îÄ Projects/\n   ‚îÇ   ‚îú‚îÄ‚îÄ Documents/\n   ‚îÇ   ‚îî‚îÄ‚îÄ Archive/\n   ‚îú‚îÄ‚îÄ Personal/\n   ‚îÇ   ‚îú‚îÄ‚îÄ Photos/\n   ‚îÇ   ‚îú‚îÄ‚îÄ Documents/\n   ‚îÇ   ‚îî‚îÄ‚îÄ Media/\n   ‚îî‚îÄ‚îÄ Downloads/\n       ‚îú‚îÄ‚îÄ To-Sort/\n       ‚îî‚îÄ‚îÄ Archive/\n   ```\n   \n   ## Changes I'll Make\n   \n   1. **Create new folders**: [list]\n   2. **Move files**:\n      - X PDFs ‚Üí Work/Documents/\n      - Y images ‚Üí Personal/Photos/\n      - Z old files ‚Üí Archive/\n   3. **Rename files**: [any renaming patterns]\n   4. **Delete**: [duplicates or trash files]\n   \n   ## Files Needing Your Decision\n   \n   - [List any files you're unsure about]\n   \n   Ready to proceed? (yes/no/modify)\n   ```\n\n6. **Execute Organization**\n   \n   After approval, organize systematically:\n   \n   ```bash\n   # Create folder structure\n   mkdir -p \"path/to/new/folders\"\n   \n   # Move files with clear logging\n   mv \"old/path/file.pdf\" \"new/path/file.pdf\"\n   \n   # Rename files with consistent patterns\n   # Example: \"YYYY-MM-DD - Description.ext\"\n   ```\n   \n   **Important Rules**:\n   - Always confirm before deleting anything\n   - Log all moves for potential undo\n   - Preserve original modification dates\n   - Handle filename conflicts gracefully\n   - Stop and ask if you encounter unexpected situations\n\n7. **Provide Summary and Maintenance Tips**\n   \n   After organizing:\n   \n   ```markdown\n   # Organization Complete! ‚ú®\n   \n   ## What Changed\n   \n   - Created [X] new folders\n   - Organized [Y] files\n   - Freed [Z] GB by removing duplicates\n   - Archived [W] old files\n   \n   ## New Structure\n   \n   [Show the new folder tree]\n   \n   ## Maintenance Tips\n   \n   To keep this organized:\n   \n   1. **Weekly**: Sort new downloads\n   2. **Monthly**: Review and archive completed projects\n   3. **Quarterly**: Check for new duplicates\n   4. **Yearly**: Archive old files\n   \n   ## Quick Commands for You\n   \n   ```bash\n   # Find files modified this week\n   find . -type f -mtime -7\n   \n   # Sort downloads by type\n   [custom command for their setup]\n   \n   # Find duplicates\n   [custom command]\n   ```\n   \n   Want to organize another folder?\n   ```\n\n## Examples\n\n### Example 1: Organizing Downloads (From Justin Dielmann)\n\n**User**: \"My Downloads folder is a mess with 500+ files. Help me organize it.\"\n\n**Process**:\n1. Analyzes Downloads folder\n2. Finds patterns: work docs, personal photos, installers, random PDFs\n3. Proposes structure:\n   - Downloads/\n     - Work/\n     - Personal/\n     - Installers/ (DMG, PKG files)\n     - Archive/\n     - ToSort/ (things needing decisions)\n4. Asks for confirmation\n5. Moves files intelligently based on content and names\n6. Results: 500 files ‚Üí 5 organized folders\n\n### Example 2: Finding and Removing Duplicates\n\n**User**: \"Find duplicate files in my Documents and help me decide which to keep.\"\n\n**Output**:\n```markdown\n# Found 23 Sets of Duplicates (156 MB total)\n\n## Duplicate Set 1: \"proposal.pdf\"\n- `/Documents/proposal.pdf` (2.3 MB, modified: 2024-03-15)\n- `/Documents/old/proposal.pdf` (2.3 MB, modified: 2024-03-15)\n- `/Desktop/proposal.pdf` (2.3 MB, modified: 2024-03-10)\n\n**Recommendation**: Keep `/Documents/proposal.pdf` (most recent in correct location)\nDelete the other 2 copies?\n\n[Continue for all duplicates...]\n```\n\n### Example 3: Restructuring Projects Folder\n\n**User**: \"Review my ~/Projects directory and suggest improvements.\"\n\n**Output**:\n```markdown\n# Analysis of ~/Projects\n\n## Current Structure Issues\n- Mix of active and archived projects (3+ years old)\n- No consistent naming convention\n- Some projects at root, others in random subfolders\n- Duplicate folders (project-name, project-name-old, project-name-v2)\n\n## Proposed Structure\n\n```\nProjects/\n‚îú‚îÄ‚îÄ Active/\n‚îÇ   ‚îú‚îÄ‚îÄ client-work/\n‚îÇ   ‚îú‚îÄ‚îÄ side-projects/\n‚îÇ   ‚îî‚îÄ‚îÄ learning/\n‚îú‚îÄ‚îÄ Archive/\n‚îÇ   ‚îú‚îÄ‚îÄ 2022/\n‚îÇ   ‚îú‚îÄ‚îÄ 2023/\n‚îÇ   ‚îî‚îÄ‚îÄ 2024/\n‚îî‚îÄ‚îÄ Templates/\n```\n\n## Specific Changes\n1. Move 12 projects not touched since 2022 ‚Üí Archive/\n2. Consolidate 4 duplicate project folders\n3. Rename projects to consistent format: \"client-name-project-name\"\n4. Create Archive for old work\n\nWant me to implement this?\n```\n\n### Example 4: Organizing Photos by Date\n\n**User**: \"Organize my photo folders by year and month.\"\n\n**Output**: Creates structure like:\n```\nPhotos/\n‚îú‚îÄ‚îÄ 2023/\n‚îÇ   ‚îú‚îÄ‚îÄ 01-January/\n‚îÇ   ‚îú‚îÄ‚îÄ 02-February/\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ 2024/\n‚îÇ   ‚îú‚îÄ‚îÄ 01-January/\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îî‚îÄ‚îÄ Unsorted/\n```\n\nThen moves photos based on EXIF data or file modification dates.\n\n## Common Organization Tasks\n\n### Downloads Cleanup\n```\nOrganize my Downloads folder - move documents to Documents, \nimages to Pictures, keep installers separate, and archive files \nolder than 3 months.\n```\n\n### Project Organization\n```\nReview my Projects folder structure and help me separate active \nprojects from old ones I should archive.\n```\n\n### Duplicate Removal\n```\nFind all duplicate files in my Documents folder and help me \ndecide which ones to keep.\n```\n\n### Desktop Cleanup\n```\nMy Desktop is covered in files. Help me organize everything into \nmy Documents folder properly.\n```\n\n### Photo Organization\n```\nOrganize all photos in this folder by date (year/month) based \non when they were taken.\n```\n\n### Work/Personal Separation\n```\nHelp me separate my work files from personal files across my \nDocuments folder.\n```\n\n## Pro Tips\n\n1. **Start Small**: Begin with one messy folder (like Downloads) to build trust\n2. **Regular Maintenance**: Run weekly cleanup on Downloads\n3. **Consistent Naming**: Use \"YYYY-MM-DD - Description\" format for important files\n4. **Archive Aggressively**: Move old projects to Archive instead of deleting\n5. **Keep Active Separate**: Maintain clear boundaries between active and archived work\n6. **Trust the Process**: Let Claude handle the cognitive load of where things go\n\n## Best Practices\n\n### Folder Naming\n- Use clear, descriptive names\n- Avoid spaces (use hyphens or underscores)\n- Be specific: \"client-proposals\" not \"docs\"\n- Use prefixes for ordering: \"01-current\", \"02-archive\"\n\n### File Naming\n- Include dates: \"2024-10-17-meeting-notes.md\"\n- Be descriptive: \"q3-financial-report.xlsx\"\n- Avoid version numbers in names (use version control instead)\n- Remove download artifacts: \"document-final-v2 (1).pdf\" ‚Üí \"document.pdf\"\n\n### When to Archive\n- Projects not touched in 6+ months\n- Completed work that might be referenced later\n- Old versions after migration to new systems\n- Files you're hesitant to delete (archive first)\n\n## Related Use Cases\n\n- Setting up organization for a new computer\n- Preparing files for backup/archiving\n- Cleaning up before storage cleanup\n- Organizing shared team folders\n- Structuring new project directories",
    "id": "file-organizer",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/file-organizer",
    "name_zh": "Êñá‰ª∂Êï¥ÁêÜÂô®",
    "description_zh": "Intelligently organizes your files and folders across your computer by understanding context, finding duplicates, suggesting better structures, and automating cleanup tasks. Reduces cognitive load and keeps your digital workspace tidy without manual effort.",
    "body_zh": "# File Organizer\n\nThis skill acts as your personal organization assistant, helping you maintain a clean, logical file structure across your computer without the mental overhead of constant manual organization.\n\n## When to Use This Skill\n\n- Your Downloads folder is a chaotic mess\n- You can't find files because they're scattered everywhere\n- You have duplicate files taking up space\n- Your folder structure doesn't make sense anymore\n- You want to establish better organization habits\n- You're starting a new project and need a good structure\n- You're cleaning up before archiving old projects\n\n## What This Skill Does\n\n1. **Analyzes Current Structure**: Reviews your folders and files to understand what you have\n2. **Finds Duplicates**: Identifies duplicate files across your system\n3. **Suggests Organization**: Proposes logical folder structures based on your content\n4. **Automates Cleanup**: Moves, renames, and organizes files with your approval\n5. **Maintains Context**: Makes smart decisions based on file types, dates, and content\n6. **Reduces Clutter**: Identifies old files you probably don't need anymore\n\n## How to Use\n\n### From Your Home Directory\n\n```\ncd ~\n```\n\nThen run Claude Code and ask for help:\n\n```\nHelp me organize my Downloads folder\n```\n\n```\nFind duplicate files in my Documents folder\n```\n\n```\nReview my project directories and suggest improvements\n```\n\n### Specific Organization Tasks\n\n```\nOrganize these downloads into proper folders based on what they are\n```\n\n```\nFind duplicate files and help me decide which to keep\n```\n\n```\nClean up old files I haven't touched in 6+ months\n```\n\n```\nCreate a better folder structure for my [work/projects/photos/etc]\n```\n\n## Instructions\n\nWhen a user requests file organization help:\n\n1. **Understand the Scope**\n   \n   Ask clarifying questions:\n   - Which directory needs organization? (Downloads, Documents, entire home folder?)\n   - What's the main problem? (Can't find things, duplicates, too messy, no structure?)\n   - Any files or folders to avoid? (Current projects, sensitive data?)\n   - How aggressively to organize? (Conservative vs. comprehensive cleanup)\n\n2. **Analyze Current State**\n   \n   Review the target directory:\n   ```bash\n   # Get overview of current structure\n   ls -la [target_directory]\n   \n   # Check file types and sizes\n   find [target_directory] -type f -exec file {} \\; | head -20\n   \n   # Identify largest files\n   du -sh [target_directory]/* | sort -rh | head -20\n   \n   # Count file types\n   find [target_directory] -type f | sed 's/.*\\.//' | sort | uniq -c | sort -rn\n   ```\n   \n   Summarize findings:\n   - Total files and folders\n   - File type breakdown\n   - Size distribution\n   - Date ranges\n   - Obvious organization issues\n\n3. **Identify Organization Patterns**\n   \n   Based on the files, determine logical groupings:\n   \n   **By Type**:\n   - Documents (PDFs, DOCX, TXT)\n   - Images (JPG, PNG, SVG)\n   - Videos (MP4, MOV)\n   - Archives (ZIP, TAR, DMG)\n   - Code/Projects (directories with code)\n   - Spreadsheets (XLSX, CSV)\n   - Presentations (PPTX, KEY)\n   \n   **By Purpose**:\n   - Work vs. Personal\n   - Active vs. Archive\n   - Project-specific\n   - Reference materials\n   - Temporary/scratch files\n   \n   **By Date**:\n   - Current year/month\n   - Previous years\n   - Very old (archive candidates)\n\n4. **Find Duplicates**\n   \n   When requested, search for duplicates:\n   ```bash\n   # Find exact duplicates by hash\n   find [directory] -type f -exec md5 {} \\; | sort | uniq -d\n   \n   # Find files with same name\n   find [directory] -type f -printf '%f\\n' | sort | uniq -d\n   \n   # Find similar-sized files\n   find [directory] -type f -printf '%s %p\\n' | sort -n\n   ```\n   \n   For each set of duplicates:\n   - Show all file paths\n   - Display sizes and modification dates\n   - Recommend which to keep (usually newest or best-named)\n   - **Important**: Always ask for confirmation before deleting\n\n5. **Propose Organization Plan**\n   \n   Present a clear plan before making changes:\n   \n   ```markdown\n   # Organization Plan for [Directory]\n   \n   ## Current State\n   - X files across Y folders\n   - [Size] total\n   - File types: [breakdown]\n   - Issues: [list problems]\n   \n   ## Proposed Structure\n   \n   ```\n   [Directory]/\n   ‚îú‚îÄ‚îÄ Work/\n   ‚îÇ   ‚îú‚îÄ‚îÄ Projects/\n   ‚îÇ   ‚îú‚îÄ‚îÄ Documents/\n   ‚îÇ   ‚îî‚îÄ‚îÄ Archive/\n   ‚îú‚îÄ‚îÄ Personal/\n   ‚îÇ   ‚îú‚îÄ‚îÄ Photos/\n   ‚îÇ   ‚îú‚îÄ‚îÄ Documents/\n   ‚îÇ   ‚îî‚îÄ‚îÄ Media/\n   ‚îî‚îÄ‚îÄ Downloads/\n       ‚îú‚îÄ‚îÄ To-Sort/\n       ‚îî‚îÄ‚îÄ Archive/\n   ```\n   \n   ## Changes I'll Make\n   \n   1. **Create new folders**: [list]\n   2. **Move files**:\n      - X PDFs ‚Üí Work/Documents/\n      - Y images ‚Üí Personal/Photos/\n      - Z old files ‚Üí Archive/\n   3. **Rename files**: [any renaming patterns]\n   4. **Delete**: [duplicates or trash files]\n   \n   ## Files Needing Your Decision\n   \n   - [List any files you're unsure about]\n   \n   Ready to proceed? (yes/no/modify)\n   ```\n\n6. **Execute Organization**\n   \n   After approval, organize systematically:\n   \n   ```bash\n   # Create folder structure\n   mkdir -p \"path/to/new/folders\"\n   \n   # Move files with clear logging\n   mv \"old/path/file.pdf\" \"new/path/file.pdf\"\n   \n   # Rename files with consistent patterns\n   # Example: \"YYYY-MM-DD - Description.ext\"\n   ```\n   \n   **Important Rules**:\n   - Always confirm before deleting anything\n   - Log all moves for potential undo\n   - Preserve original modification dates\n   - Handle filename conflicts gracefully\n   - Stop and ask if you encounter unexpected situations\n\n7. **Provide Summary and Maintenance Tips**\n   \n   After organizing:\n   \n   ```markdown\n   # Organization Complete! ‚ú®\n   \n   ## What Changed\n   \n   - Created [X] new folders\n   - Organized [Y] files\n   - Freed [Z] GB by removing duplicates\n   - Archived [W] old files\n   \n   ## New Structure\n   \n   [Show the new folder tree]\n   \n   ## Maintenance Tips\n   \n   To keep this organized:\n   \n   1. **Weekly**: Sort new downloads\n   2. **Monthly**: Review and archive completed projects\n   3. **Quarterly**: Check for new duplicates\n   4. **Yearly**: Archive old files\n   \n   ## Quick Commands for You\n   \n   ```bash\n   # Find files modified this week\n   find . -type f -mtime -7\n   \n   # Sort downloads by type\n   [custom command for their setup]\n   \n   # Find duplicates\n   [custom command]\n   ```\n   \n   Want to organize another folder?\n   ```\n\n## Examples\n\n### Example 1: Organizing Downloads (From Justin Dielmann)\n\n**User**: \"My Downloads folder is a mess with 500+ files. Help me organize it.\"\n\n**Process**:\n1. Analyzes Downloads folder\n2. Finds patterns: work docs, personal photos, installers, random PDFs\n3. Proposes structure:\n   - Downloads/\n     - Work/\n     - Personal/\n     - Installers/ (DMG, PKG files)\n     - Archive/\n     - ToSort/ (things needing decisions)\n4. Asks for confirmation\n5. Moves files intelligently based on content and names\n6. Results: 500 files ‚Üí 5 organized folders\n\n### Example 2: Finding and Removing Duplicates\n\n**User**: \"Find duplicate files in my Documents and help me decide which to keep.\"\n\n**Output**:\n```markdown\n# Found 23 Sets of Duplicates (156 MB total)\n\n## Duplicate Set 1: \"proposal.pdf\"\n- `/Documents/proposal.pdf` (2.3 MB, modified: 2024-03-15)\n- `/Documents/old/proposal.pdf` (2.3 MB, modified: 2024-03-15)\n- `/Desktop/proposal.pdf` (2.3 MB, modified: 2024-03-10)\n\n**Recommendation**: Keep `/Documents/proposal.pdf` (most recent in correct location)\nDelete the other 2 copies?\n\n[Continue for all duplicates...]\n```\n\n### Example 3: Restructuring Projects Folder\n\n**User**: \"Review my ~/Projects directory and suggest improvements.\"\n\n**Output**:\n```markdown\n# Analysis of ~/Projects\n\n## Current Structure Issues\n- Mix of active and archived projects (3+ years old)\n- No consistent naming convention\n- Some projects at root, others in random subfolders\n- Duplicate folders (project-name, project-name-old, project-name-v2)\n\n## Proposed Structure\n\n```\nProjects/\n‚îú‚îÄ‚îÄ Active/\n‚îÇ   ‚îú‚îÄ‚îÄ client-work/\n‚îÇ   ‚îú‚îÄ‚îÄ side-projects/\n‚îÇ   ‚îî‚îÄ‚îÄ learning/\n‚îú‚îÄ‚îÄ Archive/\n‚îÇ   ‚îú‚îÄ‚îÄ 2022/\n‚îÇ   ‚îú‚îÄ‚îÄ 2023/\n‚îÇ   ‚îî‚îÄ‚îÄ 2024/\n‚îî‚îÄ‚îÄ Templates/\n```\n\n## Specific Changes\n1. Move 12 projects not touched since 2022 ‚Üí Archive/\n2. Consolidate 4 duplicate project folders\n3. Rename projects to consistent format: \"client-name-project-name\"\n4. Create Archive for old work\n\nWant me to implement this?\n```\n\n### Example 4: Organizing Photos by Date\n\n**User**: \"Organize my photo folders by year and month.\"\n\n**Output**: Creates structure like:\n```\nPhotos/\n‚îú‚îÄ‚îÄ 2023/\n‚îÇ   ‚îú‚îÄ‚îÄ 01-January/\n‚îÇ   ‚îú‚îÄ‚îÄ 02-February/\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ 2024/\n‚îÇ   ‚îú‚îÄ‚îÄ 01-January/\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îî‚îÄ‚îÄ Unsorted/\n```\n\nThen moves photos based on EXIF data or file modification dates.\n\n## Common Organization Tasks\n\n### Downloads Cleanup\n```\nOrganize my Downloads folder - move documents to Documents, \nimages to Pictures, keep installers separate, and archive files \nolder than 3 months.\n```\n\n### Project Organization\n```\nReview my Projects folder structure and help me separate active \nprojects from old ones I should archive.\n```\n\n### Duplicate Removal\n```\nFind all duplicate files in my Documents folder and help me \ndecide which ones to keep.\n```\n\n### Desktop Cleanup\n```\nMy Desktop is covered in files. Help me organize everything into \nmy Documents folder properly.\n```\n\n### Photo Organization\n```\nOrganize all photos in this folder by date (year/month) based \non when they were taken.\n```\n\n### Work/Personal Separation\n```\nHelp me separate my work files from personal files across my \nDocuments folder.\n```\n\n## Pro Tips\n\n1. **Start Small**: Begin with one messy folder (like Downloads) to build trust\n2. **Regular Maintenance**: Run weekly cleanup on Downloads\n3. **Consistent Naming**: Use \"YYYY-MM-DD - Description\" format for important files\n4. **Archive Aggressively**: Move old projects to Archive instead of deleting\n5. **Keep Active Separate**: Maintain clear boundaries between active and archived work\n6. **Trust the Process**: Let Claude handle the cognitive load of where things go\n\n## Best Practices\n\n### Folder Naming\n- Use clear, descriptive names\n- Avoid spaces (use hyphens or underscores)\n- Be specific: \"client-proposals\" not \"docs\"\n- Use prefixes for ordering: \"01-current\", \"02-archive\"\n\n### File Naming\n- Include dates: \"2024-10-17-meeting-notes.md\"\n- Be descriptive: \"q3-financial-report.xlsx\"\n- Avoid version numbers in names (use version control instead)\n- Remove download artifacts: \"document-final-v2 (1).pdf\" ‚Üí \"document.pdf\"\n\n### When to Archive\n- Projects not touched in 6+ months\n- Completed work that might be referenced later\n- Old versions after migration to new systems\n- Files you're hesitant to delete (archive first)\n\n## Related Use Cases\n\n- Setting up organization for a new computer\n- Preparing files for backup/archiving\n- Cleaning up before storage cleanup\n- Organizing shared team folders\n- Structuring new project directories"
  },
  {
    "name": "frontend-design",
    "description": "Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, pages, artifacts, posters, or applications (examples include websites, landing pages, dashboards, React components, HTML/CSS layouts, or when styling/beautifying any web UI). Generates creative, polished code and UI design that avoids generic AI aesthetics.",
    "body": "This skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes.\n- **Motion**: Use animations for effects and micro-interactions. Focus on high-impact moments: one well-orchestrated page load with staggered reveals creates more delight than scattered micro-interactions.\n- **Spatial Composition**: Unexpected layouts. Asymmetry. Overlap. Diagonal flow. Grid-breaking elements. Generous negative space OR controlled density.\n- **Backgrounds & Visual Details**: Create atmosphere and depth rather than defaulting to solid colors.\n\nNEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial), cliched color schemes (purple gradients on white), predictable layouts and component patterns.\n\nInterpret creatively and make unexpected choices that feel genuinely designed for the context.",
    "id": "frontend-design",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/frontend-design",
    "name_zh": "ÂâçÁ´ØËÆæËÆ°",
    "description_zh": "Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, pages, artifacts, posters, or applications (examples include websites, landing pages, dashboards, React components, HTML/CSS layouts, or when styling/beautifying any web UI). ÁîüÊàês creative, polished code and UI design that avoids generic AI aesthetics.",
    "body_zh": "This skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes.\n- **Motion**: Use animations for effects and micro-interactions. Focus on high-impact moments: one well-orchestrated page load with staggered reveals creates more delight than scattered micro-interactions.\n- **Spatial Composition**: Unexpected layouts. Asymmetry. Overlap. Diagonal flow. Grid-breaking elements. Generous negative space OR controlled density.\n- **Backgrounds & Visual Details**: Create atmosphere and depth rather than defaulting to solid colors.\n\nNEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial), cliched color schemes (purple gradients on white), predictable layouts and component patterns.\n\nInterpret creatively and make unexpected choices that feel genuinely designed for the context."
  },
  {
    "name": "image-enhancer",
    "description": "Improves the quality of images, especially screenshots, by enhancing resolution, sharpness, and clarity. Perfect for preparing images for presentations, documentation, or social media posts.",
    "body": "# Image Enhancer\n\nThis skill takes your images and screenshots and makes them look better‚Äîsharper, clearer, and more professional.\n\n## When to Use This Skill\n\n- Improving screenshot quality for blog posts or documentation\n- Enhancing images before sharing on social media\n- Preparing images for presentations or reports\n- Upscaling low-resolution images\n- Sharpening blurry photos\n- Cleaning up compressed images\n\n## What This Skill Does\n\n1. **Analyzes Image Quality**: Checks resolution, sharpness, and compression artifacts\n2. **Enhances Resolution**: Upscales images intelligently\n3. **Improves Sharpness**: Enhances edges and details\n4. **Reduces Artifacts**: Cleans up compression artifacts and noise\n5. **Optimizes for Use Case**: Adjusts based on intended use (web, print, social media)\n\n## How to Use\n\n### Basic Enhancement\n\n```\nImprove the image quality of screenshot.png\n```\n\n```\nEnhance all images in this folder\n```\n\n### Specific Improvements\n\n```\nUpscale this image to 4K resolution\n```\n\n```\nSharpen this blurry screenshot\n```\n\n```\nReduce compression artifacts in this image\n```\n\n### Batch Processing\n\n```\nImprove the quality of all PNG files in this directory\n```\n\n## Example\n\n**User**: \"Improve the image quality of screenshot-2024.png\"\n\n**Output**:\n```\nAnalyzing screenshot-2024.png...\n\nCurrent specs:\n- Resolution: 1920x1080\n- Format: PNG\n- Quality: Good, but slight blur\n\nEnhancements applied:\n‚úì Upscaled to 2560x1440 (retina)\n‚úì Sharpened edges\n‚úì Enhanced text clarity\n‚úì Optimized file size\n\nSaved as: screenshot-2024-enhanced.png\nOriginal preserved as: screenshot-2024-original.png\n```\n\n**Inspired by:** Lenny Rachitsky's workflow from his newsletter - used for screenshots in his articles\n\n## Tips\n\n- Always keeps original files as backup\n- Works best with screenshots and digital images\n- Can batch process entire folders\n- Specify output format if needed (PNG for quality, JPG for smaller size)\n- For social media, mention the platform for optimal sizing\n\n## Common Use Cases\n\n- **Blog Posts**: Enhance screenshots before publishing\n- **Documentation**: Make UI screenshots crystal clear\n- **Social Media**: Optimize images for Twitter, LinkedIn, Instagram\n- **Presentations**: Upscale images for large screens\n- **Print Materials**: Increase resolution for physical media",
    "id": "image-enhancer",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/image-enhancer",
    "name_zh": "ÂõæÂÉèÂ¢ûÂº∫",
    "description_zh": "Improves the quality of images, especially screenshots, by enhancing resolution, sharpness, and clarity. Perfect for preparing images for presentations, documentation, or social media posts.",
    "body_zh": "# Image Enhancer\n\nThis skill takes your images and screenshots and makes them look better‚Äîsharper, clearer, and more professional.\n\n## When to Use This Skill\n\n- Improving screenshot quality for blog posts or documentation\n- Enhancing images before sharing on social media\n- Preparing images for presentations or reports\n- Upscaling low-resolution images\n- Sharpening blurry photos\n- Cleaning up compressed images\n\n## What This Skill Does\n\n1. **Analyzes Image Quality**: Checks resolution, sharpness, and compression artifacts\n2. **Enhances Resolution**: Upscales images intelligently\n3. **Improves Sharpness**: Enhances edges and details\n4. **Reduces Artifacts**: Cleans up compression artifacts and noise\n5. **Optimizes for Use Case**: Adjusts based on intended use (web, print, social media)\n\n## How to Use\n\n### Basic Enhancement\n\n```\nImprove the image quality of screenshot.png\n```\n\n```\nEnhance all images in this folder\n```\n\n### Specific Improvements\n\n```\nUpscale this image to 4K resolution\n```\n\n```\nSharpen this blurry screenshot\n```\n\n```\nReduce compression artifacts in this image\n```\n\n### Batch Processing\n\n```\nImprove the quality of all PNG files in this directory\n```\n\n## Example\n\n**User**: \"Improve the image quality of screenshot-2024.png\"\n\n**Output**:\n```\nAnalyzing screenshot-2024.png...\n\nCurrent specs:\n- Resolution: 1920x1080\n- Format: PNG\n- Quality: Good, but slight blur\n\nEnhancements applied:\n‚úì Upscaled to 2560x1440 (retina)\n‚úì Sharpened edges\n‚úì Enhanced text clarity\n‚úì Optimized file size\n\nSaved as: screenshot-2024-enhanced.png\nOriginal preserved as: screenshot-2024-original.png\n```\n\n**Inspired by:** Lenny Rachitsky's workflow from his newsletter - used for screenshots in his articles\n\n## Tips\n\n- Always keeps original files as backup\n- Works best with screenshots and digital images\n- Can batch process entire folders\n- Specify output format if needed (PNG for quality, JPG for smaller size)\n- For social media, mention the platform for optimal sizing\n\n## Common Use Cases\n\n- **Blog Posts**: Enhance screenshots before publishing\n- **Documentation**: Make UI screenshots crystal clear\n- **Social Media**: Optimize images for Twitter, LinkedIn, Instagram\n- **Presentations**: Upscale images for large screens\n- **Print Materials**: Increase resolution for physical media"
  },
  {
    "name": "internal-comms",
    "description": "Write internal communications using company formats. Use when writing status reports, leadership updates, company newsletters, FAQs, incident reports, project updates, or any internal communications.",
    "body": "# Internal Communications\n\n## Document Types\n\n### Status Report\n```markdown\n# [Project Name] Status Report\n**Date:** [Date]\n**Author:** [Name]\n**Status:** üü¢ On Track / üü° At Risk / üî¥ Blocked\n\n## Summary\n[2-3 sentence overview]\n\n## Progress This Week\n- Completed: [items]\n- In Progress: [items]\n- Blocked: [items with owners]\n\n## Key Metrics\n| Metric | Target | Actual | Trend |\n|--------|--------|--------|-------|\n| [Metric] | [Target] | [Actual] | ‚¨ÜÔ∏è/‚û°Ô∏è/‚¨áÔ∏è |\n\n## Next Week\n- [Planned items]\n\n## Risks & Mitigations\n| Risk | Impact | Mitigation | Owner |\n|------|--------|------------|-------|\n| [Risk] | H/M/L | [Action] | [Name] |\n\n## Asks\n- [Any blockers needing escalation]\n```\n\n### Leadership Update\n```markdown\n# [Team] Update - [Date]\n\n## TL;DR\n[One paragraph executive summary - the only thing busy execs will read]\n\n## Wins\n- [Key accomplishment with impact]\n- [Key accomplishment with impact]\n\n## Challenges\n- [Challenge]: [What we're doing about it]\n\n## Key Decisions Needed\n1. [Decision]: [Context, options, recommendation]\n\n## Metrics Dashboard\n[Include 3-5 key metrics with trends]\n```\n\n### Incident Report\n```markdown\n# Incident Report: [Title]\n\n**Severity:** P0/P1/P2/P3\n**Duration:** [Start] - [End]\n**Impact:** [User/revenue impact]\n**Status:** Resolved/Monitoring/Active\n\n## Timeline\n| Time (UTC) | Event |\n|------------|-------|\n| [Time] | [What happened] |\n\n## Root Cause\n[Clear explanation of what went wrong]\n\n## Resolution\n[What was done to fix it]\n\n## Action Items\n| Item | Owner | Due Date | Status |\n|------|-------|----------|--------|\n| [Action] | [Name] | [Date] | ‚¨ú/‚úÖ |\n\n## Lessons Learned\n- [What we learned]\n- [What we'll do differently]\n```\n\n### All-Hands Announcement\n```markdown\n# [Announcement Title]\n\nHey team,\n\n[Opening that sets context]\n\n**What's happening:** [Clear, simple explanation]\n\n**Why it matters:** [Impact and benefits]\n\n**What you need to do:** [Specific actions if any]\n\n**Timeline:**\n- [Date]: [Milestone]\n- [Date]: [Milestone]\n\n**Questions?** [Where to ask]\n\n[Sign-off]\n```\n\n## Writing Principles\n\n1. **Lead with the bottom line** - Busy readers skim\n2. **Be specific** - Numbers > adjectives\n3. **Own problems** - \"We missed\" not \"It was missed\"\n4. **Action-oriented** - Every problem has a next step\n5. **Appropriate tone** - Match urgency to content",
    "id": "internal-comms",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/internal-comms",
    "name_zh": "ÂÜÖÈÉ®Ê≤üÈÄö",
    "description_zh": "Write internal communications using company formats. ÈÄÇÁî®‰∫é writing status reports, leadership updates, company newsletters, FAQs, incident reports, project updates, or any internal communications.",
    "body_zh": "# Internal Communications\n\n## Document Types\n\n### Status Report\n```markdown\n# [Project Name] Status Report\n**Date:** [Date]\n**Author:** [Name]\n**Status:** üü¢ On Track / üü° At Risk / üî¥ Blocked\n\n## Summary\n[2-3 sentence overview]\n\n## Progress This Week\n- Completed: [items]\n- In Progress: [items]\n- Blocked: [items with owners]\n\n## Key Metrics\n| Metric | Target | Actual | Trend |\n|--------|--------|--------|-------|\n| [Metric] | [Target] | [Actual] | ‚¨ÜÔ∏è/‚û°Ô∏è/‚¨áÔ∏è |\n\n## Next Week\n- [Planned items]\n\n## Risks & Mitigations\n| Risk | Impact | Mitigation | Owner |\n|------|--------|------------|-------|\n| [Risk] | H/M/L | [Action] | [Name] |\n\n## Asks\n- [Any blockers needing escalation]\n```\n\n### Leadership Update\n```markdown\n# [Team] Update - [Date]\n\n## TL;DR\n[One paragraph executive summary - the only thing busy execs will read]\n\n## Wins\n- [Key accomplishment with impact]\n- [Key accomplishment with impact]\n\n## Challenges\n- [Challenge]: [What we're doing about it]\n\n## Key Decisions Needed\n1. [Decision]: [Context, options, recommendation]\n\n## Metrics Dashboard\n[Include 3-5 key metrics with trends]\n```\n\n### Incident Report\n```markdown\n# Incident Report: [Title]\n\n**Severity:** P0/P1/P2/P3\n**Duration:** [Start] - [End]\n**Impact:** [User/revenue impact]\n**Status:** Resolved/Monitoring/Active\n\n## Timeline\n| Time (UTC) | Event |\n|------------|-------|\n| [Time] | [What happened] |\n\n## Root Cause\n[Clear explanation of what went wrong]\n\n## Resolution\n[What was done to fix it]\n\n## Action Items\n| Item | Owner | Due Date | Status |\n|------|-------|----------|--------|\n| [Action] | [Name] | [Date] | ‚¨ú/‚úÖ |\n\n## Lessons Learned\n- [What we learned]\n- [What we'll do differently]\n```\n\n### All-Hands Announcement\n```markdown\n# [Announcement Title]\n\nHey team,\n\n[Opening that sets context]\n\n**What's happening:** [Clear, simple explanation]\n\n**Why it matters:** [Impact and benefits]\n\n**What you need to do:** [Specific actions if any]\n\n**Timeline:**\n- [Date]: [Milestone]\n- [Date]: [Milestone]\n\n**Questions?** [Where to ask]\n\n[Sign-off]\n```\n\n## Writing Principles\n\n1. **Lead with the bottom line** - Busy readers skim\n2. **Be specific** - Numbers > adjectives\n3. **Own problems** - \"We missed\" not \"It was missed\"\n4. **Action-oriented** - Every problem has a next step\n5. **Appropriate tone** - Match urgency to content"
  },
  {
    "name": "invoice-organizer",
    "description": "Automatically organizes invoices and receipts for tax preparation by reading messy files, extracting key information, renaming them consistently, and sorting them into logical folders. Turns hours of manual bookkeeping into minutes of automated organization.",
    "body": "# Invoice Organizer\n\nThis skill transforms chaotic folders of invoices, receipts, and financial documents into a clean, tax-ready filing system without manual effort.\n\n## When to Use This Skill\n\n- Preparing for tax season and need organized records\n- Managing business expenses across multiple vendors\n- Organizing receipts from a messy folder or email downloads\n- Setting up automated invoice filing for ongoing bookkeeping\n- Archiving financial records by year or category\n- Reconciling expenses for reimbursement\n- Preparing documentation for accountants\n\n## What This Skill Does\n\n1. **Reads Invoice Content**: Extracts information from PDFs, images, and documents:\n   - Vendor/company name\n   - Invoice number\n   - Date\n   - Amount\n   - Product or service description\n   - Payment method\n\n2. **Renames Files Consistently**: Creates standardized filenames:\n   - Format: `YYYY-MM-DD Vendor - Invoice - ProductOrService.pdf`\n   - Examples: `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n\n3. **Organizes by Category**: Sorts into logical folders:\n   - By vendor\n   - By expense category (software, office, travel, etc.)\n   - By time period (year, quarter, month)\n   - By tax category (deductible, personal, etc.)\n\n4. **Handles Multiple Formats**: Works with:\n   - PDF invoices\n   - Scanned receipts (JPG, PNG)\n   - Email attachments\n   - Screenshots\n   - Bank statements\n\n5. **Maintains Originals**: Preserves original files while organizing copies\n\n## How to Use\n\n### Basic Usage\n\nNavigate to your messy invoice folder:\n```\ncd ~/Desktop/receipts-to-sort\n```\n\nThen ask Claude Code:\n```\nOrganize these invoices for taxes\n```\n\nOr more specifically:\n```\nRead all invoices in this folder, rename them to \n\"YYYY-MM-DD Vendor - Invoice - Product.pdf\" format, \nand organize them by vendor\n```\n\n### Advanced Organization\n\n```\nOrganize these invoices:\n1. Extract date, vendor, and description from each file\n2. Rename to standard format\n3. Sort into folders by expense category (Software, Office, Travel, etc.)\n4. Create a CSV spreadsheet with all invoice details for my accountant\n```\n\n## Instructions\n\nWhen a user requests invoice organization:\n\n1. **Scan the Folder**\n   \n   Identify all invoice files:\n   ```bash\n   # Find all invoice-related files\n   find . -type f \\( -name \"*.pdf\" -o -name \"*.jpg\" -o -name \"*.png\" \\) -print\n   ```\n   \n   Report findings:\n   - Total number of files\n   - File types\n   - Date range (if discernible from names)\n   - Current organization (or lack thereof)\n\n2. **Extract Information from Each File**\n   \n   For each invoice, extract:\n   \n   **From PDF invoices**:\n   - Use text extraction to read invoice content\n   - Look for common patterns:\n     - \"Invoice Date:\", \"Date:\", \"Issued:\"\n     - \"Invoice #:\", \"Invoice Number:\"\n     - Company name (usually at top)\n     - \"Amount Due:\", \"Total:\", \"Amount:\"\n     - \"Description:\", \"Service:\", \"Product:\"\n   \n   **From image receipts**:\n   - Read visible text from images\n   - Identify vendor name (often at top)\n   - Look for date (common formats)\n   - Find total amount\n   \n   **Fallback for unclear files**:\n   - Use filename clues\n   - Check file creation/modification date\n   - Flag for manual review if critical info missing\n\n3. **Determine Organization Strategy**\n   \n   Ask user preference if not specified:\n   \n   ```markdown\n   I found [X] invoices from [date range].\n   \n   How would you like them organized?\n   \n   1. **By Vendor** (Adobe/, Amazon/, Stripe/, etc.)\n   2. **By Category** (Software/, Office Supplies/, Travel/, etc.)\n   3. **By Date** (2024/Q1/, 2024/Q2/, etc.)\n   4. **By Tax Category** (Deductible/, Personal/, etc.)\n   5. **Custom** (describe your structure)\n   \n   Or I can use a default structure: Year/Category/Vendor\n   ```\n\n4. **Create Standardized Filename**\n   \n   For each invoice, create a filename following this pattern:\n   \n   ```\n   YYYY-MM-DD Vendor - Invoice - Description.ext\n   ```\n   \n   Examples:\n   - `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n   - `2024-01-10 Amazon - Receipt - Office Supplies.pdf`\n   - `2023-12-01 Stripe - Invoice - Monthly Payment Processing.pdf`\n   \n   **Filename Best Practices**:\n   - Remove special characters except hyphens\n   - Capitalize vendor names properly\n   - Keep descriptions concise but meaningful\n   - Use consistent date format (YYYY-MM-DD) for sorting\n   - Preserve original file extension\n\n5. **Execute Organization**\n   \n   Before moving files, show the plan:\n   \n   ```markdown\n   # Organization Plan\n   \n   ## Proposed Structure\n   ```\n   Invoices/\n   ‚îú‚îÄ‚îÄ 2023/\n   ‚îÇ   ‚îú‚îÄ‚îÄ Software/\n   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Adobe/\n   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Microsoft/\n   ‚îÇ   ‚îú‚îÄ‚îÄ Services/\n   ‚îÇ   ‚îî‚îÄ‚îÄ Office/\n   ‚îî‚îÄ‚îÄ 2024/\n       ‚îú‚îÄ‚îÄ Software/\n       ‚îú‚îÄ‚îÄ Services/\n       ‚îî‚îÄ‚îÄ Office/\n   ```\n   \n   ## Sample Changes\n   \n   Before: `invoice_adobe_march.pdf`\n   After: `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n   Location: `Invoices/2024/Software/Adobe/`\n   \n   Before: `IMG_2847.jpg`\n   After: `2024-02-10 Staples - Receipt - Office Supplies.jpg`\n   Location: `Invoices/2024/Office/Staples/`\n   \n   Process [X] files? (yes/no)\n   ```\n   \n   After approval:\n   ```bash\n   # Create folder structure\n   mkdir -p \"Invoices/2024/Software/Adobe\"\n   \n   # Copy (don't move) to preserve originals\n   cp \"original.pdf\" \"Invoices/2024/Software/Adobe/2024-03-15 Adobe - Invoice - Creative Cloud.pdf\"\n   \n   # Or move if user prefers\n   mv \"original.pdf\" \"new/path/standardized-name.pdf\"\n   ```\n\n6. **Generate Summary Report**\n   \n   Create a CSV file with all invoice details:\n   \n   ```csv\n   Date,Vendor,Invoice Number,Description,Amount,Category,File Path\n   2024-03-15,Adobe,INV-12345,Creative Cloud,52.99,Software,Invoices/2024/Software/Adobe/2024-03-15 Adobe - Invoice - Creative Cloud.pdf\n   2024-03-10,Amazon,123-4567890-1234567,Office Supplies,127.45,Office,Invoices/2024/Office/Amazon/2024-03-10 Amazon - Receipt - Office Supplies.pdf\n   ...\n   ```\n   \n   This CSV is useful for:\n   - Importing into accounting software\n   - Sharing with accountants\n   - Expense tracking and reporting\n   - Tax preparation\n\n7. **Provide Completion Summary**\n   \n   ```markdown\n   # Organization Complete! üìä\n   \n   ## Summary\n   - **Processed**: [X] invoices\n   - **Date range**: [earliest] to [latest]\n   - **Total amount**: $[sum] (if amounts extracted)\n   - **Vendors**: [Y] unique vendors\n   \n   ## New Structure\n   ```\n   Invoices/\n   ‚îú‚îÄ‚îÄ 2024/ (45 files)\n   ‚îÇ   ‚îú‚îÄ‚îÄ Software/ (23 files)\n   ‚îÇ   ‚îú‚îÄ‚îÄ Services/ (12 files)\n   ‚îÇ   ‚îî‚îÄ‚îÄ Office/ (10 files)\n   ‚îî‚îÄ‚îÄ 2023/ (12 files)\n   ```\n   \n   ## Files Created\n   - `/Invoices/` - Organized invoices\n   - `/Invoices/invoice-summary.csv` - Spreadsheet for accounting\n   - `/Invoices/originals/` - Original files (if copied)\n   \n   ## Files Needing Review\n   [List any files where information couldn't be extracted completely]\n   \n   ## Next Steps\n   1. Review the `invoice-summary.csv` file\n   2. Check files in \"Needs Review\" folder\n   3. Import CSV into your accounting software\n   4. Set up auto-organization for future invoices\n   \n   Ready for tax season! üéâ\n   ```\n\n## Examples\n\n### Example 1: Tax Preparation (From Martin Merschroth)\n\n**User**: \"I have a messy folder of invoices for taxes. Sort them and rename properly.\"\n\n**Process**:\n1. Scans folder: finds 147 PDFs and images\n2. Reads each invoice to extract:\n   - Date\n   - Vendor name\n   - Invoice number\n   - Product/service description\n3. Renames all files: `YYYY-MM-DD Vendor - Invoice - Product.pdf`\n4. Organizes into: `2024/Software/`, `2024/Travel/`, etc.\n5. Creates `invoice-summary.csv` for accountant\n6. Result: Tax-ready organized invoices in minutes\n\n### Example 2: Monthly Expense Reconciliation\n\n**User**: \"Organize my business receipts from last month by category.\"\n\n**Output**:\n```markdown\n# March 2024 Receipts Organized\n\n## By Category\n- Software & Tools: $847.32 (12 invoices)\n- Office Supplies: $234.18 (8 receipts)\n- Travel & Meals: $1,456.90 (15 receipts)\n- Professional Services: $2,500.00 (3 invoices)\n\nTotal: $5,038.40\n\nAll receipts renamed and filed in:\n`Business-Receipts/2024/03-March/[Category]/`\n\nCSV export: `march-2024-expenses.csv`\n```\n\n### Example 3: Multi-Year Archive\n\n**User**: \"I have 3 years of random invoices. Organize them by year, then by vendor.\"\n\n**Output**: Creates structure:\n```\nInvoices/\n‚îú‚îÄ‚îÄ 2022/\n‚îÇ   ‚îú‚îÄ‚îÄ Adobe/\n‚îÇ   ‚îú‚îÄ‚îÄ Amazon/\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ 2023/\n‚îÇ   ‚îú‚îÄ‚îÄ Adobe/\n‚îÇ   ‚îú‚îÄ‚îÄ Amazon/\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îî‚îÄ‚îÄ 2024/\n    ‚îú‚îÄ‚îÄ Adobe/\n    ‚îú‚îÄ‚îÄ Amazon/\n    ‚îî‚îÄ‚îÄ ...\n```\n\nEach file properly renamed with date and description.\n\n### Example 4: Email Downloads Cleanup\n\n**User**: \"I download invoices from Gmail. They're all named 'invoice.pdf', 'invoice(1).pdf', etc. Fix this mess.\"\n\n**Output**:\n```markdown\nFound 89 files all named \"invoice*.pdf\"\n\nReading each file to extract real information...\n\nRenamed examples:\n- invoice.pdf ‚Üí 2024-03-15 Shopify - Invoice - Monthly Subscription.pdf\n- invoice(1).pdf ‚Üí 2024-03-14 Google - Invoice - Workspace.pdf\n- invoice(2).pdf ‚Üí 2024-03-10 Netlify - Invoice - Pro Plan.pdf\n\nAll files renamed and organized by vendor.\n```\n\n## Common Organization Patterns\n\n### By Vendor (Simple)\n```\nInvoices/\n‚îú‚îÄ‚îÄ Adobe/\n‚îú‚îÄ‚îÄ Amazon/\n‚îú‚îÄ‚îÄ Google/\n‚îî‚îÄ‚îÄ Microsoft/\n```\n\n### By Year and Category (Tax-Friendly)\n```\nInvoices/\n‚îú‚îÄ‚îÄ 2023/\n‚îÇ   ‚îú‚îÄ‚îÄ Software/\n‚îÇ   ‚îú‚îÄ‚îÄ Hardware/\n‚îÇ   ‚îú‚îÄ‚îÄ Services/\n‚îÇ   ‚îî‚îÄ‚îÄ Travel/\n‚îî‚îÄ‚îÄ 2024/\n    ‚îî‚îÄ‚îÄ ...\n```\n\n### By Quarter (Detailed Tracking)\n```\nInvoices/\n‚îú‚îÄ‚îÄ 2024/\n‚îÇ   ‚îú‚îÄ‚îÄ Q1/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Software/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Office/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Travel/\n‚îÇ   ‚îî‚îÄ‚îÄ Q2/\n‚îÇ       ‚îî‚îÄ‚îÄ ...\n```\n\n### By Tax Category (Accountant-Ready)\n```\nInvoices/\n‚îú‚îÄ‚îÄ Deductible/\n‚îÇ   ‚îú‚îÄ‚îÄ Software/\n‚îÇ   ‚îú‚îÄ‚îÄ Office/\n‚îÇ   ‚îî‚îÄ‚îÄ Professional-Services/\n‚îú‚îÄ‚îÄ Partially-Deductible/\n‚îÇ   ‚îî‚îÄ‚îÄ Meals-Travel/\n‚îî‚îÄ‚îÄ Personal/\n```\n\n## Automation Setup\n\nFor ongoing organization:\n\n```\nCreate a script that watches my ~/Downloads/invoices folder \nand auto-organizes any new invoice files using our standard \nnaming and folder structure.\n```\n\nThis creates a persistent solution that organizes invoices as they arrive.\n\n## Pro Tips\n\n1. **Scan emails to PDF**: Use Preview or similar to save email invoices as PDFs first\n2. **Consistent downloads**: Save all invoices to one folder for batch processing\n3. **Monthly routine**: Organize invoices monthly, not annually\n4. **Backup originals**: Keep original files before reorganizing\n5. **Include amounts in CSV**: Useful for budget tracking\n6. **Tag by deductibility**: Note which expenses are tax-deductible\n7. **Keep receipts 7 years**: Standard audit period\n\n## Handling Special Cases\n\n### Missing Information\nIf date/vendor can't be extracted:\n- Flag file for manual review\n- Use file modification date as fallback\n- Create \"Needs-Review/\" folder\n\n### Duplicate Invoices\nIf same invoice appears multiple times:\n- Compare file hashes\n- Keep highest quality version\n- Note duplicates in summary\n\n### Multi-Page Invoices\nFor invoices split across files:\n- Merge PDFs if needed\n- Use consistent naming for parts\n- Note in CSV if invoice is split\n\n### Non-Standard Formats\nFor unusual receipt formats:\n- Extract what's possible\n- Standardize what you can\n- Flag for review if critical info missing\n\n## Related Use Cases\n\n- Creating expense reports for reimbursement\n- Organizing bank statements\n- Managing vendor contracts\n- Archiving old financial records\n- Preparing for audits\n- Tracking subscription costs over time",
    "id": "invoice-organizer",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/invoice-organizer",
    "name_zh": "ÂèëÁ•®Êï¥ÁêÜÂô®",
    "description_zh": "Automatically organizes invoices and receipts for tax preparation by reading messy files, extracting key information, renaming them consistently, and sorting them into logical folders. Turns hours of manual bookkeeping into minutes of automated organization.",
    "body_zh": "# Invoice Organizer\n\nThis skill transforms chaotic folders of invoices, receipts, and financial documents into a clean, tax-ready filing system without manual effort.\n\n## When to Use This Skill\n\n- Preparing for tax season and need organized records\n- Managing business expenses across multiple vendors\n- Organizing receipts from a messy folder or email downloads\n- Setting up automated invoice filing for ongoing bookkeeping\n- Archiving financial records by year or category\n- Reconciling expenses for reimbursement\n- Preparing documentation for accountants\n\n## What This Skill Does\n\n1. **Reads Invoice Content**: Extracts information from PDFs, images, and documents:\n   - Vendor/company name\n   - Invoice number\n   - Date\n   - Amount\n   - Product or service description\n   - Payment method\n\n2. **Renames Files Consistently**: Creates standardized filenames:\n   - Format: `YYYY-MM-DD Vendor - Invoice - ProductOrService.pdf`\n   - Examples: `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n\n3. **Organizes by Category**: Sorts into logical folders:\n   - By vendor\n   - By expense category (software, office, travel, etc.)\n   - By time period (year, quarter, month)\n   - By tax category (deductible, personal, etc.)\n\n4. **Handles Multiple Formats**: Works with:\n   - PDF invoices\n   - Scanned receipts (JPG, PNG)\n   - Email attachments\n   - Screenshots\n   - Bank statements\n\n5. **Maintains Originals**: Preserves original files while organizing copies\n\n## How to Use\n\n### Basic Usage\n\nNavigate to your messy invoice folder:\n```\ncd ~/Desktop/receipts-to-sort\n```\n\nThen ask Claude Code:\n```\nOrganize these invoices for taxes\n```\n\nOr more specifically:\n```\nRead all invoices in this folder, rename them to \n\"YYYY-MM-DD Vendor - Invoice - Product.pdf\" format, \nand organize them by vendor\n```\n\n### Advanced Organization\n\n```\nOrganize these invoices:\n1. Extract date, vendor, and description from each file\n2. Rename to standard format\n3. Sort into folders by expense category (Software, Office, Travel, etc.)\n4. Create a CSV spreadsheet with all invoice details for my accountant\n```\n\n## Instructions\n\nWhen a user requests invoice organization:\n\n1. **Scan the Folder**\n   \n   Identify all invoice files:\n   ```bash\n   # Find all invoice-related files\n   find . -type f \\( -name \"*.pdf\" -o -name \"*.jpg\" -o -name \"*.png\" \\) -print\n   ```\n   \n   Report findings:\n   - Total number of files\n   - File types\n   - Date range (if discernible from names)\n   - Current organization (or lack thereof)\n\n2. **Extract Information from Each File**\n   \n   For each invoice, extract:\n   \n   **From PDF invoices**:\n   - Use text extraction to read invoice content\n   - Look for common patterns:\n     - \"Invoice Date:\", \"Date:\", \"Issued:\"\n     - \"Invoice #:\", \"Invoice Number:\"\n     - Company name (usually at top)\n     - \"Amount Due:\", \"Total:\", \"Amount:\"\n     - \"Description:\", \"Service:\", \"Product:\"\n   \n   **From image receipts**:\n   - Read visible text from images\n   - Identify vendor name (often at top)\n   - Look for date (common formats)\n   - Find total amount\n   \n   **Fallback for unclear files**:\n   - Use filename clues\n   - Check file creation/modification date\n   - Flag for manual review if critical info missing\n\n3. **Determine Organization Strategy**\n   \n   Ask user preference if not specified:\n   \n   ```markdown\n   I found [X] invoices from [date range].\n   \n   How would you like them organized?\n   \n   1. **By Vendor** (Adobe/, Amazon/, Stripe/, etc.)\n   2. **By Category** (Software/, Office Supplies/, Travel/, etc.)\n   3. **By Date** (2024/Q1/, 2024/Q2/, etc.)\n   4. **By Tax Category** (Deductible/, Personal/, etc.)\n   5. **Custom** (describe your structure)\n   \n   Or I can use a default structure: Year/Category/Vendor\n   ```\n\n4. **Create Standardized Filename**\n   \n   For each invoice, create a filename following this pattern:\n   \n   ```\n   YYYY-MM-DD Vendor - Invoice - Description.ext\n   ```\n   \n   Examples:\n   - `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n   - `2024-01-10 Amazon - Receipt - Office Supplies.pdf`\n   - `2023-12-01 Stripe - Invoice - Monthly Payment Processing.pdf`\n   \n   **Filename Best Practices**:\n   - Remove special characters except hyphens\n   - Capitalize vendor names properly\n   - Keep descriptions concise but meaningful\n   - Use consistent date format (YYYY-MM-DD) for sorting\n   - Preserve original file extension\n\n5. **Execute Organization**\n   \n   Before moving files, show the plan:\n   \n   ```markdown\n   # Organization Plan\n   \n   ## Proposed Structure\n   ```\n   Invoices/\n   ‚îú‚îÄ‚îÄ 2023/\n   ‚îÇ   ‚îú‚îÄ‚îÄ Software/\n   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Adobe/\n   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Microsoft/\n   ‚îÇ   ‚îú‚îÄ‚îÄ Services/\n   ‚îÇ   ‚îî‚îÄ‚îÄ Office/\n   ‚îî‚îÄ‚îÄ 2024/\n       ‚îú‚îÄ‚îÄ Software/\n       ‚îú‚îÄ‚îÄ Services/\n       ‚îî‚îÄ‚îÄ Office/\n   ```\n   \n   ## Sample Changes\n   \n   Before: `invoice_adobe_march.pdf`\n   After: `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n   Location: `Invoices/2024/Software/Adobe/`\n   \n   Before: `IMG_2847.jpg`\n   After: `2024-02-10 Staples - Receipt - Office Supplies.jpg`\n   Location: `Invoices/2024/Office/Staples/`\n   \n   Process [X] files? (yes/no)\n   ```\n   \n   After approval:\n   ```bash\n   # Create folder structure\n   mkdir -p \"Invoices/2024/Software/Adobe\"\n   \n   # Copy (don't move) to preserve originals\n   cp \"original.pdf\" \"Invoices/2024/Software/Adobe/2024-03-15 Adobe - Invoice - Creative Cloud.pdf\"\n   \n   # Or move if user prefers\n   mv \"original.pdf\" \"new/path/standardized-name.pdf\"\n   ```\n\n6. **Generate Summary Report**\n   \n   Create a CSV file with all invoice details:\n   \n   ```csv\n   Date,Vendor,Invoice Number,Description,Amount,Category,File Path\n   2024-03-15,Adobe,INV-12345,Creative Cloud,52.99,Software,Invoices/2024/Software/Adobe/2024-03-15 Adobe - Invoice - Creative Cloud.pdf\n   2024-03-10,Amazon,123-4567890-1234567,Office Supplies,127.45,Office,Invoices/2024/Office/Amazon/2024-03-10 Amazon - Receipt - Office Supplies.pdf\n   ...\n   ```\n   \n   This CSV is useful for:\n   - Importing into accounting software\n   - Sharing with accountants\n   - Expense tracking and reporting\n   - Tax preparation\n\n7. **Provide Completion Summary**\n   \n   ```markdown\n   # Organization Complete! üìä\n   \n   ## Summary\n   - **Processed**: [X] invoices\n   - **Date range**: [earliest] to [latest]\n   - **Total amount**: $[sum] (if amounts extracted)\n   - **Vendors**: [Y] unique vendors\n   \n   ## New Structure\n   ```\n   Invoices/\n   ‚îú‚îÄ‚îÄ 2024/ (45 files)\n   ‚îÇ   ‚îú‚îÄ‚îÄ Software/ (23 files)\n   ‚îÇ   ‚îú‚îÄ‚îÄ Services/ (12 files)\n   ‚îÇ   ‚îî‚îÄ‚îÄ Office/ (10 files)\n   ‚îî‚îÄ‚îÄ 2023/ (12 files)\n   ```\n   \n   ## Files Created\n   - `/Invoices/` - Organized invoices\n   - `/Invoices/invoice-summary.csv` - Spreadsheet for accounting\n   - `/Invoices/originals/` - Original files (if copied)\n   \n   ## Files Needing Review\n   [List any files where information couldn't be extracted completely]\n   \n   ## Next Steps\n   1. Review the `invoice-summary.csv` file\n   2. Check files in \"Needs Review\" folder\n   3. Import CSV into your accounting software\n   4. Set up auto-organization for future invoices\n   \n   Ready for tax season! üéâ\n   ```\n\n## Examples\n\n### Example 1: Tax Preparation (From Martin Merschroth)\n\n**User**: \"I have a messy folder of invoices for taxes. Sort them and rename properly.\"\n\n**Process**:\n1. Scans folder: finds 147 PDFs and images\n2. Reads each invoice to extract:\n   - Date\n   - Vendor name\n   - Invoice number\n   - Product/service description\n3. Renames all files: `YYYY-MM-DD Vendor - Invoice - Product.pdf`\n4. Organizes into: `2024/Software/`, `2024/Travel/`, etc.\n5. Creates `invoice-summary.csv` for accountant\n6. Result: Tax-ready organized invoices in minutes\n\n### Example 2: Monthly Expense Reconciliation\n\n**User**: \"Organize my business receipts from last month by category.\"\n\n**Output**:\n```markdown\n# March 2024 Receipts Organized\n\n## By Category\n- Software & Tools: $847.32 (12 invoices)\n- Office Supplies: $234.18 (8 receipts)\n- Travel & Meals: $1,456.90 (15 receipts)\n- Professional Services: $2,500.00 (3 invoices)\n\nTotal: $5,038.40\n\nAll receipts renamed and filed in:\n`Business-Receipts/2024/03-March/[Category]/`\n\nCSV export: `march-2024-expenses.csv`\n```\n\n### Example 3: Multi-Year Archive\n\n**User**: \"I have 3 years of random invoices. Organize them by year, then by vendor.\"\n\n**Output**: Creates structure:\n```\nInvoices/\n‚îú‚îÄ‚îÄ 2022/\n‚îÇ   ‚îú‚îÄ‚îÄ Adobe/\n‚îÇ   ‚îú‚îÄ‚îÄ Amazon/\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ 2023/\n‚îÇ   ‚îú‚îÄ‚îÄ Adobe/\n‚îÇ   ‚îú‚îÄ‚îÄ Amazon/\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îî‚îÄ‚îÄ 2024/\n    ‚îú‚îÄ‚îÄ Adobe/\n    ‚îú‚îÄ‚îÄ Amazon/\n    ‚îî‚îÄ‚îÄ ...\n```\n\nEach file properly renamed with date and description.\n\n### Example 4: Email Downloads Cleanup\n\n**User**: \"I download invoices from Gmail. They're all named 'invoice.pdf', 'invoice(1).pdf', etc. Fix this mess.\"\n\n**Output**:\n```markdown\nFound 89 files all named \"invoice*.pdf\"\n\nReading each file to extract real information...\n\nRenamed examples:\n- invoice.pdf ‚Üí 2024-03-15 Shopify - Invoice - Monthly Subscription.pdf\n- invoice(1).pdf ‚Üí 2024-03-14 Google - Invoice - Workspace.pdf\n- invoice(2).pdf ‚Üí 2024-03-10 Netlify - Invoice - Pro Plan.pdf\n\nAll files renamed and organized by vendor.\n```\n\n## Common Organization Patterns\n\n### By Vendor (Simple)\n```\nInvoices/\n‚îú‚îÄ‚îÄ Adobe/\n‚îú‚îÄ‚îÄ Amazon/\n‚îú‚îÄ‚îÄ Google/\n‚îî‚îÄ‚îÄ Microsoft/\n```\n\n### By Year and Category (Tax-Friendly)\n```\nInvoices/\n‚îú‚îÄ‚îÄ 2023/\n‚îÇ   ‚îú‚îÄ‚îÄ Software/\n‚îÇ   ‚îú‚îÄ‚îÄ Hardware/\n‚îÇ   ‚îú‚îÄ‚îÄ Services/\n‚îÇ   ‚îî‚îÄ‚îÄ Travel/\n‚îî‚îÄ‚îÄ 2024/\n    ‚îî‚îÄ‚îÄ ...\n```\n\n### By Quarter (Detailed Tracking)\n```\nInvoices/\n‚îú‚îÄ‚îÄ 2024/\n‚îÇ   ‚îú‚îÄ‚îÄ Q1/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Software/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Office/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Travel/\n‚îÇ   ‚îî‚îÄ‚îÄ Q2/\n‚îÇ       ‚îî‚îÄ‚îÄ ...\n```\n\n### By Tax Category (Accountant-Ready)\n```\nInvoices/\n‚îú‚îÄ‚îÄ Deductible/\n‚îÇ   ‚îú‚îÄ‚îÄ Software/\n‚îÇ   ‚îú‚îÄ‚îÄ Office/\n‚îÇ   ‚îî‚îÄ‚îÄ Professional-Services/\n‚îú‚îÄ‚îÄ Partially-Deductible/\n‚îÇ   ‚îî‚îÄ‚îÄ Meals-Travel/\n‚îî‚îÄ‚îÄ Personal/\n```\n\n## Automation Setup\n\nFor ongoing organization:\n\n```\nCreate a script that watches my ~/Downloads/invoices folder \nand auto-organizes any new invoice files using our standard \nnaming and folder structure.\n```\n\nThis creates a persistent solution that organizes invoices as they arrive.\n\n## Pro Tips\n\n1. **Scan emails to PDF**: Use Preview or similar to save email invoices as PDFs first\n2. **Consistent downloads**: Save all invoices to one folder for batch processing\n3. **Monthly routine**: Organize invoices monthly, not annually\n4. **Backup originals**: Keep original files before reorganizing\n5. **Include amounts in CSV**: Useful for budget tracking\n6. **Tag by deductibility**: Note which expenses are tax-deductible\n7. **Keep receipts 7 years**: Standard audit period\n\n## Handling Special Cases\n\n### Missing Information\nIf date/vendor can't be extracted:\n- Flag file for manual review\n- Use file modification date as fallback\n- Create \"Needs-Review/\" folder\n\n### Duplicate Invoices\nIf same invoice appears multiple times:\n- Compare file hashes\n- Keep highest quality version\n- Note duplicates in summary\n\n### Multi-Page Invoices\nFor invoices split across files:\n- Merge PDFs if needed\n- Use consistent naming for parts\n- Note in CSV if invoice is split\n\n### Non-Standard Formats\nFor unusual receipt formats:\n- Extract what's possible\n- Standardize what you can\n- Flag for review if critical info missing\n\n## Related Use Cases\n\n- Creating expense reports for reimbursement\n- Organizing bank statements\n- Managing vendor contracts\n- Archiving old financial records\n- Preparing for audits\n- Tracking subscription costs over time"
  },
  {
    "name": "javascript-typescript",
    "description": "JavaScript and TypeScript development with ES6+, Node.js, React, and modern web frameworks. Use for frontend, backend, or full-stack JavaScript/TypeScript projects.",
    "body": "# JavaScript/TypeScript Development\n\n## TypeScript Configuration\n\n```json\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"ESNext\",\n    \"moduleResolution\": \"bundler\",\n    \"strict\": true,\n    \"noUncheckedIndexedAccess\": true,\n    \"noImplicitOverride\": true,\n    \"skipLibCheck\": true,\n    \"declaration\": true,\n    \"outDir\": \"./dist\"\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n```\n\n## Type Patterns\n\n### Utility Types\n```typescript\n// Pick specific properties\ntype UserPreview = Pick<User, 'id' | 'name'>;\n\n// Omit properties\ntype CreateUser = Omit<User, 'id' | 'createdAt'>;\n\n// Make all properties optional\ntype PartialUser = Partial<User>;\n\n// Make all properties required\ntype RequiredUser = Required<User>;\n\n// Extract union types\ntype Status = 'pending' | 'active' | 'inactive';\ntype ActiveStatus = Extract<Status, 'active' | 'pending'>;\n```\n\n### Discriminated Unions\n```typescript\ntype Result<T> =\n  | { success: true; data: T }\n  | { success: false; error: Error };\n\nfunction handleResult<T>(result: Result<T>) {\n  if (result.success) {\n    console.log(result.data); // T\n  } else {\n    console.error(result.error); // Error\n  }\n}\n```\n\n### Generic Constraints\n```typescript\ninterface HasId {\n  id: string | number;\n}\n\nfunction findById<T extends HasId>(items: T[], id: T['id']): T | undefined {\n  return items.find(item => item.id === id);\n}\n```\n\n## Modern JavaScript\n\n### Destructuring & Spread\n```javascript\nconst { name, ...rest } = user;\nconst merged = { ...defaults, ...options };\nconst [first, ...others] = items;\n```\n\n### Optional Chaining & Nullish Coalescing\n```javascript\nconst city = user?.address?.city ?? 'Unknown';\nconst count = data?.items?.length ?? 0;\n```\n\n### Array Methods\n```javascript\nconst adults = users.filter(u => u.age >= 18);\nconst names = users.map(u => u.name);\nconst total = items.reduce((sum, item) => sum + item.price, 0);\nconst hasAdmin = users.some(u => u.role === 'admin');\nconst allActive = users.every(u => u.active);\n```\n\n## React Patterns\n\n```typescript\n// Props with children\ninterface CardProps {\n  title: string;\n  children: React.ReactNode;\n}\n\n// Event handlers\ninterface ButtonProps {\n  onClick: (event: React.MouseEvent<HTMLButtonElement>) => void;\n}\n\n// Custom hooks\nfunction useLocalStorage<T>(key: string, initial: T) {\n  const [value, setValue] = useState<T>(() => {\n    const stored = localStorage.getItem(key);\n    return stored ? JSON.parse(stored) : initial;\n  });\n\n  useEffect(() => {\n    localStorage.setItem(key, JSON.stringify(value));\n  }, [key, value]);\n\n  return [value, setValue] as const;\n}\n```\n\n## Node.js Patterns\n\n```typescript\n// ES Modules\nimport { readFile } from 'node:fs/promises';\nimport { join } from 'node:path';\n\n// Error handling\nprocess.on('unhandledRejection', (reason) => {\n  console.error('Unhandled Rejection:', reason);\n  process.exit(1);\n});\n```",
    "id": "javascript-typescript",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/javascript-typescript",
    "name_zh": "JavaScript/TypeScript",
    "description_zh": "JavaScript and TypeScript development with ES6+, Node.js, React, and modern web frameworks. Use for frontend, backend, or full-stack JavaScript/TypeScript projects.",
    "body_zh": "# JavaScript/TypeScript Development\n\n## TypeScript Configuration\n\n```json\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"ESNext\",\n    \"moduleResolution\": \"bundler\",\n    \"strict\": true,\n    \"noUncheckedIndexedAccess\": true,\n    \"noImplicitOverride\": true,\n    \"skipLibCheck\": true,\n    \"declaration\": true,\n    \"outDir\": \"./dist\"\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n```\n\n## Type Patterns\n\n### Utility Types\n```typescript\n// Pick specific properties\ntype UserPreview = Pick<User, 'id' | 'name'>;\n\n// Omit properties\ntype CreateUser = Omit<User, 'id' | 'createdAt'>;\n\n// Make all properties optional\ntype PartialUser = Partial<User>;\n\n// Make all properties required\ntype RequiredUser = Required<User>;\n\n// Extract union types\ntype Status = 'pending' | 'active' | 'inactive';\ntype ActiveStatus = Extract<Status, 'active' | 'pending'>;\n```\n\n### Discriminated Unions\n```typescript\ntype Result<T> =\n  | { success: true; data: T }\n  | { success: false; error: Error };\n\nfunction handleResult<T>(result: Result<T>) {\n  if (result.success) {\n    console.log(result.data); // T\n  } else {\n    console.error(result.error); // Error\n  }\n}\n```\n\n### Generic Constraints\n```typescript\ninterface HasId {\n  id: string | number;\n}\n\nfunction findById<T extends HasId>(items: T[], id: T['id']): T | undefined {\n  return items.find(item => item.id === id);\n}\n```\n\n## Modern JavaScript\n\n### Destructuring & Spread\n```javascript\nconst { name, ...rest } = user;\nconst merged = { ...defaults, ...options };\nconst [first, ...others] = items;\n```\n\n### Optional Chaining & Nullish Coalescing\n```javascript\nconst city = user?.address?.city ?? 'Unknown';\nconst count = data?.items?.length ?? 0;\n```\n\n### Array Methods\n```javascript\nconst adults = users.filter(u => u.age >= 18);\nconst names = users.map(u => u.name);\nconst total = items.reduce((sum, item) => sum + item.price, 0);\nconst hasAdmin = users.some(u => u.role === 'admin');\nconst allActive = users.every(u => u.active);\n```\n\n## React Patterns\n\n```typescript\n// Props with children\ninterface CardProps {\n  title: string;\n  children: React.ReactNode;\n}\n\n// Event handlers\ninterface ButtonProps {\n  onClick: (event: React.MouseEvent<HTMLButtonElement>) => void;\n}\n\n// Custom hooks\nfunction useLocalStorage<T>(key: string, initial: T) {\n  const [value, setValue] = useState<T>(() => {\n    const stored = localStorage.getItem(key);\n    return stored ? JSON.parse(stored) : initial;\n  });\n\n  useEffect(() => {\n    localStorage.setItem(key, JSON.stringify(value));\n  }, [key, value]);\n\n  return [value, setValue] as const;\n}\n```\n\n## Node.js Patterns\n\n```typescript\n// ES Modules\nimport { readFile } from 'node:fs/promises';\nimport { join } from 'node:path';\n\n// Error handling\nprocess.on('unhandledRejection', (reason) => {\n  console.error('Unhandled Rejection:', reason);\n  process.exit(1);\n});\n```"
  },
  {
    "name": "jira-issues",
    "description": "Create, update, and manage Jira issues from natural language. Use when the user wants to log bugs, create tickets, update issue status, or manage their Jira backlog.",
    "body": "# Jira Issue Management\n\nCreate and manage Jira issues using the Jira REST API or MCP.\n\n## Setup\n\n### Option 1: Jira MCP Server\nInstall the Jira MCP server for seamless integration:\n```bash\nnpx @anthropic/create-mcp-server jira\n```\n\n### Option 2: Direct API\nSet environment variables:\n```bash\nexport JIRA_BASE_URL=\"https://yourcompany.atlassian.net\"\nexport JIRA_EMAIL=\"your-email@company.com\"\nexport JIRA_API_TOKEN=\"your-api-token\"\n```\n\nGet your API token: https://id.atlassian.com/manage-profile/security/api-tokens\n\n## Creating Issues\n\n### Basic Issue\n```python\nimport requests\nfrom requests.auth import HTTPBasicAuth\nimport os\n\ndef create_issue(project_key, summary, description, issue_type=\"Task\"):\n    url = f\"{os.environ['JIRA_BASE_URL']}/rest/api/3/issue\"\n\n    auth = HTTPBasicAuth(\n        os.environ['JIRA_EMAIL'],\n        os.environ['JIRA_API_TOKEN']\n    )\n\n    payload = {\n        \"fields\": {\n            \"project\": {\"key\": project_key},\n            \"summary\": summary,\n            \"description\": {\n                \"type\": \"doc\",\n                \"version\": 1,\n                \"content\": [{\n                    \"type\": \"paragraph\",\n                    \"content\": [{\"type\": \"text\", \"text\": description}]\n                }]\n            },\n            \"issuetype\": {\"name\": issue_type}\n        }\n    }\n\n    response = requests.post(url, json=payload, auth=auth)\n    return response.json()\n\n# Example\nissue = create_issue(\"PROJ\", \"Fix login bug\", \"Users can't login with SSO\", \"Bug\")\nprint(f\"Created: {issue['key']}\")\n```\n\n### With Labels and Priority\n```python\ndef create_detailed_issue(project_key, summary, description,\n                          issue_type=\"Task\", priority=\"Medium\",\n                          labels=None, assignee=None):\n    payload = {\n        \"fields\": {\n            \"project\": {\"key\": project_key},\n            \"summary\": summary,\n            \"description\": {\n                \"type\": \"doc\",\n                \"version\": 1,\n                \"content\": [{\n                    \"type\": \"paragraph\",\n                    \"content\": [{\"type\": \"text\", \"text\": description}]\n                }]\n            },\n            \"issuetype\": {\"name\": issue_type},\n            \"priority\": {\"name\": priority},\n        }\n    }\n\n    if labels:\n        payload[\"fields\"][\"labels\"] = labels\n    if assignee:\n        payload[\"fields\"][\"assignee\"] = {\"accountId\": assignee}\n\n    # ... make request\n```\n\n## Common Issue Types\n\n| Type | Use For |\n|------|---------|\n| Bug | Something broken |\n| Task | Work item |\n| Story | User-facing feature |\n| Epic | Large initiative |\n| Sub-task | Part of larger task |\n\n## Updating Issues\n\n### Change Status\n```python\ndef transition_issue(issue_key, transition_name):\n    # Get available transitions\n    url = f\"{JIRA_BASE_URL}/rest/api/3/issue/{issue_key}/transitions\"\n    transitions = requests.get(url, auth=auth).json()\n\n    # Find matching transition\n    transition_id = None\n    for t in transitions['transitions']:\n        if t['name'].lower() == transition_name.lower():\n            transition_id = t['id']\n            break\n\n    # Execute transition\n    requests.post(url, json={\"transition\": {\"id\": transition_id}}, auth=auth)\n```\n\n### Add Comment\n```python\ndef add_comment(issue_key, comment_text):\n    url = f\"{JIRA_BASE_URL}/rest/api/3/issue/{issue_key}/comment\"\n\n    payload = {\n        \"body\": {\n            \"type\": \"doc\",\n            \"version\": 1,\n            \"content\": [{\n                \"type\": \"paragraph\",\n                \"content\": [{\"type\": \"text\", \"text\": comment_text}]\n            }]\n        }\n    }\n\n    requests.post(url, json=payload, auth=auth)\n```\n\n## Searching Issues\n\n### JQL Queries\n```python\ndef search_issues(jql):\n    url = f\"{JIRA_BASE_URL}/rest/api/3/search\"\n    params = {\"jql\": jql, \"maxResults\": 50}\n    response = requests.get(url, params=params, auth=auth)\n    return response.json()['issues']\n\n# Examples\nmy_bugs = search_issues(\"project = PROJ AND type = Bug AND assignee = currentUser()\")\nopen_items = search_issues(\"project = PROJ AND status != Done\")\nrecent = search_issues(\"project = PROJ AND created >= -7d\")\n```\n\n## Quick Commands\n\nWhen user says... create this:\n\n| Command | Action |\n|---------|--------|\n| \"log bug about X\" | Bug issue with description |\n| \"create task for X\" | Task issue |\n| \"what's on my plate\" | JQL: assignee = currentUser() AND status != Done |\n| \"move X to done\" | Transition issue to Done |\n| \"add comment to X\" | Add comment to issue |\n\n## Best Practices\n\n1. **Summary**: Keep under 80 chars, start with verb (Fix, Add, Update)\n2. **Description**: Include steps to reproduce for bugs\n3. **Labels**: Use for categorization (frontend, backend, urgent)\n4. **Links**: Reference related issues when relevant",
    "id": "jira-issues",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/jira-issues",
    "name_zh": "Jira ÈóÆÈ¢òÁÆ°ÁêÜ",
    "description_zh": "Create, update, and manage Jira issues from natural language. ÈÄÇÁî®‰∫é the user wants to log bugs, create tickets, update issue status, or manage their Jira backlog.",
    "body_zh": "# Jira Issue Management\n\nCreate and manage Jira issues using the Jira REST API or MCP.\n\n## Setup\n\n### Option 1: Jira MCP Server\nInstall the Jira MCP server for seamless integration:\n```bash\nnpx @anthropic/create-mcp-server jira\n```\n\n### Option 2: Direct API\nSet environment variables:\n```bash\nexport JIRA_BASE_URL=\"https://yourcompany.atlassian.net\"\nexport JIRA_EMAIL=\"your-email@company.com\"\nexport JIRA_API_TOKEN=\"your-api-token\"\n```\n\nGet your API token: https://id.atlassian.com/manage-profile/security/api-tokens\n\n## Creating Issues\n\n### Basic Issue\n```python\nimport requests\nfrom requests.auth import HTTPBasicAuth\nimport os\n\ndef create_issue(project_key, summary, description, issue_type=\"Task\"):\n    url = f\"{os.environ['JIRA_BASE_URL']}/rest/api/3/issue\"\n\n    auth = HTTPBasicAuth(\n        os.environ['JIRA_EMAIL'],\n        os.environ['JIRA_API_TOKEN']\n    )\n\n    payload = {\n        \"fields\": {\n            \"project\": {\"key\": project_key},\n            \"summary\": summary,\n            \"description\": {\n                \"type\": \"doc\",\n                \"version\": 1,\n                \"content\": [{\n                    \"type\": \"paragraph\",\n                    \"content\": [{\"type\": \"text\", \"text\": description}]\n                }]\n            },\n            \"issuetype\": {\"name\": issue_type}\n        }\n    }\n\n    response = requests.post(url, json=payload, auth=auth)\n    return response.json()\n\n# Example\nissue = create_issue(\"PROJ\", \"Fix login bug\", \"Users can't login with SSO\", \"Bug\")\nprint(f\"Created: {issue['key']}\")\n```\n\n### With Labels and Priority\n```python\ndef create_detailed_issue(project_key, summary, description,\n                          issue_type=\"Task\", priority=\"Medium\",\n                          labels=None, assignee=None):\n    payload = {\n        \"fields\": {\n            \"project\": {\"key\": project_key},\n            \"summary\": summary,\n            \"description\": {\n                \"type\": \"doc\",\n                \"version\": 1,\n                \"content\": [{\n                    \"type\": \"paragraph\",\n                    \"content\": [{\"type\": \"text\", \"text\": description}]\n                }]\n            },\n            \"issuetype\": {\"name\": issue_type},\n            \"priority\": {\"name\": priority},\n        }\n    }\n\n    if labels:\n        payload[\"fields\"][\"labels\"] = labels\n    if assignee:\n        payload[\"fields\"][\"assignee\"] = {\"accountId\": assignee}\n\n    # ... make request\n```\n\n## Common Issue Types\n\n| Type | Use For |\n|------|---------|\n| Bug | Something broken |\n| Task | Work item |\n| Story | User-facing feature |\n| Epic | Large initiative |\n| Sub-task | Part of larger task |\n\n## Updating Issues\n\n### Change Status\n```python\ndef transition_issue(issue_key, transition_name):\n    # Get available transitions\n    url = f\"{JIRA_BASE_URL}/rest/api/3/issue/{issue_key}/transitions\"\n    transitions = requests.get(url, auth=auth).json()\n\n    # Find matching transition\n    transition_id = None\n    for t in transitions['transitions']:\n        if t['name'].lower() == transition_name.lower():\n            transition_id = t['id']\n            break\n\n    # Execute transition\n    requests.post(url, json={\"transition\": {\"id\": transition_id}}, auth=auth)\n```\n\n### Add Comment\n```python\ndef add_comment(issue_key, comment_text):\n    url = f\"{JIRA_BASE_URL}/rest/api/3/issue/{issue_key}/comment\"\n\n    payload = {\n        \"body\": {\n            \"type\": \"doc\",\n            \"version\": 1,\n            \"content\": [{\n                \"type\": \"paragraph\",\n                \"content\": [{\"type\": \"text\", \"text\": comment_text}]\n            }]\n        }\n    }\n\n    requests.post(url, json=payload, auth=auth)\n```\n\n## Searching Issues\n\n### JQL Queries\n```python\ndef search_issues(jql):\n    url = f\"{JIRA_BASE_URL}/rest/api/3/search\"\n    params = {\"jql\": jql, \"maxResults\": 50}\n    response = requests.get(url, params=params, auth=auth)\n    return response.json()['issues']\n\n# Examples\nmy_bugs = search_issues(\"project = PROJ AND type = Bug AND assignee = currentUser()\")\nopen_items = search_issues(\"project = PROJ AND status != Done\")\nrecent = search_issues(\"project = PROJ AND created >= -7d\")\n```\n\n## Quick Commands\n\nWhen user says... create this:\n\n| Command | Action |\n|---------|--------|\n| \"log bug about X\" | Bug issue with description |\n| \"create task for X\" | Task issue |\n| \"what's on my plate\" | JQL: assignee = currentUser() AND status != Done |\n| \"move X to done\" | Transition issue to Done |\n| \"add comment to X\" | Add comment to issue |\n\n## Best Practices\n\n1. **Summary**: Keep under 80 chars, start with verb (Fix, Add, Update)\n2. **Description**: Include steps to reproduce for bugs\n3. **Labels**: Use for categorization (frontend, backend, urgent)\n4. **Links**: Reference related issues when relevant"
  },
  {
    "name": "job-application",
    "description": "Write tailored cover letters and job applications using your CV and preferred style",
    "body": "# Job Application Assistant\n\nGenerate cover letters and job applications that sound like you, not a template.\n\n## Your CV/Resume\n\n<!-- PASTE YOUR FULL CV BELOW -->\n\n```\n[Your name]\n[Your title/headline]\n\nEXPERIENCE\n- [Job 1]\n- [Job 2]\n\nSKILLS\n- [Skill 1]\n- [Skill 2]\n\nEDUCATION\n- [Degree, School, Year]\n\n[Add your full CV here]\n```\n\n## Cover Letter Examples You Like\n\n<!-- PASTE 1-2 COVER LETTERS YOU'VE WRITTEN THAT WORKED WELL -->\n\n### Example 1\n```\n[Paste a cover letter you're proud of]\n```\n\n### Example 2 (optional)\n```\n[Another example if you have one]\n```\n\n## Your Voice & Preferences\n\n### Tone\n- Professional but not stiff\n- Confident without bragging\n- Specific about achievements, not generic\n\n### Things to Emphasize\n- [What makes you unique]\n- [Key achievements to highlight]\n- [Skills you want to lead with]\n\n### Things to Avoid\n- Generic phrases like \"I'm a hard worker\"\n- Repeating the job description back\n- Being too formal or robotic\n\n## How to Use\n\n1. Paste the job description\n2. Say: \"Write a cover letter for this\"\n\nOr be more specific:\n- \"Write a cover letter emphasizing my backend experience\"\n- \"Make it shorter, 3 paragraphs max\"\n- \"Tailor this for a startup vs enterprise\"\n\n## Output Format\n\nWhen writing cover letters:\n- Keep it under 400 words unless asked otherwise\n- Lead with why you're interested in THIS role\n- Connect your experience to their specific needs\n- End with a clear call to action\n- Match the tone to the company (startup = casual, enterprise = formal)\n\n## Additional Context\n\n<!-- ADD ANY OTHER RELEVANT INFO -->\n\n- LinkedIn: [your URL]\n- Portfolio: [your URL]\n- Specific industries you're targeting: [e.g., fintech, healthtech]\n- Role types: [e.g., senior backend, staff engineer]",
    "id": "job-application",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/job-application",
    "name_zh": "Ê±ÇËÅåÁî≥ËØ∑",
    "description_zh": "Write tailored cover letters and job applications using your CV and preferred style",
    "body_zh": "# Job Application Assistant\n\nGenerate cover letters and job applications that sound like you, not a template.\n\n## Your CV/Resume\n\n<!-- PASTE YOUR FULL CV BELOW -->\n\n```\n[Your name]\n[Your title/headline]\n\nEXPERIENCE\n- [Job 1]\n- [Job 2]\n\nSKILLS\n- [Skill 1]\n- [Skill 2]\n\nEDUCATION\n- [Degree, School, Year]\n\n[Add your full CV here]\n```\n\n## Cover Letter Examples You Like\n\n<!-- PASTE 1-2 COVER LETTERS YOU'VE WRITTEN THAT WORKED WELL -->\n\n### Example 1\n```\n[Paste a cover letter you're proud of]\n```\n\n### Example 2 (optional)\n```\n[Another example if you have one]\n```\n\n## Your Voice & Preferences\n\n### Tone\n- Professional but not stiff\n- Confident without bragging\n- Specific about achievements, not generic\n\n### Things to Emphasize\n- [What makes you unique]\n- [Key achievements to highlight]\n- [Skills you want to lead with]\n\n### Things to Avoid\n- Generic phrases like \"I'm a hard worker\"\n- Repeating the job description back\n- Being too formal or robotic\n\n## How to Use\n\n1. Paste the job description\n2. Say: \"Write a cover letter for this\"\n\nOr be more specific:\n- \"Write a cover letter emphasizing my backend experience\"\n- \"Make it shorter, 3 paragraphs max\"\n- \"Tailor this for a startup vs enterprise\"\n\n## Output Format\n\nWhen writing cover letters:\n- Keep it under 400 words unless asked otherwise\n- Lead with why you're interested in THIS role\n- Connect your experience to their specific needs\n- End with a clear call to action\n- Match the tone to the company (startup = casual, enterprise = formal)\n\n## Additional Context\n\n<!-- ADD ANY OTHER RELEVANT INFO -->\n\n- LinkedIn: [your URL]\n- Portfolio: [your URL]\n- Specific industries you're targeting: [e.g., fintech, healthtech]\n- Role types: [e.g., senior backend, staff engineer]"
  },
  {
    "name": "lead-research-assistant",
    "description": "Identifies high-quality leads for your product or service by analyzing your business, searching for target companies, and providing actionable contact strategies. Perfect for sales, business development, and marketing professionals.",
    "body": "# Lead Research Assistant\n\nThis skill helps you identify and qualify potential leads for your business by analyzing your product/service, understanding your ideal customer profile, and providing actionable outreach strategies.\n\n## When to Use This Skill\n\n- Finding potential customers or clients for your product/service\n- Building a list of companies to reach out to for partnerships\n- Identifying target accounts for sales outreach\n- Researching companies that match your ideal customer profile\n- Preparing for business development activities\n\n## What This Skill Does\n\n1. **Understands Your Business**: Analyzes your product/service, value proposition, and target market\n2. **Identifies Target Companies**: Finds companies that match your ideal customer profile based on:\n   - Industry and sector\n   - Company size and location\n   - Technology stack and tools they use\n   - Growth stage and funding\n   - Pain points your product solves\n3. **Prioritizes Leads**: Ranks companies based on fit score and relevance\n4. **Provides Contact Strategies**: Suggests how to approach each lead with personalized messaging\n5. **Enriches Data**: Gathers relevant information about decision-makers and company context\n\n## How to Use\n\n### Basic Usage\n\nSimply describe your product/service and what you're looking for:\n\n```\nI'm building [product description]. Find me 10 companies in [location/industry] \nthat would be good leads for this.\n```\n\n### With Your Codebase\n\nFor even better results, run this from your product's source code directory:\n\n```\nLook at what I'm building in this repository and identify the top 10 companies \nin [location/industry] that would benefit from this product.\n```\n\n### Advanced Usage\n\nFor more targeted research:\n\n```\nMy product: [description]\nIdeal customer profile:\n- Industry: [industry]\n- Company size: [size range]\n- Location: [location]\n- Current pain points: [pain points]\n- Technologies they use: [tech stack]\n\nFind me 20 qualified leads with contact strategies for each.\n```\n\n## Instructions\n\nWhen a user requests lead research:\n\n1. **Understand the Product/Service**\n   - If in a code directory, analyze the codebase to understand the product\n   - Ask clarifying questions about the value proposition\n   - Identify key features and benefits\n   - Understand what problems it solves\n\n2. **Define Ideal Customer Profile**\n   - Determine target industries and sectors\n   - Identify company size ranges\n   - Consider geographic preferences\n   - Understand relevant pain points\n   - Note any technology requirements\n\n3. **Research and Identify Leads**\n   - Search for companies matching the criteria\n   - Look for signals of need (job postings, tech stack, recent news)\n   - Consider growth indicators (funding, expansion, hiring)\n   - Identify companies with complementary products/services\n   - Check for budget indicators\n\n4. **Prioritize and Score**\n   - Create a fit score (1-10) for each lead\n   - Consider factors like:\n     - Alignment with ICP\n     - Signals of immediate need\n     - Budget availability\n     - Competitive landscape\n     - Timing indicators\n\n5. **Provide Actionable Output**\n   \n   For each lead, provide:\n   - **Company Name** and website\n   - **Why They're a Good Fit**: Specific reasons based on their business\n   - **Priority Score**: 1-10 with explanation\n   - **Decision Maker**: Role/title to target (e.g., \"VP of Engineering\")\n   - **Contact Strategy**: Personalized approach suggestions\n   - **Value Proposition**: How your product solves their specific problem\n   - **Conversation Starters**: Specific points to mention in outreach\n   - **LinkedIn URL**: If available, for easy connection\n\n6. **Format the Output**\n\n   Present results in a clear, scannable format:\n\n   ```markdown\n   # Lead Research Results\n   \n   ## Summary\n   - Total leads found: [X]\n   - High priority (8-10): [X]\n   - Medium priority (5-7): [X]\n   - Average fit score: [X]\n   \n   ---\n   \n   ## Lead 1: [Company Name]\n   \n   **Website**: [URL]\n   **Priority Score**: [X/10]\n   **Industry**: [Industry]\n   **Size**: [Employee count/revenue range]\n   \n   **Why They're a Good Fit**:\n   [2-3 specific reasons based on their business]\n   \n   **Target Decision Maker**: [Role/Title]\n   **LinkedIn**: [URL if available]\n   \n   **Value Proposition for Them**:\n   [Specific benefit for this company]\n   \n   **Outreach Strategy**:\n   [Personalized approach - mention specific pain points, recent company news, or relevant context]\n   \n   **Conversation Starters**:\n   - [Specific point 1]\n   - [Specific point 2]\n   \n   ---\n   \n   [Repeat for each lead]\n   ```\n\n7. **Offer Next Steps**\n   - Suggest saving results to a CSV for CRM import\n   - Offer to draft personalized outreach messages\n   - Recommend prioritization based on timing\n   - Suggest follow-up research for top leads\n\n## Examples\n\n### Example 1: From Lenny's Newsletter\n\n**User**: \"I'm building a tool that masks sensitive data in AI coding assistant queries. Find potential leads.\"\n\n**Output**: Creates a prioritized list of companies that:\n- Use AI coding assistants (Copilot, Cursor, etc.)\n- Handle sensitive data (fintech, healthcare, legal)\n- Have evidence in their GitHub repos of using coding agents\n- May have accidentally exposed sensitive data in code\n- Includes LinkedIn URLs of relevant decision-makers\n\n### Example 2: Local Business\n\n**User**: \"I run a consulting practice for remote team productivity. Find me 10 companies in the Bay Area that recently went remote.\"\n\n**Output**: Identifies companies that:\n- Recently posted remote job listings\n- Announced remote-first policies\n- Are hiring distributed teams\n- Show signs of remote work challenges\n- Provides personalized outreach strategies for each\n\n## Tips for Best Results\n\n- **Be specific** about your product and its unique value\n- **Run from your codebase** if applicable for automatic context\n- **Provide context** about your ideal customer profile\n- **Specify constraints** like industry, location, or company size\n- **Request follow-up** research on promising leads for deeper insights\n\n## Related Use Cases\n\n- Drafting personalized outreach emails after identifying leads\n- Building a CRM-ready CSV of qualified prospects\n- Researching specific companies in detail\n- Analyzing competitor customer bases\n- Identifying partnership opportunities",
    "id": "lead-research-assistant",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/lead-research-assistant",
    "name_zh": "ÊΩúÂÆ¢Á†îÁ©∂Âä©Êâã",
    "description_zh": "Identifies high-quality leads for your product or service by analyzing your business, searching for target companies, and providing actionable contact strategies. Perfect for sales, business development, and marketing professionals.",
    "body_zh": "# Lead Research Assistant\n\nThis skill helps you identify and qualify potential leads for your business by analyzing your product/service, understanding your ideal customer profile, and providing actionable outreach strategies.\n\n## When to Use This Skill\n\n- Finding potential customers or clients for your product/service\n- Building a list of companies to reach out to for partnerships\n- Identifying target accounts for sales outreach\n- Researching companies that match your ideal customer profile\n- Preparing for business development activities\n\n## What This Skill Does\n\n1. **Understands Your Business**: Analyzes your product/service, value proposition, and target market\n2. **Identifies Target Companies**: Finds companies that match your ideal customer profile based on:\n   - Industry and sector\n   - Company size and location\n   - Technology stack and tools they use\n   - Growth stage and funding\n   - Pain points your product solves\n3. **Prioritizes Leads**: Ranks companies based on fit score and relevance\n4. **Provides Contact Strategies**: Suggests how to approach each lead with personalized messaging\n5. **Enriches Data**: Gathers relevant information about decision-makers and company context\n\n## How to Use\n\n### Basic Usage\n\nSimply describe your product/service and what you're looking for:\n\n```\nI'm building [product description]. Find me 10 companies in [location/industry] \nthat would be good leads for this.\n```\n\n### With Your Codebase\n\nFor even better results, run this from your product's source code directory:\n\n```\nLook at what I'm building in this repository and identify the top 10 companies \nin [location/industry] that would benefit from this product.\n```\n\n### Advanced Usage\n\nFor more targeted research:\n\n```\nMy product: [description]\nIdeal customer profile:\n- Industry: [industry]\n- Company size: [size range]\n- Location: [location]\n- Current pain points: [pain points]\n- Technologies they use: [tech stack]\n\nFind me 20 qualified leads with contact strategies for each.\n```\n\n## Instructions\n\nWhen a user requests lead research:\n\n1. **Understand the Product/Service**\n   - If in a code directory, analyze the codebase to understand the product\n   - Ask clarifying questions about the value proposition\n   - Identify key features and benefits\n   - Understand what problems it solves\n\n2. **Define Ideal Customer Profile**\n   - Determine target industries and sectors\n   - Identify company size ranges\n   - Consider geographic preferences\n   - Understand relevant pain points\n   - Note any technology requirements\n\n3. **Research and Identify Leads**\n   - Search for companies matching the criteria\n   - Look for signals of need (job postings, tech stack, recent news)\n   - Consider growth indicators (funding, expansion, hiring)\n   - Identify companies with complementary products/services\n   - Check for budget indicators\n\n4. **Prioritize and Score**\n   - Create a fit score (1-10) for each lead\n   - Consider factors like:\n     - Alignment with ICP\n     - Signals of immediate need\n     - Budget availability\n     - Competitive landscape\n     - Timing indicators\n\n5. **Provide Actionable Output**\n   \n   For each lead, provide:\n   - **Company Name** and website\n   - **Why They're a Good Fit**: Specific reasons based on their business\n   - **Priority Score**: 1-10 with explanation\n   - **Decision Maker**: Role/title to target (e.g., \"VP of Engineering\")\n   - **Contact Strategy**: Personalized approach suggestions\n   - **Value Proposition**: How your product solves their specific problem\n   - **Conversation Starters**: Specific points to mention in outreach\n   - **LinkedIn URL**: If available, for easy connection\n\n6. **Format the Output**\n\n   Present results in a clear, scannable format:\n\n   ```markdown\n   # Lead Research Results\n   \n   ## Summary\n   - Total leads found: [X]\n   - High priority (8-10): [X]\n   - Medium priority (5-7): [X]\n   - Average fit score: [X]\n   \n   ---\n   \n   ## Lead 1: [Company Name]\n   \n   **Website**: [URL]\n   **Priority Score**: [X/10]\n   **Industry**: [Industry]\n   **Size**: [Employee count/revenue range]\n   \n   **Why They're a Good Fit**:\n   [2-3 specific reasons based on their business]\n   \n   **Target Decision Maker**: [Role/Title]\n   **LinkedIn**: [URL if available]\n   \n   **Value Proposition for Them**:\n   [Specific benefit for this company]\n   \n   **Outreach Strategy**:\n   [Personalized approach - mention specific pain points, recent company news, or relevant context]\n   \n   **Conversation Starters**:\n   - [Specific point 1]\n   - [Specific point 2]\n   \n   ---\n   \n   [Repeat for each lead]\n   ```\n\n7. **Offer Next Steps**\n   - Suggest saving results to a CSV for CRM import\n   - Offer to draft personalized outreach messages\n   - Recommend prioritization based on timing\n   - Suggest follow-up research for top leads\n\n## Examples\n\n### Example 1: From Lenny's Newsletter\n\n**User**: \"I'm building a tool that masks sensitive data in AI coding assistant queries. Find potential leads.\"\n\n**Output**: Creates a prioritized list of companies that:\n- Use AI coding assistants (Copilot, Cursor, etc.)\n- Handle sensitive data (fintech, healthcare, legal)\n- Have evidence in their GitHub repos of using coding agents\n- May have accidentally exposed sensitive data in code\n- Includes LinkedIn URLs of relevant decision-makers\n\n### Example 2: Local Business\n\n**User**: \"I run a consulting practice for remote team productivity. Find me 10 companies in the Bay Area that recently went remote.\"\n\n**Output**: Identifies companies that:\n- Recently posted remote job listings\n- Announced remote-first policies\n- Are hiring distributed teams\n- Show signs of remote work challenges\n- Provides personalized outreach strategies for each\n\n## Tips for Best Results\n\n- **Be specific** about your product and its unique value\n- **Run from your codebase** if applicable for automatic context\n- **Provide context** about your ideal customer profile\n- **Specify constraints** like industry, location, or company size\n- **Request follow-up** research on promising leads for deeper insights\n\n## Related Use Cases\n\n- Drafting personalized outreach emails after identifying leads\n- Building a CRM-ready CSV of qualified prospects\n- Researching specific companies in detail\n- Analyzing competitor customer bases\n- Identifying partnership opportunities"
  },
  {
    "name": "llm-application-dev",
    "description": "Building applications with Large Language Models - prompt engineering, RAG patterns, and LLM integration. Use for AI-powered features, chatbots, or LLM-based automation.",
    "body": "# LLM Application Development\n\n## Prompt Engineering\n\n### Structured Prompts\n```typescript\nconst systemPrompt = `You are a helpful assistant that answers questions about our product.\n\nRULES:\n- Only answer questions about our product\n- If you don't know, say \"I don't know\"\n- Keep responses concise (under 100 words)\n- Never make up information\n\nCONTEXT:\n{context}`;\n\nconst userPrompt = `Question: {question}`;\n```\n\n### Few-Shot Examples\n```typescript\nconst prompt = `Classify the sentiment of customer feedback.\n\nExamples:\nInput: \"Love this product!\"\nOutput: positive\n\nInput: \"Worst purchase ever\"\nOutput: negative\n\nInput: \"It works fine\"\nOutput: neutral\n\nInput: \"${customerFeedback}\"\nOutput:`;\n```\n\n### Chain of Thought\n```typescript\nconst prompt = `Solve this step by step:\n\nQuestion: ${question}\n\nLet's think through this:\n1. First, identify the key information\n2. Then, determine the approach\n3. Finally, calculate the answer\n\nStep-by-step solution:`;\n```\n\n## API Integration\n\n### OpenAI Pattern\n```typescript\nimport OpenAI from 'openai';\n\nconst openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });\n\nasync function chat(messages: Message[]): Promise<string> {\n  const response = await openai.chat.completions.create({\n    model: 'gpt-4',\n    messages,\n    temperature: 0.7,\n    max_tokens: 500,\n  });\n\n  return response.choices[0].message.content ?? '';\n}\n```\n\n### Anthropic Pattern\n```typescript\nimport Anthropic from '@anthropic-ai/sdk';\n\nconst anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });\n\nasync function chat(prompt: string): Promise<string> {\n  const response = await anthropic.messages.create({\n    model: 'claude-3-opus-20240229',\n    max_tokens: 1024,\n    messages: [{ role: 'user', content: prompt }],\n  });\n\n  return response.content[0].type === 'text'\n    ? response.content[0].text\n    : '';\n}\n```\n\n### Streaming Responses\n```typescript\nasync function* streamChat(prompt: string) {\n  const stream = await openai.chat.completions.create({\n    model: 'gpt-4',\n    messages: [{ role: 'user', content: prompt }],\n    stream: true,\n  });\n\n  for await (const chunk of stream) {\n    const content = chunk.choices[0]?.delta?.content;\n    if (content) yield content;\n  }\n}\n```\n\n## RAG (Retrieval-Augmented Generation)\n\n### Basic RAG Pipeline\n```typescript\nasync function ragQuery(question: string): Promise<string> {\n  // 1. Embed the question\n  const questionEmbedding = await embedText(question);\n\n  // 2. Search vector database\n  const relevantDocs = await vectorDb.search(questionEmbedding, { limit: 5 });\n\n  // 3. Build context\n  const context = relevantDocs.map(d => d.content).join('\\n\\n');\n\n  // 4. Generate answer\n  const prompt = `Answer based on this context:\\n${context}\\n\\nQuestion: ${question}`;\n  return await chat(prompt);\n}\n```\n\n### Document Chunking\n```typescript\nfunction chunkDocument(text: string, options: ChunkOptions): string[] {\n  const { chunkSize = 1000, overlap = 200 } = options;\n  const chunks: string[] = [];\n\n  let start = 0;\n  while (start < text.length) {\n    const end = Math.min(start + chunkSize, text.length);\n    chunks.push(text.slice(start, end));\n    start += chunkSize - overlap;\n  }\n\n  return chunks;\n}\n```\n\n### Embedding Storage\n```typescript\n// Using Supabase with pgvector\nasync function storeEmbeddings(docs: Document[]) {\n  for (const doc of docs) {\n    const embedding = await embedText(doc.content);\n\n    await supabase.from('documents').insert({\n      content: doc.content,\n      metadata: doc.metadata,\n      embedding: embedding,  // vector column\n    });\n  }\n}\n\nasync function searchSimilar(query: string, limit = 5) {\n  const embedding = await embedText(query);\n\n  const { data } = await supabase.rpc('match_documents', {\n    query_embedding: embedding,\n    match_count: limit,\n  });\n\n  return data;\n}\n```\n\n## Error Handling\n\n```typescript\nasync function safeLLMCall<T>(\n  fn: () => Promise<T>,\n  options: { retries?: number; fallback?: T }\n): Promise<T> {\n  const { retries = 3, fallback } = options;\n\n  for (let i = 0; i < retries; i++) {\n    try {\n      return await fn();\n    } catch (error) {\n      if (error.status === 429) {\n        // Rate limit - exponential backoff\n        await sleep(Math.pow(2, i) * 1000);\n        continue;\n      }\n      if (i === retries - 1) {\n        if (fallback !== undefined) return fallback;\n        throw error;\n      }\n    }\n  }\n  throw new Error('Max retries exceeded');\n}\n```\n\n## Best Practices\n\n- **Token Management**: Track usage and set limits\n- **Caching**: Cache embeddings and common queries\n- **Evaluation**: Test prompts with diverse inputs\n- **Guardrails**: Validate outputs before using\n- **Logging**: Log prompts and responses for debugging\n- **Cost Control**: Use cheaper models for simple tasks\n- **Latency**: Stream responses for better UX\n- **Privacy**: Don't send PII to external APIs",
    "id": "llm-application-dev",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/llm-application-dev",
    "name_zh": "LLM Â∫îÁî®ÂºÄÂèë",
    "description_zh": "ÊûÑÂª∫ing applications with Large Language Models - prompt engineering, RAG patterns, and LLM integration. Use for AI-powered features, chatbots, or LLM-based automation.",
    "body_zh": "# LLM Application Development\n\n## Prompt Engineering\n\n### Structured Prompts\n```typescript\nconst systemPrompt = `You are a helpful assistant that answers questions about our product.\n\nRULES:\n- Only answer questions about our product\n- If you don't know, say \"I don't know\"\n- Keep responses concise (under 100 words)\n- Never make up information\n\nCONTEXT:\n{context}`;\n\nconst userPrompt = `Question: {question}`;\n```\n\n### Few-Shot Examples\n```typescript\nconst prompt = `Classify the sentiment of customer feedback.\n\nExamples:\nInput: \"Love this product!\"\nOutput: positive\n\nInput: \"Worst purchase ever\"\nOutput: negative\n\nInput: \"It works fine\"\nOutput: neutral\n\nInput: \"${customerFeedback}\"\nOutput:`;\n```\n\n### Chain of Thought\n```typescript\nconst prompt = `Solve this step by step:\n\nQuestion: ${question}\n\nLet's think through this:\n1. First, identify the key information\n2. Then, determine the approach\n3. Finally, calculate the answer\n\nStep-by-step solution:`;\n```\n\n## API Integration\n\n### OpenAI Pattern\n```typescript\nimport OpenAI from 'openai';\n\nconst openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });\n\nasync function chat(messages: Message[]): Promise<string> {\n  const response = await openai.chat.completions.create({\n    model: 'gpt-4',\n    messages,\n    temperature: 0.7,\n    max_tokens: 500,\n  });\n\n  return response.choices[0].message.content ?? '';\n}\n```\n\n### Anthropic Pattern\n```typescript\nimport Anthropic from '@anthropic-ai/sdk';\n\nconst anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });\n\nasync function chat(prompt: string): Promise<string> {\n  const response = await anthropic.messages.create({\n    model: 'claude-3-opus-20240229',\n    max_tokens: 1024,\n    messages: [{ role: 'user', content: prompt }],\n  });\n\n  return response.content[0].type === 'text'\n    ? response.content[0].text\n    : '';\n}\n```\n\n### Streaming Responses\n```typescript\nasync function* streamChat(prompt: string) {\n  const stream = await openai.chat.completions.create({\n    model: 'gpt-4',\n    messages: [{ role: 'user', content: prompt }],\n    stream: true,\n  });\n\n  for await (const chunk of stream) {\n    const content = chunk.choices[0]?.delta?.content;\n    if (content) yield content;\n  }\n}\n```\n\n## RAG (Retrieval-Augmented Generation)\n\n### Basic RAG Pipeline\n```typescript\nasync function ragQuery(question: string): Promise<string> {\n  // 1. Embed the question\n  const questionEmbedding = await embedText(question);\n\n  // 2. Search vector database\n  const relevantDocs = await vectorDb.search(questionEmbedding, { limit: 5 });\n\n  // 3. Build context\n  const context = relevantDocs.map(d => d.content).join('\\n\\n');\n\n  // 4. Generate answer\n  const prompt = `Answer based on this context:\\n${context}\\n\\nQuestion: ${question}`;\n  return await chat(prompt);\n}\n```\n\n### Document Chunking\n```typescript\nfunction chunkDocument(text: string, options: ChunkOptions): string[] {\n  const { chunkSize = 1000, overlap = 200 } = options;\n  const chunks: string[] = [];\n\n  let start = 0;\n  while (start < text.length) {\n    const end = Math.min(start + chunkSize, text.length);\n    chunks.push(text.slice(start, end));\n    start += chunkSize - overlap;\n  }\n\n  return chunks;\n}\n```\n\n### Embedding Storage\n```typescript\n// Using Supabase with pgvector\nasync function storeEmbeddings(docs: Document[]) {\n  for (const doc of docs) {\n    const embedding = await embedText(doc.content);\n\n    await supabase.from('documents').insert({\n      content: doc.content,\n      metadata: doc.metadata,\n      embedding: embedding,  // vector column\n    });\n  }\n}\n\nasync function searchSimilar(query: string, limit = 5) {\n  const embedding = await embedText(query);\n\n  const { data } = await supabase.rpc('match_documents', {\n    query_embedding: embedding,\n    match_count: limit,\n  });\n\n  return data;\n}\n```\n\n## Error Handling\n\n```typescript\nasync function safeLLMCall<T>(\n  fn: () => Promise<T>,\n  options: { retries?: number; fallback?: T }\n): Promise<T> {\n  const { retries = 3, fallback } = options;\n\n  for (let i = 0; i < retries; i++) {\n    try {\n      return await fn();\n    } catch (error) {\n      if (error.status === 429) {\n        // Rate limit - exponential backoff\n        await sleep(Math.pow(2, i) * 1000);\n        continue;\n      }\n      if (i === retries - 1) {\n        if (fallback !== undefined) return fallback;\n        throw error;\n      }\n    }\n  }\n  throw new Error('Max retries exceeded');\n}\n```\n\n## Best Practices\n\n- **Token Management**: Track usage and set limits\n- **Caching**: Cache embeddings and common queries\n- **Evaluation**: Test prompts with diverse inputs\n- **Guardrails**: Validate outputs before using\n- **Logging**: Log prompts and responses for debugging\n- **Cost Control**: Use cheaper models for simple tasks\n- **Latency**: Stream responses for better UX\n- **Privacy**: Don't send PII to external APIs"
  },
  {
    "name": "mcp-builder",
    "description": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).",
    "body": "# MCP Server Development Guide\n\nCreate MCP servers that enable LLMs to interact with external services through well-designed tools.\n\n## High-Level Workflow\n\n### Phase 1: Research and Planning\n\n**Understand Modern MCP Design:**\n- Balance comprehensive API coverage with specialized workflow tools\n- Use clear, descriptive tool names with consistent prefixes (e.g., `github_create_issue`)\n- Design tools that return focused, relevant data\n- Provide actionable error messages\n\n**Study MCP Protocol:**\n- Start with sitemap: `https://modelcontextprotocol.io/sitemap.xml`\n- Key pages: specification, transport mechanisms, tool definitions\n\n### Phase 2: Implementation\n\n**Recommended Stack:**\n- **Language**: TypeScript (best SDK support)\n- **Transport**: Streamable HTTP for remote, stdio for local\n\n**Project Structure:**\n```\nmy-mcp-server/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ index.ts      # Server entry point\n‚îÇ   ‚îú‚îÄ‚îÄ tools/        # Tool implementations\n‚îÇ   ‚îî‚îÄ‚îÄ utils/        # Shared utilities\n‚îú‚îÄ‚îÄ package.json\n‚îî‚îÄ‚îÄ tsconfig.json\n```\n\n**Tool Implementation Pattern:**\n```typescript\nserver.registerTool({\n  name: \"github_create_issue\",\n  description: \"Create a new GitHub issue\",\n  inputSchema: z.object({\n    repo: z.string().describe(\"Repository name (owner/repo)\"),\n    title: z.string().describe(\"Issue title\"),\n    body: z.string().optional().describe(\"Issue body\")\n  }),\n  outputSchema: z.object({\n    id: z.number(),\n    url: z.string()\n  }),\n  annotations: {\n    readOnlyHint: false,\n    destructiveHint: false,\n    idempotentHint: false\n  },\n  handler: async (input) => {\n    // Implementation\n    return { id: 123, url: \"https://...\" };\n  }\n});\n```\n\n### Phase 3: Test\n\n```bash\n# TypeScript\nnpm run build\nnpx @modelcontextprotocol/inspector\n\n# Python\npython -m py_compile your_server.py\n```\n\n### Phase 4: Create Evaluations\n\nCreate 10 complex, realistic questions to test your MCP server:\n\n```xml\n<evaluation>\n  <qa_pair>\n    <question>Find all open issues labeled 'bug' in the repo</question>\n    <answer>5</answer>\n  </qa_pair>\n</evaluation>\n```\n\n## Tool Design Best Practices\n\n- Use Zod (TS) or Pydantic (Python) for schemas\n- Include constraints and examples in field descriptions\n- Define `outputSchema` for structured data\n- Support pagination where applicable\n- Add tool annotations (readOnly, destructive, idempotent)",
    "id": "mcp-builder",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/mcp-builder",
    "name_zh": "MCP ÊûÑÂª∫Âô®",
    "description_zh": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. ÈÄÇÁî®‰∫é building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).",
    "body_zh": "# MCP Server Development Guide\n\nCreate MCP servers that enable LLMs to interact with external services through well-designed tools.\n\n## High-Level Workflow\n\n### Phase 1: Research and Planning\n\n**Understand Modern MCP Design:**\n- Balance comprehensive API coverage with specialized workflow tools\n- Use clear, descriptive tool names with consistent prefixes (e.g., `github_create_issue`)\n- Design tools that return focused, relevant data\n- Provide actionable error messages\n\n**Study MCP Protocol:**\n- Start with sitemap: `https://modelcontextprotocol.io/sitemap.xml`\n- Key pages: specification, transport mechanisms, tool definitions\n\n### Phase 2: Implementation\n\n**Recommended Stack:**\n- **Language**: TypeScript (best SDK support)\n- **Transport**: Streamable HTTP for remote, stdio for local\n\n**Project Structure:**\n```\nmy-mcp-server/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ index.ts      # Server entry point\n‚îÇ   ‚îú‚îÄ‚îÄ tools/        # Tool implementations\n‚îÇ   ‚îî‚îÄ‚îÄ utils/        # Shared utilities\n‚îú‚îÄ‚îÄ package.json\n‚îî‚îÄ‚îÄ tsconfig.json\n```\n\n**Tool Implementation Pattern:**\n```typescript\nserver.registerTool({\n  name: \"github_create_issue\",\n  description: \"Create a new GitHub issue\",\n  inputSchema: z.object({\n    repo: z.string().describe(\"Repository name (owner/repo)\"),\n    title: z.string().describe(\"Issue title\"),\n    body: z.string().optional().describe(\"Issue body\")\n  }),\n  outputSchema: z.object({\n    id: z.number(),\n    url: z.string()\n  }),\n  annotations: {\n    readOnlyHint: false,\n    destructiveHint: false,\n    idempotentHint: false\n  },\n  handler: async (input) => {\n    // Implementation\n    return { id: 123, url: \"https://...\" };\n  }\n});\n```\n\n### Phase 3: Test\n\n```bash\n# TypeScript\nnpm run build\nnpx @modelcontextprotocol/inspector\n\n# Python\npython -m py_compile your_server.py\n```\n\n### Phase 4: Create Evaluations\n\nCreate 10 complex, realistic questions to test your MCP server:\n\n```xml\n<evaluation>\n  <qa_pair>\n    <question>Find all open issues labeled 'bug' in the repo</question>\n    <answer>5</answer>\n  </qa_pair>\n</evaluation>\n```\n\n## Tool Design Best Practices\n\n- Use Zod (TS) or Pydantic (Python) for schemas\n- Include constraints and examples in field descriptions\n- Define `outputSchema` for structured data\n- Support pagination where applicable\n- Add tool annotations (readOnly, destructive, idempotent)"
  },
  {
    "name": "meeting-insights-analyzer",
    "description": "Analyzes meeting transcripts and recordings to uncover behavioral patterns, communication insights, and actionable feedback. Identifies when you avoid conflict, use filler words, dominate conversations, or miss opportunities to listen. Perfect for professionals seeking to improve their communication and leadership skills.",
    "body": "# Meeting Insights Analyzer\n\nThis skill transforms your meeting transcripts into actionable insights about your communication patterns, helping you become a more effective communicator and leader.\n\n## When to Use This Skill\n\n- Analyzing your communication patterns across multiple meetings\n- Getting feedback on your leadership and facilitation style\n- Identifying when you avoid difficult conversations\n- Understanding your speaking habits and filler words\n- Tracking improvement in communication skills over time\n- Preparing for performance reviews with concrete examples\n- Coaching team members on their communication style\n\n## What This Skill Does\n\n1. **Pattern Recognition**: Identifies recurring behaviors across meetings like:\n   - Conflict avoidance or indirect communication\n   - Speaking ratios and turn-taking\n   - Question-asking vs. statement-making patterns\n   - Active listening indicators\n   - Decision-making approaches\n\n2. **Communication Analysis**: Evaluates communication effectiveness:\n   - Clarity and directness\n   - Use of filler words and hedging language\n   - Tone and sentiment patterns\n   - Meeting control and facilitation\n\n3. **Actionable Feedback**: Provides specific, timestamped examples with:\n   - What happened\n   - Why it matters\n   - How to improve\n\n4. **Trend Tracking**: Compares patterns over time when analyzing multiple meetings\n\n## How to Use\n\n### Basic Setup\n\n1. Download your meeting transcripts to a folder (e.g., `~/meetings/`)\n2. Navigate to that folder in Claude Code\n3. Ask for the analysis you want\n\n### Quick Start Examples\n\n```\nAnalyze all meetings in this folder and tell me when I avoided conflict.\n```\n\n```\nLook at my meetings from the past month and identify my communication patterns.\n```\n\n```\nCompare my facilitation style between these two meeting folders.\n```\n\n### Advanced Analysis\n\n```\nAnalyze all transcripts in this folder and:\n1. Identify when I interrupted others\n2. Calculate my speaking ratio\n3. Find moments I avoided giving direct feedback\n4. Track my use of filler words\n5. Show examples of good active listening\n```\n\n## Instructions\n\nWhen a user requests meeting analysis:\n\n1. **Discover Available Data**\n   - Scan the folder for transcript files (.txt, .md, .vtt, .srt, .docx)\n   - Check if files contain speaker labels and timestamps\n   - Confirm the date range of meetings\n   - Identify the user's name/identifier in transcripts\n\n2. **Clarify Analysis Goals**\n   \n   If not specified, ask what they want to learn:\n   - Specific behaviors (conflict avoidance, interruptions, filler words)\n   - Communication effectiveness (clarity, directness, listening)\n   - Meeting facilitation skills\n   - Speaking patterns and ratios\n   - Growth areas for improvement\n   \n3. **Analyze Patterns**\n\n   For each requested insight:\n   \n   **Conflict Avoidance**:\n   - Look for hedging language (\"maybe\", \"kind of\", \"I think\")\n   - Indirect phrasing instead of direct requests\n   - Changing subject when tension arises\n   - Agreeing without commitment (\"yeah, but...\")\n   - Not addressing obvious problems\n   \n   **Speaking Ratios**:\n   - Calculate percentage of meeting spent speaking\n   - Count interruptions (by and of the user)\n   - Measure average speaking turn length\n   - Track question vs. statement ratios\n   \n   **Filler Words**:\n   - Count \"um\", \"uh\", \"like\", \"you know\", \"actually\", etc.\n   - Note frequency per minute or per speaking turn\n   - Identify situations where they increase (nervous, uncertain)\n   \n   **Active Listening**:\n   - Questions that reference others' previous points\n   - Paraphrasing or summarizing others' ideas\n   - Building on others' contributions\n   - Asking clarifying questions\n   \n   **Leadership & Facilitation**:\n   - Decision-making approach (directive vs. collaborative)\n   - How disagreements are handled\n   - Inclusion of quieter participants\n   - Time management and agenda control\n   - Follow-up and action item clarity\n\n4. **Provide Specific Examples**\n\n   For each pattern found, include:\n   \n   ```markdown\n   ### [Pattern Name]\n   \n   **Finding**: [One-sentence summary of the pattern]\n   \n   **Frequency**: [X times across Y meetings]\n   \n   **Examples**:\n   \n   1. **[Meeting Name/Date]** - [Timestamp]\n      \n      **What Happened**:\n      > [Actual quote from transcript]\n      \n      **Why This Matters**:\n      [Explanation of the impact or missed opportunity]\n      \n      **Better Approach**:\n      [Specific alternative phrasing or behavior]\n   \n   [Repeat for 2-3 strongest examples]\n   ```\n\n5. **Synthesize Insights**\n\n   After analyzing all patterns, provide:\n   \n   ```markdown\n   # Meeting Insights Summary\n   \n   **Analysis Period**: [Date range]\n   **Meetings Analyzed**: [X meetings]\n   **Total Duration**: [X hours]\n   \n   ## Key Patterns Identified\n   \n   ### 1. [Primary Pattern]\n   - **Observed**: [What you saw]\n   - **Impact**: [Why it matters]\n   - **Recommendation**: [How to improve]\n   \n   ### 2. [Second Pattern]\n   [Same structure]\n   \n   ## Communication Strengths\n   \n   1. [Strength 1 with example]\n   2. [Strength 2 with example]\n   3. [Strength 3 with example]\n   \n   ## Growth Opportunities\n   \n   1. **[Area 1]**: [Specific, actionable advice]\n   2. **[Area 2]**: [Specific, actionable advice]\n   3. **[Area 3]**: [Specific, actionable advice]\n   \n   ## Speaking Statistics\n   \n   - Average speaking time: [X% of meeting]\n   - Questions asked: [X per meeting average]\n   - Filler words: [X per minute]\n   - Interruptions: [X given / Y received per meeting]\n   \n   ## Next Steps\n   \n   [3-5 concrete actions to improve communication]\n   ```\n\n6. **Offer Follow-Up Options**\n   - Track these same metrics in future meetings\n   - Deep dive into specific meetings or patterns\n   - Compare to industry benchmarks\n   - Create a personal communication development plan\n   - Generate a summary for performance reviews\n\n## Examples\n\n### Example 1: Conflict Avoidance Analysis (Inspired by Dan Shipper)\n\n**User**: \"I download all of my meeting recordings and put them in a folder. Tell me all the times I've subtly avoided conflict.\"\n\n**Output**: \n```markdown\n# Conflict Avoidance Patterns\n\nFound 23 instances across 15 meetings where you used indirect \ncommunication or avoided addressing tensions directly.\n\n## Pattern: Hedging on Critical Feedback\n\n**Frequency**: 8 times across 7 meetings\n\n**Example 1: 1:1 with Sarah** - 00:14:32\n\n**What Happened**:\n> \"So, I was thinking... maybe we could, like, potentially \n> consider looking at the timeline again? I mean, if you \n> think that makes sense. But whatever you think is best!\"\n\n**Why This Matters**:\nYou needed to address that Sarah's project was behind schedule, \nbut the hedging language (\"maybe\", \"potentially\", \"if you think\") \nand the deflection at the end (\"whatever you think\") made it easy \nfor her to miss the urgency.\n\n**Better Approach**:\n\"Sarah, the project is two weeks behind schedule. We need to \ndiscuss what's blocking progress and create a new timeline \ntoday.\"\n\n[Additional examples...]\n\n## Recommendations\n\n1. **Name the issue directly** in the first sentence\n2. **Remove hedging words** like \"maybe,\" \"kind of,\" \"sort of\"\n3. **Ask specific questions** instead of hinting\n4. **Schedule difficult conversations** instead of raising them casually\n```\n\n### Example 2: Leadership Facilitation\n\n**User**: \"Analyze my team meetings and tell me about my facilitation style.\"\n\n**Output**: Provides insights on:\n- How much you speak vs. team members (60% vs. 40%)\n- Whether you ask questions or make statements (3:1 ratio)\n- How you handle disagreements (tendency to resolve too quickly)\n- Who speaks least and whether you draw them in\n- Examples of good and missed facilitation moments\n\n### Example 3: Personal Development Tracking\n\n**User**: \"Compare my meetings from Q1 vs. Q2 to see if I've improved my listening skills.\"\n\n**Output**: Creates a comparative analysis showing:\n- Decrease in interruptions (8 per meeting ‚Üí 3 per meeting)\n- Increase in clarifying questions (2 ‚Üí 7 per meeting)\n- Improvement in building on others' ideas\n- Specific examples showing the difference\n- Remaining areas for growth\n\n## Setup Tips\n\n### Getting Meeting Transcripts\n\n**From Granola** (free with Lenny's newsletter subscription):\n- Granola auto-transcribes your meetings\n- Export transcripts to a folder: [Instructions on how]\n- Point Claude Code to that folder\n\n**From Zoom**:\n- Enable cloud recording with transcription\n- Download VTT or SRT files after meetings\n- Store in a dedicated folder\n\n**From Google Meet**:\n- Use Google Docs auto-transcription\n- Save transcript docs to a folder\n- Download as .txt files or give Claude Code access\n\n**From Fireflies.ai, Otter.ai, etc.**:\n- Export transcripts in bulk\n- Store in a local folder\n- Run analysis on the folder\n\n### Best Practices\n\n1. **Consistent naming**: Use `YYYY-MM-DD - Meeting Name.txt` format\n2. **Regular analysis**: Review monthly or quarterly for trends\n3. **Specific queries**: Ask about one behavior at a time for depth\n4. **Privacy**: Keep sensitive meeting data local\n5. **Action-oriented**: Focus on one improvement area at a time\n\n## Common Analysis Requests\n\n- \"When do I avoid difficult conversations?\"\n- \"How often do I interrupt others?\"\n- \"What's my speaking vs. listening ratio?\"\n- \"Do I ask good questions?\"\n- \"How do I handle disagreement?\"\n- \"Am I inclusive of all voices?\"\n- \"Do I use too many filler words?\"\n- \"How clear are my action items?\"\n- \"Do I stay on agenda or get sidetracked?\"\n- \"How has my communication changed over time?\"\n\n## Related Use Cases\n\n- Creating a personal development plan from insights\n- Preparing performance review materials with examples\n- Coaching direct reports on their communication\n- Analyzing customer calls for sales or support patterns\n- Studying negotiation tactics and outcomes",
    "id": "meeting-insights-analyzer",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/meeting-insights-analyzer",
    "name_zh": "‰ºöËÆÆÊ¥ûÂØüÂàÜÊûê",
    "description_zh": "Analyzes meeting transcripts and recordings to uncover behavioral patterns, communication insights, and actionable feedback. Identifies when you avoid conflict, use filler words, dominate conversations, or miss opportunities to listen. Perfect for professionals seeking to improve their communication and leadership skills.",
    "body_zh": "# Meeting Insights Analyzer\n\nThis skill transforms your meeting transcripts into actionable insights about your communication patterns, helping you become a more effective communicator and leader.\n\n## When to Use This Skill\n\n- Analyzing your communication patterns across multiple meetings\n- Getting feedback on your leadership and facilitation style\n- Identifying when you avoid difficult conversations\n- Understanding your speaking habits and filler words\n- Tracking improvement in communication skills over time\n- Preparing for performance reviews with concrete examples\n- Coaching team members on their communication style\n\n## What This Skill Does\n\n1. **Pattern Recognition**: Identifies recurring behaviors across meetings like:\n   - Conflict avoidance or indirect communication\n   - Speaking ratios and turn-taking\n   - Question-asking vs. statement-making patterns\n   - Active listening indicators\n   - Decision-making approaches\n\n2. **Communication Analysis**: Evaluates communication effectiveness:\n   - Clarity and directness\n   - Use of filler words and hedging language\n   - Tone and sentiment patterns\n   - Meeting control and facilitation\n\n3. **Actionable Feedback**: Provides specific, timestamped examples with:\n   - What happened\n   - Why it matters\n   - How to improve\n\n4. **Trend Tracking**: Compares patterns over time when analyzing multiple meetings\n\n## How to Use\n\n### Basic Setup\n\n1. Download your meeting transcripts to a folder (e.g., `~/meetings/`)\n2. Navigate to that folder in Claude Code\n3. Ask for the analysis you want\n\n### Quick Start Examples\n\n```\nAnalyze all meetings in this folder and tell me when I avoided conflict.\n```\n\n```\nLook at my meetings from the past month and identify my communication patterns.\n```\n\n```\nCompare my facilitation style between these two meeting folders.\n```\n\n### Advanced Analysis\n\n```\nAnalyze all transcripts in this folder and:\n1. Identify when I interrupted others\n2. Calculate my speaking ratio\n3. Find moments I avoided giving direct feedback\n4. Track my use of filler words\n5. Show examples of good active listening\n```\n\n## Instructions\n\nWhen a user requests meeting analysis:\n\n1. **Discover Available Data**\n   - Scan the folder for transcript files (.txt, .md, .vtt, .srt, .docx)\n   - Check if files contain speaker labels and timestamps\n   - Confirm the date range of meetings\n   - Identify the user's name/identifier in transcripts\n\n2. **Clarify Analysis Goals**\n   \n   If not specified, ask what they want to learn:\n   - Specific behaviors (conflict avoidance, interruptions, filler words)\n   - Communication effectiveness (clarity, directness, listening)\n   - Meeting facilitation skills\n   - Speaking patterns and ratios\n   - Growth areas for improvement\n   \n3. **Analyze Patterns**\n\n   For each requested insight:\n   \n   **Conflict Avoidance**:\n   - Look for hedging language (\"maybe\", \"kind of\", \"I think\")\n   - Indirect phrasing instead of direct requests\n   - Changing subject when tension arises\n   - Agreeing without commitment (\"yeah, but...\")\n   - Not addressing obvious problems\n   \n   **Speaking Ratios**:\n   - Calculate percentage of meeting spent speaking\n   - Count interruptions (by and of the user)\n   - Measure average speaking turn length\n   - Track question vs. statement ratios\n   \n   **Filler Words**:\n   - Count \"um\", \"uh\", \"like\", \"you know\", \"actually\", etc.\n   - Note frequency per minute or per speaking turn\n   - Identify situations where they increase (nervous, uncertain)\n   \n   **Active Listening**:\n   - Questions that reference others' previous points\n   - Paraphrasing or summarizing others' ideas\n   - Building on others' contributions\n   - Asking clarifying questions\n   \n   **Leadership & Facilitation**:\n   - Decision-making approach (directive vs. collaborative)\n   - How disagreements are handled\n   - Inclusion of quieter participants\n   - Time management and agenda control\n   - Follow-up and action item clarity\n\n4. **Provide Specific Examples**\n\n   For each pattern found, include:\n   \n   ```markdown\n   ### [Pattern Name]\n   \n   **Finding**: [One-sentence summary of the pattern]\n   \n   **Frequency**: [X times across Y meetings]\n   \n   **Examples**:\n   \n   1. **[Meeting Name/Date]** - [Timestamp]\n      \n      **What Happened**:\n      > [Actual quote from transcript]\n      \n      **Why This Matters**:\n      [Explanation of the impact or missed opportunity]\n      \n      **Better Approach**:\n      [Specific alternative phrasing or behavior]\n   \n   [Repeat for 2-3 strongest examples]\n   ```\n\n5. **Synthesize Insights**\n\n   After analyzing all patterns, provide:\n   \n   ```markdown\n   # Meeting Insights Summary\n   \n   **Analysis Period**: [Date range]\n   **Meetings Analyzed**: [X meetings]\n   **Total Duration**: [X hours]\n   \n   ## Key Patterns Identified\n   \n   ### 1. [Primary Pattern]\n   - **Observed**: [What you saw]\n   - **Impact**: [Why it matters]\n   - **Recommendation**: [How to improve]\n   \n   ### 2. [Second Pattern]\n   [Same structure]\n   \n   ## Communication Strengths\n   \n   1. [Strength 1 with example]\n   2. [Strength 2 with example]\n   3. [Strength 3 with example]\n   \n   ## Growth Opportunities\n   \n   1. **[Area 1]**: [Specific, actionable advice]\n   2. **[Area 2]**: [Specific, actionable advice]\n   3. **[Area 3]**: [Specific, actionable advice]\n   \n   ## Speaking Statistics\n   \n   - Average speaking time: [X% of meeting]\n   - Questions asked: [X per meeting average]\n   - Filler words: [X per minute]\n   - Interruptions: [X given / Y received per meeting]\n   \n   ## Next Steps\n   \n   [3-5 concrete actions to improve communication]\n   ```\n\n6. **Offer Follow-Up Options**\n   - Track these same metrics in future meetings\n   - Deep dive into specific meetings or patterns\n   - Compare to industry benchmarks\n   - Create a personal communication development plan\n   - Generate a summary for performance reviews\n\n## Examples\n\n### Example 1: Conflict Avoidance Analysis (Inspired by Dan Shipper)\n\n**User**: \"I download all of my meeting recordings and put them in a folder. Tell me all the times I've subtly avoided conflict.\"\n\n**Output**: \n```markdown\n# Conflict Avoidance Patterns\n\nFound 23 instances across 15 meetings where you used indirect \ncommunication or avoided addressing tensions directly.\n\n## Pattern: Hedging on Critical Feedback\n\n**Frequency**: 8 times across 7 meetings\n\n**Example 1: 1:1 with Sarah** - 00:14:32\n\n**What Happened**:\n> \"So, I was thinking... maybe we could, like, potentially \n> consider looking at the timeline again? I mean, if you \n> think that makes sense. But whatever you think is best!\"\n\n**Why This Matters**:\nYou needed to address that Sarah's project was behind schedule, \nbut the hedging language (\"maybe\", \"potentially\", \"if you think\") \nand the deflection at the end (\"whatever you think\") made it easy \nfor her to miss the urgency.\n\n**Better Approach**:\n\"Sarah, the project is two weeks behind schedule. We need to \ndiscuss what's blocking progress and create a new timeline \ntoday.\"\n\n[Additional examples...]\n\n## Recommendations\n\n1. **Name the issue directly** in the first sentence\n2. **Remove hedging words** like \"maybe,\" \"kind of,\" \"sort of\"\n3. **Ask specific questions** instead of hinting\n4. **Schedule difficult conversations** instead of raising them casually\n```\n\n### Example 2: Leadership Facilitation\n\n**User**: \"Analyze my team meetings and tell me about my facilitation style.\"\n\n**Output**: Provides insights on:\n- How much you speak vs. team members (60% vs. 40%)\n- Whether you ask questions or make statements (3:1 ratio)\n- How you handle disagreements (tendency to resolve too quickly)\n- Who speaks least and whether you draw them in\n- Examples of good and missed facilitation moments\n\n### Example 3: Personal Development Tracking\n\n**User**: \"Compare my meetings from Q1 vs. Q2 to see if I've improved my listening skills.\"\n\n**Output**: Creates a comparative analysis showing:\n- Decrease in interruptions (8 per meeting ‚Üí 3 per meeting)\n- Increase in clarifying questions (2 ‚Üí 7 per meeting)\n- Improvement in building on others' ideas\n- Specific examples showing the difference\n- Remaining areas for growth\n\n## Setup Tips\n\n### Getting Meeting Transcripts\n\n**From Granola** (free with Lenny's newsletter subscription):\n- Granola auto-transcribes your meetings\n- Export transcripts to a folder: [Instructions on how]\n- Point Claude Code to that folder\n\n**From Zoom**:\n- Enable cloud recording with transcription\n- Download VTT or SRT files after meetings\n- Store in a dedicated folder\n\n**From Google Meet**:\n- Use Google Docs auto-transcription\n- Save transcript docs to a folder\n- Download as .txt files or give Claude Code access\n\n**From Fireflies.ai, Otter.ai, etc.**:\n- Export transcripts in bulk\n- Store in a local folder\n- Run analysis on the folder\n\n### Best Practices\n\n1. **Consistent naming**: Use `YYYY-MM-DD - Meeting Name.txt` format\n2. **Regular analysis**: Review monthly or quarterly for trends\n3. **Specific queries**: Ask about one behavior at a time for depth\n4. **Privacy**: Keep sensitive meeting data local\n5. **Action-oriented**: Focus on one improvement area at a time\n\n## Common Analysis Requests\n\n- \"When do I avoid difficult conversations?\"\n- \"How often do I interrupt others?\"\n- \"What's my speaking vs. listening ratio?\"\n- \"Do I ask good questions?\"\n- \"How do I handle disagreement?\"\n- \"Am I inclusive of all voices?\"\n- \"Do I use too many filler words?\"\n- \"How clear are my action items?\"\n- \"Do I stay on agenda or get sidetracked?\"\n- \"How has my communication changed over time?\"\n\n## Related Use Cases\n\n- Creating a personal development plan from insights\n- Preparing performance review materials with examples\n- Coaching direct reports on their communication\n- Analyzing customer calls for sales or support patterns\n- Studying negotiation tactics and outcomes"
  },
  {
    "name": "pdf",
    "description": "Comprehensive PDF manipulation toolkit for extracting text and tables, creating new PDFs, merging/splitting documents, and handling forms. When Claude needs to fill in a PDF form or programmatically process, generate, or analyze PDF documents at scale.",
    "body": "# PDF Processing Guide\n\n## Quick Start\n\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Read a PDF\nreader = PdfReader(\"document.pdf\")\nprint(f\"Pages: {len(reader.pages)}\")\n\n# Extract text\ntext = \"\"\nfor page in reader.pages:\n    text += page.extract_text()\n```\n\n## Python Libraries\n\n### pypdf - Basic Operations\n\n#### Merge PDFs\n```python\nfrom pypdf import PdfWriter, PdfReader\n\nwriter = PdfWriter()\nfor pdf_file in [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]:\n    reader = PdfReader(pdf_file)\n    for page in reader.pages:\n        writer.add_page(page)\n\nwith open(\"merged.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n#### Split PDF\n```python\nreader = PdfReader(\"input.pdf\")\nfor i, page in enumerate(reader.pages):\n    writer = PdfWriter()\n    writer.add_page(page)\n    with open(f\"page_{i+1}.pdf\", \"wb\") as output:\n        writer.write(output)\n```\n\n### pdfplumber - Text and Table Extraction\n\n#### Extract Tables\n```python\nimport pdfplumber\nimport pandas as pd\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    all_tables = []\n    for page in pdf.pages:\n        tables = page.extract_tables()\n        for table in tables:\n            if table:\n                df = pd.DataFrame(table[1:], columns=table[0])\n                all_tables.append(df)\n```\n\n### reportlab - Create PDFs\n\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\n\nc = canvas.Canvas(\"hello.pdf\", pagesize=letter)\nwidth, height = letter\nc.drawString(100, height - 100, \"Hello World!\")\nc.save()\n```\n\n## Command-Line Tools\n\n```bash\n# Extract text (poppler-utils)\npdftotext input.pdf output.txt\n\n# Merge PDFs (qpdf)\nqpdf --empty --pages file1.pdf file2.pdf -- merged.pdf\n\n# Split pages\nqpdf input.pdf --pages . 1-5 -- pages1-5.pdf\n```\n\n## Quick Reference\n\n| Task | Best Tool | Command/Code |\n|------|-----------|--------------|\n| Merge PDFs | pypdf | `writer.add_page(page)` |\n| Split PDFs | pypdf | One page per file |\n| Extract text | pdfplumber | `page.extract_text()` |\n| Extract tables | pdfplumber | `page.extract_tables()` |\n| Create PDFs | reportlab | Canvas or Platypus |\n| OCR scanned PDFs | pytesseract | Convert to image first |",
    "id": "pdf",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/pdf",
    "name_zh": "PDF Â§ÑÁêÜ",
    "description_zh": "Comprehensive PDF manipulation toolkit for extracting text and tables, creating new PDFs, merging/splitting documents, and handling forms. When Claude needs to fill in a PDF form or programmatically process, generate, or analyze PDF documents at scale.",
    "body_zh": "# PDF Processing Guide\n\n## Quick Start\n\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Read a PDF\nreader = PdfReader(\"document.pdf\")\nprint(f\"Pages: {len(reader.pages)}\")\n\n# Extract text\ntext = \"\"\nfor page in reader.pages:\n    text += page.extract_text()\n```\n\n## Python Libraries\n\n### pypdf - Basic Operations\n\n#### Merge PDFs\n```python\nfrom pypdf import PdfWriter, PdfReader\n\nwriter = PdfWriter()\nfor pdf_file in [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]:\n    reader = PdfReader(pdf_file)\n    for page in reader.pages:\n        writer.add_page(page)\n\nwith open(\"merged.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n#### Split PDF\n```python\nreader = PdfReader(\"input.pdf\")\nfor i, page in enumerate(reader.pages):\n    writer = PdfWriter()\n    writer.add_page(page)\n    with open(f\"page_{i+1}.pdf\", \"wb\") as output:\n        writer.write(output)\n```\n\n### pdfplumber - Text and Table Extraction\n\n#### Extract Tables\n```python\nimport pdfplumber\nimport pandas as pd\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    all_tables = []\n    for page in pdf.pages:\n        tables = page.extract_tables()\n        for table in tables:\n            if table:\n                df = pd.DataFrame(table[1:], columns=table[0])\n                all_tables.append(df)\n```\n\n### reportlab - Create PDFs\n\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\n\nc = canvas.Canvas(\"hello.pdf\", pagesize=letter)\nwidth, height = letter\nc.drawString(100, height - 100, \"Hello World!\")\nc.save()\n```\n\n## Command-Line Tools\n\n```bash\n# Extract text (poppler-utils)\npdftotext input.pdf output.txt\n\n# Merge PDFs (qpdf)\nqpdf --empty --pages file1.pdf file2.pdf -- merged.pdf\n\n# Split pages\nqpdf input.pdf --pages . 1-5 -- pages1-5.pdf\n```\n\n## Quick Reference\n\n| Task | Best Tool | Command/Code |\n|------|-----------|--------------|\n| Merge PDFs | pypdf | `writer.add_page(page)` |\n| Split PDFs | pypdf | One page per file |\n| Extract text | pdfplumber | `page.extract_text()` |\n| Extract tables | pdfplumber | `page.extract_tables()` |\n| Create PDFs | reportlab | Canvas or Platypus |\n| OCR scanned PDFs | pytesseract | Convert to image first |"
  },
  {
    "name": "pptx",
    "description": "Presentation creation, editing, and analysis. When Claude needs to work with presentations (.pptx files) for creating new presentations, modifying content, working with layouts, adding speaker notes, or any presentation tasks.",
    "body": "# PowerPoint Processing\n\n## Creating Presentations (Python)\n\n```python\nfrom pptx import Presentation\nfrom pptx.util import Inches, Pt\n\nprs = Presentation()\n\n# Add title slide\ntitle_slide_layout = prs.slide_layouts[0]\nslide = prs.slides.add_slide(title_slide_layout)\ntitle = slide.shapes.title\nsubtitle = slide.placeholders[1]\ntitle.text = \"Hello, World!\"\nsubtitle.text = \"python-pptx demo\"\n\n# Add content slide\nbullet_slide_layout = prs.slide_layouts[1]\nslide = prs.slides.add_slide(bullet_slide_layout)\nshapes = slide.shapes\ntitle_shape = shapes.title\nbody_shape = shapes.placeholders[1]\ntitle_shape.text = \"Key Points\"\ntf = body_shape.text_frame\ntf.text = \"First bullet point\"\np = tf.add_paragraph()\np.text = \"Second bullet point\"\np.level = 1\n\nprs.save('presentation.pptx')\n```\n\n## Adding Images\n\n```python\nfrom pptx.util import Inches\n\nblank_layout = prs.slide_layouts[6]\nslide = prs.slides.add_slide(blank_layout)\n\nleft = Inches(1)\ntop = Inches(1)\nwidth = Inches(5)\nslide.shapes.add_picture('image.png', left, top, width=width)\n```\n\n## Adding Tables\n\n```python\nrows, cols = 3, 4\nleft = Inches(1)\ntop = Inches(2)\nwidth = Inches(6)\nheight = Inches(1.5)\n\ntable = slide.shapes.add_table(rows, cols, left, top, width, height).table\n\n# Set column widths\ntable.columns[0].width = Inches(2)\n\n# Add content\ntable.cell(0, 0).text = \"Header 1\"\ntable.cell(1, 0).text = \"Data 1\"\n```\n\n## Adding Charts\n\n```python\nfrom pptx.chart.data import CategoryChartData\nfrom pptx.enum.chart import XL_CHART_TYPE\n\nchart_data = CategoryChartData()\nchart_data.categories = ['East', 'West', 'Midwest']\nchart_data.add_series('Sales', (19.2, 21.4, 16.7))\n\nx, y, cx, cy = Inches(2), Inches(2), Inches(6), Inches(4.5)\nslide.shapes.add_chart(\n    XL_CHART_TYPE.COLUMN_CLUSTERED, x, y, cx, cy, chart_data\n)\n```\n\n## Editing Existing Presentations\n\n```python\nprs = Presentation('existing.pptx')\n\n# Access slides\nfor slide in prs.slides:\n    for shape in slide.shapes:\n        if shape.has_text_frame:\n            print(shape.text_frame.text)\n\n# Modify text\nslide = prs.slides[0]\nslide.shapes.title.text = \"New Title\"\n\nprs.save('modified.pptx')\n```\n\n## Best Practices\n\n- Use slide layouts for consistency\n- Keep text minimal, use visuals\n- Use Inches() or Pt() for sizing\n- Save frequently during creation",
    "id": "pptx",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/pptx",
    "name_zh": "PPT Â§ÑÁêÜ",
    "description_zh": "Presentation creation, editing, and analysis. When Claude needs to work with presentations (.pptx files) for creating new presentations, modifying content, working with layouts, adding speaker notes, or any presentation tasks.",
    "body_zh": "# PowerPoint Processing\n\n## Creating Presentations (Python)\n\n```python\nfrom pptx import Presentation\nfrom pptx.util import Inches, Pt\n\nprs = Presentation()\n\n# Add title slide\ntitle_slide_layout = prs.slide_layouts[0]\nslide = prs.slides.add_slide(title_slide_layout)\ntitle = slide.shapes.title\nsubtitle = slide.placeholders[1]\ntitle.text = \"Hello, World!\"\nsubtitle.text = \"python-pptx demo\"\n\n# Add content slide\nbullet_slide_layout = prs.slide_layouts[1]\nslide = prs.slides.add_slide(bullet_slide_layout)\nshapes = slide.shapes\ntitle_shape = shapes.title\nbody_shape = shapes.placeholders[1]\ntitle_shape.text = \"Key Points\"\ntf = body_shape.text_frame\ntf.text = \"First bullet point\"\np = tf.add_paragraph()\np.text = \"Second bullet point\"\np.level = 1\n\nprs.save('presentation.pptx')\n```\n\n## Adding Images\n\n```python\nfrom pptx.util import Inches\n\nblank_layout = prs.slide_layouts[6]\nslide = prs.slides.add_slide(blank_layout)\n\nleft = Inches(1)\ntop = Inches(1)\nwidth = Inches(5)\nslide.shapes.add_picture('image.png', left, top, width=width)\n```\n\n## Adding Tables\n\n```python\nrows, cols = 3, 4\nleft = Inches(1)\ntop = Inches(2)\nwidth = Inches(6)\nheight = Inches(1.5)\n\ntable = slide.shapes.add_table(rows, cols, left, top, width, height).table\n\n# Set column widths\ntable.columns[0].width = Inches(2)\n\n# Add content\ntable.cell(0, 0).text = \"Header 1\"\ntable.cell(1, 0).text = \"Data 1\"\n```\n\n## Adding Charts\n\n```python\nfrom pptx.chart.data import CategoryChartData\nfrom pptx.enum.chart import XL_CHART_TYPE\n\nchart_data = CategoryChartData()\nchart_data.categories = ['East', 'West', 'Midwest']\nchart_data.add_series('Sales', (19.2, 21.4, 16.7))\n\nx, y, cx, cy = Inches(2), Inches(2), Inches(6), Inches(4.5)\nslide.shapes.add_chart(\n    XL_CHART_TYPE.COLUMN_CLUSTERED, x, y, cx, cy, chart_data\n)\n```\n\n## Editing Existing Presentations\n\n```python\nprs = Presentation('existing.pptx')\n\n# Access slides\nfor slide in prs.slides:\n    for shape in slide.shapes:\n        if shape.has_text_frame:\n            print(shape.text_frame.text)\n\n# Modify text\nslide = prs.slides[0]\nslide.shapes.title.text = \"New Title\"\n\nprs.save('modified.pptx')\n```\n\n## Best Practices\n\n- Use slide layouts for consistency\n- Keep text minimal, use visuals\n- Use Inches() or Pt() for sizing\n- Save frequently during creation"
  },
  {
    "name": "python-development",
    "description": "Modern Python development with Python 3.12+, Django, FastAPI, async patterns, and production best practices. Use for Python projects, APIs, data processing, or automation scripts.",
    "body": "# Python Development\n\n## Project Setup\n\n### Modern Python Project Structure\n```\nmy-project/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îî‚îÄ‚îÄ my_project/\n‚îÇ       ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ       ‚îú‚îÄ‚îÄ main.py\n‚îÇ       ‚îî‚îÄ‚îÄ utils.py\n‚îú‚îÄ‚îÄ tests/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îî‚îÄ‚îÄ test_main.py\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ .gitignore\n```\n\n### pyproject.toml\n```toml\n[project]\nname = \"my-project\"\nversion = \"0.1.0\"\nrequires-python = \">=3.12\"\ndependencies = [\n    \"fastapi>=0.100.0\",\n    \"pydantic>=2.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest>=7.0\",\n    \"ruff>=0.1.0\",\n    \"mypy>=1.0\",\n]\n\n[tool.ruff]\nline-length = 88\nselect = [\"E\", \"F\", \"I\", \"N\", \"W\"]\n\n[tool.mypy]\nstrict = true\n```\n\n## Type Hints\n\n```python\nfrom typing import TypeVar, Generic\nfrom collections.abc import Sequence\n\nT = TypeVar('T')\n\ndef process_items(items: Sequence[str]) -> list[str]:\n    return [item.upper() for item in items]\n\nclass Repository(Generic[T]):\n    def get(self, id: int) -> T | None: ...\n    def save(self, item: T) -> T: ...\n```\n\n## Async Patterns\n\n```python\nimport asyncio\nfrom collections.abc import AsyncIterator\n\nasync def fetch_all(urls: list[str]) -> list[dict]:\n    async with aiohttp.ClientSession() as session:\n        tasks = [fetch_one(session, url) for url in urls]\n        return await asyncio.gather(*tasks)\n\nasync def stream_data() -> AsyncIterator[bytes]:\n    async with aiofiles.open('large_file.txt', 'rb') as f:\n        async for chunk in f:\n            yield chunk\n```\n\n## FastAPI Patterns\n\n```python\nfrom fastapi import FastAPI, Depends, HTTPException\nfrom pydantic import BaseModel\n\napp = FastAPI()\n\nclass UserCreate(BaseModel):\n    email: str\n    name: str\n\nclass UserResponse(BaseModel):\n    id: int\n    email: str\n    name: str\n\n@app.post(\"/users\", response_model=UserResponse)\nasync def create_user(\n    user: UserCreate,\n    db: Database = Depends(get_db)\n) -> UserResponse:\n    result = await db.users.create(user.model_dump())\n    return UserResponse(**result)\n```\n\n## Testing\n\n```python\nimport pytest\nfrom unittest.mock import AsyncMock, patch\n\n@pytest.fixture\ndef mock_db():\n    db = AsyncMock()\n    db.users.get.return_value = {\"id\": 1, \"name\": \"Test\"}\n    return db\n\n@pytest.mark.asyncio\nasync def test_get_user(mock_db):\n    result = await get_user(1, db=mock_db)\n    assert result[\"name\"] == \"Test\"\n    mock_db.users.get.assert_called_once_with(1)\n```\n\n## Best Practices\n\n- Use `ruff` for linting and formatting\n- Use `mypy` with strict mode\n- Prefer `pathlib.Path` over `os.path`\n- Use dataclasses or Pydantic for data structures\n- Use `asyncio` for I/O-bound operations\n- Use `contextlib.asynccontextmanager` for async resources",
    "id": "python-development",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/python-development",
    "name_zh": "Python ÂºÄÂèë",
    "description_zh": "Modern Python development with Python 3.12+, Django, FastAPI, async patterns, and production best practices. Use for Python projects, APIs, data processing, or automation scripts.",
    "body_zh": "# Python Development\n\n## Project Setup\n\n### Modern Python Project Structure\n```\nmy-project/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îî‚îÄ‚îÄ my_project/\n‚îÇ       ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ       ‚îú‚îÄ‚îÄ main.py\n‚îÇ       ‚îî‚îÄ‚îÄ utils.py\n‚îú‚îÄ‚îÄ tests/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îî‚îÄ‚îÄ test_main.py\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ .gitignore\n```\n\n### pyproject.toml\n```toml\n[project]\nname = \"my-project\"\nversion = \"0.1.0\"\nrequires-python = \">=3.12\"\ndependencies = [\n    \"fastapi>=0.100.0\",\n    \"pydantic>=2.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest>=7.0\",\n    \"ruff>=0.1.0\",\n    \"mypy>=1.0\",\n]\n\n[tool.ruff]\nline-length = 88\nselect = [\"E\", \"F\", \"I\", \"N\", \"W\"]\n\n[tool.mypy]\nstrict = true\n```\n\n## Type Hints\n\n```python\nfrom typing import TypeVar, Generic\nfrom collections.abc import Sequence\n\nT = TypeVar('T')\n\ndef process_items(items: Sequence[str]) -> list[str]:\n    return [item.upper() for item in items]\n\nclass Repository(Generic[T]):\n    def get(self, id: int) -> T | None: ...\n    def save(self, item: T) -> T: ...\n```\n\n## Async Patterns\n\n```python\nimport asyncio\nfrom collections.abc import AsyncIterator\n\nasync def fetch_all(urls: list[str]) -> list[dict]:\n    async with aiohttp.ClientSession() as session:\n        tasks = [fetch_one(session, url) for url in urls]\n        return await asyncio.gather(*tasks)\n\nasync def stream_data() -> AsyncIterator[bytes]:\n    async with aiofiles.open('large_file.txt', 'rb') as f:\n        async for chunk in f:\n            yield chunk\n```\n\n## FastAPI Patterns\n\n```python\nfrom fastapi import FastAPI, Depends, HTTPException\nfrom pydantic import BaseModel\n\napp = FastAPI()\n\nclass UserCreate(BaseModel):\n    email: str\n    name: str\n\nclass UserResponse(BaseModel):\n    id: int\n    email: str\n    name: str\n\n@app.post(\"/users\", response_model=UserResponse)\nasync def create_user(\n    user: UserCreate,\n    db: Database = Depends(get_db)\n) -> UserResponse:\n    result = await db.users.create(user.model_dump())\n    return UserResponse(**result)\n```\n\n## Testing\n\n```python\nimport pytest\nfrom unittest.mock import AsyncMock, patch\n\n@pytest.fixture\ndef mock_db():\n    db = AsyncMock()\n    db.users.get.return_value = {\"id\": 1, \"name\": \"Test\"}\n    return db\n\n@pytest.mark.asyncio\nasync def test_get_user(mock_db):\n    result = await get_user(1, db=mock_db)\n    assert result[\"name\"] == \"Test\"\n    mock_db.users.get.assert_called_once_with(1)\n```\n\n## Best Practices\n\n- Use `ruff` for linting and formatting\n- Use `mypy` with strict mode\n- Prefer `pathlib.Path` over `os.path`\n- Use dataclasses or Pydantic for data structures\n- Use `asyncio` for I/O-bound operations\n- Use `contextlib.asynccontextmanager` for async resources"
  },
  {
    "name": "qa-regression",
    "description": "Automate QA regression testing with reusable test skills. Create login flows, dashboard checks, user creation, and other common test scenarios that run consistently.",
    "body": "# QA Regression Testing\n\nBuild and run automated regression tests using Playwright. Each test is a reusable skill that can be composed into full test suites.\n\n## Setup\n\n```bash\nnpm init -y\nnpm install playwright @playwright/test\nnpx playwright install\n```\n\n## Test Structure\n\nCreate tests in `tests/` folder:\n\n```\ntests/\n‚îú‚îÄ‚îÄ auth/\n‚îÇ   ‚îú‚îÄ‚îÄ login.spec.ts\n‚îÇ   ‚îî‚îÄ‚îÄ logout.spec.ts\n‚îú‚îÄ‚îÄ dashboard/\n‚îÇ   ‚îî‚îÄ‚îÄ load.spec.ts\n‚îú‚îÄ‚îÄ users/\n‚îÇ   ‚îú‚îÄ‚îÄ create.spec.ts\n‚îÇ   ‚îî‚îÄ‚îÄ delete.spec.ts\n‚îî‚îÄ‚îÄ regression.spec.ts   # Full suite\n```\n\n## Common Test Skills\n\n### Login Test\n\n```typescript\n// tests/auth/login.spec.ts\nimport { test, expect } from '@playwright/test';\n\ntest.describe('Login Flow', () => {\n  test('should login with valid credentials', async ({ page }) => {\n    await page.goto('/login');\n\n    await page.fill('[data-testid=\"email\"]', process.env.TEST_EMAIL!);\n    await page.fill('[data-testid=\"password\"]', process.env.TEST_PASSWORD!);\n    await page.click('[data-testid=\"submit\"]');\n\n    // Verify redirect to dashboard\n    await expect(page).toHaveURL(/dashboard/);\n    await expect(page.locator('[data-testid=\"user-menu\"]')).toBeVisible();\n  });\n\n  test('should show error for invalid credentials', async ({ page }) => {\n    await page.goto('/login');\n\n    await page.fill('[data-testid=\"email\"]', 'wrong@example.com');\n    await page.fill('[data-testid=\"password\"]', 'wrongpassword');\n    await page.click('[data-testid=\"submit\"]');\n\n    await expect(page.locator('[data-testid=\"error-message\"]')).toBeVisible();\n  });\n});\n```\n\n### Dashboard Load Test\n\n```typescript\n// tests/dashboard/load.spec.ts\nimport { test, expect } from '@playwright/test';\nimport { login } from '../helpers/auth';\n\ntest.describe('Dashboard', () => {\n  test.beforeEach(async ({ page }) => {\n    await login(page);\n  });\n\n  test('should load dashboard within 3 seconds', async ({ page }) => {\n    const start = Date.now();\n    await page.goto('/dashboard');\n    await page.waitForSelector('[data-testid=\"dashboard-content\"]');\n    const loadTime = Date.now() - start;\n\n    expect(loadTime).toBeLessThan(3000);\n  });\n\n  test('should display all widgets', async ({ page }) => {\n    await page.goto('/dashboard');\n\n    await expect(page.locator('[data-testid=\"stats-widget\"]')).toBeVisible();\n    await expect(page.locator('[data-testid=\"chart-widget\"]')).toBeVisible();\n    await expect(page.locator('[data-testid=\"activity-widget\"]')).toBeVisible();\n  });\n\n  test('should refresh data on button click', async ({ page }) => {\n    await page.goto('/dashboard');\n\n    const initialValue = await page.locator('[data-testid=\"last-updated\"]').textContent();\n    await page.click('[data-testid=\"refresh-button\"]');\n    await page.waitForTimeout(1000);\n    const newValue = await page.locator('[data-testid=\"last-updated\"]').textContent();\n\n    expect(newValue).not.toBe(initialValue);\n  });\n});\n```\n\n### Create User Test\n\n```typescript\n// tests/users/create.spec.ts\nimport { test, expect } from '@playwright/test';\nimport { login } from '../helpers/auth';\nimport { generateTestUser, deleteTestUser } from '../helpers/users';\n\ntest.describe('User Creation', () => {\n  let testUser: { email: string; name: string };\n\n  test.beforeEach(async ({ page }) => {\n    await login(page);\n    testUser = generateTestUser();\n  });\n\n  test.afterEach(async () => {\n    // Cleanup\n    await deleteTestUser(testUser.email);\n  });\n\n  test('should create new user successfully', async ({ page }) => {\n    await page.goto('/users/new');\n\n    await page.fill('[data-testid=\"user-name\"]', testUser.name);\n    await page.fill('[data-testid=\"user-email\"]', testUser.email);\n    await page.selectOption('[data-testid=\"user-role\"]', 'member');\n    await page.click('[data-testid=\"create-user-btn\"]');\n\n    // Verify success\n    await expect(page.locator('[data-testid=\"success-toast\"]')).toBeVisible();\n    await expect(page).toHaveURL(/users/);\n\n    // Verify user appears in list\n    await expect(page.locator(`text=${testUser.email}`)).toBeVisible();\n  });\n\n  test('should validate required fields', async ({ page }) => {\n    await page.goto('/users/new');\n    await page.click('[data-testid=\"create-user-btn\"]');\n\n    await expect(page.locator('[data-testid=\"name-error\"]')).toBeVisible();\n    await expect(page.locator('[data-testid=\"email-error\"]')).toBeVisible();\n  });\n});\n```\n\n## Shared Helpers\n\n```typescript\n// tests/helpers/auth.ts\nimport { Page } from '@playwright/test';\n\nexport async function login(page: Page) {\n  await page.goto('/login');\n  await page.fill('[data-testid=\"email\"]', process.env.TEST_EMAIL!);\n  await page.fill('[data-testid=\"password\"]', process.env.TEST_PASSWORD!);\n  await page.click('[data-testid=\"submit\"]');\n  await page.waitForURL(/dashboard/);\n}\n\nexport async function logout(page: Page) {\n  await page.click('[data-testid=\"user-menu\"]');\n  await page.click('[data-testid=\"logout\"]');\n  await page.waitForURL(/login/);\n}\n```\n\n```typescript\n// tests/helpers/users.ts\nexport function generateTestUser() {\n  const id = Date.now();\n  return {\n    name: `Test User ${id}`,\n    email: `test-${id}@example.com`,\n  };\n}\n\nexport async function deleteTestUser(email: string) {\n  // API call to cleanup test user\n  await fetch(`${process.env.API_URL}/admin/users`, {\n    method: 'DELETE',\n    headers: {\n      'Authorization': `Bearer ${process.env.ADMIN_TOKEN}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ email }),\n  });\n}\n```\n\n## Full Regression Suite\n\n```typescript\n// tests/regression.spec.ts\nimport { test } from '@playwright/test';\n\n// Import all test suites\nimport './auth/login.spec';\nimport './auth/logout.spec';\nimport './dashboard/load.spec';\nimport './users/create.spec';\nimport './users/delete.spec';\n\ntest.describe('Full Regression Suite', () => {\n  // Tests run in order defined above\n});\n```\n\n## Playwright Config\n\n```typescript\n// playwright.config.ts\nimport { defineConfig, devices } from '@playwright/test';\n\nexport default defineConfig({\n  testDir: './tests',\n  fullyParallel: true,\n  forbidOnly: !!process.env.CI,\n  retries: process.env.CI ? 2 : 0,\n  workers: process.env.CI ? 1 : undefined,\n  reporter: [\n    ['html'],\n    ['json', { outputFile: 'test-results.json' }],\n  ],\n  use: {\n    baseURL: process.env.BASE_URL || 'http://localhost:3000',\n    trace: 'on-first-retry',\n    screenshot: 'only-on-failure',\n  },\n  projects: [\n    {\n      name: 'chromium',\n      use: { ...devices['Desktop Chrome'] },\n    },\n    {\n      name: 'firefox',\n      use: { ...devices['Desktop Firefox'] },\n    },\n    {\n      name: 'webkit',\n      use: { ...devices['Desktop Safari'] },\n    },\n  ],\n});\n```\n\n## Running Tests\n\n```bash\n# Run all tests\nnpx playwright test\n\n# Run specific test file\nnpx playwright test tests/auth/login.spec.ts\n\n# Run tests with UI\nnpx playwright test --ui\n\n# Run in headed mode (see browser)\nnpx playwright test --headed\n\n# Generate report\nnpx playwright show-report\n```\n\n## CI Integration\n\n```yaml\n# .github/workflows/regression.yml\nname: Regression Tests\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  schedule:\n    - cron: '0 6 * * *'  # Daily at 6 AM\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Install Playwright\n        run: npx playwright install --with-deps\n\n      - name: Run tests\n        run: npx playwright test\n        env:\n          BASE_URL: ${{ secrets.STAGING_URL }}\n          TEST_EMAIL: ${{ secrets.TEST_EMAIL }}\n          TEST_PASSWORD: ${{ secrets.TEST_PASSWORD }}\n\n      - uses: actions/upload-artifact@v4\n        if: always()\n        with:\n          name: playwright-report\n          path: playwright-report/\n```\n\n## Best Practices\n\n1. **Use data-testid attributes** - More stable than CSS selectors\n2. **Clean up test data** - Always delete what you create\n3. **Avoid hardcoded waits** - Use `waitForSelector` instead of `waitForTimeout`\n4. **Run in parallel** - Faster feedback on CI\n5. **Screenshot on failure** - Easier debugging\n6. **Environment variables** - Never commit credentials\n\n## Quick Commands\n\n| Task | Command |\n|------|---------|\n| Run all | `npx playwright test` |\n| Run one file | `npx playwright test login.spec.ts` |\n| Debug mode | `npx playwright test --debug` |\n| UI mode | `npx playwright test --ui` |\n| Update snapshots | `npx playwright test --update-snapshots` |",
    "id": "qa-regression",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/qa-regression",
    "name_zh": "QA ÂõûÂΩíÊµãËØï",
    "description_zh": "Ëá™Âä®Âåñ QA regression testing with reusable test skills. Create login flows, dashboard checks, user creation, and other common test scenarios that run consistently.",
    "body_zh": "# QA Regression Testing\n\nBuild and run automated regression tests using Playwright. Each test is a reusable skill that can be composed into full test suites.\n\n## Setup\n\n```bash\nnpm init -y\nnpm install playwright @playwright/test\nnpx playwright install\n```\n\n## Test Structure\n\nCreate tests in `tests/` folder:\n\n```\ntests/\n‚îú‚îÄ‚îÄ auth/\n‚îÇ   ‚îú‚îÄ‚îÄ login.spec.ts\n‚îÇ   ‚îî‚îÄ‚îÄ logout.spec.ts\n‚îú‚îÄ‚îÄ dashboard/\n‚îÇ   ‚îî‚îÄ‚îÄ load.spec.ts\n‚îú‚îÄ‚îÄ users/\n‚îÇ   ‚îú‚îÄ‚îÄ create.spec.ts\n‚îÇ   ‚îî‚îÄ‚îÄ delete.spec.ts\n‚îî‚îÄ‚îÄ regression.spec.ts   # Full suite\n```\n\n## Common Test Skills\n\n### Login Test\n\n```typescript\n// tests/auth/login.spec.ts\nimport { test, expect } from '@playwright/test';\n\ntest.describe('Login Flow', () => {\n  test('should login with valid credentials', async ({ page }) => {\n    await page.goto('/login');\n\n    await page.fill('[data-testid=\"email\"]', process.env.TEST_EMAIL!);\n    await page.fill('[data-testid=\"password\"]', process.env.TEST_PASSWORD!);\n    await page.click('[data-testid=\"submit\"]');\n\n    // Verify redirect to dashboard\n    await expect(page).toHaveURL(/dashboard/);\n    await expect(page.locator('[data-testid=\"user-menu\"]')).toBeVisible();\n  });\n\n  test('should show error for invalid credentials', async ({ page }) => {\n    await page.goto('/login');\n\n    await page.fill('[data-testid=\"email\"]', 'wrong@example.com');\n    await page.fill('[data-testid=\"password\"]', 'wrongpassword');\n    await page.click('[data-testid=\"submit\"]');\n\n    await expect(page.locator('[data-testid=\"error-message\"]')).toBeVisible();\n  });\n});\n```\n\n### Dashboard Load Test\n\n```typescript\n// tests/dashboard/load.spec.ts\nimport { test, expect } from '@playwright/test';\nimport { login } from '../helpers/auth';\n\ntest.describe('Dashboard', () => {\n  test.beforeEach(async ({ page }) => {\n    await login(page);\n  });\n\n  test('should load dashboard within 3 seconds', async ({ page }) => {\n    const start = Date.now();\n    await page.goto('/dashboard');\n    await page.waitForSelector('[data-testid=\"dashboard-content\"]');\n    const loadTime = Date.now() - start;\n\n    expect(loadTime).toBeLessThan(3000);\n  });\n\n  test('should display all widgets', async ({ page }) => {\n    await page.goto('/dashboard');\n\n    await expect(page.locator('[data-testid=\"stats-widget\"]')).toBeVisible();\n    await expect(page.locator('[data-testid=\"chart-widget\"]')).toBeVisible();\n    await expect(page.locator('[data-testid=\"activity-widget\"]')).toBeVisible();\n  });\n\n  test('should refresh data on button click', async ({ page }) => {\n    await page.goto('/dashboard');\n\n    const initialValue = await page.locator('[data-testid=\"last-updated\"]').textContent();\n    await page.click('[data-testid=\"refresh-button\"]');\n    await page.waitForTimeout(1000);\n    const newValue = await page.locator('[data-testid=\"last-updated\"]').textContent();\n\n    expect(newValue).not.toBe(initialValue);\n  });\n});\n```\n\n### Create User Test\n\n```typescript\n// tests/users/create.spec.ts\nimport { test, expect } from '@playwright/test';\nimport { login } from '../helpers/auth';\nimport { generateTestUser, deleteTestUser } from '../helpers/users';\n\ntest.describe('User Creation', () => {\n  let testUser: { email: string; name: string };\n\n  test.beforeEach(async ({ page }) => {\n    await login(page);\n    testUser = generateTestUser();\n  });\n\n  test.afterEach(async () => {\n    // Cleanup\n    await deleteTestUser(testUser.email);\n  });\n\n  test('should create new user successfully', async ({ page }) => {\n    await page.goto('/users/new');\n\n    await page.fill('[data-testid=\"user-name\"]', testUser.name);\n    await page.fill('[data-testid=\"user-email\"]', testUser.email);\n    await page.selectOption('[data-testid=\"user-role\"]', 'member');\n    await page.click('[data-testid=\"create-user-btn\"]');\n\n    // Verify success\n    await expect(page.locator('[data-testid=\"success-toast\"]')).toBeVisible();\n    await expect(page).toHaveURL(/users/);\n\n    // Verify user appears in list\n    await expect(page.locator(`text=${testUser.email}`)).toBeVisible();\n  });\n\n  test('should validate required fields', async ({ page }) => {\n    await page.goto('/users/new');\n    await page.click('[data-testid=\"create-user-btn\"]');\n\n    await expect(page.locator('[data-testid=\"name-error\"]')).toBeVisible();\n    await expect(page.locator('[data-testid=\"email-error\"]')).toBeVisible();\n  });\n});\n```\n\n## Shared Helpers\n\n```typescript\n// tests/helpers/auth.ts\nimport { Page } from '@playwright/test';\n\nexport async function login(page: Page) {\n  await page.goto('/login');\n  await page.fill('[data-testid=\"email\"]', process.env.TEST_EMAIL!);\n  await page.fill('[data-testid=\"password\"]', process.env.TEST_PASSWORD!);\n  await page.click('[data-testid=\"submit\"]');\n  await page.waitForURL(/dashboard/);\n}\n\nexport async function logout(page: Page) {\n  await page.click('[data-testid=\"user-menu\"]');\n  await page.click('[data-testid=\"logout\"]');\n  await page.waitForURL(/login/);\n}\n```\n\n```typescript\n// tests/helpers/users.ts\nexport function generateTestUser() {\n  const id = Date.now();\n  return {\n    name: `Test User ${id}`,\n    email: `test-${id}@example.com`,\n  };\n}\n\nexport async function deleteTestUser(email: string) {\n  // API call to cleanup test user\n  await fetch(`${process.env.API_URL}/admin/users`, {\n    method: 'DELETE',\n    headers: {\n      'Authorization': `Bearer ${process.env.ADMIN_TOKEN}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ email }),\n  });\n}\n```\n\n## Full Regression Suite\n\n```typescript\n// tests/regression.spec.ts\nimport { test } from '@playwright/test';\n\n// Import all test suites\nimport './auth/login.spec';\nimport './auth/logout.spec';\nimport './dashboard/load.spec';\nimport './users/create.spec';\nimport './users/delete.spec';\n\ntest.describe('Full Regression Suite', () => {\n  // Tests run in order defined above\n});\n```\n\n## Playwright Config\n\n```typescript\n// playwright.config.ts\nimport { defineConfig, devices } from '@playwright/test';\n\nexport default defineConfig({\n  testDir: './tests',\n  fullyParallel: true,\n  forbidOnly: !!process.env.CI,\n  retries: process.env.CI ? 2 : 0,\n  workers: process.env.CI ? 1 : undefined,\n  reporter: [\n    ['html'],\n    ['json', { outputFile: 'test-results.json' }],\n  ],\n  use: {\n    baseURL: process.env.BASE_URL || 'http://localhost:3000',\n    trace: 'on-first-retry',\n    screenshot: 'only-on-failure',\n  },\n  projects: [\n    {\n      name: 'chromium',\n      use: { ...devices['Desktop Chrome'] },\n    },\n    {\n      name: 'firefox',\n      use: { ...devices['Desktop Firefox'] },\n    },\n    {\n      name: 'webkit',\n      use: { ...devices['Desktop Safari'] },\n    },\n  ],\n});\n```\n\n## Running Tests\n\n```bash\n# Run all tests\nnpx playwright test\n\n# Run specific test file\nnpx playwright test tests/auth/login.spec.ts\n\n# Run tests with UI\nnpx playwright test --ui\n\n# Run in headed mode (see browser)\nnpx playwright test --headed\n\n# Generate report\nnpx playwright show-report\n```\n\n## CI Integration\n\n```yaml\n# .github/workflows/regression.yml\nname: Regression Tests\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  schedule:\n    - cron: '0 6 * * *'  # Daily at 6 AM\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Install Playwright\n        run: npx playwright install --with-deps\n\n      - name: Run tests\n        run: npx playwright test\n        env:\n          BASE_URL: ${{ secrets.STAGING_URL }}\n          TEST_EMAIL: ${{ secrets.TEST_EMAIL }}\n          TEST_PASSWORD: ${{ secrets.TEST_PASSWORD }}\n\n      - uses: actions/upload-artifact@v4\n        if: always()\n        with:\n          name: playwright-report\n          path: playwright-report/\n```\n\n## Best Practices\n\n1. **Use data-testid attributes** - More stable than CSS selectors\n2. **Clean up test data** - Always delete what you create\n3. **Avoid hardcoded waits** - Use `waitForSelector` instead of `waitForTimeout`\n4. **Run in parallel** - Faster feedback on CI\n5. **Screenshot on failure** - Easier debugging\n6. **Environment variables** - Never commit credentials\n\n## Quick Commands\n\n| Task | Command |\n|------|---------|\n| Run all | `npx playwright test` |\n| Run one file | `npx playwright test login.spec.ts` |\n| Debug mode | `npx playwright test --debug` |\n| UI mode | `npx playwright test --ui` |\n| Update snapshots | `npx playwright test --update-snapshots` |"
  },
  {
    "name": "raffle-winner-picker",
    "description": "Picks random winners from lists, spreadsheets, or Google Sheets for giveaways, raffles, and contests. Ensures fair, unbiased selection with transparency.",
    "body": "# Raffle Winner Picker\n\nThis skill randomly selects winners from lists, spreadsheets, or Google Sheets for giveaways and contests.\n\n## When to Use This Skill\n\n- Running social media giveaways\n- Picking raffle winners at events\n- Randomly selecting participants for surveys or tests\n- Choosing winners from contest submissions\n- Fair distribution of limited spots or resources\n- Random team assignments\n\n## What This Skill Does\n\n1. **Random Selection**: Uses cryptographically random selection\n2. **Multiple Sources**: Works with CSV, Excel, Google Sheets, or plain lists\n3. **Multiple Winners**: Can pick one or multiple winners\n4. **Duplicate Prevention**: Ensures the same person can't win twice\n5. **Transparent Results**: Shows the selection process clearly\n6. **Winner Details**: Displays all relevant information about winners\n\n## How to Use\n\n### From Google Sheets\n\n```\nPick a random row from this Google Sheet to select a winner \nfor a giveaway: [Sheet URL]\n```\n\n### From Local File\n\n```\nPick 3 random winners from entries.csv\n```\n\n### From List\n\n```\nPick a random winner from this list:\n- Alice (alice@email.com)\n- Bob (bob@email.com)\n- Carol (carol@email.com)\n...\n```\n\n### Multiple Winners\n\n```\nPick 5 random winners from contest-entries.xlsx, \nmake sure no duplicates\n```\n\n## Example\n\n**User**: \"Pick a random row from this Google Sheet to select a winner for a giveaway.\"\n\n**Output**:\n```\nAccessing Google Sheet...\nTotal entries found: 247\n\nRandomly selecting winner...\n\nüéâ WINNER SELECTED! üéâ\n\nRow #142\nName: Sarah Johnson\nEmail: sarah.j@email.com\nEntry Date: March 10, 2024\nComment: \"Love your newsletter!\"\n\nSelection method: Cryptographically random\nTimestamp: 2024-03-15 14:32:18 UTC\n\nWould you like to:\n- Pick another winner (excluding Sarah)?\n- Export winner details?\n- Pick runner-ups?\n```\n\n**Inspired by:** Lenny's use case - picking a Sora 2 giveaway winner from his subscriber Slack community\n\n## Features\n\n### Fair Selection\n- Uses secure random number generation\n- No bias or patterns\n- Transparent process\n- Repeatable with seed (for verification)\n\n### Exclusions\n```\nPick a random winner excluding previous winners: \nAlice, Bob, Carol\n```\n\n### Weighted Selection\n```\nPick a winner with weighted probability based on \nthe \"entries\" column (1 entry = 1 ticket)\n```\n\n### Runner-ups\n```\nPick 1 winner and 3 runner-ups from the list\n```\n\n## Example Workflows\n\n### Social Media Giveaway\n1. Export entries from Google Form to Sheets\n2. \"Pick a random winner from [Sheet URL]\"\n3. Verify winner details\n4. Announce publicly with timestamp\n\n### Event Raffle\n1. Create CSV of attendee names and emails\n2. \"Pick 10 random winners from attendees.csv\"\n3. Export winner list\n4. Email winners directly\n\n### Team Assignment\n1. Have list of participants\n2. \"Randomly split this list into 4 equal teams\"\n3. Review assignments\n4. Share team rosters\n\n## Tips\n\n- **Document the process**: Save the timestamp and method\n- **Public announcement**: Share selection details for transparency\n- **Check eligibility**: Verify winner meets contest rules\n- **Have backups**: Pick runner-ups in case winner is ineligible\n- **Export results**: Save winner list for records\n\n## Privacy & Fairness\n\n‚úì Uses cryptographically secure randomness\n‚úì No manipulation possible\n‚úì Timestamp recorded for verification\n‚úì Can provide seed for third-party verification\n‚úì Respects data privacy\n\n## Common Use Cases\n\n- Newsletter subscriber giveaways\n- Product launch raffles\n- Conference ticket drawings\n- Beta tester selection\n- Focus group participant selection\n- Random prize distribution at events",
    "id": "raffle-winner-picker",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/raffle-winner-picker",
    "name_zh": "ÊäΩÂ•ñÂô®",
    "description_zh": "Picks random winners from lists, spreadsheets, or Google Sheets for giveaways, raffles, and contests. Ensures fair, unbiased selection with transparency.",
    "body_zh": "# Raffle Winner Picker\n\nThis skill randomly selects winners from lists, spreadsheets, or Google Sheets for giveaways and contests.\n\n## When to Use This Skill\n\n- Running social media giveaways\n- Picking raffle winners at events\n- Randomly selecting participants for surveys or tests\n- Choosing winners from contest submissions\n- Fair distribution of limited spots or resources\n- Random team assignments\n\n## What This Skill Does\n\n1. **Random Selection**: Uses cryptographically random selection\n2. **Multiple Sources**: Works with CSV, Excel, Google Sheets, or plain lists\n3. **Multiple Winners**: Can pick one or multiple winners\n4. **Duplicate Prevention**: Ensures the same person can't win twice\n5. **Transparent Results**: Shows the selection process clearly\n6. **Winner Details**: Displays all relevant information about winners\n\n## How to Use\n\n### From Google Sheets\n\n```\nPick a random row from this Google Sheet to select a winner \nfor a giveaway: [Sheet URL]\n```\n\n### From Local File\n\n```\nPick 3 random winners from entries.csv\n```\n\n### From List\n\n```\nPick a random winner from this list:\n- Alice (alice@email.com)\n- Bob (bob@email.com)\n- Carol (carol@email.com)\n...\n```\n\n### Multiple Winners\n\n```\nPick 5 random winners from contest-entries.xlsx, \nmake sure no duplicates\n```\n\n## Example\n\n**User**: \"Pick a random row from this Google Sheet to select a winner for a giveaway.\"\n\n**Output**:\n```\nAccessing Google Sheet...\nTotal entries found: 247\n\nRandomly selecting winner...\n\nüéâ WINNER SELECTED! üéâ\n\nRow #142\nName: Sarah Johnson\nEmail: sarah.j@email.com\nEntry Date: March 10, 2024\nComment: \"Love your newsletter!\"\n\nSelection method: Cryptographically random\nTimestamp: 2024-03-15 14:32:18 UTC\n\nWould you like to:\n- Pick another winner (excluding Sarah)?\n- Export winner details?\n- Pick runner-ups?\n```\n\n**Inspired by:** Lenny's use case - picking a Sora 2 giveaway winner from his subscriber Slack community\n\n## Features\n\n### Fair Selection\n- Uses secure random number generation\n- No bias or patterns\n- Transparent process\n- Repeatable with seed (for verification)\n\n### Exclusions\n```\nPick a random winner excluding previous winners: \nAlice, Bob, Carol\n```\n\n### Weighted Selection\n```\nPick a winner with weighted probability based on \nthe \"entries\" column (1 entry = 1 ticket)\n```\n\n### Runner-ups\n```\nPick 1 winner and 3 runner-ups from the list\n```\n\n## Example Workflows\n\n### Social Media Giveaway\n1. Export entries from Google Form to Sheets\n2. \"Pick a random winner from [Sheet URL]\"\n3. Verify winner details\n4. Announce publicly with timestamp\n\n### Event Raffle\n1. Create CSV of attendee names and emails\n2. \"Pick 10 random winners from attendees.csv\"\n3. Export winner list\n4. Email winners directly\n\n### Team Assignment\n1. Have list of participants\n2. \"Randomly split this list into 4 equal teams\"\n3. Review assignments\n4. Share team rosters\n\n## Tips\n\n- **Document the process**: Save the timestamp and method\n- **Public announcement**: Share selection details for transparency\n- **Check eligibility**: Verify winner meets contest rules\n- **Have backups**: Pick runner-ups in case winner is ineligible\n- **Export results**: Save winner list for records\n\n## Privacy & Fairness\n\n‚úì Uses cryptographically secure randomness\n‚úì No manipulation possible\n‚úì Timestamp recorded for verification\n‚úì Can provide seed for third-party verification\n‚úì Respects data privacy\n\n## Common Use Cases\n\n- Newsletter subscriber giveaways\n- Product launch raffles\n- Conference ticket drawings\n- Beta tester selection\n- Focus group participant selection\n- Random prize distribution at events"
  },
  {
    "name": "react-best-practices",
    "description": "React development guidelines with hooks, component patterns, state management, and performance optimization.",
    "body": "# React Best Practices\n\nModern React development guidelines covering hooks, component patterns, state management, and performance optimization.\n\n## When to Use\n\n- Building React applications\n- Learning React best practices\n- Code reviews for React projects\n- Performance optimization\n\n## Source\n\nThis skill references patterns from [Vercel's agent-skills](https://github.com/vercel-labs/agent-skills).",
    "id": "react-best-practices",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/react-best-practices",
    "name_zh": "React ÊúÄ‰Ω≥ÂÆûË∑µ",
    "description_zh": "React development guidelines with hooks, component patterns, state management, and performance optimization.",
    "body_zh": "# React Best Practices\n\nModern React development guidelines covering hooks, component patterns, state management, and performance optimization.\n\n## When to Use\n\n- Building React applications\n- Learning React best practices\n- Code reviews for React projects\n- Performance optimization\n\n## Source\n\nThis skill references patterns from [Vercel's agent-skills](https://github.com/vercel-labs/agent-skills)."
  },
  {
    "name": "skill-creator",
    "description": "Guide for creating effective skills. Use when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
    "body": "# Skill Creator\n\nSkills are modular packages that extend Claude's capabilities by providing specialized knowledge, workflows, and tools.\n\n## Core Principles\n\n### Concise is Key\nThe context window is a shared resource. Only add context Claude doesn't already have. Challenge each piece: \"Does Claude really need this?\"\n\n### Anatomy of a Skill\n\n```\nskill-name/\n‚îú‚îÄ‚îÄ SKILL.md (required)\n‚îÇ   ‚îú‚îÄ‚îÄ YAML frontmatter (name, description)\n‚îÇ   ‚îî‚îÄ‚îÄ Markdown instructions\n‚îî‚îÄ‚îÄ Bundled Resources (optional)\n    ‚îú‚îÄ‚îÄ scripts/      - Executable code\n    ‚îú‚îÄ‚îÄ references/   - Documentation\n    ‚îî‚îÄ‚îÄ assets/       - Templates, images\n```\n\n### SKILL.md Format\n\n```markdown\n---\nname: my-skill-name\ndescription: A clear description of what this skill does and when to use it\n---\n\n# My Skill Name\n\n[Instructions for Claude when this skill is active]\n\n## Examples\n- Example usage 1\n- Example usage 2\n\n## Guidelines\n- Guideline 1\n- Guideline 2\n```\n\n## Skill Creation Process\n\n### Step 1: Understand with Examples\nGather concrete examples of how the skill will be used. Ask:\n- \"What functionality should this skill support?\"\n- \"What would a user say that should trigger this skill?\"\n\n### Step 2: Plan Reusable Contents\nAnalyze examples to identify:\n- **Scripts**: Code that gets rewritten repeatedly\n- **References**: Documentation Claude needs to reference\n- **Assets**: Templates, images for output\n\n### Step 3: Initialize\nCreate the skill directory structure with SKILL.md and resource folders.\n\n### Step 4: Implement\n- Start with reusable resources (scripts, references, assets)\n- Write clear SKILL.md with proper frontmatter\n- Test scripts by actually running them\n\n### Step 5: Iterate\nUse the skill on real tasks, notice struggles, improve.\n\n## Progressive Disclosure\n\nKeep SKILL.md under 500 lines. Split content:\n\n```markdown\n# PDF Processing\n\n## Quick start\n[code example]\n\n## Advanced features\n- **Form filling**: See [FORMS.md](FORMS.md)\n- **API reference**: See [REFERENCE.md](REFERENCE.md)\n```\n\n## What NOT to Include\n\n- README.md\n- INSTALLATION_GUIDE.md\n- CHANGELOG.md\n- User-facing documentation\n\nSkills are for AI agents, not humans.",
    "id": "skill-creator",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/skill-creator",
    "name_zh": "ÊäÄËÉΩÂàõÂª∫Âô®",
    "description_zh": "Guide for creating effective skills. ÈÄÇÁî®‰∫é users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
    "body_zh": "# Skill Creator\n\nSkills are modular packages that extend Claude's capabilities by providing specialized knowledge, workflows, and tools.\n\n## Core Principles\n\n### Concise is Key\nThe context window is a shared resource. Only add context Claude doesn't already have. Challenge each piece: \"Does Claude really need this?\"\n\n### Anatomy of a Skill\n\n```\nskill-name/\n‚îú‚îÄ‚îÄ SKILL.md (required)\n‚îÇ   ‚îú‚îÄ‚îÄ YAML frontmatter (name, description)\n‚îÇ   ‚îî‚îÄ‚îÄ Markdown instructions\n‚îî‚îÄ‚îÄ Bundled Resources (optional)\n    ‚îú‚îÄ‚îÄ scripts/      - Executable code\n    ‚îú‚îÄ‚îÄ references/   - Documentation\n    ‚îî‚îÄ‚îÄ assets/       - Templates, images\n```\n\n### SKILL.md Format\n\n```markdown\n---\nname: my-skill-name\ndescription: A clear description of what this skill does and when to use it\n---\n\n# My Skill Name\n\n[Instructions for Claude when this skill is active]\n\n## Examples\n- Example usage 1\n- Example usage 2\n\n## Guidelines\n- Guideline 1\n- Guideline 2\n```\n\n## Skill Creation Process\n\n### Step 1: Understand with Examples\nGather concrete examples of how the skill will be used. Ask:\n- \"What functionality should this skill support?\"\n- \"What would a user say that should trigger this skill?\"\n\n### Step 2: Plan Reusable Contents\nAnalyze examples to identify:\n- **Scripts**: Code that gets rewritten repeatedly\n- **References**: Documentation Claude needs to reference\n- **Assets**: Templates, images for output\n\n### Step 3: Initialize\nCreate the skill directory structure with SKILL.md and resource folders.\n\n### Step 4: Implement\n- Start with reusable resources (scripts, references, assets)\n- Write clear SKILL.md with proper frontmatter\n- Test scripts by actually running them\n\n### Step 5: Iterate\nUse the skill on real tasks, notice struggles, improve.\n\n## Progressive Disclosure\n\nKeep SKILL.md under 500 lines. Split content:\n\n```markdown\n# PDF Processing\n\n## Quick start\n[code example]\n\n## Advanced features\n- **Form filling**: See [FORMS.md](FORMS.md)\n- **API reference**: See [REFERENCE.md](REFERENCE.md)\n```\n\n## What NOT to Include\n\n- README.md\n- INSTALLATION_GUIDE.md\n- CHANGELOG.md\n- User-facing documentation\n\nSkills are for AI agents, not humans."
  },
  {
    "name": "slack-gif-creator",
    "description": "Toolkit for creating animated GIFs optimized for Slack, with validators for size constraints and composable animation primitives. This skill applies when users request animated GIFs or emoji animations for Slack from descriptions like \"make me a GIF for Slack of X doing Y\".",
    "body": "# Slack GIF Creator - Flexible Toolkit\n\nA toolkit for creating animated GIFs optimized for Slack. Provides validators for Slack's constraints, composable animation primitives, and optional helper utilities. **Apply these tools however needed to achieve the creative vision.**\n\n## Slack's Requirements\n\nSlack has specific requirements for GIFs based on their use:\n\n**Message GIFs:**\n- Max size: ~2MB\n- Optimal dimensions: 480x480\n- Typical FPS: 15-20\n- Color limit: 128-256\n- Duration: 2-5s\n\n**Emoji GIFs:**\n- Max size: 64KB (strict limit)\n- Optimal dimensions: 128x128\n- Typical FPS: 10-12\n- Color limit: 32-48\n- Duration: 1-2s\n\n**Emoji GIFs are challenging** - the 64KB limit is strict. Strategies that help:\n- Limit to 10-15 frames total\n- Use 32-48 colors maximum\n- Keep designs simple\n- Avoid gradients\n- Validate file size frequently\n\n## Toolkit Structure\n\nThis skill provides three types of tools:\n\n1. **Validators** - Check if a GIF meets Slack's requirements\n2. **Animation Primitives** - Composable building blocks for motion (shake, bounce, move, kaleidoscope)\n3. **Helper Utilities** - Optional functions for common needs (text, colors, effects)\n\n**Complete creative freedom is available in how these tools are applied.**\n\n## Core Validators\n\nTo ensure a GIF meets Slack's constraints, use these validators:\n\n```python\nfrom core.gif_builder import GIFBuilder\n\n# After creating your GIF, check if it meets requirements\nbuilder = GIFBuilder(width=128, height=128, fps=10)\n# ... add your frames however you want ...\n\n# Save and check size\ninfo = builder.save('emoji.gif', num_colors=48, optimize_for_emoji=True)\n\n# The save method automatically warns if file exceeds limits\n# info dict contains: size_kb, size_mb, frame_count, duration_seconds\n```\n\n**File size validator**:\n```python\nfrom core.validators import check_slack_size\n\n# Check if GIF meets size limits\npasses, info = check_slack_size('emoji.gif', is_emoji=True)\n# Returns: (True/False, dict with size details)\n```\n\n**Dimension validator**:\n```python\nfrom core.validators import validate_dimensions\n\n# Check dimensions\npasses, info = validate_dimensions(128, 128, is_emoji=True)\n# Returns: (True/False, dict with dimension details)\n```\n\n**Complete validation**:\n```python\nfrom core.validators import validate_gif, is_slack_ready\n\n# Run all validations\nall_pass, results = validate_gif('emoji.gif', is_emoji=True)\n\n# Or quick check\nif is_slack_ready('emoji.gif', is_emoji=True):\n    print(\"Ready to upload!\")\n```\n\n## Animation Primitives\n\nThese are composable building blocks for motion. Apply these to any object in any combination:\n\n### Shake\n```python\nfrom templates.shake import create_shake_animation\n\n# Shake an emoji\nframes = create_shake_animation(\n    object_type='emoji',\n    object_data={'emoji': 'üò±', 'size': 80},\n    num_frames=20,\n    shake_intensity=15,\n    direction='both'  # or 'horizontal', 'vertical'\n)\n```\n\n### Bounce\n```python\nfrom templates.bounce import create_bounce_animation\n\n# Bounce a circle\nframes = create_bounce_animation(\n    object_type='circle',\n    object_data={'radius': 40, 'color': (255, 100, 100)},\n    num_frames=30,\n    bounce_height=150\n)\n```\n\n### Spin / Rotate\n```python\nfrom templates.spin import create_spin_animation, create_loading_spinner\n\n# Clockwise spin\nframes = create_spin_animation(\n    object_type='emoji',\n    object_data={'emoji': 'üîÑ', 'size': 100},\n    rotation_type='clockwise',\n    full_rotations=2\n)\n\n# Wobble rotation\nframes = create_spin_animation(rotation_type='wobble', full_rotations=3)\n\n# Loading spinner\nframes = create_loading_spinner(spinner_type='dots')\n```\n\n### Pulse / Heartbeat\n```python\nfrom templates.pulse import create_pulse_animation, create_attention_pulse\n\n# Smooth pulse\nframes = create_pulse_animation(\n    object_data={'emoji': '‚ù§Ô∏è', 'size': 100},\n    pulse_type='smooth',\n    scale_range=(0.8, 1.2)\n)\n\n# Heartbeat (double-pump)\nframes = create_pulse_animation(pulse_type='heartbeat')\n\n# Attention pulse for emoji GIFs\nframes = create_attention_pulse(emoji='‚ö†Ô∏è', num_frames=20)\n```\n\n### Fade\n```python\nfrom templates.fade import create_fade_animation, create_crossfade\n\n# Fade in\nframes = create_fade_animation(fade_type='in')\n\n# Fade out\nframes = create_fade_animation(fade_type='out')\n\n# Crossfade between two emojis\nframes = create_crossfade(\n    object1_data={'emoji': 'üòä', 'size': 100},\n    object2_data={'emoji': 'üòÇ', 'size': 100}\n)\n```\n\n### Zoom\n```python\nfrom templates.zoom import create_zoom_animation, create_explosion_zoom\n\n# Zoom in dramatically\nframes = create_zoom_animation(\n    zoom_type='in',\n    scale_range=(0.1, 2.0),\n    add_motion_blur=True\n)\n\n# Zoom out\nframes = create_zoom_animation(zoom_type='out')\n\n# Explosion zoom\nframes = create_explosion_zoom(emoji='üí•')\n```\n\n### Explode / Shatter\n```python\nfrom templates.explode import create_explode_animation, create_particle_burst\n\n# Burst explosion\nframes = create_explode_animation(\n    explode_type='burst',\n    num_pieces=25\n)\n\n# Shatter effect\nframes = create_explode_animation(explode_type='shatter')\n\n# Dissolve into particles\nframes = create_explode_animation(explode_type='dissolve')\n\n# Particle burst\nframes = create_particle_burst(particle_count=30)\n```\n\n### Wiggle / Jiggle\n```python\nfrom templates.wiggle import create_wiggle_animation, create_excited_wiggle\n\n# Jello wobble\nframes = create_wiggle_animation(\n    wiggle_type='jello',\n    intensity=1.0,\n    cycles=2\n)\n\n# Wave motion\nframes = create_wiggle_animation(wiggle_type='wave')\n\n# Excited wiggle for emoji GIFs\nframes = create_excited_wiggle(emoji='üéâ')\n```\n\n### Slide\n```python\nfrom templates.slide import create_slide_animation, create_multi_slide\n\n# Slide in from left with overshoot\nframes = create_slide_animation(\n    direction='left',\n    slide_type='in',\n    overshoot=True\n)\n\n# Slide across\nframes = create_slide_animation(direction='left', slide_type='across')\n\n# Multiple objects sliding in sequence\nobjects = [\n    {'data': {'emoji': 'üéØ', 'size': 60}, 'direction': 'left', 'final_pos': (120, 240)},\n    {'data': {'emoji': 'üé™', 'size': 60}, 'direction': 'right', 'final_pos': (240, 240)}\n]\nframes = create_multi_slide(objects, stagger_delay=5)\n```\n\n### Flip\n```python\nfrom templates.flip import create_flip_animation, create_quick_flip\n\n# Horizontal flip between two emojis\nframes = create_flip_animation(\n    object1_data={'emoji': 'üòä', 'size': 120},\n    object2_data={'emoji': 'üòÇ', 'size': 120},\n    flip_axis='horizontal'\n)\n\n# Vertical flip\nframes = create_flip_animation(flip_axis='vertical')\n\n# Quick flip for emoji GIFs\nframes = create_quick_flip('üëç', 'üëé')\n```\n\n### Morph / Transform\n```python\nfrom templates.morph import create_morph_animation, create_reaction_morph\n\n# Crossfade morph\nframes = create_morph_animation(\n    object1_data={'emoji': 'üòä', 'size': 100},\n    object2_data={'emoji': 'üòÇ', 'size': 100},\n    morph_type='crossfade'\n)\n\n# Scale morph (shrink while other grows)\nframes = create_morph_animation(morph_type='scale')\n\n# Spin morph (3D flip-like)\nframes = create_morph_animation(morph_type='spin_morph')\n```\n\n### Move Effect\n```python\nfrom templates.move import create_move_animation\n\n# Linear movement\nframes = create_move_animation(\n    object_type='emoji',\n    object_data={'emoji': 'üöÄ', 'size': 60},\n    start_pos=(50, 240),\n    end_pos=(430, 240),\n    motion_type='linear',\n    easing='ease_out'\n)\n\n# Arc movement (parabolic trajectory)\nframes = create_move_animation(\n    object_type='emoji',\n    object_data={'emoji': '‚öΩ', 'size': 60},\n    start_pos=(50, 350),\n    end_pos=(430, 350),\n    motion_type='arc',\n    motion_params={'arc_height': 150}\n)\n\n# Circular movement\nframes = create_move_animation(\n    object_type='emoji',\n    object_data={'emoji': 'üåç', 'size': 50},\n    motion_type='circle',\n    motion_params={\n        'center': (240, 240),\n        'radius': 120,\n        'angle_range': 360  # full circle\n    }\n)\n\n# Wave movement\nframes = create_move_animation(\n    motion_type='wave',\n    motion_params={\n        'wave_amplitude': 50,\n        'wave_frequency': 2\n    }\n)\n\n# Or use low-level easing functions\nfrom core.easing import interpolate, calculate_arc_motion\n\nfor i in range(num_frames):\n    t = i / (num_frames - 1)\n    x = interpolate(start_x, end_x, t, easing='ease_out')\n    # Or: x, y = calculate_arc_motion(start, end, height, t)\n```\n\n### Kaleidoscope Effect\n```python\nfrom templates.kaleidoscope import apply_kaleidoscope, create_kaleidoscope_animation\n\n# Apply to a single frame\nkaleido_frame = apply_kaleidoscope(frame, segments=8)\n\n# Or create animated kaleidoscope\nframes = create_kaleidoscope_animation(\n    base_frame=my_frame,  # or None for demo pattern\n    num_frames=30,\n    segments=8,\n    rotation_speed=1.0\n)\n\n# Simple mirror effects (faster)\nfrom templates.kaleidoscope import apply_simple_mirror\n\nmirrored = apply_simple_mirror(frame, mode='quad')  # 4-way mirror\n# modes: 'horizontal', 'vertical', 'quad', 'radial'\n```\n\n**To compose primitives freely, follow these patterns:**\n```python\n# Example: Bounce + shake for impact\nfor i in range(num_frames):\n    frame = create_blank_frame(480, 480, bg_color)\n\n    # Bounce motion\n    t_bounce = i / (num_frames - 1)\n    y = interpolate(start_y, ground_y, t_bounce, 'bounce_out')\n\n    # Add shake on impact (when y reaches ground)\n    if y >= ground_y - 5:\n        shake_x = math.sin(i * 2) * 10\n        x = center_x + shake_x\n    else:\n        x = center_x\n\n    draw_emoji(frame, '‚öΩ', (x, y), size=60)\n    builder.add_frame(frame)\n```\n\n## Helper Utilities\n\nThese are optional helpers for common needs. **Use, modify, or replace these with custom implementations as needed.**\n\n### GIF Builder (Assembly & Optimization)\n\n```python\nfrom core.gif_builder import GIFBuilder\n\n# Create builder with your chosen settings\nbuilder = GIFBuilder(width=480, height=480, fps=20)\n\n# Add frames (however you created them)\nfor frame in my_frames:\n    builder.add_frame(frame)\n\n# Save with optimization\nbuilder.save('output.gif',\n             num_colors=128,\n             optimize_for_emoji=False)\n```\n\nKey features:\n- Automatic color quantization\n- Duplicate frame removal\n- Size warnings for Slack limits\n- Emoji mode (aggressive optimization)\n\n### Text Rendering\n\nFor small GIFs like emojis, text readability is challenging. A common solution involves adding outlines:\n\n```python\nfrom core.typography import draw_text_with_outline, TYPOGRAPHY_SCALE\n\n# Text with outline (helps readability)\ndraw_text_with_outline(\n    frame, \"BONK!\",\n    position=(240, 100),\n    font_size=TYPOGRAPHY_SCALE['h1'],  # 60px\n    text_color=(255, 68, 68),\n    outline_color=(0, 0, 0),\n    outline_width=4,\n    centered=True\n)\n```\n\nTo implement custom text rendering, use PIL's `ImageDraw.text()` which works fine for larger GIFs.\n\n### Color Management\n\nProfessional-looking GIFs often use cohesive color palettes:\n\n```python\nfrom core.color_palettes import get_palette\n\n# Get a pre-made palette\npalette = get_palette('vibrant')  # or 'pastel', 'dark', 'neon', 'professional'\n\nbg_color = palette['background']\ntext_color = palette['primary']\naccent_color = palette['accent']\n```\n\nTo work with colors directly, use RGB tuples - whatever works for the use case.\n\n### Visual Effects\n\nOptional effects for impact moments:\n\n```python\nfrom core.visual_effects import ParticleSystem, create_impact_flash, create_shockwave_rings\n\n# Particle system\nparticles = ParticleSystem()\nparticles.emit_sparkles(x=240, y=200, count=15)\nparticles.emit_confetti(x=240, y=200, count=20)\n\n# Update and render each frame\nparticles.update()\nparticles.render(frame)\n\n# Flash effect\nframe = create_impact_flash(frame, position=(240, 200), radius=100)\n\n# Shockwave rings\nframe = create_shockwave_rings(frame, position=(240, 200), radii=[30, 60, 90])\n```\n\n### Easing Functions\n\nSmooth motion uses easing instead of linear interpolation:\n\n```python\nfrom core.easing import interpolate\n\n# Object falling (accelerates)\ny = interpolate(start=0, end=400, t=progress, easing='ease_in')\n\n# Object landing (decelerates)\ny = interpolate(start=0, end=400, t=progress, easing='ease_out')\n\n# Bouncing\ny = interpolate(start=0, end=400, t=progress, easing='bounce_out')\n\n# Overshoot (elastic)\nscale = interpolate(start=0.5, end=1.0, t=progress, easing='elastic_out')\n```\n\nAvailable easings: `linear`, `ease_in`, `ease_out`, `ease_in_out`, `bounce_out`, `elastic_out`, `back_out` (overshoot), and more in `core/easing.py`.\n\n### Frame Composition\n\nBasic drawing utilities if you need them:\n\n```python\nfrom core.frame_composer import (\n    create_gradient_background,  # Gradient backgrounds\n    draw_emoji_enhanced,         # Emoji with optional shadow\n    draw_circle_with_shadow,     # Shapes with depth\n    draw_star                    # 5-pointed stars\n)\n\n# Gradient background\nframe = create_gradient_background(480, 480, top_color, bottom_color)\n\n# Emoji with shadow\ndraw_emoji_enhanced(frame, 'üéâ', position=(200, 200), size=80, shadow=True)\n```\n\n## Optimization Strategies\n\nWhen your GIF is too large:\n\n**For Message GIFs (>2MB):**\n1. Reduce frames (lower FPS or shorter duration)\n2. Reduce colors (128 ‚Üí 64 colors)\n3. Reduce dimensions (480x480 ‚Üí 320x320)\n4. Enable duplicate frame removal\n\n**For Emoji GIFs (>64KB) - be aggressive:**\n1. Limit to 10-12 frames total\n2. Use 32-40 colors maximum\n3. Avoid gradients (solid colors compress better)\n4. Simplify design (fewer elements)\n5. Use `optimize_for_emoji=True` in save method\n\n## Example Composition Patterns\n\n### Simple Reaction (Pulsing)\n```python\nbuilder = GIFBuilder(128, 128, 10)\n\nfor i in range(12):\n    frame = Image.new('RGB', (128, 128), (240, 248, 255))\n\n    # Pulsing scale\n    scale = 1.0 + math.sin(i * 0.5) * 0.15\n    size = int(60 * scale)\n\n    draw_emoji_enhanced(frame, 'üò±', position=(64-size//2, 64-size//2),\n                       size=size, shadow=False)\n    builder.add_frame(frame)\n\nbuilder.save('reaction.gif', num_colors=40, optimize_for_emoji=True)\n\n# Validate\nfrom core.validators import check_slack_size\ncheck_slack_size('reaction.gif', is_emoji=True)\n```\n\n### Action with Impact (Bounce + Flash)\n```python\nbuilder = GIFBuilder(480, 480, 20)\n\n# Phase 1: Object falls\nfor i in range(15):\n    frame = create_gradient_background(480, 480, (240, 248, 255), (200, 230, 255))\n    t = i / 14\n    y = interpolate(0, 350, t, 'ease_in')\n    draw_emoji_enhanced(frame, '‚öΩ', position=(220, int(y)), size=80)\n    builder.add_frame(frame)\n\n# Phase 2: Impact + flash\nfor i in range(8):\n    frame = create_gradient_background(480, 480, (240, 248, 255), (200, 230, 255))\n\n    # Flash on first frames\n    if i < 3:\n        frame = create_impact_flash(frame, (240, 350), radius=120, intensity=0.6)\n\n    draw_emoji_enhanced(frame, '‚öΩ', position=(220, 350), size=80)\n\n    # Text appears\n    if i > 2:\n        draw_text_with_outline(frame, \"GOAL!\", position=(240, 150),\n                              font_size=60, text_color=(255, 68, 68),\n                              outline_color=(0, 0, 0), outline_width=4, centered=True)\n\n    builder.add_frame(frame)\n\nbuilder.save('goal.gif', num_colors=128)\n```\n\n### Combining Primitives (Move + Shake)\n```python\nfrom templates.shake import create_shake_animation\n\n# Create shake animation\nshake_frames = create_shake_animation(\n    object_type='emoji',\n    object_data={'emoji': 'üò∞', 'size': 70},\n    num_frames=20,\n    shake_intensity=12\n)\n\n# Create moving element that triggers the shake\nbuilder = GIFBuilder(480, 480, 20)\nfor i in range(40):\n    t = i / 39\n\n    if i < 20:\n        # Before trigger - use blank frame with moving object\n        frame = create_blank_frame(480, 480, (255, 255, 255))\n        x = interpolate(50, 300, t * 2, 'linear')\n        draw_emoji_enhanced(frame, 'üöó', position=(int(x), 300), size=60)\n        draw_emoji_enhanced(frame, 'üò∞', position=(350, 200), size=70)\n    else:\n        # After trigger - use shake frame\n        frame = shake_frames[i - 20]\n        # Add the car in final position\n        draw_emoji_enhanced(frame, 'üöó', position=(300, 300), size=60)\n\n    builder.add_frame(frame)\n\nbuilder.save('scare.gif')\n```\n\n## Philosophy\n\nThis toolkit provides building blocks, not rigid recipes. To work with a GIF request:\n\n1. **Understand the creative vision** - What should happen? What's the mood?\n2. **Design the animation** - Break it into phases (anticipation, action, reaction)\n3. **Apply primitives as needed** - Shake, bounce, move, effects - mix freely\n4. **Validate constraints** - Check file size, especially for emoji GIFs\n5. **Iterate if needed** - Reduce frames/colors if over size limits\n\n**The goal is creative freedom within Slack's technical constraints.**\n\n## Dependencies\n\nTo use this toolkit, install these dependencies only if they aren't already present:\n\n```bash\npip install pillow imageio numpy\n```",
    "id": "slack-gif-creator",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/slack-gif-creator",
    "name_zh": "Slack GIF Âà∂‰Ωú",
    "description_zh": "Toolkit for creating animated GIFs optimized for Slack, with validators for size constraints and composable animation primitives. This skill applies when Áî®Êà∑ËØ∑Ê±Ç animated GIFs or emoji animations for Slack from descriptions like \"make me a GIF for Slack of X doing Y\".",
    "body_zh": "# Slack GIF Creator - Flexible Toolkit\n\nA toolkit for creating animated GIFs optimized for Slack. Provides validators for Slack's constraints, composable animation primitives, and optional helper utilities. **Apply these tools however needed to achieve the creative vision.**\n\n## Slack's Requirements\n\nSlack has specific requirements for GIFs based on their use:\n\n**Message GIFs:**\n- Max size: ~2MB\n- Optimal dimensions: 480x480\n- Typical FPS: 15-20\n- Color limit: 128-256\n- Duration: 2-5s\n\n**Emoji GIFs:**\n- Max size: 64KB (strict limit)\n- Optimal dimensions: 128x128\n- Typical FPS: 10-12\n- Color limit: 32-48\n- Duration: 1-2s\n\n**Emoji GIFs are challenging** - the 64KB limit is strict. Strategies that help:\n- Limit to 10-15 frames total\n- Use 32-48 colors maximum\n- Keep designs simple\n- Avoid gradients\n- Validate file size frequently\n\n## Toolkit Structure\n\nThis skill provides three types of tools:\n\n1. **Validators** - Check if a GIF meets Slack's requirements\n2. **Animation Primitives** - Composable building blocks for motion (shake, bounce, move, kaleidoscope)\n3. **Helper Utilities** - Optional functions for common needs (text, colors, effects)\n\n**Complete creative freedom is available in how these tools are applied.**\n\n## Core Validators\n\nTo ensure a GIF meets Slack's constraints, use these validators:\n\n```python\nfrom core.gif_builder import GIFBuilder\n\n# After creating your GIF, check if it meets requirements\nbuilder = GIFBuilder(width=128, height=128, fps=10)\n# ... add your frames however you want ...\n\n# Save and check size\ninfo = builder.save('emoji.gif', num_colors=48, optimize_for_emoji=True)\n\n# The save method automatically warns if file exceeds limits\n# info dict contains: size_kb, size_mb, frame_count, duration_seconds\n```\n\n**File size validator**:\n```python\nfrom core.validators import check_slack_size\n\n# Check if GIF meets size limits\npasses, info = check_slack_size('emoji.gif', is_emoji=True)\n# Returns: (True/False, dict with size details)\n```\n\n**Dimension validator**:\n```python\nfrom core.validators import validate_dimensions\n\n# Check dimensions\npasses, info = validate_dimensions(128, 128, is_emoji=True)\n# Returns: (True/False, dict with dimension details)\n```\n\n**Complete validation**:\n```python\nfrom core.validators import validate_gif, is_slack_ready\n\n# Run all validations\nall_pass, results = validate_gif('emoji.gif', is_emoji=True)\n\n# Or quick check\nif is_slack_ready('emoji.gif', is_emoji=True):\n    print(\"Ready to upload!\")\n```\n\n## Animation Primitives\n\nThese are composable building blocks for motion. Apply these to any object in any combination:\n\n### Shake\n```python\nfrom templates.shake import create_shake_animation\n\n# Shake an emoji\nframes = create_shake_animation(\n    object_type='emoji',\n    object_data={'emoji': 'üò±', 'size': 80},\n    num_frames=20,\n    shake_intensity=15,\n    direction='both'  # or 'horizontal', 'vertical'\n)\n```\n\n### Bounce\n```python\nfrom templates.bounce import create_bounce_animation\n\n# Bounce a circle\nframes = create_bounce_animation(\n    object_type='circle',\n    object_data={'radius': 40, 'color': (255, 100, 100)},\n    num_frames=30,\n    bounce_height=150\n)\n```\n\n### Spin / Rotate\n```python\nfrom templates.spin import create_spin_animation, create_loading_spinner\n\n# Clockwise spin\nframes = create_spin_animation(\n    object_type='emoji',\n    object_data={'emoji': 'üîÑ', 'size': 100},\n    rotation_type='clockwise',\n    full_rotations=2\n)\n\n# Wobble rotation\nframes = create_spin_animation(rotation_type='wobble', full_rotations=3)\n\n# Loading spinner\nframes = create_loading_spinner(spinner_type='dots')\n```\n\n### Pulse / Heartbeat\n```python\nfrom templates.pulse import create_pulse_animation, create_attention_pulse\n\n# Smooth pulse\nframes = create_pulse_animation(\n    object_data={'emoji': '‚ù§Ô∏è', 'size': 100},\n    pulse_type='smooth',\n    scale_range=(0.8, 1.2)\n)\n\n# Heartbeat (double-pump)\nframes = create_pulse_animation(pulse_type='heartbeat')\n\n# Attention pulse for emoji GIFs\nframes = create_attention_pulse(emoji='‚ö†Ô∏è', num_frames=20)\n```\n\n### Fade\n```python\nfrom templates.fade import create_fade_animation, create_crossfade\n\n# Fade in\nframes = create_fade_animation(fade_type='in')\n\n# Fade out\nframes = create_fade_animation(fade_type='out')\n\n# Crossfade between two emojis\nframes = create_crossfade(\n    object1_data={'emoji': 'üòä', 'size': 100},\n    object2_data={'emoji': 'üòÇ', 'size': 100}\n)\n```\n\n### Zoom\n```python\nfrom templates.zoom import create_zoom_animation, create_explosion_zoom\n\n# Zoom in dramatically\nframes = create_zoom_animation(\n    zoom_type='in',\n    scale_range=(0.1, 2.0),\n    add_motion_blur=True\n)\n\n# Zoom out\nframes = create_zoom_animation(zoom_type='out')\n\n# Explosion zoom\nframes = create_explosion_zoom(emoji='üí•')\n```\n\n### Explode / Shatter\n```python\nfrom templates.explode import create_explode_animation, create_particle_burst\n\n# Burst explosion\nframes = create_explode_animation(\n    explode_type='burst',\n    num_pieces=25\n)\n\n# Shatter effect\nframes = create_explode_animation(explode_type='shatter')\n\n# Dissolve into particles\nframes = create_explode_animation(explode_type='dissolve')\n\n# Particle burst\nframes = create_particle_burst(particle_count=30)\n```\n\n### Wiggle / Jiggle\n```python\nfrom templates.wiggle import create_wiggle_animation, create_excited_wiggle\n\n# Jello wobble\nframes = create_wiggle_animation(\n    wiggle_type='jello',\n    intensity=1.0,\n    cycles=2\n)\n\n# Wave motion\nframes = create_wiggle_animation(wiggle_type='wave')\n\n# Excited wiggle for emoji GIFs\nframes = create_excited_wiggle(emoji='üéâ')\n```\n\n### Slide\n```python\nfrom templates.slide import create_slide_animation, create_multi_slide\n\n# Slide in from left with overshoot\nframes = create_slide_animation(\n    direction='left',\n    slide_type='in',\n    overshoot=True\n)\n\n# Slide across\nframes = create_slide_animation(direction='left', slide_type='across')\n\n# Multiple objects sliding in sequence\nobjects = [\n    {'data': {'emoji': 'üéØ', 'size': 60}, 'direction': 'left', 'final_pos': (120, 240)},\n    {'data': {'emoji': 'üé™', 'size': 60}, 'direction': 'right', 'final_pos': (240, 240)}\n]\nframes = create_multi_slide(objects, stagger_delay=5)\n```\n\n### Flip\n```python\nfrom templates.flip import create_flip_animation, create_quick_flip\n\n# Horizontal flip between two emojis\nframes = create_flip_animation(\n    object1_data={'emoji': 'üòä', 'size': 120},\n    object2_data={'emoji': 'üòÇ', 'size': 120},\n    flip_axis='horizontal'\n)\n\n# Vertical flip\nframes = create_flip_animation(flip_axis='vertical')\n\n# Quick flip for emoji GIFs\nframes = create_quick_flip('üëç', 'üëé')\n```\n\n### Morph / Transform\n```python\nfrom templates.morph import create_morph_animation, create_reaction_morph\n\n# Crossfade morph\nframes = create_morph_animation(\n    object1_data={'emoji': 'üòä', 'size': 100},\n    object2_data={'emoji': 'üòÇ', 'size': 100},\n    morph_type='crossfade'\n)\n\n# Scale morph (shrink while other grows)\nframes = create_morph_animation(morph_type='scale')\n\n# Spin morph (3D flip-like)\nframes = create_morph_animation(morph_type='spin_morph')\n```\n\n### Move Effect\n```python\nfrom templates.move import create_move_animation\n\n# Linear movement\nframes = create_move_animation(\n    object_type='emoji',\n    object_data={'emoji': 'üöÄ', 'size': 60},\n    start_pos=(50, 240),\n    end_pos=(430, 240),\n    motion_type='linear',\n    easing='ease_out'\n)\n\n# Arc movement (parabolic trajectory)\nframes = create_move_animation(\n    object_type='emoji',\n    object_data={'emoji': '‚öΩ', 'size': 60},\n    start_pos=(50, 350),\n    end_pos=(430, 350),\n    motion_type='arc',\n    motion_params={'arc_height': 150}\n)\n\n# Circular movement\nframes = create_move_animation(\n    object_type='emoji',\n    object_data={'emoji': 'üåç', 'size': 50},\n    motion_type='circle',\n    motion_params={\n        'center': (240, 240),\n        'radius': 120,\n        'angle_range': 360  # full circle\n    }\n)\n\n# Wave movement\nframes = create_move_animation(\n    motion_type='wave',\n    motion_params={\n        'wave_amplitude': 50,\n        'wave_frequency': 2\n    }\n)\n\n# Or use low-level easing functions\nfrom core.easing import interpolate, calculate_arc_motion\n\nfor i in range(num_frames):\n    t = i / (num_frames - 1)\n    x = interpolate(start_x, end_x, t, easing='ease_out')\n    # Or: x, y = calculate_arc_motion(start, end, height, t)\n```\n\n### Kaleidoscope Effect\n```python\nfrom templates.kaleidoscope import apply_kaleidoscope, create_kaleidoscope_animation\n\n# Apply to a single frame\nkaleido_frame = apply_kaleidoscope(frame, segments=8)\n\n# Or create animated kaleidoscope\nframes = create_kaleidoscope_animation(\n    base_frame=my_frame,  # or None for demo pattern\n    num_frames=30,\n    segments=8,\n    rotation_speed=1.0\n)\n\n# Simple mirror effects (faster)\nfrom templates.kaleidoscope import apply_simple_mirror\n\nmirrored = apply_simple_mirror(frame, mode='quad')  # 4-way mirror\n# modes: 'horizontal', 'vertical', 'quad', 'radial'\n```\n\n**To compose primitives freely, follow these patterns:**\n```python\n# Example: Bounce + shake for impact\nfor i in range(num_frames):\n    frame = create_blank_frame(480, 480, bg_color)\n\n    # Bounce motion\n    t_bounce = i / (num_frames - 1)\n    y = interpolate(start_y, ground_y, t_bounce, 'bounce_out')\n\n    # Add shake on impact (when y reaches ground)\n    if y >= ground_y - 5:\n        shake_x = math.sin(i * 2) * 10\n        x = center_x + shake_x\n    else:\n        x = center_x\n\n    draw_emoji(frame, '‚öΩ', (x, y), size=60)\n    builder.add_frame(frame)\n```\n\n## Helper Utilities\n\nThese are optional helpers for common needs. **Use, modify, or replace these with custom implementations as needed.**\n\n### GIF Builder (Assembly & Optimization)\n\n```python\nfrom core.gif_builder import GIFBuilder\n\n# Create builder with your chosen settings\nbuilder = GIFBuilder(width=480, height=480, fps=20)\n\n# Add frames (however you created them)\nfor frame in my_frames:\n    builder.add_frame(frame)\n\n# Save with optimization\nbuilder.save('output.gif',\n             num_colors=128,\n             optimize_for_emoji=False)\n```\n\nKey features:\n- Automatic color quantization\n- Duplicate frame removal\n- Size warnings for Slack limits\n- Emoji mode (aggressive optimization)\n\n### Text Rendering\n\nFor small GIFs like emojis, text readability is challenging. A common solution involves adding outlines:\n\n```python\nfrom core.typography import draw_text_with_outline, TYPOGRAPHY_SCALE\n\n# Text with outline (helps readability)\ndraw_text_with_outline(\n    frame, \"BONK!\",\n    position=(240, 100),\n    font_size=TYPOGRAPHY_SCALE['h1'],  # 60px\n    text_color=(255, 68, 68),\n    outline_color=(0, 0, 0),\n    outline_width=4,\n    centered=True\n)\n```\n\nTo implement custom text rendering, use PIL's `ImageDraw.text()` which works fine for larger GIFs.\n\n### Color Management\n\nProfessional-looking GIFs often use cohesive color palettes:\n\n```python\nfrom core.color_palettes import get_palette\n\n# Get a pre-made palette\npalette = get_palette('vibrant')  # or 'pastel', 'dark', 'neon', 'professional'\n\nbg_color = palette['background']\ntext_color = palette['primary']\naccent_color = palette['accent']\n```\n\nTo work with colors directly, use RGB tuples - whatever works for the use case.\n\n### Visual Effects\n\nOptional effects for impact moments:\n\n```python\nfrom core.visual_effects import ParticleSystem, create_impact_flash, create_shockwave_rings\n\n# Particle system\nparticles = ParticleSystem()\nparticles.emit_sparkles(x=240, y=200, count=15)\nparticles.emit_confetti(x=240, y=200, count=20)\n\n# Update and render each frame\nparticles.update()\nparticles.render(frame)\n\n# Flash effect\nframe = create_impact_flash(frame, position=(240, 200), radius=100)\n\n# Shockwave rings\nframe = create_shockwave_rings(frame, position=(240, 200), radii=[30, 60, 90])\n```\n\n### Easing Functions\n\nSmooth motion uses easing instead of linear interpolation:\n\n```python\nfrom core.easing import interpolate\n\n# Object falling (accelerates)\ny = interpolate(start=0, end=400, t=progress, easing='ease_in')\n\n# Object landing (decelerates)\ny = interpolate(start=0, end=400, t=progress, easing='ease_out')\n\n# Bouncing\ny = interpolate(start=0, end=400, t=progress, easing='bounce_out')\n\n# Overshoot (elastic)\nscale = interpolate(start=0.5, end=1.0, t=progress, easing='elastic_out')\n```\n\nAvailable easings: `linear`, `ease_in`, `ease_out`, `ease_in_out`, `bounce_out`, `elastic_out`, `back_out` (overshoot), and more in `core/easing.py`.\n\n### Frame Composition\n\nBasic drawing utilities if you need them:\n\n```python\nfrom core.frame_composer import (\n    create_gradient_background,  # Gradient backgrounds\n    draw_emoji_enhanced,         # Emoji with optional shadow\n    draw_circle_with_shadow,     # Shapes with depth\n    draw_star                    # 5-pointed stars\n)\n\n# Gradient background\nframe = create_gradient_background(480, 480, top_color, bottom_color)\n\n# Emoji with shadow\ndraw_emoji_enhanced(frame, 'üéâ', position=(200, 200), size=80, shadow=True)\n```\n\n## Optimization Strategies\n\nWhen your GIF is too large:\n\n**For Message GIFs (>2MB):**\n1. Reduce frames (lower FPS or shorter duration)\n2. Reduce colors (128 ‚Üí 64 colors)\n3. Reduce dimensions (480x480 ‚Üí 320x320)\n4. Enable duplicate frame removal\n\n**For Emoji GIFs (>64KB) - be aggressive:**\n1. Limit to 10-12 frames total\n2. Use 32-40 colors maximum\n3. Avoid gradients (solid colors compress better)\n4. Simplify design (fewer elements)\n5. Use `optimize_for_emoji=True` in save method\n\n## Example Composition Patterns\n\n### Simple Reaction (Pulsing)\n```python\nbuilder = GIFBuilder(128, 128, 10)\n\nfor i in range(12):\n    frame = Image.new('RGB', (128, 128), (240, 248, 255))\n\n    # Pulsing scale\n    scale = 1.0 + math.sin(i * 0.5) * 0.15\n    size = int(60 * scale)\n\n    draw_emoji_enhanced(frame, 'üò±', position=(64-size//2, 64-size//2),\n                       size=size, shadow=False)\n    builder.add_frame(frame)\n\nbuilder.save('reaction.gif', num_colors=40, optimize_for_emoji=True)\n\n# Validate\nfrom core.validators import check_slack_size\ncheck_slack_size('reaction.gif', is_emoji=True)\n```\n\n### Action with Impact (Bounce + Flash)\n```python\nbuilder = GIFBuilder(480, 480, 20)\n\n# Phase 1: Object falls\nfor i in range(15):\n    frame = create_gradient_background(480, 480, (240, 248, 255), (200, 230, 255))\n    t = i / 14\n    y = interpolate(0, 350, t, 'ease_in')\n    draw_emoji_enhanced(frame, '‚öΩ', position=(220, int(y)), size=80)\n    builder.add_frame(frame)\n\n# Phase 2: Impact + flash\nfor i in range(8):\n    frame = create_gradient_background(480, 480, (240, 248, 255), (200, 230, 255))\n\n    # Flash on first frames\n    if i < 3:\n        frame = create_impact_flash(frame, (240, 350), radius=120, intensity=0.6)\n\n    draw_emoji_enhanced(frame, '‚öΩ', position=(220, 350), size=80)\n\n    # Text appears\n    if i > 2:\n        draw_text_with_outline(frame, \"GOAL!\", position=(240, 150),\n                              font_size=60, text_color=(255, 68, 68),\n                              outline_color=(0, 0, 0), outline_width=4, centered=True)\n\n    builder.add_frame(frame)\n\nbuilder.save('goal.gif', num_colors=128)\n```\n\n### Combining Primitives (Move + Shake)\n```python\nfrom templates.shake import create_shake_animation\n\n# Create shake animation\nshake_frames = create_shake_animation(\n    object_type='emoji',\n    object_data={'emoji': 'üò∞', 'size': 70},\n    num_frames=20,\n    shake_intensity=12\n)\n\n# Create moving element that triggers the shake\nbuilder = GIFBuilder(480, 480, 20)\nfor i in range(40):\n    t = i / 39\n\n    if i < 20:\n        # Before trigger - use blank frame with moving object\n        frame = create_blank_frame(480, 480, (255, 255, 255))\n        x = interpolate(50, 300, t * 2, 'linear')\n        draw_emoji_enhanced(frame, 'üöó', position=(int(x), 300), size=60)\n        draw_emoji_enhanced(frame, 'üò∞', position=(350, 200), size=70)\n    else:\n        # After trigger - use shake frame\n        frame = shake_frames[i - 20]\n        # Add the car in final position\n        draw_emoji_enhanced(frame, 'üöó', position=(300, 300), size=60)\n\n    builder.add_frame(frame)\n\nbuilder.save('scare.gif')\n```\n\n## Philosophy\n\nThis toolkit provides building blocks, not rigid recipes. To work with a GIF request:\n\n1. **Understand the creative vision** - What should happen? What's the mood?\n2. **Design the animation** - Break it into phases (anticipation, action, reaction)\n3. **Apply primitives as needed** - Shake, bounce, move, effects - mix freely\n4. **Validate constraints** - Check file size, especially for emoji GIFs\n5. **Iterate if needed** - Reduce frames/colors if over size limits\n\n**The goal is creative freedom within Slack's technical constraints.**\n\n## Dependencies\n\nTo use this toolkit, install these dependencies only if they aren't already present:\n\n```bash\npip install pillow imageio numpy\n```"
  },
  {
    "name": "theme-factory",
    "description": "Toolkit for styling artifacts with a theme. These artifacts can be slides, docs, reportings, HTML landing pages, etc. There are 10 pre-set themes with colors/fonts that you can apply to any artifact that has been creating, or can generate a new theme on-the-fly.",
    "body": "# Theme Factory Skill\n\nThis skill provides a curated collection of professional font and color themes themes, each with carefully selected color palettes and font pairings. Once a theme is chosen, it can be applied to any artifact.\n\n## Purpose\n\nTo apply consistent, professional styling to presentation slide decks, use this skill. Each theme includes:\n- A cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- A distinct visual identity suitable for different contexts and audiences\n\n## Usage Instructions\n\nTo apply styling to a slide deck or other artifact:\n\n1. **Show the theme showcase**: Display the `theme-showcase.pdf` file to allow users to see all available themes visually. Do not make any modifications to it; simply show the file for viewing.\n2. **Ask for their choice**: Ask which theme to apply to the deck\n3. **Wait for selection**: Get explicit confirmation about the chosen theme\n4. **Apply the theme**: Once a theme has been chosen, apply the selected theme's colors and fonts to the deck/artifact\n\n## Themes Available\n\nThe following 10 themes are available, each showcased in `theme-showcase.pdf`:\n\n1. **Ocean Depths** - Professional and calming maritime theme\n2. **Sunset Boulevard** - Warm and vibrant sunset colors\n3. **Forest Canopy** - Natural and grounded earth tones\n4. **Modern Minimalist** - Clean and contemporary grayscale\n5. **Golden Hour** - Rich and warm autumnal palette\n6. **Arctic Frost** - Cool and crisp winter-inspired theme\n7. **Desert Rose** - Soft and sophisticated dusty tones\n8. **Tech Innovation** - Bold and modern tech aesthetic\n9. **Botanical Garden** - Fresh and organic garden colors\n10. **Midnight Galaxy** - Dramatic and cosmic deep tones\n\n## Theme Details\n\nEach theme is defined in the `themes/` directory with complete specifications including:\n- Cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- Distinct visual identity suitable for different contexts and audiences\n\n## Application Process\n\nAfter a preferred theme is selected:\n1. Read the corresponding theme file from the `themes/` directory\n2. Apply the specified colors and fonts consistently throughout the deck\n3. Ensure proper contrast and readability\n4. Maintain the theme's visual identity across all slides\n\n## Create your Own Theme\nTo handle cases where none of the existing themes work for an artifact, create a custom theme. Based on provided inputs, generate a new theme similar to the ones above. Give the theme a similar name describing what the font/color combinations represent. Use any basic description provided to choose appropriate colors/fonts. After generating the theme, show it for review and verification. Following that, apply the theme as described above.",
    "id": "theme-factory",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/theme-factory",
    "name_zh": "‰∏ªÈ¢òÂ∑•ÂéÇ",
    "description_zh": "Toolkit for styling artifacts with a theme. These artifacts can be slides, docs, reportings, HTML landing pages, etc. There are 10 pre-set themes with colors/fonts that you can apply to any artifact that has been creating, or can generate a new theme on-the-fly.",
    "body_zh": "# Theme Factory Skill\n\nThis skill provides a curated collection of professional font and color themes themes, each with carefully selected color palettes and font pairings. Once a theme is chosen, it can be applied to any artifact.\n\n## Purpose\n\nTo apply consistent, professional styling to presentation slide decks, use this skill. Each theme includes:\n- A cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- A distinct visual identity suitable for different contexts and audiences\n\n## Usage Instructions\n\nTo apply styling to a slide deck or other artifact:\n\n1. **Show the theme showcase**: Display the `theme-showcase.pdf` file to allow users to see all available themes visually. Do not make any modifications to it; simply show the file for viewing.\n2. **Ask for their choice**: Ask which theme to apply to the deck\n3. **Wait for selection**: Get explicit confirmation about the chosen theme\n4. **Apply the theme**: Once a theme has been chosen, apply the selected theme's colors and fonts to the deck/artifact\n\n## Themes Available\n\nThe following 10 themes are available, each showcased in `theme-showcase.pdf`:\n\n1. **Ocean Depths** - Professional and calming maritime theme\n2. **Sunset Boulevard** - Warm and vibrant sunset colors\n3. **Forest Canopy** - Natural and grounded earth tones\n4. **Modern Minimalist** - Clean and contemporary grayscale\n5. **Golden Hour** - Rich and warm autumnal palette\n6. **Arctic Frost** - Cool and crisp winter-inspired theme\n7. **Desert Rose** - Soft and sophisticated dusty tones\n8. **Tech Innovation** - Bold and modern tech aesthetic\n9. **Botanical Garden** - Fresh and organic garden colors\n10. **Midnight Galaxy** - Dramatic and cosmic deep tones\n\n## Theme Details\n\nEach theme is defined in the `themes/` directory with complete specifications including:\n- Cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- Distinct visual identity suitable for different contexts and audiences\n\n## Application Process\n\nAfter a preferred theme is selected:\n1. Read the corresponding theme file from the `themes/` directory\n2. Apply the specified colors and fonts consistently throughout the deck\n3. Ensure proper contrast and readability\n4. Maintain the theme's visual identity across all slides\n\n## Create your Own Theme\nTo handle cases where none of the existing themes work for an artifact, create a custom theme. Based on provided inputs, generate a new theme similar to the ones above. Give the theme a similar name describing what the font/color combinations represent. Use any basic description provided to choose appropriate colors/fonts. After generating the theme, show it for review and verification. Following that, apply the theme as described above."
  },
  {
    "name": "upgrading-expo",
    "description": "Guidelines for upgrading Expo SDK versions and fixing dependency issues.",
    "body": "# Upgrading Expo\n\nGuidelines for upgrading Expo SDK versions and fixing dependency issues.\n\n## When to Use\n\n- Upgrading Expo SDK versions\n- Fixing dependency conflicts\n- Migration patterns\n- Breaking change handling\n\n## Source\n\nThis skill references patterns from [Expo's skills](https://github.com/expo/skills).",
    "id": "upgrading-expo",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/upgrading-expo",
    "name_zh": "ÂçáÁ∫ß Expo",
    "description_zh": "Guidelines for upgrading Expo SDK versions and fixing dependency issues.",
    "body_zh": "# Upgrading Expo\n\nGuidelines for upgrading Expo SDK versions and fixing dependency issues.\n\n## When to Use\n\n- Upgrading Expo SDK versions\n- Fixing dependency conflicts\n- Migration patterns\n- Breaking change handling\n\n## Source\n\nThis skill references patterns from [Expo's skills](https://github.com/expo/skills)."
  },
  {
    "name": "vercel-deploy",
    "description": "Deploy applications to Vercel with edge functions, serverless, and ISR.",
    "body": "# Vercel Deploy\n\nDeploy applications to Vercel with edge functions, serverless, and ISR.\n\n## When to Use\n\n- Deploying Next.js applications\n- Setting up edge functions\n- Configuring ISR (Incremental Static Regeneration)\n- Serverless deployments\n\n## Source\n\nThis skill references patterns from [Vercel's agent-skills](https://github.com/vercel-labs/agent-skills).",
    "id": "vercel-deploy",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/vercel-deploy",
    "name_zh": "Vercel ÈÉ®ÁΩ≤",
    "description_zh": "Deploy applications to Vercel with edge functions, serverless, and ISR.",
    "body_zh": "# Vercel Deploy\n\nDeploy applications to Vercel with edge functions, serverless, and ISR.\n\n## When to Use\n\n- Deploying Next.js applications\n- Setting up edge functions\n- Configuring ISR (Incremental Static Regeneration)\n- Serverless deployments\n\n## Source\n\nThis skill references patterns from [Vercel's agent-skills](https://github.com/vercel-labs/agent-skills)."
  },
  {
    "name": "video-downloader",
    "description": "Downloads videos from YouTube and other platforms for offline viewing, editing, or archival. Handles various formats and quality options.",
    "body": "# Video Downloader\n\nThis skill downloads videos from YouTube and other platforms directly to your computer.\n\n## When to Use This Skill\n\n- Downloading YouTube videos for offline viewing\n- Saving educational content for reference\n- Archiving important videos\n- Getting video files for editing or repurposing\n- Downloading your own content from platforms\n- Saving conference talks or webinars\n\n## What This Skill Does\n\n1. **Downloads Videos**: Fetches videos from YouTube and other platforms\n2. **Quality Selection**: Lets you choose resolution (480p, 720p, 1080p, 4K)\n3. **Format Options**: Downloads in various formats (MP4, WebM, audio-only)\n4. **Batch Downloads**: Can download multiple videos or playlists\n5. **Metadata Preservation**: Saves title, description, and thumbnail\n\n## How to Use\n\n### Basic Download\n\n```\nDownload this YouTube video: https://youtube.com/watch?v=...\n```\n\n```\nDownload this video in 1080p quality\n```\n\n### Audio Only\n\n```\nDownload the audio from this YouTube video as MP3\n```\n\n### Playlist Download\n\n```\nDownload all videos from this YouTube playlist: [URL]\n```\n\n### Batch Download\n\n```\nDownload these 5 YouTube videos:\n1. [URL]\n2. [URL]\n...\n```\n\n## Example\n\n**User**: \"Download this YouTube video: https://youtube.com/watch?v=abc123\"\n\n**Output**:\n```\nDownloading from YouTube...\n\nVideo: \"How to Build Products Users Love\"\nChannel: Lenny's Podcast\nDuration: 45:32\nQuality: 1080p\n\nProgress: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%\n\n‚úì Downloaded: how-to-build-products-users-love.mp4\n‚úì Saved thumbnail: how-to-build-products-users-love.jpg\n‚úì Size: 342 MB\n\nSaved to: ~/Downloads/\n```\n\n**Inspired by:** Lenny's workflow from his newsletter\n\n## Important Notes\n\n‚ö†Ô∏è **Copyright & Fair Use**\n- Only download videos you have permission to download\n- Respect copyright laws and platform terms of service\n- Use for personal, educational, or fair use purposes\n- Don't redistribute copyrighted content\n\n## Tips\n\n- Specify quality if you need lower file size (720p vs 1080p)\n- Use audio-only for podcasts or music to save space\n- Download to a dedicated folder to stay organized\n- Check file size before downloading on slow connections\n\n## Common Use Cases\n\n- **Education**: Save tutorials and courses for offline learning\n- **Research**: Archive videos for reference\n- **Content Creation**: Download your own content from platforms\n- **Backup**: Save important videos before they're removed\n- **Offline Viewing**: Watch videos without internet access",
    "id": "video-downloader",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/video-downloader",
    "name_zh": "ËßÜÈ¢ë‰∏ãËΩΩÂô®",
    "description_zh": "Downloads videos from YouTube and other platforms for offline viewing, editing, or archival. Handles various formats and quality options.",
    "body_zh": "# Video Downloader\n\nThis skill downloads videos from YouTube and other platforms directly to your computer.\n\n## When to Use This Skill\n\n- Downloading YouTube videos for offline viewing\n- Saving educational content for reference\n- Archiving important videos\n- Getting video files for editing or repurposing\n- Downloading your own content from platforms\n- Saving conference talks or webinars\n\n## What This Skill Does\n\n1. **Downloads Videos**: Fetches videos from YouTube and other platforms\n2. **Quality Selection**: Lets you choose resolution (480p, 720p, 1080p, 4K)\n3. **Format Options**: Downloads in various formats (MP4, WebM, audio-only)\n4. **Batch Downloads**: Can download multiple videos or playlists\n5. **Metadata Preservation**: Saves title, description, and thumbnail\n\n## How to Use\n\n### Basic Download\n\n```\nDownload this YouTube video: https://youtube.com/watch?v=...\n```\n\n```\nDownload this video in 1080p quality\n```\n\n### Audio Only\n\n```\nDownload the audio from this YouTube video as MP3\n```\n\n### Playlist Download\n\n```\nDownload all videos from this YouTube playlist: [URL]\n```\n\n### Batch Download\n\n```\nDownload these 5 YouTube videos:\n1. [URL]\n2. [URL]\n...\n```\n\n## Example\n\n**User**: \"Download this YouTube video: https://youtube.com/watch?v=abc123\"\n\n**Output**:\n```\nDownloading from YouTube...\n\nVideo: \"How to Build Products Users Love\"\nChannel: Lenny's Podcast\nDuration: 45:32\nQuality: 1080p\n\nProgress: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%\n\n‚úì Downloaded: how-to-build-products-users-love.mp4\n‚úì Saved thumbnail: how-to-build-products-users-love.jpg\n‚úì Size: 342 MB\n\nSaved to: ~/Downloads/\n```\n\n**Inspired by:** Lenny's workflow from his newsletter\n\n## Important Notes\n\n‚ö†Ô∏è **Copyright & Fair Use**\n- Only download videos you have permission to download\n- Respect copyright laws and platform terms of service\n- Use for personal, educational, or fair use purposes\n- Don't redistribute copyrighted content\n\n## Tips\n\n- Specify quality if you need lower file size (720p vs 1080p)\n- Use audio-only for podcasts or music to save space\n- Download to a dedicated folder to stay organized\n- Check file size before downloading on slow connections\n\n## Common Use Cases\n\n- **Education**: Save tutorials and courses for offline learning\n- **Research**: Archive videos for reference\n- **Content Creation**: Download your own content from platforms\n- **Backup**: Save important videos before they're removed\n- **Offline Viewing**: Watch videos without internet access"
  },
  {
    "name": "web-design-guidelines",
    "description": "Modern web design principles for responsive layouts, accessibility, and visual hierarchy.",
    "body": "# Web Design Guidelines\n\nModern web design principles for responsive layouts, accessibility, and visual hierarchy.\n\n## When to Use\n\n- Creating polished web interfaces\n- Improving accessibility\n- Responsive design patterns\n- Visual hierarchy decisions\n\n## Source\n\nThis skill references patterns from [Vercel's agent-skills](https://github.com/vercel-labs/agent-skills).",
    "id": "web-design-guidelines",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/web-design-guidelines",
    "name_zh": "ÁΩëÈ°µËÆæËÆ°ÊåáÂçó",
    "description_zh": "Modern web design principles for responsive layouts, accessibility, and visual hierarchy.",
    "body_zh": "# Web Design Guidelines\n\nModern web design principles for responsive layouts, accessibility, and visual hierarchy.\n\n## When to Use\n\n- Creating polished web interfaces\n- Improving accessibility\n- Responsive design patterns\n- Visual hierarchy decisions\n\n## Source\n\nThis skill references patterns from [Vercel's agent-skills](https://github.com/vercel-labs/agent-skills)."
  },
  {
    "name": "webapp-testing",
    "description": "Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs.",
    "body": "# Web App Testing with Playwright\n\n## Setup\n\n```bash\nnpm init playwright@latest\n```\n\n## Basic Test Structure\n\n```typescript\nimport { test, expect } from '@playwright/test';\n\ntest('homepage has title', async ({ page }) => {\n  await page.goto('http://localhost:3000');\n  await expect(page).toHaveTitle(/My App/);\n});\n\ntest('can navigate to about page', async ({ page }) => {\n  await page.goto('http://localhost:3000');\n  await page.click('text=About');\n  await expect(page).toHaveURL(/.*about/);\n});\n```\n\n## Common Actions\n\n### Navigation\n```typescript\nawait page.goto('http://localhost:3000');\nawait page.goBack();\nawait page.reload();\n```\n\n### Clicking\n```typescript\nawait page.click('button');\nawait page.click('text=Submit');\nawait page.click('#submit-btn');\nawait page.click('[data-testid=\"submit\"]');\n```\n\n### Form Input\n```typescript\nawait page.fill('input[name=\"email\"]', 'test@example.com');\nawait page.fill('#password', 'secret123');\nawait page.selectOption('select#country', 'USA');\nawait page.check('input[type=\"checkbox\"]');\n```\n\n### Waiting\n```typescript\nawait page.waitForSelector('.loaded');\nawait page.waitForURL('**/dashboard');\nawait page.waitForResponse('**/api/data');\nawait page.waitForTimeout(1000); // Avoid if possible\n```\n\n## Assertions\n\n```typescript\nawait expect(page.locator('h1')).toHaveText('Welcome');\nawait expect(page.locator('.items')).toHaveCount(5);\nawait expect(page.locator('button')).toBeEnabled();\nawait expect(page.locator('.modal')).toBeVisible();\nawait expect(page.locator('input')).toHaveValue('test');\n```\n\n## Screenshots\n\n```typescript\n// Full page\nawait page.screenshot({ path: 'screenshot.png', fullPage: true });\n\n// Element only\nawait page.locator('.chart').screenshot({ path: 'chart.png' });\n```\n\n## Console Logs\n\n```typescript\npage.on('console', msg => console.log(msg.text()));\npage.on('pageerror', err => console.error(err.message));\n```\n\n## Network Interception\n\n```typescript\nawait page.route('**/api/data', route => {\n  route.fulfill({\n    status: 200,\n    body: JSON.stringify({ items: [] })\n  });\n});\n```\n\n## Running Tests\n\n```bash\n# Run all tests\nnpx playwright test\n\n# Run specific file\nnpx playwright test tests/login.spec.ts\n\n# Run in headed mode\nnpx playwright test --headed\n\n# Run with UI\nnpx playwright test --ui\n```",
    "id": "webapp-testing",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/webapp-testing",
    "name_zh": "Web Â∫îÁî®ÊµãËØï",
    "description_zh": "Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs.",
    "body_zh": "# Web App Testing with Playwright\n\n## Setup\n\n```bash\nnpm init playwright@latest\n```\n\n## Basic Test Structure\n\n```typescript\nimport { test, expect } from '@playwright/test';\n\ntest('homepage has title', async ({ page }) => {\n  await page.goto('http://localhost:3000');\n  await expect(page).toHaveTitle(/My App/);\n});\n\ntest('can navigate to about page', async ({ page }) => {\n  await page.goto('http://localhost:3000');\n  await page.click('text=About');\n  await expect(page).toHaveURL(/.*about/);\n});\n```\n\n## Common Actions\n\n### Navigation\n```typescript\nawait page.goto('http://localhost:3000');\nawait page.goBack();\nawait page.reload();\n```\n\n### Clicking\n```typescript\nawait page.click('button');\nawait page.click('text=Submit');\nawait page.click('#submit-btn');\nawait page.click('[data-testid=\"submit\"]');\n```\n\n### Form Input\n```typescript\nawait page.fill('input[name=\"email\"]', 'test@example.com');\nawait page.fill('#password', 'secret123');\nawait page.selectOption('select#country', 'USA');\nawait page.check('input[type=\"checkbox\"]');\n```\n\n### Waiting\n```typescript\nawait page.waitForSelector('.loaded');\nawait page.waitForURL('**/dashboard');\nawait page.waitForResponse('**/api/data');\nawait page.waitForTimeout(1000); // Avoid if possible\n```\n\n## Assertions\n\n```typescript\nawait expect(page.locator('h1')).toHaveText('Welcome');\nawait expect(page.locator('.items')).toHaveCount(5);\nawait expect(page.locator('button')).toBeEnabled();\nawait expect(page.locator('.modal')).toBeVisible();\nawait expect(page.locator('input')).toHaveValue('test');\n```\n\n## Screenshots\n\n```typescript\n// Full page\nawait page.screenshot({ path: 'screenshot.png', fullPage: true });\n\n// Element only\nawait page.locator('.chart').screenshot({ path: 'chart.png' });\n```\n\n## Console Logs\n\n```typescript\npage.on('console', msg => console.log(msg.text()));\npage.on('pageerror', err => console.error(err.message));\n```\n\n## Network Interception\n\n```typescript\nawait page.route('**/api/data', route => {\n  route.fulfill({\n    status: 200,\n    body: JSON.stringify({ items: [] })\n  });\n});\n```\n\n## Running Tests\n\n```bash\n# Run all tests\nnpx playwright test\n\n# Run specific file\nnpx playwright test tests/login.spec.ts\n\n# Run in headed mode\nnpx playwright test --headed\n\n# Run with UI\nnpx playwright test --ui\n```"
  },
  {
    "name": "xlsx",
    "description": "Comprehensive spreadsheet creation, editing, and analysis with support for formulas, formatting, data analysis, and visualization. When Claude needs to work with spreadsheets (.xlsx, .xlsm, .csv, .tsv, etc) for creating new spreadsheets, reading/analyzing data, modifying existing spreadsheets, or recalculating formulas.",
    "body": "# Excel/Spreadsheet Processing\n\n## Reading and Analyzing Data\n\n```python\nimport pandas as pd\n\n# Read Excel\ndf = pd.read_excel('file.xlsx')  # Default: first sheet\nall_sheets = pd.read_excel('file.xlsx', sheet_name=None)  # All sheets as dict\n\n# Analyze\ndf.head()      # Preview data\ndf.info()      # Column info\ndf.describe()  # Statistics\n\n# Write Excel\ndf.to_excel('output.xlsx', index=False)\n```\n\n## Creating Excel Files with openpyxl\n\n```python\nfrom openpyxl import Workbook\nfrom openpyxl.styles import Font, PatternFill, Alignment\n\nwb = Workbook()\nsheet = wb.active\n\n# Add data\nsheet['A1'] = 'Hello'\nsheet['B1'] = 'World'\nsheet.append(['Row', 'of', 'data'])\n\n# Add formula - ALWAYS use formulas, not hardcoded values\nsheet['B2'] = '=SUM(A1:A10)'\n\n# Formatting\nsheet['A1'].font = Font(bold=True, color='FF0000')\nsheet['A1'].fill = PatternFill('solid', start_color='FFFF00')\nsheet['A1'].alignment = Alignment(horizontal='center')\n\n# Column width\nsheet.column_dimensions['A'].width = 20\n\nwb.save('output.xlsx')\n```\n\n## Editing Existing Files\n\n```python\nfrom openpyxl import load_workbook\n\nwb = load_workbook('existing.xlsx')\nsheet = wb.active\n\n# Modify cells\nsheet['A1'] = 'New Value'\nsheet.insert_rows(2)\nsheet.delete_cols(3)\n\n# Add new sheet\nnew_sheet = wb.create_sheet('NewSheet')\nnew_sheet['A1'] = 'Data'\n\nwb.save('modified.xlsx')\n```\n\n## Critical: Use Formulas, Not Hardcoded Values\n\n```python\n# BAD - Hardcoding calculated values\ntotal = df['Sales'].sum()\nsheet['B10'] = total  # Hardcodes 5000\n\n# GOOD - Using Excel formulas\nsheet['B10'] = '=SUM(B2:B9)'\nsheet['C5'] = '=(C4-C2)/C2'  # Growth rate\nsheet['D20'] = '=AVERAGE(D2:D19)'\n```\n\n## Financial Model Standards\n\n- **Blue text**: Hardcoded inputs\n- **Black text**: ALL formulas\n- **Green text**: Links from other worksheets\n- **Yellow background**: Key assumptions\n\n## Best Practices\n\n- Use `data_only=True` to read calculated values\n- For large files: Use `read_only=True` or `write_only=True`\n- Formulas are preserved but not evaluated by openpyxl",
    "id": "xlsx",
    "source": "Ai-Agent-Skills",
    "html_url": "https://github.com/skillcreatorai/Ai-Agent-Skills/tree/main/skills/xlsx",
    "name_zh": "Excel Â§ÑÁêÜ",
    "description_zh": "Comprehensive spreadsheet creation, editing, and analysis with support for formulas, formatting, data analysis, and visualization. When Claude needs to work with spreadsheets (.xlsx, .xlsm, .csv, .tsv, etc) for creating new spreadsheets, reading/analyzing data, modifying existing spreadsheets, or recalculating formulas.",
    "body_zh": "# Excel/Spreadsheet Processing\n\n## Reading and Analyzing Data\n\n```python\nimport pandas as pd\n\n# Read Excel\ndf = pd.read_excel('file.xlsx')  # Default: first sheet\nall_sheets = pd.read_excel('file.xlsx', sheet_name=None)  # All sheets as dict\n\n# Analyze\ndf.head()      # Preview data\ndf.info()      # Column info\ndf.describe()  # Statistics\n\n# Write Excel\ndf.to_excel('output.xlsx', index=False)\n```\n\n## Creating Excel Files with openpyxl\n\n```python\nfrom openpyxl import Workbook\nfrom openpyxl.styles import Font, PatternFill, Alignment\n\nwb = Workbook()\nsheet = wb.active\n\n# Add data\nsheet['A1'] = 'Hello'\nsheet['B1'] = 'World'\nsheet.append(['Row', 'of', 'data'])\n\n# Add formula - ALWAYS use formulas, not hardcoded values\nsheet['B2'] = '=SUM(A1:A10)'\n\n# Formatting\nsheet['A1'].font = Font(bold=True, color='FF0000')\nsheet['A1'].fill = PatternFill('solid', start_color='FFFF00')\nsheet['A1'].alignment = Alignment(horizontal='center')\n\n# Column width\nsheet.column_dimensions['A'].width = 20\n\nwb.save('output.xlsx')\n```\n\n## Editing Existing Files\n\n```python\nfrom openpyxl import load_workbook\n\nwb = load_workbook('existing.xlsx')\nsheet = wb.active\n\n# Modify cells\nsheet['A1'] = 'New Value'\nsheet.insert_rows(2)\nsheet.delete_cols(3)\n\n# Add new sheet\nnew_sheet = wb.create_sheet('NewSheet')\nnew_sheet['A1'] = 'Data'\n\nwb.save('modified.xlsx')\n```\n\n## Critical: Use Formulas, Not Hardcoded Values\n\n```python\n# BAD - Hardcoding calculated values\ntotal = df['Sales'].sum()\nsheet['B10'] = total  # Hardcodes 5000\n\n# GOOD - Using Excel formulas\nsheet['B10'] = '=SUM(B2:B9)'\nsheet['C5'] = '=(C4-C2)/C2'  # Growth rate\nsheet['D20'] = '=AVERAGE(D2:D19)'\n```\n\n## Financial Model Standards\n\n- **Blue text**: Hardcoded inputs\n- **Black text**: ALL formulas\n- **Green text**: Links from other worksheets\n- **Yellow background**: Key assumptions\n\n## Best Practices\n\n- Use `data_only=True` to read calculated values\n- For large files: Use `read_only=True` or `write_only=True`\n- Formulas are preserved but not evaluated by openpyxl"
  },
  {
    "name": "algorithmic-art",
    "description": "Creating algorithmic art using p5.js with seeded randomness and interactive parameter exploration. Use this when users request creating art using code, generative art, algorithmic art, flow fields, or particle systems. Create original algorithmic art rather than copying existing artists' work to avoid copyright violations.",
    "body": "Algorithmic philosophies are computational aesthetic movements that are then expressed through code. Output .md files (philosophy), .html files (interactive viewer), and .js files (generative algorithms).\n\nThis happens in two steps:\n1. Algorithmic Philosophy Creation (.md file)\n2. Express by creating p5.js generative art (.html + .js files)\n\nFirst, undertake this task:\n\n## ALGORITHMIC PHILOSOPHY CREATION\n\nTo begin, create an ALGORITHMIC PHILOSOPHY (not static images or templates) that will be interpreted through:\n- Computational processes, emergent behavior, mathematical beauty\n- Seeded randomness, noise fields, organic systems\n- Particles, flows, fields, forces\n- Parametric variation and controlled chaos\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user to take into account, but use as a foundation; it should not constrain creative freedom.\n- What is created: An algorithmic philosophy/generative aesthetic movement.\n- What happens next: The same version receives the philosophy and EXPRESSES IT IN CODE - creating p5.js sketches that are 90% algorithmic generation, 10% essential parameters.\n\nConsider this approach:\n- Write a manifesto for a generative art movement\n- The next phase involves writing the algorithm that brings it to life\n\nThe philosophy must emphasize: Algorithmic expression. Emergent behavior. Computational beauty. Seeded variation.\n\n### HOW TO GENERATE AN ALGORITHMIC PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Organic Turbulence\" / \"Quantum Harmonics\" / \"Emergent Stillness\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the ALGORITHMIC essence, express how this philosophy manifests through:\n- Computational processes and mathematical relationships?\n- Noise functions and randomness patterns?\n- Particle behaviors and field dynamics?\n- Temporal evolution and system states?\n- Parametric variation and emergent complexity?\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each algorithmic aspect should be mentioned once. Avoid repeating concepts about noise theory, particle dynamics, or mathematical principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final algorithm should appear as though it took countless hours to develop, was refined with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted algorithm,\" \"the product of deep computational expertise,\" \"painstaking optimization,\" \"master-level implementation.\"\n- **Leave creative space**: Be specific about the algorithmic direction, but concise enough that the next Claude has room to make interpretive implementation choices at an extremely high level of craftsmanship.\n\nThe philosophy must guide the next version to express ideas ALGORITHMICALLY, not through static images. Beauty lives in the process, not the final frame.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Organic Turbulence\"**\nPhilosophy: Chaos constrained by natural law, order emerging from disorder.\nAlgorithmic expression: Flow fields driven by layered Perlin noise. Thousands of particles following vector forces, their trails accumulating into organic density maps. Multiple noise octaves create turbulent regions and calm zones. Color emerges from velocity and density - fast particles burn bright, slow ones fade to shadow. The algorithm runs until equilibrium - a meticulously tuned balance where every parameter was refined through countless iterations by a master of computational aesthetics.\n\n**\"Quantum Harmonics\"**\nPhilosophy: Discrete entities exhibiting wave-like interference patterns.\nAlgorithmic expression: Particles initialized on a grid, each carrying a phase value that evolves through sine waves. When particles are near, their phases interfere - constructive interference creates bright nodes, destructive creates voids. Simple harmonic motion generates complex emergent mandalas. The result of painstaking frequency calibration where every ratio was carefully chosen to produce resonant beauty.\n\n**\"Recursive Whispers\"**\nPhilosophy: Self-similarity across scales, infinite depth in finite space.\nAlgorithmic expression: Branching structures that subdivide recursively. Each branch slightly randomized but constrained by golden ratios. L-systems or recursive subdivision generate tree-like forms that feel both mathematical and organic. Subtle noise perturbations break perfect symmetry. Line weights diminish with each recursion level. Every branching angle the product of deep mathematical exploration.\n\n**\"Field Dynamics\"**\nPhilosophy: Invisible forces made visible through their effects on matter.\nAlgorithmic expression: Vector fields constructed from mathematical functions or noise. Particles born at edges, flowing along field lines, dying when they reach equilibrium or boundaries. Multiple fields can attract, repel, or rotate particles. The visualization shows only the traces - ghost-like evidence of invisible forces. A computational dance meticulously choreographed through force balance.\n\n**\"Stochastic Crystallization\"**\nPhilosophy: Random processes crystallizing into ordered structures.\nAlgorithmic expression: Randomized circle packing or Voronoi tessellation. Start with random points, let them evolve through relaxation algorithms. Cells push apart until equilibrium. Color based on cell size, neighbor count, or distance from center. The organic tiling that emerges feels both random and inevitable. Every seed produces unique crystalline beauty - the mark of a master-level generative algorithm.\n\n*These are condensed examples. The actual algorithmic philosophy should be 4-6 substantial paragraphs.*\n\n### ESSENTIAL PRINCIPLES\n- **ALGORITHMIC PHILOSOPHY**: Creating a computational worldview to be expressed through code\n- **PROCESS OVER PRODUCT**: Always emphasize that beauty emerges from the algorithm's execution - each run is unique\n- **PARAMETRIC EXPRESSION**: Ideas communicate through mathematical relationships, forces, behaviors - not static composition\n- **ARTISTIC FREEDOM**: The next Claude interprets the philosophy algorithmically - provide creative implementation room\n- **PURE GENERATIVE ART**: This is about making LIVING ALGORITHMS, not static images with randomness\n- **EXPERT CRAFTSMANSHIP**: Repeatedly emphasize the final algorithm must feel meticulously crafted, refined through countless iterations, the product of deep expertise by someone at the absolute top of their field in computational aesthetics\n\n**The algorithmic philosophy should be 4-6 paragraphs long.** Fill it with poetic computational philosophy that brings together the intended vision. Avoid repeating the same points. Output this algorithmic philosophy as a .md file.\n\n---\n\n## DEDUCING THE CONCEPTUAL SEED\n\n**CRITICAL STEP**: Before implementing the algorithm, identify the subtle conceptual thread from the original request.\n\n**THE ESSENTIAL PRINCIPLE**:\nThe concept is a **subtle, niche reference embedded within the algorithm itself** - not always literal, always sophisticated. Someone familiar with the subject should feel it intuitively, while others simply experience a masterful generative composition. The algorithmic philosophy provides the computational language. The deduced concept provides the soul - the quiet conceptual DNA woven invisibly into parameters, behaviors, and emergence patterns.\n\nThis is **VERY IMPORTANT**: The reference must be so refined that it enhances the work's depth without announcing itself. Think like a jazz musician quoting another song through algorithmic harmony - only those who know will catch it, but everyone appreciates the generative beauty.\n\n---\n\n## P5.JS IMPLEMENTATION\n\nWith the philosophy AND conceptual framework established, express it through code. Pause to gather thoughts before proceeding. Use only the algorithmic philosophy created and the instructions below.\n\n### ‚ö†Ô∏è STEP 0: READ THE TEMPLATE FIRST ‚ö†Ô∏è\n\n**CRITICAL: BEFORE writing any HTML:**\n\n1. **Read** `templates/viewer.html` using the Read tool\n2. **Study** the exact structure, styling, and Anthropic branding\n3. **Use that file as the LITERAL STARTING POINT** - not just inspiration\n4. **Keep all FIXED sections exactly as shown** (header, sidebar structure, Anthropic colors/fonts, seed controls, action buttons)\n5. **Replace only the VARIABLE sections** marked in the file's comments (algorithm, parameters, UI controls for parameters)\n\n**Avoid:**\n- ‚ùå Creating HTML from scratch\n- ‚ùå Inventing custom styling or color schemes\n- ‚ùå Using system fonts or dark themes\n- ‚ùå Changing the sidebar structure\n\n**Follow these practices:**\n- ‚úÖ Copy the template's exact HTML structure\n- ‚úÖ Keep Anthropic branding (Poppins/Lora fonts, light colors, gradient backdrop)\n- ‚úÖ Maintain the sidebar layout (Seed ‚Üí Parameters ‚Üí Colors? ‚Üí Actions)\n- ‚úÖ Replace only the p5.js algorithm and parameter controls\n\nThe template is the foundation. Build on it, don't rebuild it.\n\n---\n\nTo create gallery-quality computational art that lives and breathes, use the algorithmic philosophy as the foundation.\n\n### TECHNICAL REQUIREMENTS\n\n**Seeded Randomness (Art Blocks Pattern)**:\n```javascript\n// ALWAYS use a seed for reproducibility\nlet seed = 12345; // or hash from user input\nrandomSeed(seed);\nnoiseSeed(seed);\n```\n\n**Parameter Structure - FOLLOW THE PHILOSOPHY**:\n\nTo establish parameters that emerge naturally from the algorithmic philosophy, consider: \"What qualities of this system can be adjusted?\"\n\n```javascript\nlet params = {\n  seed: 12345,  // Always include seed for reproducibility\n  // colors\n  // Add parameters that control YOUR algorithm:\n  // - Quantities (how many?)\n  // - Scales (how big? how fast?)\n  // - Probabilities (how likely?)\n  // - Ratios (what proportions?)\n  // - Angles (what direction?)\n  // - Thresholds (when does behavior change?)\n};\n```\n\n**To design effective parameters, focus on the properties the system needs to be tunable rather than thinking in terms of \"pattern types\".**\n\n**Core Algorithm - EXPRESS THE PHILOSOPHY**:\n\n**CRITICAL**: The algorithmic philosophy should dictate what to build.\n\nTo express the philosophy through code, avoid thinking \"which pattern should I use?\" and instead think \"how to express this philosophy through code?\"\n\nIf the philosophy is about **organic emergence**, consider using:\n- Elements that accumulate or grow over time\n- Random processes constrained by natural rules\n- Feedback loops and interactions\n\nIf the philosophy is about **mathematical beauty**, consider using:\n- Geometric relationships and ratios\n- Trigonometric functions and harmonics\n- Precise calculations creating unexpected patterns\n\nIf the philosophy is about **controlled chaos**, consider using:\n- Random variation within strict boundaries\n- Bifurcation and phase transitions\n- Order emerging from disorder\n\n**The algorithm flows from the philosophy, not from a menu of options.**\n\nTo guide the implementation, let the conceptual essence inform creative and original choices. Build something that expresses the vision for this particular request.\n\n**Canvas Setup**: Standard p5.js structure:\n```javascript\nfunction setup() {\n  createCanvas(1200, 1200);\n  // Initialize your system\n}\n\nfunction draw() {\n  // Your generative algorithm\n  // Can be static (noLoop) or animated\n}\n```\n\n### CRAFTSMANSHIP REQUIREMENTS\n\n**CRITICAL**: To achieve mastery, create algorithms that feel like they emerged through countless iterations by a master generative artist. Tune every parameter carefully. Ensure every pattern emerges with purpose. This is NOT random noise - this is CONTROLLED CHAOS refined through deep expertise.\n\n- **Balance**: Complexity without visual noise, order without rigidity\n- **Color Harmony**: Thoughtful palettes, not random RGB values\n- **Composition**: Even in randomness, maintain visual hierarchy and flow\n- **Performance**: Smooth execution, optimized for real-time if animated\n- **Reproducibility**: Same seed ALWAYS produces identical output\n\n### OUTPUT FORMAT\n\nOutput:\n1. **Algorithmic Philosophy** - As markdown or text explaining the generative aesthetic\n2. **Single HTML Artifact** - Self-contained interactive generative art built from `templates/viewer.html` (see STEP 0 and next section)\n\nThe HTML artifact contains everything: p5.js (from CDN), the algorithm, parameter controls, and UI - all in one file that works immediately in claude.ai artifacts or any browser. Start from the template file, not from scratch.\n\n---\n\n## INTERACTIVE ARTIFACT CREATION\n\n**REMINDER: `templates/viewer.html` should have already been read (see STEP 0). Use that file as the starting point.**\n\nTo allow exploration of the generative art, create a single, self-contained HTML artifact. Ensure this artifact works immediately in claude.ai or any browser - no setup required. Embed everything inline.\n\n### CRITICAL: WHAT'S FIXED VS VARIABLE\n\nThe `templates/viewer.html` file is the foundation. It contains the exact structure and styling needed.\n\n**FIXED (always include exactly as shown):**\n- Layout structure (header, sidebar, main canvas area)\n- Anthropic branding (UI colors, fonts, gradients)\n- Seed section in sidebar:\n  - Seed display\n  - Previous/Next buttons\n  - Random button\n  - Jump to seed input + Go button\n- Actions section in sidebar:\n  - Regenerate button\n  - Reset button\n\n**VARIABLE (customize for each artwork):**\n- The entire p5.js algorithm (setup/draw/classes)\n- The parameters object (define what the art needs)\n- The Parameters section in sidebar:\n  - Number of parameter controls\n  - Parameter names\n  - Min/max/step values for sliders\n  - Control types (sliders, inputs, etc.)\n- Colors section (optional):\n  - Some art needs color pickers\n  - Some art might use fixed colors\n  - Some art might be monochrome (no color controls needed)\n  - Decide based on the art's needs\n\n**Every artwork should have unique parameters and algorithm!** The fixed parts provide consistent UX - everything else expresses the unique vision.\n\n### REQUIRED FEATURES\n\n**1. Parameter Controls**\n- Sliders for numeric parameters (particle count, noise scale, speed, etc.)\n- Color pickers for palette colors\n- Real-time updates when parameters change\n- Reset button to restore defaults\n\n**2. Seed Navigation**\n- Display current seed number\n- \"Previous\" and \"Next\" buttons to cycle through seeds\n- \"Random\" button for random seed\n- Input field to jump to specific seed\n- Generate 100 variations when requested (seeds 1-100)\n\n**3. Single Artifact Structure**\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <!-- p5.js from CDN - always available -->\n  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.7.0/p5.min.js\"></script>\n  <style>\n    /* All styling inline - clean, minimal */\n    /* Canvas on top, controls below */\n  </style>\n</head>\n<body>\n  <div id=\"canvas-container\"></div>\n  <div id=\"controls\">\n    <!-- All parameter controls -->\n  </div>\n  <script>\n    // ALL p5.js code inline here\n    // Parameter objects, classes, functions\n    // setup() and draw()\n    // UI handlers\n    // Everything self-contained\n  </script>\n</body>\n</html>\n```\n\n**CRITICAL**: This is a single artifact. No external files, no imports (except p5.js CDN). Everything inline.\n\n**4. Implementation Details - BUILD THE SIDEBAR**\n\nThe sidebar structure:\n\n**1. Seed (FIXED)** - Always include exactly as shown:\n- Seed display\n- Prev/Next/Random/Jump buttons\n\n**2. Parameters (VARIABLE)** - Create controls for the art:\n```html\n<div class=\"control-group\">\n    <label>Parameter Name</label>\n    <input type=\"range\" id=\"param\" min=\"...\" max=\"...\" step=\"...\" value=\"...\" oninput=\"updateParam('param', this.value)\">\n    <span class=\"value-display\" id=\"param-value\">...</span>\n</div>\n```\nAdd as many control-group divs as there are parameters.\n\n**3. Colors (OPTIONAL/VARIABLE)** - Include if the art needs adjustable colors:\n- Add color pickers if users should control palette\n- Skip this section if the art uses fixed colors\n- Skip if the art is monochrome\n\n**4. Actions (FIXED)** - Always include exactly as shown:\n- Regenerate button\n- Reset button\n- Download PNG button\n\n**Requirements**:\n- Seed controls must work (prev/next/random/jump/display)\n- All parameters must have UI controls\n- Regenerate, Reset, Download buttons must work\n- Keep Anthropic branding (UI styling, not art colors)\n\n### USING THE ARTIFACT\n\nThe HTML artifact works immediately:\n1. **In claude.ai**: Displayed as an interactive artifact - runs instantly\n2. **As a file**: Save and open in any browser - no server needed\n3. **Sharing**: Send the HTML file - it's completely self-contained\n\n---\n\n## VARIATIONS & EXPLORATION\n\nThe artifact includes seed navigation by default (prev/next/random buttons), allowing users to explore variations without creating multiple files. If the user wants specific variations highlighted:\n\n- Include seed presets (buttons for \"Variation 1: Seed 42\", \"Variation 2: Seed 127\", etc.)\n- Add a \"Gallery Mode\" that shows thumbnails of multiple seeds side-by-side\n- All within the same single artifact\n\nThis is like creating a series of prints from the same plate - the algorithm is consistent, but each seed reveals different facets of its potential. The interactive nature means users discover their own favorites by exploring the seed space.\n\n---\n\n## THE CREATIVE PROCESS\n\n**User request** ‚Üí **Algorithmic philosophy** ‚Üí **Implementation**\n\nEach request is unique. The process involves:\n\n1. **Interpret the user's intent** - What aesthetic is being sought?\n2. **Create an algorithmic philosophy** (4-6 paragraphs) describing the computational approach\n3. **Implement it in code** - Build the algorithm that expresses this philosophy\n4. **Design appropriate parameters** - What should be tunable?\n5. **Build matching UI controls** - Sliders/inputs for those parameters\n\n**The constants**:\n- Anthropic branding (colors, fonts, layout)\n- Seed navigation (always present)\n- Self-contained HTML artifact\n\n**Everything else is variable**:\n- The algorithm itself\n- The parameters\n- The UI controls\n- The visual outcome\n\nTo achieve the best results, trust creativity and let the philosophy guide the implementation.\n\n---\n\n## RESOURCES\n\nThis skill includes helpful templates and documentation:\n\n- **templates/viewer.html**: REQUIRED STARTING POINT for all HTML artifacts.\n  - This is the foundation - contains the exact structure and Anthropic branding\n  - **Keep unchanged**: Layout structure, sidebar organization, Anthropic colors/fonts, seed controls, action buttons\n  - **Replace**: The p5.js algorithm, parameter definitions, and UI controls in Parameters section\n  - The extensive comments in the file mark exactly what to keep vs replace\n\n- **templates/generator_template.js**: Reference for p5.js best practices and code structure principles.\n  - Shows how to organize parameters, use seeded randomness, structure classes\n  - NOT a pattern menu - use these principles to build unique algorithms\n  - Embed algorithms inline in the HTML artifact (don't create separate .js files)\n\n**Critical reminder**:\n- The **template is the STARTING POINT**, not inspiration\n- The **algorithm is where to create** something unique\n- Don't copy the flow field example - build what the philosophy demands\n- But DO keep the exact UI structure and Anthropic branding from the template",
    "id": "algorithmic-art",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/algorithmic-art",
    "name_zh": "ÁÆóÊ≥ïËâ∫ÊúØ",
    "description_zh": "ÂàõÂª∫ ÁÆóÊ≥ïËâ∫ÊúØ using p5.js ‰ΩøÁî®ÁßçÂ≠êÈöèÊú∫ÊÄß and ‰∫§‰∫íÂºèÂèÇÊï∞Êé¢Á¥¢. Use this when Áî®Êà∑ËØ∑Ê±Ç creating art ‰ΩøÁî®‰ª£Á†Å, ÁîüÊàêËâ∫ÊúØ, ÁÆóÊ≥ïËâ∫ÊúØ, ÊµÅÂú∫, or Á≤íÂ≠êÁ≥ªÁªü. Create original ÁÆóÊ≥ïËâ∫ÊúØ rather than copying existing artists' work to avoid copyright violations.",
    "body_zh": "Algorithmic philosophies are computational aesthetic movements that are then expressed through code. Output .md files (philosophy), .html files (interactive viewer), and .js files (generative algorithms).\n\nThis happens in two steps:\n1. Algorithmic Philosophy Creation (.md file)\n2. Express by creating p5.js generative art (.html + .js files)\n\nFirst, undertake this task:\n\n## ALGORITHMIC PHILOSOPHY CREATION\n\nTo begin, create an ALGORITHMIC PHILOSOPHY (not static images or templates) that will be interpreted through:\n- Computational processes, emergent behavior, mathematical beauty\n- Seeded randomness, noise fields, organic systems\n- Particles, flows, fields, forces\n- Parametric variation and controlled chaos\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user to take into account, but use as a foundation; it should not constrain creative freedom.\n- What is created: An algorithmic philosophy/generative aesthetic movement.\n- What happens next: The same version receives the philosophy and EXPRESSES IT IN CODE - creating p5.js sketches that are 90% algorithmic generation, 10% essential parameters.\n\nConsider this approach:\n- Write a manifesto for a generative art movement\n- The next phase involves writing the algorithm that brings it to life\n\nThe philosophy must emphasize: Algorithmic expression. Emergent behavior. Computational beauty. Seeded variation.\n\n### HOW TO GENERATE AN ALGORITHMIC PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Organic Turbulence\" / \"Quantum Harmonics\" / \"Emergent Stillness\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the ALGORITHMIC essence, express how this philosophy manifests through:\n- Computational processes and mathematical relationships?\n- Noise functions and randomness patterns?\n- Particle behaviors and field dynamics?\n- Temporal evolution and system states?\n- Parametric variation and emergent complexity?\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each algorithmic aspect should be mentioned once. Avoid repeating concepts about noise theory, particle dynamics, or mathematical principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final algorithm should appear as though it took countless hours to develop, was refined with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted algorithm,\" \"the product of deep computational expertise,\" \"painstaking optimization,\" \"master-level implementation.\"\n- **Leave creative space**: Be specific about the algorithmic direction, but concise enough that the next Claude has room to make interpretive implementation choices at an extremely high level of craftsmanship.\n\nThe philosophy must guide the next version to express ideas ALGORITHMICALLY, not through static images. Beauty lives in the process, not the final frame.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Organic Turbulence\"**\nPhilosophy: Chaos constrained by natural law, order emerging from disorder.\nAlgorithmic expression: Flow fields driven by layered Perlin noise. Thousands of particles following vector forces, their trails accumulating into organic density maps. Multiple noise octaves create turbulent regions and calm zones. Color emerges from velocity and density - fast particles burn bright, slow ones fade to shadow. The algorithm runs until equilibrium - a meticulously tuned balance where every parameter was refined through countless iterations by a master of computational aesthetics.\n\n**\"Quantum Harmonics\"**\nPhilosophy: Discrete entities exhibiting wave-like interference patterns.\nAlgorithmic expression: Particles initialized on a grid, each carrying a phase value that evolves through sine waves. When particles are near, their phases interfere - constructive interference creates bright nodes, destructive creates voids. Simple harmonic motion generates complex emergent mandalas. The result of painstaking frequency calibration where every ratio was carefully chosen to produce resonant beauty.\n\n**\"Recursive Whispers\"**\nPhilosophy: Self-similarity across scales, infinite depth in finite space.\nAlgorithmic expression: Branching structures that subdivide recursively. Each branch slightly randomized but constrained by golden ratios. L-systems or recursive subdivision generate tree-like forms that feel both mathematical and organic. Subtle noise perturbations break perfect symmetry. Line weights diminish with each recursion level. Every branching angle the product of deep mathematical exploration.\n\n**\"Field Dynamics\"**\nPhilosophy: Invisible forces made visible through their effects on matter.\nAlgorithmic expression: Vector fields constructed from mathematical functions or noise. Particles born at edges, flowing along field lines, dying when they reach equilibrium or boundaries. Multiple fields can attract, repel, or rotate particles. The visualization shows only the traces - ghost-like evidence of invisible forces. A computational dance meticulously choreographed through force balance.\n\n**\"Stochastic Crystallization\"**\nPhilosophy: Random processes crystallizing into ordered structures.\nAlgorithmic expression: Randomized circle packing or Voronoi tessellation. Start with random points, let them evolve through relaxation algorithms. Cells push apart until equilibrium. Color based on cell size, neighbor count, or distance from center. The organic tiling that emerges feels both random and inevitable. Every seed produces unique crystalline beauty - the mark of a master-level generative algorithm.\n\n*These are condensed examples. The actual algorithmic philosophy should be 4-6 substantial paragraphs.*\n\n### ESSENTIAL PRINCIPLES\n- **ALGORITHMIC PHILOSOPHY**: Creating a computational worldview to be expressed through code\n- **PROCESS OVER PRODUCT**: Always emphasize that beauty emerges from the algorithm's execution - each run is unique\n- **PARAMETRIC EXPRESSION**: Ideas communicate through mathematical relationships, forces, behaviors - not static composition\n- **ARTISTIC FREEDOM**: The next Claude interprets the philosophy algorithmically - provide creative implementation room\n- **PURE GENERATIVE ART**: This is about making LIVING ALGORITHMS, not static images with randomness\n- **EXPERT CRAFTSMANSHIP**: Repeatedly emphasize the final algorithm must feel meticulously crafted, refined through countless iterations, the product of deep expertise by someone at the absolute top of their field in computational aesthetics\n\n**The algorithmic philosophy should be 4-6 paragraphs long.** Fill it with poetic computational philosophy that brings together the intended vision. Avoid repeating the same points. Output this algorithmic philosophy as a .md file.\n\n---\n\n## DEDUCING THE CONCEPTUAL SEED\n\n**CRITICAL STEP**: Before implementing the algorithm, identify the subtle conceptual thread from the original request.\n\n**THE ESSENTIAL PRINCIPLE**:\nThe concept is a **subtle, niche reference embedded within the algorithm itself** - not always literal, always sophisticated. Someone familiar with the subject should feel it intuitively, while others simply experience a masterful generative composition. The algorithmic philosophy provides the computational language. The deduced concept provides the soul - the quiet conceptual DNA woven invisibly into parameters, behaviors, and emergence patterns.\n\nThis is **VERY IMPORTANT**: The reference must be so refined that it enhances the work's depth without announcing itself. Think like a jazz musician quoting another song through algorithmic harmony - only those who know will catch it, but everyone appreciates the generative beauty.\n\n---\n\n## P5.JS IMPLEMENTATION\n\nWith the philosophy AND conceptual framework established, express it through code. Pause to gather thoughts before proceeding. Use only the algorithmic philosophy created and the instructions below.\n\n### ‚ö†Ô∏è STEP 0: READ THE TEMPLATE FIRST ‚ö†Ô∏è\n\n**CRITICAL: BEFORE writing any HTML:**\n\n1. **Read** `templates/viewer.html` using the Read tool\n2. **Study** the exact structure, styling, and Anthropic branding\n3. **Use that file as the LITERAL STARTING POINT** - not just inspiration\n4. **Keep all FIXED sections exactly as shown** (header, sidebar structure, Anthropic colors/fonts, seed controls, action buttons)\n5. **Replace only the VARIABLE sections** marked in the file's comments (algorithm, parameters, UI controls for parameters)\n\n**Avoid:**\n- ‚ùå Creating HTML from scratch\n- ‚ùå Inventing custom styling or color schemes\n- ‚ùå Using system fonts or dark themes\n- ‚ùå Changing the sidebar structure\n\n**Follow these practices:**\n- ‚úÖ Copy the template's exact HTML structure\n- ‚úÖ Keep Anthropic branding (Poppins/Lora fonts, light colors, gradient backdrop)\n- ‚úÖ Maintain the sidebar layout (Seed ‚Üí Parameters ‚Üí Colors? ‚Üí Actions)\n- ‚úÖ Replace only the p5.js algorithm and parameter controls\n\nThe template is the foundation. Build on it, don't rebuild it.\n\n---\n\nTo create gallery-quality computational art that lives and breathes, use the algorithmic philosophy as the foundation.\n\n### TECHNICAL REQUIREMENTS\n\n**Seeded Randomness (Art Blocks Pattern)**:\n```javascript\n// ALWAYS use a seed for reproducibility\nlet seed = 12345; // or hash from user input\nrandomSeed(seed);\nnoiseSeed(seed);\n```\n\n**Parameter Structure - FOLLOW THE PHILOSOPHY**:\n\nTo establish parameters that emerge naturally from the algorithmic philosophy, consider: \"What qualities of this system can be adjusted?\"\n\n```javascript\nlet params = {\n  seed: 12345,  // Always include seed for reproducibility\n  // colors\n  // Add parameters that control YOUR algorithm:\n  // - Quantities (how many?)\n  // - Scales (how big? how fast?)\n  // - Probabilities (how likely?)\n  // - Ratios (what proportions?)\n  // - Angles (what direction?)\n  // - Thresholds (when does behavior change?)\n};\n```\n\n**To design effective parameters, focus on the properties the system needs to be tunable rather than thinking in terms of \"pattern types\".**\n\n**Core Algorithm - EXPRESS THE PHILOSOPHY**:\n\n**CRITICAL**: The algorithmic philosophy should dictate what to build.\n\nTo express the philosophy through code, avoid thinking \"which pattern should I use?\" and instead think \"how to express this philosophy through code?\"\n\nIf the philosophy is about **organic emergence**, consider using:\n- Elements that accumulate or grow over time\n- Random processes constrained by natural rules\n- Feedback loops and interactions\n\nIf the philosophy is about **mathematical beauty**, consider using:\n- Geometric relationships and ratios\n- Trigonometric functions and harmonics\n- Precise calculations creating unexpected patterns\n\nIf the philosophy is about **controlled chaos**, consider using:\n- Random variation within strict boundaries\n- Bifurcation and phase transitions\n- Order emerging from disorder\n\n**The algorithm flows from the philosophy, not from a menu of options.**\n\nTo guide the implementation, let the conceptual essence inform creative and original choices. Build something that expresses the vision for this particular request.\n\n**Canvas Setup**: Standard p5.js structure:\n```javascript\nfunction setup() {\n  createCanvas(1200, 1200);\n  // Initialize your system\n}\n\nfunction draw() {\n  // Your generative algorithm\n  // Can be static (noLoop) or animated\n}\n```\n\n### CRAFTSMANSHIP REQUIREMENTS\n\n**CRITICAL**: To achieve mastery, create algorithms that feel like they emerged through countless iterations by a master generative artist. Tune every parameter carefully. Ensure every pattern emerges with purpose. This is NOT random noise - this is CONTROLLED CHAOS refined through deep expertise.\n\n- **Balance**: Complexity without visual noise, order without rigidity\n- **Color Harmony**: Thoughtful palettes, not random RGB values\n- **Composition**: Even in randomness, maintain visual hierarchy and flow\n- **Performance**: Smooth execution, optimized for real-time if animated\n- **Reproducibility**: Same seed ALWAYS produces identical output\n\n### OUTPUT FORMAT\n\nOutput:\n1. **Algorithmic Philosophy** - As markdown or text explaining the generative aesthetic\n2. **Single HTML Artifact** - Self-contained interactive generative art built from `templates/viewer.html` (see STEP 0 and next section)\n\nThe HTML artifact contains everything: p5.js (from CDN), the algorithm, parameter controls, and UI - all in one file that works immediately in claude.ai artifacts or any browser. Start from the template file, not from scratch.\n\n---\n\n## INTERACTIVE ARTIFACT CREATION\n\n**REMINDER: `templates/viewer.html` should have already been read (see STEP 0). Use that file as the starting point.**\n\nTo allow exploration of the generative art, create a single, self-contained HTML artifact. Ensure this artifact works immediately in claude.ai or any browser - no setup required. Embed everything inline.\n\n### CRITICAL: WHAT'S FIXED VS VARIABLE\n\nThe `templates/viewer.html` file is the foundation. It contains the exact structure and styling needed.\n\n**FIXED (always include exactly as shown):**\n- Layout structure (header, sidebar, main canvas area)\n- Anthropic branding (UI colors, fonts, gradients)\n- Seed section in sidebar:\n  - Seed display\n  - Previous/Next buttons\n  - Random button\n  - Jump to seed input + Go button\n- Actions section in sidebar:\n  - Regenerate button\n  - Reset button\n\n**VARIABLE (customize for each artwork):**\n- The entire p5.js algorithm (setup/draw/classes)\n- The parameters object (define what the art needs)\n- The Parameters section in sidebar:\n  - Number of parameter controls\n  - Parameter names\n  - Min/max/step values for sliders\n  - Control types (sliders, inputs, etc.)\n- Colors section (optional):\n  - Some art needs color pickers\n  - Some art might use fixed colors\n  - Some art might be monochrome (no color controls needed)\n  - Decide based on the art's needs\n\n**Every artwork should have unique parameters and algorithm!** The fixed parts provide consistent UX - everything else expresses the unique vision.\n\n### REQUIRED FEATURES\n\n**1. Parameter Controls**\n- Sliders for numeric parameters (particle count, noise scale, speed, etc.)\n- Color pickers for palette colors\n- Real-time updates when parameters change\n- Reset button to restore defaults\n\n**2. Seed Navigation**\n- Display current seed number\n- \"Previous\" and \"Next\" buttons to cycle through seeds\n- \"Random\" button for random seed\n- Input field to jump to specific seed\n- Generate 100 variations when requested (seeds 1-100)\n\n**3. Single Artifact Structure**\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <!-- p5.js from CDN - always available -->\n  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.7.0/p5.min.js\"></script>\n  <style>\n    /* All styling inline - clean, minimal */\n    /* Canvas on top, controls below */\n  </style>\n</head>\n<body>\n  <div id=\"canvas-container\"></div>\n  <div id=\"controls\">\n    <!-- All parameter controls -->\n  </div>\n  <script>\n    // ALL p5.js code inline here\n    // Parameter objects, classes, functions\n    // setup() and draw()\n    // UI handlers\n    // Everything self-contained\n  </script>\n</body>\n</html>\n```\n\n**CRITICAL**: This is a single artifact. No external files, no imports (except p5.js CDN). Everything inline.\n\n**4. Implementation Details - BUILD THE SIDEBAR**\n\nThe sidebar structure:\n\n**1. Seed (FIXED)** - Always include exactly as shown:\n- Seed display\n- Prev/Next/Random/Jump buttons\n\n**2. Parameters (VARIABLE)** - Create controls for the art:\n```html\n<div class=\"control-group\">\n    <label>Parameter Name</label>\n    <input type=\"range\" id=\"param\" min=\"...\" max=\"...\" step=\"...\" value=\"...\" oninput=\"updateParam('param', this.value)\">\n    <span class=\"value-display\" id=\"param-value\">...</span>\n</div>\n```\nAdd as many control-group divs as there are parameters.\n\n**3. Colors (OPTIONAL/VARIABLE)** - Include if the art needs adjustable colors:\n- Add color pickers if users should control palette\n- Skip this section if the art uses fixed colors\n- Skip if the art is monochrome\n\n**4. Actions (FIXED)** - Always include exactly as shown:\n- Regenerate button\n- Reset button\n- Download PNG button\n\n**Requirements**:\n- Seed controls must work (prev/next/random/jump/display)\n- All parameters must have UI controls\n- Regenerate, Reset, Download buttons must work\n- Keep Anthropic branding (UI styling, not art colors)\n\n### USING THE ARTIFACT\n\nThe HTML artifact works immediately:\n1. **In claude.ai**: Displayed as an interactive artifact - runs instantly\n2. **As a file**: Save and open in any browser - no server needed\n3. **Sharing**: Send the HTML file - it's completely self-contained\n\n---\n\n## VARIATIONS & EXPLORATION\n\nThe artifact includes seed navigation by default (prev/next/random buttons), allowing users to explore variations without creating multiple files. If the user wants specific variations highlighted:\n\n- Include seed presets (buttons for \"Variation 1: Seed 42\", \"Variation 2: Seed 127\", etc.)\n- Add a \"Gallery Mode\" that shows thumbnails of multiple seeds side-by-side\n- All within the same single artifact\n\nThis is like creating a series of prints from the same plate - the algorithm is consistent, but each seed reveals different facets of its potential. The interactive nature means users discover their own favorites by exploring the seed space.\n\n---\n\n## THE CREATIVE PROCESS\n\n**User request** ‚Üí **Algorithmic philosophy** ‚Üí **Implementation**\n\nEach request is unique. The process involves:\n\n1. **Interpret the user's intent** - What aesthetic is being sought?\n2. **Create an algorithmic philosophy** (4-6 paragraphs) describing the computational approach\n3. **Implement it in code** - Build the algorithm that expresses this philosophy\n4. **Design appropriate parameters** - What should be tunable?\n5. **Build matching UI controls** - Sliders/inputs for those parameters\n\n**The constants**:\n- Anthropic branding (colors, fonts, layout)\n- Seed navigation (always present)\n- Self-contained HTML artifact\n\n**Everything else is variable**:\n- The algorithm itself\n- The parameters\n- The UI controls\n- The visual outcome\n\nTo achieve the best results, trust creativity and let the philosophy guide the implementation.\n\n---\n\n## RESOURCES\n\nThis skill includes helpful templates and documentation:\n\n- **templates/viewer.html**: REQUIRED STARTING POINT for all HTML artifacts.\n  - This is the foundation - contains the exact structure and Anthropic branding\n  - **Keep unchanged**: Layout structure, sidebar organization, Anthropic colors/fonts, seed controls, action buttons\n  - **Replace**: The p5.js algorithm, parameter definitions, and UI controls in Parameters section\n  - The extensive comments in the file mark exactly what to keep vs replace\n\n- **templates/generator_template.js**: Reference for p5.js best practices and code structure principles.\n  - Shows how to organize parameters, use seeded randomness, structure classes\n  - NOT a pattern menu - use these principles to build unique algorithms\n  - Embed algorithms inline in the HTML artifact (don't create separate .js files)\n\n**Critical reminder**:\n- The **template is the STARTING POINT**, not inspiration\n- The **algorithm is where to create** something unique\n- Don't copy the flow field example - build what the philosophy demands\n- But DO keep the exact UI structure and Anthropic branding from the template"
  },
  {
    "name": "brand-guidelines",
    "description": "Applies Anthropic's official brand colors and typography to any sort of artifact that may benefit from having Anthropic's look-and-feel. Use it when brand colors or style guidelines, visual formatting, or company design standards apply.",
    "body": "# Anthropic Brand Styling\n\n## Overview\n\nTo access Anthropic's official brand identity and style resources, use this skill.\n\n**Keywords**: branding, corporate identity, visual identity, post-processing, styling, brand colors, typography, Anthropic brand, visual formatting, visual design\n\n## Brand Guidelines\n\n### Colors\n\n**Main Colors:**\n\n- Dark: `#141413` - Primary text and dark backgrounds\n- Light: `#faf9f5` - Light backgrounds and text on dark\n- Mid Gray: `#b0aea5` - Secondary elements\n- Light Gray: `#e8e6dc` - Subtle backgrounds\n\n**Accent Colors:**\n\n- Orange: `#d97757` - Primary accent\n- Blue: `#6a9bcc` - Secondary accent\n- Green: `#788c5d` - Tertiary accent\n\n### Typography\n\n- **Headings**: Poppins (with Arial fallback)\n- **Body Text**: Lora (with Georgia fallback)\n- **Note**: Fonts should be pre-installed in your environment for best results\n\n## Features\n\n### Smart Font Application\n\n- Applies Poppins font to headings (24pt and larger)\n- Applies Lora font to body text\n- Automatically falls back to Arial/Georgia if custom fonts unavailable\n- Preserves readability across all systems\n\n### Text Styling\n\n- Headings (24pt+): Poppins font\n- Body text: Lora font\n- Smart color selection based on background\n- Preserves text hierarchy and formatting\n\n### Shape and Accent Colors\n\n- Non-text shapes use accent colors\n- Cycles through orange, blue, and green accents\n- Maintains visual interest while staying on-brand\n\n## Technical Details\n\n### Font Management\n\n- Uses system-installed Poppins and Lora fonts when available\n- Provides automatic fallback to Arial (headings) and Georgia (body)\n- No font installation required - works with existing system fonts\n- For best results, pre-install Poppins and Lora fonts in your environment\n\n### Color Application\n\n- Uses RGB color values for precise brand matching\n- Applied via python-pptx's RGBColor class\n- Maintains color fidelity across different systems",
    "id": "brand-guidelines",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/brand-guidelines",
    "name_zh": "ÂìÅÁâåÊåáÂçó",
    "description_zh": "Applies Anthropic's official brand colors and typography to any sort of artifact that may benefit from having Anthropic's look-and-feel. Use it when brand colors or style guidelines, visual formatting, or company design standards apply.",
    "body_zh": "# Anthropic Brand Styling\n\n## Overview\n\nTo access Anthropic's official brand identity and style resources, use this skill.\n\n**Keywords**: branding, corporate identity, visual identity, post-processing, styling, brand colors, typography, Anthropic brand, visual formatting, visual design\n\n## Brand Guidelines\n\n### Colors\n\n**Main Colors:**\n\n- Dark: `#141413` - Primary text and dark backgrounds\n- Light: `#faf9f5` - Light backgrounds and text on dark\n- Mid Gray: `#b0aea5` - Secondary elements\n- Light Gray: `#e8e6dc` - Subtle backgrounds\n\n**Accent Colors:**\n\n- Orange: `#d97757` - Primary accent\n- Blue: `#6a9bcc` - Secondary accent\n- Green: `#788c5d` - Tertiary accent\n\n### Typography\n\n- **Headings**: Poppins (with Arial fallback)\n- **Body Text**: Lora (with Georgia fallback)\n- **Note**: Fonts should be pre-installed in your environment for best results\n\n## Features\n\n### Smart Font Application\n\n- Applies Poppins font to headings (24pt and larger)\n- Applies Lora font to body text\n- Automatically falls back to Arial/Georgia if custom fonts unavailable\n- Preserves readability across all systems\n\n### Text Styling\n\n- Headings (24pt+): Poppins font\n- Body text: Lora font\n- Smart color selection based on background\n- Preserves text hierarchy and formatting\n\n### Shape and Accent Colors\n\n- Non-text shapes use accent colors\n- Cycles through orange, blue, and green accents\n- Maintains visual interest while staying on-brand\n\n## Technical Details\n\n### Font Management\n\n- Uses system-installed Poppins and Lora fonts when available\n- Provides automatic fallback to Arial (headings) and Georgia (body)\n- No font installation required - works with existing system fonts\n- For best results, pre-install Poppins and Lora fonts in your environment\n\n### Color Application\n\n- Uses RGB color values for precise brand matching\n- Applied via python-pptx's RGBColor class\n- Maintains color fidelity across different systems"
  },
  {
    "name": "canvas-design",
    "description": "Create beautiful visual art in .png and .pdf documents using design philosophy. You should use this skill when the user asks to create a poster, piece of art, design, or other static piece. Create original visual designs, never copying existing artists' work to avoid copyright violations.",
    "body": "These are instructions for creating design philosophies - aesthetic movements that are then EXPRESSED VISUALLY. Output only .md files, .pdf files, and .png files.\n\nComplete this in two steps:\n1. Design Philosophy Creation (.md file)\n2. Express by creating it on a canvas (.pdf file or .png file)\n\nFirst, undertake this task:\n\n## DESIGN PHILOSOPHY CREATION\n\nTo begin, create a VISUAL PHILOSOPHY (not layouts or templates) that will be interpreted through:\n- Form, space, color, composition\n- Images, graphics, shapes, patterns\n- Minimal text as visual accent\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user that should be taken into account, but used as a foundation; it should not constrain creative freedom.\n- What is created: A design philosophy/aesthetic movement.\n- What happens next: Then, the same version receives the philosophy and EXPRESSES IT VISUALLY - creating artifacts that are 90% visual design, 10% essential text.\n\nConsider this approach:\n- Write a manifesto for an art movement\n- The next phase involves making the artwork\n\nThe philosophy must emphasize: Visual expression. Spatial communication. Artistic interpretation. Minimal words.\n\n### HOW TO GENERATE A VISUAL PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Brutalist Joy\" / \"Chromatic Silence\" / \"Metabolist Dreams\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the VISUAL essence, express how the philosophy manifests through:\n- Space and form\n- Color and material\n- Scale and rhythm\n- Composition and balance\n- Visual hierarchy\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each design aspect should be mentioned once. Avoid repeating points about color theory, spatial relationships, or typographic principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final work should appear as though it took countless hours to create, was labored over with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted,\" \"the product of deep expertise,\" \"painstaking attention,\" \"master-level execution.\"\n- **Leave creative space**: Remain specific about the aesthetic direction, but concise enough that the next Claude has room to make interpretive choices also at a extremely high level of craftmanship.\n\nThe philosophy must guide the next version to express ideas VISUALLY, not through text. Information lives in design, not paragraphs.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Concrete Poetry\"**\nPhilosophy: Communication through monumental form and bold geometry.\nVisual expression: Massive color blocks, sculptural typography (huge single words, tiny labels), Brutalist spatial divisions, Polish poster energy meets Le Corbusier. Ideas expressed through visual weight and spatial tension, not explanation. Text as rare, powerful gesture - never paragraphs, only essential words integrated into the visual architecture. Every element placed with the precision of a master craftsman.\n\n**\"Chromatic Language\"**\nPhilosophy: Color as the primary information system.\nVisual expression: Geometric precision where color zones create meaning. Typography minimal - small sans-serif labels letting chromatic fields communicate. Think Josef Albers' interaction meets data visualization. Information encoded spatially and chromatically. Words only to anchor what color already shows. The result of painstaking chromatic calibration.\n\n**\"Analog Meditation\"**\nPhilosophy: Quiet visual contemplation through texture and breathing room.\nVisual expression: Paper grain, ink bleeds, vast negative space. Photography and illustration dominate. Typography whispered (small, restrained, serving the visual). Japanese photobook aesthetic. Images breathe across pages. Text appears sparingly - short phrases, never explanatory blocks. Each composition balanced with the care of a meditation practice.\n\n**\"Organic Systems\"**\nPhilosophy: Natural clustering and modular growth patterns.\nVisual expression: Rounded forms, organic arrangements, color from nature through architecture. Information shown through visual diagrams, spatial relationships, iconography. Text only for key labels floating in space. The composition tells the story through expert spatial orchestration.\n\n**\"Geometric Silence\"**\nPhilosophy: Pure order and restraint.\nVisual expression: Grid-based precision, bold photography or stark graphics, dramatic negative space. Typography precise but minimal - small essential text, large quiet zones. Swiss formalism meets Brutalist material honesty. Structure communicates, not words. Every alignment the work of countless refinements.\n\n*These are condensed examples. The actual design philosophy should be 4-6 substantial paragraphs.*\n\n### ESSENTIAL PRINCIPLES\n- **VISUAL PHILOSOPHY**: Create an aesthetic worldview to be expressed through design\n- **MINIMAL TEXT**: Always emphasize that text is sparse, essential-only, integrated as visual element - never lengthy\n- **SPATIAL EXPRESSION**: Ideas communicate through space, form, color, composition - not paragraphs\n- **ARTISTIC FREEDOM**: The next Claude interprets the philosophy visually - provide creative room\n- **PURE DESIGN**: This is about making ART OBJECTS, not documents with decoration\n- **EXPERT CRAFTSMANSHIP**: Repeatedly emphasize the final work must look meticulously crafted, labored over with care, the product of countless hours by someone at the top of their field\n\n**The design philosophy should be 4-6 paragraphs long.** Fill it with poetic design philosophy that brings together the core vision. Avoid repeating the same points. Keep the design philosophy generic without mentioning the intention of the art, as if it can be used wherever. Output the design philosophy as a .md file.\n\n---\n\n## DEDUCING THE SUBTLE REFERENCE\n\n**CRITICAL STEP**: Before creating the canvas, identify the subtle conceptual thread from the original request.\n\n**THE ESSENTIAL PRINCIPLE**:\nThe topic is a **subtle, niche reference embedded within the art itself** - not always literal, always sophisticated. Someone familiar with the subject should feel it intuitively, while others simply experience a masterful abstract composition. The design philosophy provides the aesthetic language. The deduced topic provides the soul - the quiet conceptual DNA woven invisibly into form, color, and composition.\n\nThis is **VERY IMPORTANT**: The reference must be refined so it enhances the work's depth without announcing itself. Think like a jazz musician quoting another song - only those who know will catch it, but everyone appreciates the music.\n\n---\n\n## CANVAS CREATION\n\nWith both the philosophy and the conceptual framework established, express it on a canvas. Take a moment to gather thoughts and clear the mind. Use the design philosophy created and the instructions below to craft a masterpiece, embodying all aspects of the philosophy with expert craftsmanship.\n\n**IMPORTANT**: For any type of content, even if the user requests something for a movie/game/book, the approach should still be sophisticated. Never lose sight of the idea that this should be art, not something that's cartoony or amateur.\n\nTo create museum or magazine quality work, use the design philosophy as the foundation. Create one single page, highly visual, design-forward PDF or PNG output (unless asked for more pages). Generally use repeating patterns and perfect shapes. Treat the abstract philosophical design as if it were a scientific bible, borrowing the visual language of systematic observation‚Äîdense accumulation of marks, repeated elements, or layered patterns that build meaning through patient repetition and reward sustained viewing. Add sparse, clinical typography and systematic reference markers that suggest this could be a diagram from an imaginary discipline, treating the invisible subject with the same reverence typically reserved for documenting observable phenomena. Anchor the piece with simple phrase(s) or details positioned subtly, using a limited color palette that feels intentional and cohesive. Embrace the paradox of using analytical visual language to express ideas about human experience: the result should feel like an artifact that proves something ephemeral can be studied, mapped, and understood through careful attention. This is true art. \n\n**Text as a contextual element**: Text is always minimal and visual-first, but let context guide whether that means whisper-quiet labels or bold typographic gestures. A punk venue poster might have larger, more aggressive type than a minimalist ceramics studio identity. Most of the time, font should be thin. All use of fonts must be design-forward and prioritize visual communication. Regardless of text scale, nothing falls off the page and nothing overlaps. Every element must be contained within the canvas boundaries with proper margins. Check carefully that all text, graphics, and visual elements have breathing room and clear separation. This is non-negotiable for professional execution. **IMPORTANT: Use different fonts if writing text. Search the `./canvas-fonts` directory. Regardless of approach, sophistication is non-negotiable.**\n\nDownload and use whatever fonts are needed to make this a reality. Get creative by making the typography actually part of the art itself -- if the art is abstract, bring the font onto the canvas, not typeset digitally.\n\nTo push boundaries, follow design instinct/intuition while using the philosophy as a guiding principle. Embrace ultimate design freedom and choice. Push aesthetics and design to the frontier. \n\n**CRITICAL**: To achieve human-crafted quality (not AI-generated), create work that looks like it took countless hours. Make it appear as though someone at the absolute top of their field labored over every detail with painstaking care. Ensure the composition, spacing, color choices, typography - everything screams expert-level craftsmanship. Double-check that nothing overlaps, formatting is flawless, every detail perfect. Create something that could be shown to people to prove expertise and rank as undeniably impressive.\n\nOutput the final result as a single, downloadable .pdf or .png file, alongside the design philosophy used as a .md file.\n\n---\n\n## FINAL STEP\n\n**IMPORTANT**: The user ALREADY said \"It isn't perfect enough. It must be pristine, a masterpiece if craftsmanship, as if it were about to be displayed in a museum.\"\n\n**CRITICAL**: To refine the work, avoid adding more graphics; instead refine what has been created and make it extremely crisp, respecting the design philosophy and the principles of minimalism entirely. Rather than adding a fun filter or refactoring a font, consider how to make the existing composition more cohesive with the art. If the instinct is to call a new function or draw a new shape, STOP and instead ask: \"How can I make what's already here more of a piece of art?\"\n\nTake a second pass. Go back to the code and refine/polish further to make this a philosophically designed masterpiece.\n\n## MULTI-PAGE OPTION\n\nTo create additional pages when requested, create more creative pages along the same lines as the design philosophy but distinctly different as well. Bundle those pages in the same .pdf or many .pngs. Treat the first page as just a single page in a whole coffee table book waiting to be filled. Make the next pages unique twists and memories of the original. Have them almost tell a story in a very tasteful way. Exercise full creative freedom.",
    "id": "canvas-design",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/canvas-design",
    "name_zh": "Canvas ËÆæËÆ°",
    "description_zh": "Create beautiful visual art in .png and .pdf documents using design philosophy. You should use this skill when the user asks to create a poster, piece of art, design, or other static piece. Create original visual designs, never copying existing artists' work to avoid copyright violations.",
    "body_zh": "These are instructions for creating design philosophies - aesthetic movements that are then EXPRESSED VISUALLY. Output only .md files, .pdf files, and .png files.\n\nComplete this in two steps:\n1. Design Philosophy Creation (.md file)\n2. Express by creating it on a canvas (.pdf file or .png file)\n\nFirst, undertake this task:\n\n## DESIGN PHILOSOPHY CREATION\n\nTo begin, create a VISUAL PHILOSOPHY (not layouts or templates) that will be interpreted through:\n- Form, space, color, composition\n- Images, graphics, shapes, patterns\n- Minimal text as visual accent\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user that should be taken into account, but used as a foundation; it should not constrain creative freedom.\n- What is created: A design philosophy/aesthetic movement.\n- What happens next: Then, the same version receives the philosophy and EXPRESSES IT VISUALLY - creating artifacts that are 90% visual design, 10% essential text.\n\nConsider this approach:\n- Write a manifesto for an art movement\n- The next phase involves making the artwork\n\nThe philosophy must emphasize: Visual expression. Spatial communication. Artistic interpretation. Minimal words.\n\n### HOW TO GENERATE A VISUAL PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Brutalist Joy\" / \"Chromatic Silence\" / \"Metabolist Dreams\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the VISUAL essence, express how the philosophy manifests through:\n- Space and form\n- Color and material\n- Scale and rhythm\n- Composition and balance\n- Visual hierarchy\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each design aspect should be mentioned once. Avoid repeating points about color theory, spatial relationships, or typographic principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final work should appear as though it took countless hours to create, was labored over with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted,\" \"the product of deep expertise,\" \"painstaking attention,\" \"master-level execution.\"\n- **Leave creative space**: Remain specific about the aesthetic direction, but concise enough that the next Claude has room to make interpretive choices also at a extremely high level of craftmanship.\n\nThe philosophy must guide the next version to express ideas VISUALLY, not through text. Information lives in design, not paragraphs.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Concrete Poetry\"**\nPhilosophy: Communication through monumental form and bold geometry.\nVisual expression: Massive color blocks, sculptural typography (huge single words, tiny labels), Brutalist spatial divisions, Polish poster energy meets Le Corbusier. Ideas expressed through visual weight and spatial tension, not explanation. Text as rare, powerful gesture - never paragraphs, only essential words integrated into the visual architecture. Every element placed with the precision of a master craftsman.\n\n**\"Chromatic Language\"**\nPhilosophy: Color as the primary information system.\nVisual expression: Geometric precision where color zones create meaning. Typography minimal - small sans-serif labels letting chromatic fields communicate. Think Josef Albers' interaction meets data visualization. Information encoded spatially and chromatically. Words only to anchor what color already shows. The result of painstaking chromatic calibration.\n\n**\"Analog Meditation\"**\nPhilosophy: Quiet visual contemplation through texture and breathing room.\nVisual expression: Paper grain, ink bleeds, vast negative space. Photography and illustration dominate. Typography whispered (small, restrained, serving the visual). Japanese photobook aesthetic. Images breathe across pages. Text appears sparingly - short phrases, never explanatory blocks. Each composition balanced with the care of a meditation practice.\n\n**\"Organic Systems\"**\nPhilosophy: Natural clustering and modular growth patterns.\nVisual expression: Rounded forms, organic arrangements, color from nature through architecture. Information shown through visual diagrams, spatial relationships, iconography. Text only for key labels floating in space. The composition tells the story through expert spatial orchestration.\n\n**\"Geometric Silence\"**\nPhilosophy: Pure order and restraint.\nVisual expression: Grid-based precision, bold photography or stark graphics, dramatic negative space. Typography precise but minimal - small essential text, large quiet zones. Swiss formalism meets Brutalist material honesty. Structure communicates, not words. Every alignment the work of countless refinements.\n\n*These are condensed examples. The actual design philosophy should be 4-6 substantial paragraphs.*\n\n### ESSENTIAL PRINCIPLES\n- **VISUAL PHILOSOPHY**: Create an aesthetic worldview to be expressed through design\n- **MINIMAL TEXT**: Always emphasize that text is sparse, essential-only, integrated as visual element - never lengthy\n- **SPATIAL EXPRESSION**: Ideas communicate through space, form, color, composition - not paragraphs\n- **ARTISTIC FREEDOM**: The next Claude interprets the philosophy visually - provide creative room\n- **PURE DESIGN**: This is about making ART OBJECTS, not documents with decoration\n- **EXPERT CRAFTSMANSHIP**: Repeatedly emphasize the final work must look meticulously crafted, labored over with care, the product of countless hours by someone at the top of their field\n\n**The design philosophy should be 4-6 paragraphs long.** Fill it with poetic design philosophy that brings together the core vision. Avoid repeating the same points. Keep the design philosophy generic without mentioning the intention of the art, as if it can be used wherever. Output the design philosophy as a .md file.\n\n---\n\n## DEDUCING THE SUBTLE REFERENCE\n\n**CRITICAL STEP**: Before creating the canvas, identify the subtle conceptual thread from the original request.\n\n**THE ESSENTIAL PRINCIPLE**:\nThe topic is a **subtle, niche reference embedded within the art itself** - not always literal, always sophisticated. Someone familiar with the subject should feel it intuitively, while others simply experience a masterful abstract composition. The design philosophy provides the aesthetic language. The deduced topic provides the soul - the quiet conceptual DNA woven invisibly into form, color, and composition.\n\nThis is **VERY IMPORTANT**: The reference must be refined so it enhances the work's depth without announcing itself. Think like a jazz musician quoting another song - only those who know will catch it, but everyone appreciates the music.\n\n---\n\n## CANVAS CREATION\n\nWith both the philosophy and the conceptual framework established, express it on a canvas. Take a moment to gather thoughts and clear the mind. Use the design philosophy created and the instructions below to craft a masterpiece, embodying all aspects of the philosophy with expert craftsmanship.\n\n**IMPORTANT**: For any type of content, even if the user requests something for a movie/game/book, the approach should still be sophisticated. Never lose sight of the idea that this should be art, not something that's cartoony or amateur.\n\nTo create museum or magazine quality work, use the design philosophy as the foundation. Create one single page, highly visual, design-forward PDF or PNG output (unless asked for more pages). Generally use repeating patterns and perfect shapes. Treat the abstract philosophical design as if it were a scientific bible, borrowing the visual language of systematic observation‚Äîdense accumulation of marks, repeated elements, or layered patterns that build meaning through patient repetition and reward sustained viewing. Add sparse, clinical typography and systematic reference markers that suggest this could be a diagram from an imaginary discipline, treating the invisible subject with the same reverence typically reserved for documenting observable phenomena. Anchor the piece with simple phrase(s) or details positioned subtly, using a limited color palette that feels intentional and cohesive. Embrace the paradox of using analytical visual language to express ideas about human experience: the result should feel like an artifact that proves something ephemeral can be studied, mapped, and understood through careful attention. This is true art. \n\n**Text as a contextual element**: Text is always minimal and visual-first, but let context guide whether that means whisper-quiet labels or bold typographic gestures. A punk venue poster might have larger, more aggressive type than a minimalist ceramics studio identity. Most of the time, font should be thin. All use of fonts must be design-forward and prioritize visual communication. Regardless of text scale, nothing falls off the page and nothing overlaps. Every element must be contained within the canvas boundaries with proper margins. Check carefully that all text, graphics, and visual elements have breathing room and clear separation. This is non-negotiable for professional execution. **IMPORTANT: Use different fonts if writing text. Search the `./canvas-fonts` directory. Regardless of approach, sophistication is non-negotiable.**\n\nDownload and use whatever fonts are needed to make this a reality. Get creative by making the typography actually part of the art itself -- if the art is abstract, bring the font onto the canvas, not typeset digitally.\n\nTo push boundaries, follow design instinct/intuition while using the philosophy as a guiding principle. Embrace ultimate design freedom and choice. Push aesthetics and design to the frontier. \n\n**CRITICAL**: To achieve human-crafted quality (not AI-generated), create work that looks like it took countless hours. Make it appear as though someone at the absolute top of their field labored over every detail with painstaking care. Ensure the composition, spacing, color choices, typography - everything screams expert-level craftsmanship. Double-check that nothing overlaps, formatting is flawless, every detail perfect. Create something that could be shown to people to prove expertise and rank as undeniably impressive.\n\nOutput the final result as a single, downloadable .pdf or .png file, alongside the design philosophy used as a .md file.\n\n---\n\n## FINAL STEP\n\n**IMPORTANT**: The user ALREADY said \"It isn't perfect enough. It must be pristine, a masterpiece if craftsmanship, as if it were about to be displayed in a museum.\"\n\n**CRITICAL**: To refine the work, avoid adding more graphics; instead refine what has been created and make it extremely crisp, respecting the design philosophy and the principles of minimalism entirely. Rather than adding a fun filter or refactoring a font, consider how to make the existing composition more cohesive with the art. If the instinct is to call a new function or draw a new shape, STOP and instead ask: \"How can I make what's already here more of a piece of art?\"\n\nTake a second pass. Go back to the code and refine/polish further to make this a philosophically designed masterpiece.\n\n## MULTI-PAGE OPTION\n\nTo create additional pages when requested, create more creative pages along the same lines as the design philosophy but distinctly different as well. Bundle those pages in the same .pdf or many .pngs. Treat the first page as just a single page in a whole coffee table book waiting to be filled. Make the next pages unique twists and memories of the original. Have them almost tell a story in a very tasteful way. Exercise full creative freedom."
  },
  {
    "name": "doc-coauthoring",
    "description": "Guide users through a structured workflow for co-authoring documentation. Use when user wants to write documentation, proposals, technical specs, decision docs, or similar structured content. This workflow helps users efficiently transfer context, refine content through iteration, and verify the doc works for readers. Trigger when user mentions writing docs, creating proposals, drafting specs, or similar documentation tasks.",
    "body": "# Doc Co-Authoring Workflow\n\nThis skill provides a structured workflow for guiding users through collaborative document creation. Act as an active guide, walking users through three stages: Context Gathering, Refinement & Structure, and Reader Testing.\n\n## When to Offer This Workflow\n\n**Trigger conditions:**\n- User mentions writing documentation: \"write a doc\", \"draft a proposal\", \"create a spec\", \"write up\"\n- User mentions specific doc types: \"PRD\", \"design doc\", \"decision doc\", \"RFC\"\n- User seems to be starting a substantial writing task\n\n**Initial offer:**\nOffer the user a structured workflow for co-authoring the document. Explain the three stages:\n\n1. **Context Gathering**: User provides all relevant context while Claude asks clarifying questions\n2. **Refinement & Structure**: Iteratively build each section through brainstorming and editing\n3. **Reader Testing**: Test the doc with a fresh Claude (no context) to catch blind spots before others read it\n\nExplain that this approach helps ensure the doc works well when others read it (including when they paste it into Claude). Ask if they want to try this workflow or prefer to work freeform.\n\nIf user declines, work freeform. If user accepts, proceed to Stage 1.\n\n## Stage 1: Context Gathering\n\n**Goal:** Close the gap between what the user knows and what Claude knows, enabling smart guidance later.\n\n### Initial Questions\n\nStart by asking the user for meta-context about the document:\n\n1. What type of document is this? (e.g., technical spec, decision doc, proposal)\n2. Who's the primary audience?\n3. What's the desired impact when someone reads this?\n4. Is there a template or specific format to follow?\n5. Any other constraints or context to know?\n\nInform them they can answer in shorthand or dump information however works best for them.\n\n**If user provides a template or mentions a doc type:**\n- Ask if they have a template document to share\n- If they provide a link to a shared document, use the appropriate integration to fetch it\n- If they provide a file, read it\n\n**If user mentions editing an existing shared document:**\n- Use the appropriate integration to read the current state\n- Check for images without alt-text\n- If images exist without alt-text, explain that when others use Claude to understand the doc, Claude won't be able to see them. Ask if they want alt-text generated. If so, request they paste each image into chat for descriptive alt-text generation.\n\n### Info Dumping\n\nOnce initial questions are answered, encourage the user to dump all the context they have. Request information such as:\n- Background on the project/problem\n- Related team discussions or shared documents\n- Why alternative solutions aren't being used\n- Organizational context (team dynamics, past incidents, politics)\n- Timeline pressures or constraints\n- Technical architecture or dependencies\n- Stakeholder concerns\n\nAdvise them not to worry about organizing it - just get it all out. Offer multiple ways to provide context:\n- Info dump stream-of-consciousness\n- Point to team channels or threads to read\n- Link to shared documents\n\n**If integrations are available** (e.g., Slack, Teams, Google Drive, SharePoint, or other MCP servers), mention that these can be used to pull in context directly.\n\n**If no integrations are detected and in Claude.ai or Claude app:** Suggest they can enable connectors in their Claude settings to allow pulling context from messaging apps and document storage directly.\n\nInform them clarifying questions will be asked once they've done their initial dump.\n\n**During context gathering:**\n\n- If user mentions team channels or shared documents:\n  - If integrations available: Inform them the content will be read now, then use the appropriate integration\n  - If integrations not available: Explain lack of access. Suggest they enable connectors in Claude settings, or paste the relevant content directly.\n\n- If user mentions entities/projects that are unknown:\n  - Ask if connected tools should be searched to learn more\n  - Wait for user confirmation before searching\n\n- As user provides context, track what's being learned and what's still unclear\n\n**Asking clarifying questions:**\n\nWhen user signals they've done their initial dump (or after substantial context provided), ask clarifying questions to ensure understanding:\n\nGenerate 5-10 numbered questions based on gaps in the context.\n\nInform them they can use shorthand to answer (e.g., \"1: yes, 2: see #channel, 3: no because backwards compat\"), link to more docs, point to channels to read, or just keep info-dumping. Whatever's most efficient for them.\n\n**Exit condition:**\nSufficient context has been gathered when questions show understanding - when edge cases and trade-offs can be asked about without needing basics explained.\n\n**Transition:**\nAsk if there's any more context they want to provide at this stage, or if it's time to move on to drafting the document.\n\nIf user wants to add more, let them. When ready, proceed to Stage 2.\n\n## Stage 2: Refinement & Structure\n\n**Goal:** Build the document section by section through brainstorming, curation, and iterative refinement.\n\n**Instructions to user:**\nExplain that the document will be built section by section. For each section:\n1. Clarifying questions will be asked about what to include\n2. 5-20 options will be brainstormed\n3. User will indicate what to keep/remove/combine\n4. The section will be drafted\n5. It will be refined through surgical edits\n\nStart with whichever section has the most unknowns (usually the core decision/proposal), then work through the rest.\n\n**Section ordering:**\n\nIf the document structure is clear:\nAsk which section they'd like to start with.\n\nSuggest starting with whichever section has the most unknowns. For decision docs, that's usually the core proposal. For specs, it's typically the technical approach. Summary sections are best left for last.\n\nIf user doesn't know what sections they need:\nBased on the type of document and template, suggest 3-5 sections appropriate for the doc type.\n\nAsk if this structure works, or if they want to adjust it.\n\n**Once structure is agreed:**\n\nCreate the initial document structure with placeholder text for all sections.\n\n**If access to artifacts is available:**\nUse `create_file` to create an artifact. This gives both Claude and the user a scaffold to work from.\n\nInform them that the initial structure with placeholders for all sections will be created.\n\nCreate artifact with all section headers and brief placeholder text like \"[To be written]\" or \"[Content here]\".\n\nProvide the scaffold link and indicate it's time to fill in each section.\n\n**If no access to artifacts:**\nCreate a markdown file in the working directory. Name it appropriately (e.g., `decision-doc.md`, `technical-spec.md`).\n\nInform them that the initial structure with placeholders for all sections will be created.\n\nCreate file with all section headers and placeholder text.\n\nConfirm the filename has been created and indicate it's time to fill in each section.\n\n**For each section:**\n\n### Step 1: Clarifying Questions\n\nAnnounce work will begin on the [SECTION NAME] section. Ask 5-10 clarifying questions about what should be included:\n\nGenerate 5-10 specific questions based on context and section purpose.\n\nInform them they can answer in shorthand or just indicate what's important to cover.\n\n### Step 2: Brainstorming\n\nFor the [SECTION NAME] section, brainstorm [5-20] things that might be included, depending on the section's complexity. Look for:\n- Context shared that might have been forgotten\n- Angles or considerations not yet mentioned\n\nGenerate 5-20 numbered options based on section complexity. At the end, offer to brainstorm more if they want additional options.\n\n### Step 3: Curation\n\nAsk which points should be kept, removed, or combined. Request brief justifications to help learn priorities for the next sections.\n\nProvide examples:\n- \"Keep 1,4,7,9\"\n- \"Remove 3 (duplicates 1)\"\n- \"Remove 6 (audience already knows this)\"\n- \"Combine 11 and 12\"\n\n**If user gives freeform feedback** (e.g., \"looks good\" or \"I like most of it but...\") instead of numbered selections, extract their preferences and proceed. Parse what they want kept/removed/changed and apply it.\n\n### Step 4: Gap Check\n\nBased on what they've selected, ask if there's anything important missing for the [SECTION NAME] section.\n\n### Step 5: Drafting\n\nUse `str_replace` to replace the placeholder text for this section with the actual drafted content.\n\nAnnounce the [SECTION NAME] section will be drafted now based on what they've selected.\n\n**If using artifacts:**\nAfter drafting, provide a link to the artifact.\n\nAsk them to read through it and indicate what to change. Note that being specific helps learning for the next sections.\n\n**If using a file (no artifacts):**\nAfter drafting, confirm completion.\n\nInform them the [SECTION NAME] section has been drafted in [filename]. Ask them to read through it and indicate what to change. Note that being specific helps learning for the next sections.\n\n**Key instruction for user (include when drafting the first section):**\nProvide a note: Instead of editing the doc directly, ask them to indicate what to change. This helps learning of their style for future sections. For example: \"Remove the X bullet - already covered by Y\" or \"Make the third paragraph more concise\".\n\n### Step 6: Iterative Refinement\n\nAs user provides feedback:\n- Use `str_replace` to make edits (never reprint the whole doc)\n- **If using artifacts:** Provide link to artifact after each edit\n- **If using files:** Just confirm edits are complete\n- If user edits doc directly and asks to read it: mentally note the changes they made and keep them in mind for future sections (this shows their preferences)\n\n**Continue iterating** until user is satisfied with the section.\n\n### Quality Checking\n\nAfter 3 consecutive iterations with no substantial changes, ask if anything can be removed without losing important information.\n\nWhen section is done, confirm [SECTION NAME] is complete. Ask if ready to move to the next section.\n\n**Repeat for all sections.**\n\n### Near Completion\n\nAs approaching completion (80%+ of sections done), announce intention to re-read the entire document and check for:\n- Flow and consistency across sections\n- Redundancy or contradictions\n- Anything that feels like \"slop\" or generic filler\n- Whether every sentence carries weight\n\nRead entire document and provide feedback.\n\n**When all sections are drafted and refined:**\nAnnounce all sections are drafted. Indicate intention to review the complete document one more time.\n\nReview for overall coherence, flow, completeness.\n\nProvide any final suggestions.\n\nAsk if ready to move to Reader Testing, or if they want to refine anything else.\n\n## Stage 3: Reader Testing\n\n**Goal:** Test the document with a fresh Claude (no context bleed) to verify it works for readers.\n\n**Instructions to user:**\nExplain that testing will now occur to see if the document actually works for readers. This catches blind spots - things that make sense to the authors but might confuse others.\n\n### Testing Approach\n\n**If access to sub-agents is available (e.g., in Claude Code):**\n\nPerform the testing directly without user involvement.\n\n### Step 1: Predict Reader Questions\n\nAnnounce intention to predict what questions readers might ask when trying to discover this document.\n\nGenerate 5-10 questions that readers would realistically ask.\n\n### Step 2: Test with Sub-Agent\n\nAnnounce that these questions will be tested with a fresh Claude instance (no context from this conversation).\n\nFor each question, invoke a sub-agent with just the document content and the question.\n\nSummarize what Reader Claude got right/wrong for each question.\n\n### Step 3: Run Additional Checks\n\nAnnounce additional checks will be performed.\n\nInvoke sub-agent to check for ambiguity, false assumptions, contradictions.\n\nSummarize any issues found.\n\n### Step 4: Report and Fix\n\nIf issues found:\nReport that Reader Claude struggled with specific issues.\n\nList the specific issues.\n\nIndicate intention to fix these gaps.\n\nLoop back to refinement for problematic sections.\n\n---\n\n**If no access to sub-agents (e.g., claude.ai web interface):**\n\nThe user will need to do the testing manually.\n\n### Step 1: Predict Reader Questions\n\nAsk what questions people might ask when trying to discover this document. What would they type into Claude.ai?\n\nGenerate 5-10 questions that readers would realistically ask.\n\n### Step 2: Setup Testing\n\nProvide testing instructions:\n1. Open a fresh Claude conversation: https://claude.ai\n2. Paste or share the document content (if using a shared doc platform with connectors enabled, provide the link)\n3. Ask Reader Claude the generated questions\n\nFor each question, instruct Reader Claude to provide:\n- The answer\n- Whether anything was ambiguous or unclear\n- What knowledge/context the doc assumes is already known\n\nCheck if Reader Claude gives correct answers or misinterprets anything.\n\n### Step 3: Additional Checks\n\nAlso ask Reader Claude:\n- \"What in this doc might be ambiguous or unclear to readers?\"\n- \"What knowledge or context does this doc assume readers already have?\"\n- \"Are there any internal contradictions or inconsistencies?\"\n\n### Step 4: Iterate Based on Results\n\nAsk what Reader Claude got wrong or struggled with. Indicate intention to fix those gaps.\n\nLoop back to refinement for any problematic sections.\n\n---\n\n### Exit Condition (Both Approaches)\n\nWhen Reader Claude consistently answers questions correctly and doesn't surface new gaps or ambiguities, the doc is ready.\n\n## Final Review\n\nWhen Reader Testing passes:\nAnnounce the doc has passed Reader Claude testing. Before completion:\n\n1. Recommend they do a final read-through themselves - they own this document and are responsible for its quality\n2. Suggest double-checking any facts, links, or technical details\n3. Ask them to verify it achieves the impact they wanted\n\nAsk if they want one more review, or if the work is done.\n\n**If user wants final review, provide it. Otherwise:**\nAnnounce document completion. Provide a few final tips:\n- Consider linking this conversation in an appendix so readers can see how the doc was developed\n- Use appendices to provide depth without bloating the main doc\n- Update the doc as feedback is received from real readers\n\n## Tips for Effective Guidance\n\n**Tone:**\n- Be direct and procedural\n- Explain rationale briefly when it affects user behavior\n- Don't try to \"sell\" the approach - just execute it\n\n**Handling Deviations:**\n- If user wants to skip a stage: Ask if they want to skip this and write freeform\n- If user seems frustrated: Acknowledge this is taking longer than expected. Suggest ways to move faster\n- Always give user agency to adjust the process\n\n**Context Management:**\n- Throughout, if context is missing on something mentioned, proactively ask\n- Don't let gaps accumulate - address them as they come up\n\n**Artifact Management:**\n- Use `create_file` for drafting full sections\n- Use `str_replace` for all edits\n- Provide artifact link after every change\n- Never use artifacts for brainstorming lists - that's just conversation\n\n**Quality over Speed:**\n- Don't rush through stages\n- Each iteration should make meaningful improvements\n- The goal is a document that actually works for readers",
    "id": "doc-coauthoring",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/doc-coauthoring",
    "name_zh": "ÊñáÊ°£Âçè‰Ωú",
    "description_zh": "Guide users through a structured workflow for co-authoring documentation. ÈÄÇÁî®‰∫é user wants to write documentation, proposals, technical specs, decision docs, or similar structured content. This workflow helps users efficiently transfer context, refine content through iteration, and verify the doc works for readers. Trigger when user mentions writing docs, creating proposals, drafting specs, or similar documentation tasks.",
    "body_zh": "# Doc Co-Authoring Workflow\n\nThis skill provides a structured workflow for guiding users through collaborative document creation. Act as an active guide, walking users through three stages: Context Gathering, Refinement & Structure, and Reader Testing.\n\n## When to Offer This Workflow\n\n**Trigger conditions:**\n- User mentions writing documentation: \"write a doc\", \"draft a proposal\", \"create a spec\", \"write up\"\n- User mentions specific doc types: \"PRD\", \"design doc\", \"decision doc\", \"RFC\"\n- User seems to be starting a substantial writing task\n\n**Initial offer:**\nOffer the user a structured workflow for co-authoring the document. Explain the three stages:\n\n1. **Context Gathering**: User provides all relevant context while Claude asks clarifying questions\n2. **Refinement & Structure**: Iteratively build each section through brainstorming and editing\n3. **Reader Testing**: Test the doc with a fresh Claude (no context) to catch blind spots before others read it\n\nExplain that this approach helps ensure the doc works well when others read it (including when they paste it into Claude). Ask if they want to try this workflow or prefer to work freeform.\n\nIf user declines, work freeform. If user accepts, proceed to Stage 1.\n\n## Stage 1: Context Gathering\n\n**Goal:** Close the gap between what the user knows and what Claude knows, enabling smart guidance later.\n\n### Initial Questions\n\nStart by asking the user for meta-context about the document:\n\n1. What type of document is this? (e.g., technical spec, decision doc, proposal)\n2. Who's the primary audience?\n3. What's the desired impact when someone reads this?\n4. Is there a template or specific format to follow?\n5. Any other constraints or context to know?\n\nInform them they can answer in shorthand or dump information however works best for them.\n\n**If user provides a template or mentions a doc type:**\n- Ask if they have a template document to share\n- If they provide a link to a shared document, use the appropriate integration to fetch it\n- If they provide a file, read it\n\n**If user mentions editing an existing shared document:**\n- Use the appropriate integration to read the current state\n- Check for images without alt-text\n- If images exist without alt-text, explain that when others use Claude to understand the doc, Claude won't be able to see them. Ask if they want alt-text generated. If so, request they paste each image into chat for descriptive alt-text generation.\n\n### Info Dumping\n\nOnce initial questions are answered, encourage the user to dump all the context they have. Request information such as:\n- Background on the project/problem\n- Related team discussions or shared documents\n- Why alternative solutions aren't being used\n- Organizational context (team dynamics, past incidents, politics)\n- Timeline pressures or constraints\n- Technical architecture or dependencies\n- Stakeholder concerns\n\nAdvise them not to worry about organizing it - just get it all out. Offer multiple ways to provide context:\n- Info dump stream-of-consciousness\n- Point to team channels or threads to read\n- Link to shared documents\n\n**If integrations are available** (e.g., Slack, Teams, Google Drive, SharePoint, or other MCP servers), mention that these can be used to pull in context directly.\n\n**If no integrations are detected and in Claude.ai or Claude app:** Suggest they can enable connectors in their Claude settings to allow pulling context from messaging apps and document storage directly.\n\nInform them clarifying questions will be asked once they've done their initial dump.\n\n**During context gathering:**\n\n- If user mentions team channels or shared documents:\n  - If integrations available: Inform them the content will be read now, then use the appropriate integration\n  - If integrations not available: Explain lack of access. Suggest they enable connectors in Claude settings, or paste the relevant content directly.\n\n- If user mentions entities/projects that are unknown:\n  - Ask if connected tools should be searched to learn more\n  - Wait for user confirmation before searching\n\n- As user provides context, track what's being learned and what's still unclear\n\n**Asking clarifying questions:**\n\nWhen user signals they've done their initial dump (or after substantial context provided), ask clarifying questions to ensure understanding:\n\nGenerate 5-10 numbered questions based on gaps in the context.\n\nInform them they can use shorthand to answer (e.g., \"1: yes, 2: see #channel, 3: no because backwards compat\"), link to more docs, point to channels to read, or just keep info-dumping. Whatever's most efficient for them.\n\n**Exit condition:**\nSufficient context has been gathered when questions show understanding - when edge cases and trade-offs can be asked about without needing basics explained.\n\n**Transition:**\nAsk if there's any more context they want to provide at this stage, or if it's time to move on to drafting the document.\n\nIf user wants to add more, let them. When ready, proceed to Stage 2.\n\n## Stage 2: Refinement & Structure\n\n**Goal:** Build the document section by section through brainstorming, curation, and iterative refinement.\n\n**Instructions to user:**\nExplain that the document will be built section by section. For each section:\n1. Clarifying questions will be asked about what to include\n2. 5-20 options will be brainstormed\n3. User will indicate what to keep/remove/combine\n4. The section will be drafted\n5. It will be refined through surgical edits\n\nStart with whichever section has the most unknowns (usually the core decision/proposal), then work through the rest.\n\n**Section ordering:**\n\nIf the document structure is clear:\nAsk which section they'd like to start with.\n\nSuggest starting with whichever section has the most unknowns. For decision docs, that's usually the core proposal. For specs, it's typically the technical approach. Summary sections are best left for last.\n\nIf user doesn't know what sections they need:\nBased on the type of document and template, suggest 3-5 sections appropriate for the doc type.\n\nAsk if this structure works, or if they want to adjust it.\n\n**Once structure is agreed:**\n\nCreate the initial document structure with placeholder text for all sections.\n\n**If access to artifacts is available:**\nUse `create_file` to create an artifact. This gives both Claude and the user a scaffold to work from.\n\nInform them that the initial structure with placeholders for all sections will be created.\n\nCreate artifact with all section headers and brief placeholder text like \"[To be written]\" or \"[Content here]\".\n\nProvide the scaffold link and indicate it's time to fill in each section.\n\n**If no access to artifacts:**\nCreate a markdown file in the working directory. Name it appropriately (e.g., `decision-doc.md`, `technical-spec.md`).\n\nInform them that the initial structure with placeholders for all sections will be created.\n\nCreate file with all section headers and placeholder text.\n\nConfirm the filename has been created and indicate it's time to fill in each section.\n\n**For each section:**\n\n### Step 1: Clarifying Questions\n\nAnnounce work will begin on the [SECTION NAME] section. Ask 5-10 clarifying questions about what should be included:\n\nGenerate 5-10 specific questions based on context and section purpose.\n\nInform them they can answer in shorthand or just indicate what's important to cover.\n\n### Step 2: Brainstorming\n\nFor the [SECTION NAME] section, brainstorm [5-20] things that might be included, depending on the section's complexity. Look for:\n- Context shared that might have been forgotten\n- Angles or considerations not yet mentioned\n\nGenerate 5-20 numbered options based on section complexity. At the end, offer to brainstorm more if they want additional options.\n\n### Step 3: Curation\n\nAsk which points should be kept, removed, or combined. Request brief justifications to help learn priorities for the next sections.\n\nProvide examples:\n- \"Keep 1,4,7,9\"\n- \"Remove 3 (duplicates 1)\"\n- \"Remove 6 (audience already knows this)\"\n- \"Combine 11 and 12\"\n\n**If user gives freeform feedback** (e.g., \"looks good\" or \"I like most of it but...\") instead of numbered selections, extract their preferences and proceed. Parse what they want kept/removed/changed and apply it.\n\n### Step 4: Gap Check\n\nBased on what they've selected, ask if there's anything important missing for the [SECTION NAME] section.\n\n### Step 5: Drafting\n\nUse `str_replace` to replace the placeholder text for this section with the actual drafted content.\n\nAnnounce the [SECTION NAME] section will be drafted now based on what they've selected.\n\n**If using artifacts:**\nAfter drafting, provide a link to the artifact.\n\nAsk them to read through it and indicate what to change. Note that being specific helps learning for the next sections.\n\n**If using a file (no artifacts):**\nAfter drafting, confirm completion.\n\nInform them the [SECTION NAME] section has been drafted in [filename]. Ask them to read through it and indicate what to change. Note that being specific helps learning for the next sections.\n\n**Key instruction for user (include when drafting the first section):**\nProvide a note: Instead of editing the doc directly, ask them to indicate what to change. This helps learning of their style for future sections. For example: \"Remove the X bullet - already covered by Y\" or \"Make the third paragraph more concise\".\n\n### Step 6: Iterative Refinement\n\nAs user provides feedback:\n- Use `str_replace` to make edits (never reprint the whole doc)\n- **If using artifacts:** Provide link to artifact after each edit\n- **If using files:** Just confirm edits are complete\n- If user edits doc directly and asks to read it: mentally note the changes they made and keep them in mind for future sections (this shows their preferences)\n\n**Continue iterating** until user is satisfied with the section.\n\n### Quality Checking\n\nAfter 3 consecutive iterations with no substantial changes, ask if anything can be removed without losing important information.\n\nWhen section is done, confirm [SECTION NAME] is complete. Ask if ready to move to the next section.\n\n**Repeat for all sections.**\n\n### Near Completion\n\nAs approaching completion (80%+ of sections done), announce intention to re-read the entire document and check for:\n- Flow and consistency across sections\n- Redundancy or contradictions\n- Anything that feels like \"slop\" or generic filler\n- Whether every sentence carries weight\n\nRead entire document and provide feedback.\n\n**When all sections are drafted and refined:**\nAnnounce all sections are drafted. Indicate intention to review the complete document one more time.\n\nReview for overall coherence, flow, completeness.\n\nProvide any final suggestions.\n\nAsk if ready to move to Reader Testing, or if they want to refine anything else.\n\n## Stage 3: Reader Testing\n\n**Goal:** Test the document with a fresh Claude (no context bleed) to verify it works for readers.\n\n**Instructions to user:**\nExplain that testing will now occur to see if the document actually works for readers. This catches blind spots - things that make sense to the authors but might confuse others.\n\n### Testing Approach\n\n**If access to sub-agents is available (e.g., in Claude Code):**\n\nPerform the testing directly without user involvement.\n\n### Step 1: Predict Reader Questions\n\nAnnounce intention to predict what questions readers might ask when trying to discover this document.\n\nGenerate 5-10 questions that readers would realistically ask.\n\n### Step 2: Test with Sub-Agent\n\nAnnounce that these questions will be tested with a fresh Claude instance (no context from this conversation).\n\nFor each question, invoke a sub-agent with just the document content and the question.\n\nSummarize what Reader Claude got right/wrong for each question.\n\n### Step 3: Run Additional Checks\n\nAnnounce additional checks will be performed.\n\nInvoke sub-agent to check for ambiguity, false assumptions, contradictions.\n\nSummarize any issues found.\n\n### Step 4: Report and Fix\n\nIf issues found:\nReport that Reader Claude struggled with specific issues.\n\nList the specific issues.\n\nIndicate intention to fix these gaps.\n\nLoop back to refinement for problematic sections.\n\n---\n\n**If no access to sub-agents (e.g., claude.ai web interface):**\n\nThe user will need to do the testing manually.\n\n### Step 1: Predict Reader Questions\n\nAsk what questions people might ask when trying to discover this document. What would they type into Claude.ai?\n\nGenerate 5-10 questions that readers would realistically ask.\n\n### Step 2: Setup Testing\n\nProvide testing instructions:\n1. Open a fresh Claude conversation: https://claude.ai\n2. Paste or share the document content (if using a shared doc platform with connectors enabled, provide the link)\n3. Ask Reader Claude the generated questions\n\nFor each question, instruct Reader Claude to provide:\n- The answer\n- Whether anything was ambiguous or unclear\n- What knowledge/context the doc assumes is already known\n\nCheck if Reader Claude gives correct answers or misinterprets anything.\n\n### Step 3: Additional Checks\n\nAlso ask Reader Claude:\n- \"What in this doc might be ambiguous or unclear to readers?\"\n- \"What knowledge or context does this doc assume readers already have?\"\n- \"Are there any internal contradictions or inconsistencies?\"\n\n### Step 4: Iterate Based on Results\n\nAsk what Reader Claude got wrong or struggled with. Indicate intention to fix those gaps.\n\nLoop back to refinement for any problematic sections.\n\n---\n\n### Exit Condition (Both Approaches)\n\nWhen Reader Claude consistently answers questions correctly and doesn't surface new gaps or ambiguities, the doc is ready.\n\n## Final Review\n\nWhen Reader Testing passes:\nAnnounce the doc has passed Reader Claude testing. Before completion:\n\n1. Recommend they do a final read-through themselves - they own this document and are responsible for its quality\n2. Suggest double-checking any facts, links, or technical details\n3. Ask them to verify it achieves the impact they wanted\n\nAsk if they want one more review, or if the work is done.\n\n**If user wants final review, provide it. Otherwise:**\nAnnounce document completion. Provide a few final tips:\n- Consider linking this conversation in an appendix so readers can see how the doc was developed\n- Use appendices to provide depth without bloating the main doc\n- Update the doc as feedback is received from real readers\n\n## Tips for Effective Guidance\n\n**Tone:**\n- Be direct and procedural\n- Explain rationale briefly when it affects user behavior\n- Don't try to \"sell\" the approach - just execute it\n\n**Handling Deviations:**\n- If user wants to skip a stage: Ask if they want to skip this and write freeform\n- If user seems frustrated: Acknowledge this is taking longer than expected. Suggest ways to move faster\n- Always give user agency to adjust the process\n\n**Context Management:**\n- Throughout, if context is missing on something mentioned, proactively ask\n- Don't let gaps accumulate - address them as they come up\n\n**Artifact Management:**\n- Use `create_file` for drafting full sections\n- Use `str_replace` for all edits\n- Provide artifact link after every change\n- Never use artifacts for brainstorming lists - that's just conversation\n\n**Quality over Speed:**\n- Don't rush through stages\n- Each iteration should make meaningful improvements\n- The goal is a document that actually works for readers"
  },
  {
    "name": "docx",
    "description": "Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. When Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks",
    "body": "# DOCX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .docx file. A .docx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Workflow Decision Tree\n\n### Reading/Analyzing Content\nUse \"Text extraction\" or \"Raw XML access\" sections below\n\n### Creating New Document\nUse \"Creating a new Word document\" workflow\n\n### Editing Existing Document\n- **Your own document + simple changes**\n  Use \"Basic OOXML editing\" workflow\n\n- **Someone else's document**\n  Use **\"Redlining workflow\"** (recommended default)\n\n- **Legal, academic, business, or government docs**\n  Use **\"Redlining workflow\"** (required)\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a document, you should convert the document to markdown using pandoc. Pandoc provides excellent support for preserving document structure and can show tracked changes:\n\n```bash\n# Convert document to markdown with tracked changes\npandoc --track-changes=all path-to-file.docx -o output.md\n# Options: --track-changes=accept/reject/all\n```\n\n### Raw XML access\nYou need raw XML access for: comments, complex formatting, document structure, embedded media, and metadata. For any of these features, you'll need to unpack a document and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_directory>`\n\n#### Key file structures\n* `word/document.xml` - Main document contents\n* `word/comments.xml` - Comments referenced in document.xml\n* `word/media/` - Embedded images and media files\n* Tracked changes use `<w:ins>` (insertions) and `<w:del>` (deletions) tags\n\n## Creating a new Word document\n\nWhen creating a new Word document from scratch, use **docx-js**, which allows you to create Word documents using JavaScript/TypeScript.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`docx-js.md`](docx-js.md) (~500 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for detailed syntax, critical formatting rules, and best practices before proceeding with document creation.\n2. Create a JavaScript/TypeScript file using Document, Paragraph, TextRun components (You can assume all dependencies are installed, but if not, refer to the dependencies section below)\n3. Export as .docx using Packer.toBuffer()\n\n## Editing an existing Word document\n\nWhen editing an existing Word document, use the **Document library** (a Python library for OOXML manipulation). The library automatically handles infrastructure setup and provides methods for document manipulation. For complex scenarios, you can access the underlying DOM directly through the library.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~600 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for the Document library API and XML patterns for directly editing document files.\n2. Unpack the document: `python ooxml/scripts/unpack.py <office_file> <output_directory>`\n3. Create and run a Python script using the Document library (see \"Document Library\" section in ooxml.md)\n4. Pack the final document: `python ooxml/scripts/pack.py <input_directory> <office_file>`\n\nThe Document library provides both high-level methods for common operations and direct DOM access for complex scenarios.\n\n## Redlining workflow for document review\n\nThis workflow allows you to plan comprehensive tracked changes using markdown before implementing them in OOXML. **CRITICAL**: For complete tracked changes, you must implement ALL changes systematically.\n\n**Batching Strategy**: Group related changes into batches of 3-10 changes. This makes debugging manageable while maintaining efficiency. Test each batch before moving to the next.\n\n**Principle: Minimal, Precise Edits**\nWhen implementing tracked changes, only mark text that actually changes. Repeating unchanged text makes edits harder to review and appears unprofessional. Break replacements into: [unchanged text] + [deletion] + [insertion] + [unchanged text]. Preserve the original run's RSID for unchanged text by extracting the `<w:r>` element from the original and reusing it.\n\nExample - Changing \"30 days\" to \"60 days\" in a sentence:\n```python\n# BAD - Replaces entire sentence\n'<w:del><w:r><w:delText>The term is 30 days.</w:delText></w:r></w:del><w:ins><w:r><w:t>The term is 60 days.</w:t></w:r></w:ins>'\n\n# GOOD - Only marks what changed, preserves original <w:r> for unchanged text\n'<w:r w:rsidR=\"00AB12CD\"><w:t>The term is </w:t></w:r><w:del><w:r><w:delText>30</w:delText></w:r></w:del><w:ins><w:r><w:t>60</w:t></w:r></w:ins><w:r w:rsidR=\"00AB12CD\"><w:t> days.</w:t></w:r>'\n```\n\n### Tracked changes workflow\n\n1. **Get markdown representation**: Convert document to markdown with tracked changes preserved:\n   ```bash\n   pandoc --track-changes=all path-to-file.docx -o current.md\n   ```\n\n2. **Identify and group changes**: Review the document and identify ALL changes needed, organizing them into logical batches:\n\n   **Location methods** (for finding changes in XML):\n   - Section/heading numbers (e.g., \"Section 3.2\", \"Article IV\")\n   - Paragraph identifiers if numbered\n   - Grep patterns with unique surrounding text\n   - Document structure (e.g., \"first paragraph\", \"signature block\")\n   - **DO NOT use markdown line numbers** - they don't map to XML structure\n\n   **Batch organization** (group 3-10 related changes per batch):\n   - By section: \"Batch 1: Section 2 amendments\", \"Batch 2: Section 5 updates\"\n   - By type: \"Batch 1: Date corrections\", \"Batch 2: Party name changes\"\n   - By complexity: Start with simple text replacements, then tackle complex structural changes\n   - Sequential: \"Batch 1: Pages 1-3\", \"Batch 2: Pages 4-6\"\n\n3. **Read documentation and unpack**:\n   - **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~600 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Pay special attention to the \"Document Library\" and \"Tracked Change Patterns\" sections.\n   - **Unpack the document**: `python ooxml/scripts/unpack.py <file.docx> <dir>`\n   - **Note the suggested RSID**: The unpack script will suggest an RSID to use for your tracked changes. Copy this RSID for use in step 4b.\n\n4. **Implement changes in batches**: Group changes logically (by section, by type, or by proximity) and implement them together in a single script. This approach:\n   - Makes debugging easier (smaller batch = easier to isolate errors)\n   - Allows incremental progress\n   - Maintains efficiency (batch size of 3-10 changes works well)\n\n   **Suggested batch groupings:**\n   - By document section (e.g., \"Section 3 changes\", \"Definitions\", \"Termination clause\")\n   - By change type (e.g., \"Date changes\", \"Party name updates\", \"Legal term replacements\")\n   - By proximity (e.g., \"Changes on pages 1-3\", \"Changes in first half of document\")\n\n   For each batch of related changes:\n\n   **a. Map text to XML**: Grep for text in `word/document.xml` to verify how text is split across `<w:r>` elements.\n\n   **b. Create and run script**: Use `get_node` to find nodes, implement changes, then `doc.save()`. See **\"Document Library\"** section in ooxml.md for patterns.\n\n   **Note**: Always grep `word/document.xml` immediately before writing a script to get current line numbers and verify text content. Line numbers change after each script run.\n\n5. **Pack the document**: After all batches are complete, convert the unpacked directory back to .docx:\n   ```bash\n   python ooxml/scripts/pack.py unpacked reviewed-document.docx\n   ```\n\n6. **Final verification**: Do a comprehensive check of the complete document:\n   - Convert final document to markdown:\n     ```bash\n     pandoc --track-changes=all reviewed-document.docx -o verification.md\n     ```\n   - Verify ALL changes were applied correctly:\n     ```bash\n     grep \"original phrase\" verification.md  # Should NOT find it\n     grep \"replacement phrase\" verification.md  # Should find it\n     ```\n   - Check that no unintended changes were introduced\n\n\n## Converting Documents to Images\n\nTo visually analyze Word documents, convert them to images using a two-step process:\n\n1. **Convert DOCX to PDF**:\n   ```bash\n   soffice --headless --convert-to pdf document.docx\n   ```\n\n2. **Convert PDF pages to JPEG images**:\n   ```bash\n   pdftoppm -jpeg -r 150 document.pdf page\n   ```\n   This creates files like `page-1.jpg`, `page-2.jpg`, etc.\n\nOptions:\n- `-r 150`: Sets resolution to 150 DPI (adjust for quality/size balance)\n- `-jpeg`: Output JPEG format (use `-png` for PNG if preferred)\n- `-f N`: First page to convert (e.g., `-f 2` starts from page 2)\n- `-l N`: Last page to convert (e.g., `-l 5` stops at page 5)\n- `page`: Prefix for output files\n\nExample for specific range:\n```bash\npdftoppm -jpeg -r 150 -f 2 -l 5 document.pdf page  # Converts only pages 2-5\n```\n\n## Code Style Guidelines\n**IMPORTANT**: When generating code for DOCX operations:\n- Write concise code\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n## Dependencies\n\nRequired dependencies (install if not available):\n\n- **pandoc**: `sudo apt-get install pandoc` (for text extraction)\n- **docx**: `npm install -g docx` (for creating new documents)\n- **LibreOffice**: `sudo apt-get install libreoffice` (for PDF conversion)\n- **Poppler**: `sudo apt-get install poppler-utils` (for pdftoppm to convert PDF to images)\n- **defusedxml**: `pip install defusedxml` (for secure XML parsing)",
    "id": "docx",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/docx",
    "name_zh": "Word ÊñáÊ°£Â§ÑÁêÜ",
    "description_zh": "Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. When Claude needs to work with professional documents (.docx files) for: (1) ÂàõÂª∫ new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks",
    "body_zh": "# DOCX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .docx file. A .docx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Workflow Decision Tree\n\n### Reading/Analyzing Content\nUse \"Text extraction\" or \"Raw XML access\" sections below\n\n### Creating New Document\nUse \"Creating a new Word document\" workflow\n\n### Editing Existing Document\n- **Your own document + simple changes**\n  Use \"Basic OOXML editing\" workflow\n\n- **Someone else's document**\n  Use **\"Redlining workflow\"** (recommended default)\n\n- **Legal, academic, business, or government docs**\n  Use **\"Redlining workflow\"** (required)\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a document, you should convert the document to markdown using pandoc. Pandoc provides excellent support for preserving document structure and can show tracked changes:\n\n```bash\n# Convert document to markdown with tracked changes\npandoc --track-changes=all path-to-file.docx -o output.md\n# Options: --track-changes=accept/reject/all\n```\n\n### Raw XML access\nYou need raw XML access for: comments, complex formatting, document structure, embedded media, and metadata. For any of these features, you'll need to unpack a document and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_directory>`\n\n#### Key file structures\n* `word/document.xml` - Main document contents\n* `word/comments.xml` - Comments referenced in document.xml\n* `word/media/` - Embedded images and media files\n* Tracked changes use `<w:ins>` (insertions) and `<w:del>` (deletions) tags\n\n## Creating a new Word document\n\nWhen creating a new Word document from scratch, use **docx-js**, which allows you to create Word documents using JavaScript/TypeScript.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`docx-js.md`](docx-js.md) (~500 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for detailed syntax, critical formatting rules, and best practices before proceeding with document creation.\n2. Create a JavaScript/TypeScript file using Document, Paragraph, TextRun components (You can assume all dependencies are installed, but if not, refer to the dependencies section below)\n3. Export as .docx using Packer.toBuffer()\n\n## Editing an existing Word document\n\nWhen editing an existing Word document, use the **Document library** (a Python library for OOXML manipulation). The library automatically handles infrastructure setup and provides methods for document manipulation. For complex scenarios, you can access the underlying DOM directly through the library.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~600 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for the Document library API and XML patterns for directly editing document files.\n2. Unpack the document: `python ooxml/scripts/unpack.py <office_file> <output_directory>`\n3. Create and run a Python script using the Document library (see \"Document Library\" section in ooxml.md)\n4. Pack the final document: `python ooxml/scripts/pack.py <input_directory> <office_file>`\n\nThe Document library provides both high-level methods for common operations and direct DOM access for complex scenarios.\n\n## Redlining workflow for document review\n\nThis workflow allows you to plan comprehensive tracked changes using markdown before implementing them in OOXML. **CRITICAL**: For complete tracked changes, you must implement ALL changes systematically.\n\n**Batching Strategy**: Group related changes into batches of 3-10 changes. This makes debugging manageable while maintaining efficiency. Test each batch before moving to the next.\n\n**Principle: Minimal, Precise Edits**\nWhen implementing tracked changes, only mark text that actually changes. Repeating unchanged text makes edits harder to review and appears unprofessional. Break replacements into: [unchanged text] + [deletion] + [insertion] + [unchanged text]. Preserve the original run's RSID for unchanged text by extracting the `<w:r>` element from the original and reusing it.\n\nExample - Changing \"30 days\" to \"60 days\" in a sentence:\n```python\n# BAD - Replaces entire sentence\n'<w:del><w:r><w:delText>The term is 30 days.</w:delText></w:r></w:del><w:ins><w:r><w:t>The term is 60 days.</w:t></w:r></w:ins>'\n\n# GOOD - Only marks what changed, preserves original <w:r> for unchanged text\n'<w:r w:rsidR=\"00AB12CD\"><w:t>The term is </w:t></w:r><w:del><w:r><w:delText>30</w:delText></w:r></w:del><w:ins><w:r><w:t>60</w:t></w:r></w:ins><w:r w:rsidR=\"00AB12CD\"><w:t> days.</w:t></w:r>'\n```\n\n### Tracked changes workflow\n\n1. **Get markdown representation**: Convert document to markdown with tracked changes preserved:\n   ```bash\n   pandoc --track-changes=all path-to-file.docx -o current.md\n   ```\n\n2. **Identify and group changes**: Review the document and identify ALL changes needed, organizing them into logical batches:\n\n   **Location methods** (for finding changes in XML):\n   - Section/heading numbers (e.g., \"Section 3.2\", \"Article IV\")\n   - Paragraph identifiers if numbered\n   - Grep patterns with unique surrounding text\n   - Document structure (e.g., \"first paragraph\", \"signature block\")\n   - **DO NOT use markdown line numbers** - they don't map to XML structure\n\n   **Batch organization** (group 3-10 related changes per batch):\n   - By section: \"Batch 1: Section 2 amendments\", \"Batch 2: Section 5 updates\"\n   - By type: \"Batch 1: Date corrections\", \"Batch 2: Party name changes\"\n   - By complexity: Start with simple text replacements, then tackle complex structural changes\n   - Sequential: \"Batch 1: Pages 1-3\", \"Batch 2: Pages 4-6\"\n\n3. **Read documentation and unpack**:\n   - **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~600 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Pay special attention to the \"Document Library\" and \"Tracked Change Patterns\" sections.\n   - **Unpack the document**: `python ooxml/scripts/unpack.py <file.docx> <dir>`\n   - **Note the suggested RSID**: The unpack script will suggest an RSID to use for your tracked changes. Copy this RSID for use in step 4b.\n\n4. **Implement changes in batches**: Group changes logically (by section, by type, or by proximity) and implement them together in a single script. This approach:\n   - Makes debugging easier (smaller batch = easier to isolate errors)\n   - Allows incremental progress\n   - Maintains efficiency (batch size of 3-10 changes works well)\n\n   **Suggested batch groupings:**\n   - By document section (e.g., \"Section 3 changes\", \"Definitions\", \"Termination clause\")\n   - By change type (e.g., \"Date changes\", \"Party name updates\", \"Legal term replacements\")\n   - By proximity (e.g., \"Changes on pages 1-3\", \"Changes in first half of document\")\n\n   For each batch of related changes:\n\n   **a. Map text to XML**: Grep for text in `word/document.xml` to verify how text is split across `<w:r>` elements.\n\n   **b. Create and run script**: Use `get_node` to find nodes, implement changes, then `doc.save()`. See **\"Document Library\"** section in ooxml.md for patterns.\n\n   **Note**: Always grep `word/document.xml` immediately before writing a script to get current line numbers and verify text content. Line numbers change after each script run.\n\n5. **Pack the document**: After all batches are complete, convert the unpacked directory back to .docx:\n   ```bash\n   python ooxml/scripts/pack.py unpacked reviewed-document.docx\n   ```\n\n6. **Final verification**: Do a comprehensive check of the complete document:\n   - Convert final document to markdown:\n     ```bash\n     pandoc --track-changes=all reviewed-document.docx -o verification.md\n     ```\n   - Verify ALL changes were applied correctly:\n     ```bash\n     grep \"original phrase\" verification.md  # Should NOT find it\n     grep \"replacement phrase\" verification.md  # Should find it\n     ```\n   - Check that no unintended changes were introduced\n\n\n## Converting Documents to Images\n\nTo visually analyze Word documents, convert them to images using a two-step process:\n\n1. **Convert DOCX to PDF**:\n   ```bash\n   soffice --headless --convert-to pdf document.docx\n   ```\n\n2. **Convert PDF pages to JPEG images**:\n   ```bash\n   pdftoppm -jpeg -r 150 document.pdf page\n   ```\n   This creates files like `page-1.jpg`, `page-2.jpg`, etc.\n\nOptions:\n- `-r 150`: Sets resolution to 150 DPI (adjust for quality/size balance)\n- `-jpeg`: Output JPEG format (use `-png` for PNG if preferred)\n- `-f N`: First page to convert (e.g., `-f 2` starts from page 2)\n- `-l N`: Last page to convert (e.g., `-l 5` stops at page 5)\n- `page`: Prefix for output files\n\nExample for specific range:\n```bash\npdftoppm -jpeg -r 150 -f 2 -l 5 document.pdf page  # Converts only pages 2-5\n```\n\n## Code Style Guidelines\n**IMPORTANT**: When generating code for DOCX operations:\n- Write concise code\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n## Dependencies\n\nRequired dependencies (install if not available):\n\n- **pandoc**: `sudo apt-get install pandoc` (for text extraction)\n- **docx**: `npm install -g docx` (for creating new documents)\n- **LibreOffice**: `sudo apt-get install libreoffice` (for PDF conversion)\n- **Poppler**: `sudo apt-get install poppler-utils` (for pdftoppm to convert PDF to images)\n- **defusedxml**: `pip install defusedxml` (for secure XML parsing)"
  },
  {
    "name": "frontend-design",
    "description": "Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, pages, artifacts, posters, or applications (examples include websites, landing pages, dashboards, React components, HTML/CSS layouts, or when styling/beautifying any web UI). Generates creative, polished code and UI design that avoids generic AI aesthetics.",
    "body": "This skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc. There are so many flavors to choose from. Use these for inspiration but design one that is true to the aesthetic direction.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics; unexpected, characterful font choices. Pair a distinctive display font with a refined body font.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes.\n- **Motion**: Use animations for effects and micro-interactions. Prioritize CSS-only solutions for HTML. Use Motion library for React when available. Focus on high-impact moments: one well-orchestrated page load with staggered reveals (animation-delay) creates more delight than scattered micro-interactions. Use scroll-triggering and hover states that surprise.\n- **Spatial Composition**: Unexpected layouts. Asymmetry. Overlap. Diagonal flow. Grid-breaking elements. Generous negative space OR controlled density.\n- **Backgrounds & Visual Details**: Create atmosphere and depth rather than defaulting to solid colors. Add contextual effects and textures that match the overall aesthetic. Apply creative forms like gradient meshes, noise textures, geometric patterns, layered transparencies, dramatic shadows, decorative borders, custom cursors, and grain overlays.\n\nNEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial, system fonts), cliched color schemes (particularly purple gradients on white backgrounds), predictable layouts and component patterns, and cookie-cutter design that lacks context-specific character.\n\nInterpret creatively and make unexpected choices that feel genuinely designed for the context. No design should be the same. Vary between light and dark themes, different fonts, different aesthetics. NEVER converge on common choices (Space Grotesk, for example) across generations.\n\n**IMPORTANT**: Match implementation complexity to the aesthetic vision. Maximalist designs need elaborate code with extensive animations and effects. Minimalist or refined designs need restraint, precision, and careful attention to spacing, typography, and subtle details. Elegance comes from executing the vision well.\n\nRemember: Claude is capable of extraordinary creative work. Don't hold back, show what can truly be created when thinking outside the box and committing fully to a distinctive vision.",
    "id": "frontend-design",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/frontend-design",
    "name_zh": "ÂâçÁ´ØËÆæËÆ°",
    "description_zh": "Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, pages, artifacts, posters, or applications (examples include websites, landing pages, dashboards, React components, HTML/CSS layouts, or when styling/beautifying any web UI). ÁîüÊàês creative, polished code and UI design that avoids generic AI aesthetics.",
    "body_zh": "This skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc. There are so many flavors to choose from. Use these for inspiration but design one that is true to the aesthetic direction.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics; unexpected, characterful font choices. Pair a distinctive display font with a refined body font.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes.\n- **Motion**: Use animations for effects and micro-interactions. Prioritize CSS-only solutions for HTML. Use Motion library for React when available. Focus on high-impact moments: one well-orchestrated page load with staggered reveals (animation-delay) creates more delight than scattered micro-interactions. Use scroll-triggering and hover states that surprise.\n- **Spatial Composition**: Unexpected layouts. Asymmetry. Overlap. Diagonal flow. Grid-breaking elements. Generous negative space OR controlled density.\n- **Backgrounds & Visual Details**: Create atmosphere and depth rather than defaulting to solid colors. Add contextual effects and textures that match the overall aesthetic. Apply creative forms like gradient meshes, noise textures, geometric patterns, layered transparencies, dramatic shadows, decorative borders, custom cursors, and grain overlays.\n\nNEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial, system fonts), cliched color schemes (particularly purple gradients on white backgrounds), predictable layouts and component patterns, and cookie-cutter design that lacks context-specific character.\n\nInterpret creatively and make unexpected choices that feel genuinely designed for the context. No design should be the same. Vary between light and dark themes, different fonts, different aesthetics. NEVER converge on common choices (Space Grotesk, for example) across generations.\n\n**IMPORTANT**: Match implementation complexity to the aesthetic vision. Maximalist designs need elaborate code with extensive animations and effects. Minimalist or refined designs need restraint, precision, and careful attention to spacing, typography, and subtle details. Elegance comes from executing the vision well.\n\nRemember: Claude is capable of extraordinary creative work. Don't hold back, show what can truly be created when thinking outside the box and committing fully to a distinctive vision."
  },
  {
    "name": "internal-comms",
    "description": "A set of resources to help me write all kinds of internal communications, using the formats that my company likes to use. Claude should use this skill whenever asked to write some sort of internal communications (status reports, leadership updates, 3P updates, company newsletters, FAQs, incident reports, project updates, etc.).",
    "body": "## When to use this skill\nTo write internal communications, use this skill for:\n- 3P updates (Progress, Plans, Problems)\n- Company newsletters\n- FAQ responses\n- Status reports\n- Leadership updates\n- Project updates\n- Incident reports\n\n## How to use this skill\n\nTo write any internal communication:\n\n1. **Identify the communication type** from the request\n2. **Load the appropriate guideline file** from the `examples/` directory:\n    - `examples/3p-updates.md` - For Progress/Plans/Problems team updates\n    - `examples/company-newsletter.md` - For company-wide newsletters\n    - `examples/faq-answers.md` - For answering frequently asked questions\n    - `examples/general-comms.md` - For anything else that doesn't explicitly match one of the above\n3. **Follow the specific instructions** in that file for formatting, tone, and content gathering\n\nIf the communication type doesn't match any existing guideline, ask for clarification or more context about the desired format.\n\n## Keywords\n3P updates, company newsletter, company comms, weekly update, faqs, common questions, updates, internal comms",
    "id": "internal-comms",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/internal-comms",
    "name_zh": "ÂÜÖÈÉ®Ê≤üÈÄö",
    "description_zh": "A set of resources to help me write all kinds of internal communications, using the formats that my company likes to use. Claude should use this skill whenever asked to write some sort of internal communications (status reports, leadership updates, 3P updates, company newsletters, FAQs, incident reports, project updates, etc.).",
    "body_zh": "## When to use this skill\nTo write internal communications, use this skill for:\n- 3P updates (Progress, Plans, Problems)\n- Company newsletters\n- FAQ responses\n- Status reports\n- Leadership updates\n- Project updates\n- Incident reports\n\n## How to use this skill\n\nTo write any internal communication:\n\n1. **Identify the communication type** from the request\n2. **Load the appropriate guideline file** from the `examples/` directory:\n    - `examples/3p-updates.md` - For Progress/Plans/Problems team updates\n    - `examples/company-newsletter.md` - For company-wide newsletters\n    - `examples/faq-answers.md` - For answering frequently asked questions\n    - `examples/general-comms.md` - For anything else that doesn't explicitly match one of the above\n3. **Follow the specific instructions** in that file for formatting, tone, and content gathering\n\nIf the communication type doesn't match any existing guideline, ask for clarification or more context about the desired format.\n\n## Keywords\n3P updates, company newsletter, company comms, weekly update, faqs, common questions, updates, internal comms"
  },
  {
    "name": "mcp-builder",
    "description": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).",
    "body": "# MCP Server Development Guide\n\n## Overview\n\nCreate MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. The quality of an MCP server is measured by how well it enables LLMs to accomplish real-world tasks.\n\n---\n\n# Process\n\n## üöÄ High-Level Workflow\n\nCreating a high-quality MCP server involves four main phases:\n\n### Phase 1: Deep Research and Planning\n\n#### 1.1 Understand Modern MCP Design\n\n**API Coverage vs. Workflow Tools:**\nBalance comprehensive API endpoint coverage with specialized workflow tools. Workflow tools can be more convenient for specific tasks, while comprehensive coverage gives agents flexibility to compose operations. Performance varies by client‚Äîsome clients benefit from code execution that combines basic tools, while others work better with higher-level workflows. When uncertain, prioritize comprehensive API coverage.\n\n**Tool Naming and Discoverability:**\nClear, descriptive tool names help agents find the right tools quickly. Use consistent prefixes (e.g., `github_create_issue`, `github_list_repos`) and action-oriented naming.\n\n**Context Management:**\nAgents benefit from concise tool descriptions and the ability to filter/paginate results. Design tools that return focused, relevant data. Some clients support code execution which can help agents filter and process data efficiently.\n\n**Actionable Error Messages:**\nError messages should guide agents toward solutions with specific suggestions and next steps.\n\n#### 1.2 Study MCP Protocol Documentation\n\n**Navigate the MCP specification:**\n\nStart with the sitemap to find relevant pages: `https://modelcontextprotocol.io/sitemap.xml`\n\nThen fetch specific pages with `.md` suffix for markdown format (e.g., `https://modelcontextprotocol.io/specification/draft.md`).\n\nKey pages to review:\n- Specification overview and architecture\n- Transport mechanisms (streamable HTTP, stdio)\n- Tool, resource, and prompt definitions\n\n#### 1.3 Study Framework Documentation\n\n**Recommended stack:**\n- **Language**: TypeScript (high-quality SDK support and good compatibility in many execution environments e.g. MCPB. Plus AI models are good at generating TypeScript code, benefiting from its broad usage, static typing and good linting tools)\n- **Transport**: Streamable HTTP for remote servers, using stateless JSON (simpler to scale and maintain, as opposed to stateful sessions and streaming responses). stdio for local servers.\n\n**Load framework documentation:**\n\n- **MCP Best Practices**: [üìã View Best Practices](./reference/mcp_best_practices.md) - Core guidelines\n\n**For TypeScript (recommended):**\n- **TypeScript SDK**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`\n- [‚ö° TypeScript Guide](./reference/node_mcp_server.md) - TypeScript patterns and examples\n\n**For Python:**\n- **Python SDK**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n- [üêç Python Guide](./reference/python_mcp_server.md) - Python patterns and examples\n\n#### 1.4 Plan Your Implementation\n\n**Understand the API:**\nReview the service's API documentation to identify key endpoints, authentication requirements, and data models. Use web search and WebFetch as needed.\n\n**Tool Selection:**\nPrioritize comprehensive API coverage. List endpoints to implement, starting with the most common operations.\n\n---\n\n### Phase 2: Implementation\n\n#### 2.1 Set Up Project Structure\n\nSee language-specific guides for project setup:\n- [‚ö° TypeScript Guide](./reference/node_mcp_server.md) - Project structure, package.json, tsconfig.json\n- [üêç Python Guide](./reference/python_mcp_server.md) - Module organization, dependencies\n\n#### 2.2 Implement Core Infrastructure\n\nCreate shared utilities:\n- API client with authentication\n- Error handling helpers\n- Response formatting (JSON/Markdown)\n- Pagination support\n\n#### 2.3 Implement Tools\n\nFor each tool:\n\n**Input Schema:**\n- Use Zod (TypeScript) or Pydantic (Python)\n- Include constraints and clear descriptions\n- Add examples in field descriptions\n\n**Output Schema:**\n- Define `outputSchema` where possible for structured data\n- Use `structuredContent` in tool responses (TypeScript SDK feature)\n- Helps clients understand and process tool outputs\n\n**Tool Description:**\n- Concise summary of functionality\n- Parameter descriptions\n- Return type schema\n\n**Implementation:**\n- Async/await for I/O operations\n- Proper error handling with actionable messages\n- Support pagination where applicable\n- Return both text content and structured data when using modern SDKs\n\n**Annotations:**\n- `readOnlyHint`: true/false\n- `destructiveHint`: true/false\n- `idempotentHint`: true/false\n- `openWorldHint`: true/false\n\n---\n\n### Phase 3: Review and Test\n\n#### 3.1 Code Quality\n\nReview for:\n- No duplicated code (DRY principle)\n- Consistent error handling\n- Full type coverage\n- Clear tool descriptions\n\n#### 3.2 Build and Test\n\n**TypeScript:**\n- Run `npm run build` to verify compilation\n- Test with MCP Inspector: `npx @modelcontextprotocol/inspector`\n\n**Python:**\n- Verify syntax: `python -m py_compile your_server.py`\n- Test with MCP Inspector\n\nSee language-specific guides for detailed testing approaches and quality checklists.\n\n---\n\n### Phase 4: Create Evaluations\n\nAfter implementing your MCP server, create comprehensive evaluations to test its effectiveness.\n\n**Load [‚úÖ Evaluation Guide](./reference/evaluation.md) for complete evaluation guidelines.**\n\n#### 4.1 Understand Evaluation Purpose\n\nUse evaluations to test whether LLMs can effectively use your MCP server to answer realistic, complex questions.\n\n#### 4.2 Create 10 Evaluation Questions\n\nTo create effective evaluations, follow the process outlined in the evaluation guide:\n\n1. **Tool Inspection**: List available tools and understand their capabilities\n2. **Content Exploration**: Use READ-ONLY operations to explore available data\n3. **Question Generation**: Create 10 complex, realistic questions\n4. **Answer Verification**: Solve each question yourself to verify answers\n\n#### 4.3 Evaluation Requirements\n\nEnsure each question is:\n- **Independent**: Not dependent on other questions\n- **Read-only**: Only non-destructive operations required\n- **Complex**: Requiring multiple tool calls and deep exploration\n- **Realistic**: Based on real use cases humans would care about\n- **Verifiable**: Single, clear answer that can be verified by string comparison\n- **Stable**: Answer won't change over time\n\n#### 4.4 Output Format\n\nCreate an XML file with this structure:\n\n```xml\n<evaluation>\n  <qa_pair>\n    <question>Find discussions about AI model launches with animal codenames. One model needed a specific safety designation that uses the format ASL-X. What number X was being determined for the model named after a spotted wild cat?</question>\n    <answer>3</answer>\n  </qa_pair>\n<!-- More qa_pairs... -->\n</evaluation>\n```\n\n---\n\n# Reference Files\n\n## üìö Documentation Library\n\nLoad these resources as needed during development:\n\n### Core MCP Documentation (Load First)\n- **MCP Protocol**: Start with sitemap at `https://modelcontextprotocol.io/sitemap.xml`, then fetch specific pages with `.md` suffix\n- [üìã MCP Best Practices](./reference/mcp_best_practices.md) - Universal MCP guidelines including:\n  - Server and tool naming conventions\n  - Response format guidelines (JSON vs Markdown)\n  - Pagination best practices\n  - Transport selection (streamable HTTP vs stdio)\n  - Security and error handling standards\n\n### SDK Documentation (Load During Phase 1/2)\n- **Python SDK**: Fetch from `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n- **TypeScript SDK**: Fetch from `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`\n\n### Language-Specific Implementation Guides (Load During Phase 2)\n- [üêç Python Implementation Guide](./reference/python_mcp_server.md) - Complete Python/FastMCP guide with:\n  - Server initialization patterns\n  - Pydantic model examples\n  - Tool registration with `@mcp.tool`\n  - Complete working examples\n  - Quality checklist\n\n- [‚ö° TypeScript Implementation Guide](./reference/node_mcp_server.md) - Complete TypeScript guide with:\n  - Project structure\n  - Zod schema patterns\n  - Tool registration with `server.registerTool`\n  - Complete working examples\n  - Quality checklist\n\n### Evaluation Guide (Load During Phase 4)\n- [‚úÖ Evaluation Guide](./reference/evaluation.md) - Complete evaluation creation guide with:\n  - Question creation guidelines\n  - Answer verification strategies\n  - XML format specifications\n  - Example questions and answers\n  - Running an evaluation with the provided scripts",
    "id": "mcp-builder",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/mcp-builder",
    "name_zh": "MCP ÊûÑÂª∫Âô®",
    "description_zh": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. ÈÄÇÁî®‰∫é building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).",
    "body_zh": "# MCP Server Development Guide\n\n## Overview\n\nCreate MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. The quality of an MCP server is measured by how well it enables LLMs to accomplish real-world tasks.\n\n---\n\n# Process\n\n## üöÄ High-Level Workflow\n\nCreating a high-quality MCP server involves four main phases:\n\n### Phase 1: Deep Research and Planning\n\n#### 1.1 Understand Modern MCP Design\n\n**API Coverage vs. Workflow Tools:**\nBalance comprehensive API endpoint coverage with specialized workflow tools. Workflow tools can be more convenient for specific tasks, while comprehensive coverage gives agents flexibility to compose operations. Performance varies by client‚Äîsome clients benefit from code execution that combines basic tools, while others work better with higher-level workflows. When uncertain, prioritize comprehensive API coverage.\n\n**Tool Naming and Discoverability:**\nClear, descriptive tool names help agents find the right tools quickly. Use consistent prefixes (e.g., `github_create_issue`, `github_list_repos`) and action-oriented naming.\n\n**Context Management:**\nAgents benefit from concise tool descriptions and the ability to filter/paginate results. Design tools that return focused, relevant data. Some clients support code execution which can help agents filter and process data efficiently.\n\n**Actionable Error Messages:**\nError messages should guide agents toward solutions with specific suggestions and next steps.\n\n#### 1.2 Study MCP Protocol Documentation\n\n**Navigate the MCP specification:**\n\nStart with the sitemap to find relevant pages: `https://modelcontextprotocol.io/sitemap.xml`\n\nThen fetch specific pages with `.md` suffix for markdown format (e.g., `https://modelcontextprotocol.io/specification/draft.md`).\n\nKey pages to review:\n- Specification overview and architecture\n- Transport mechanisms (streamable HTTP, stdio)\n- Tool, resource, and prompt definitions\n\n#### 1.3 Study Framework Documentation\n\n**Recommended stack:**\n- **Language**: TypeScript (high-quality SDK support and good compatibility in many execution environments e.g. MCPB. Plus AI models are good at generating TypeScript code, benefiting from its broad usage, static typing and good linting tools)\n- **Transport**: Streamable HTTP for remote servers, using stateless JSON (simpler to scale and maintain, as opposed to stateful sessions and streaming responses). stdio for local servers.\n\n**Load framework documentation:**\n\n- **MCP Best Practices**: [üìã View Best Practices](./reference/mcp_best_practices.md) - Core guidelines\n\n**For TypeScript (recommended):**\n- **TypeScript SDK**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`\n- [‚ö° TypeScript Guide](./reference/node_mcp_server.md) - TypeScript patterns and examples\n\n**For Python:**\n- **Python SDK**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n- [üêç Python Guide](./reference/python_mcp_server.md) - Python patterns and examples\n\n#### 1.4 Plan Your Implementation\n\n**Understand the API:**\nReview the service's API documentation to identify key endpoints, authentication requirements, and data models. Use web search and WebFetch as needed.\n\n**Tool Selection:**\nPrioritize comprehensive API coverage. List endpoints to implement, starting with the most common operations.\n\n---\n\n### Phase 2: Implementation\n\n#### 2.1 Set Up Project Structure\n\nSee language-specific guides for project setup:\n- [‚ö° TypeScript Guide](./reference/node_mcp_server.md) - Project structure, package.json, tsconfig.json\n- [üêç Python Guide](./reference/python_mcp_server.md) - Module organization, dependencies\n\n#### 2.2 Implement Core Infrastructure\n\nCreate shared utilities:\n- API client with authentication\n- Error handling helpers\n- Response formatting (JSON/Markdown)\n- Pagination support\n\n#### 2.3 Implement Tools\n\nFor each tool:\n\n**Input Schema:**\n- Use Zod (TypeScript) or Pydantic (Python)\n- Include constraints and clear descriptions\n- Add examples in field descriptions\n\n**Output Schema:**\n- Define `outputSchema` where possible for structured data\n- Use `structuredContent` in tool responses (TypeScript SDK feature)\n- Helps clients understand and process tool outputs\n\n**Tool Description:**\n- Concise summary of functionality\n- Parameter descriptions\n- Return type schema\n\n**Implementation:**\n- Async/await for I/O operations\n- Proper error handling with actionable messages\n- Support pagination where applicable\n- Return both text content and structured data when using modern SDKs\n\n**Annotations:**\n- `readOnlyHint`: true/false\n- `destructiveHint`: true/false\n- `idempotentHint`: true/false\n- `openWorldHint`: true/false\n\n---\n\n### Phase 3: Review and Test\n\n#### 3.1 Code Quality\n\nReview for:\n- No duplicated code (DRY principle)\n- Consistent error handling\n- Full type coverage\n- Clear tool descriptions\n\n#### 3.2 Build and Test\n\n**TypeScript:**\n- Run `npm run build` to verify compilation\n- Test with MCP Inspector: `npx @modelcontextprotocol/inspector`\n\n**Python:**\n- Verify syntax: `python -m py_compile your_server.py`\n- Test with MCP Inspector\n\nSee language-specific guides for detailed testing approaches and quality checklists.\n\n---\n\n### Phase 4: Create Evaluations\n\nAfter implementing your MCP server, create comprehensive evaluations to test its effectiveness.\n\n**Load [‚úÖ Evaluation Guide](./reference/evaluation.md) for complete evaluation guidelines.**\n\n#### 4.1 Understand Evaluation Purpose\n\nUse evaluations to test whether LLMs can effectively use your MCP server to answer realistic, complex questions.\n\n#### 4.2 Create 10 Evaluation Questions\n\nTo create effective evaluations, follow the process outlined in the evaluation guide:\n\n1. **Tool Inspection**: List available tools and understand their capabilities\n2. **Content Exploration**: Use READ-ONLY operations to explore available data\n3. **Question Generation**: Create 10 complex, realistic questions\n4. **Answer Verification**: Solve each question yourself to verify answers\n\n#### 4.3 Evaluation Requirements\n\nEnsure each question is:\n- **Independent**: Not dependent on other questions\n- **Read-only**: Only non-destructive operations required\n- **Complex**: Requiring multiple tool calls and deep exploration\n- **Realistic**: Based on real use cases humans would care about\n- **Verifiable**: Single, clear answer that can be verified by string comparison\n- **Stable**: Answer won't change over time\n\n#### 4.4 Output Format\n\nCreate an XML file with this structure:\n\n```xml\n<evaluation>\n  <qa_pair>\n    <question>Find discussions about AI model launches with animal codenames. One model needed a specific safety designation that uses the format ASL-X. What number X was being determined for the model named after a spotted wild cat?</question>\n    <answer>3</answer>\n  </qa_pair>\n<!-- More qa_pairs... -->\n</evaluation>\n```\n\n---\n\n# Reference Files\n\n## üìö Documentation Library\n\nLoad these resources as needed during development:\n\n### Core MCP Documentation (Load First)\n- **MCP Protocol**: Start with sitemap at `https://modelcontextprotocol.io/sitemap.xml`, then fetch specific pages with `.md` suffix\n- [üìã MCP Best Practices](./reference/mcp_best_practices.md) - Universal MCP guidelines including:\n  - Server and tool naming conventions\n  - Response format guidelines (JSON vs Markdown)\n  - Pagination best practices\n  - Transport selection (streamable HTTP vs stdio)\n  - Security and error handling standards\n\n### SDK Documentation (Load During Phase 1/2)\n- **Python SDK**: Fetch from `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n- **TypeScript SDK**: Fetch from `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`\n\n### Language-Specific Implementation Guides (Load During Phase 2)\n- [üêç Python Implementation Guide](./reference/python_mcp_server.md) - Complete Python/FastMCP guide with:\n  - Server initialization patterns\n  - Pydantic model examples\n  - Tool registration with `@mcp.tool`\n  - Complete working examples\n  - Quality checklist\n\n- [‚ö° TypeScript Implementation Guide](./reference/node_mcp_server.md) - Complete TypeScript guide with:\n  - Project structure\n  - Zod schema patterns\n  - Tool registration with `server.registerTool`\n  - Complete working examples\n  - Quality checklist\n\n### Evaluation Guide (Load During Phase 4)\n- [‚úÖ Evaluation Guide](./reference/evaluation.md) - Complete evaluation creation guide with:\n  - Question creation guidelines\n  - Answer verification strategies\n  - XML format specifications\n  - Example questions and answers\n  - Running an evaluation with the provided scripts"
  },
  {
    "name": "pdf",
    "description": "Comprehensive PDF manipulation toolkit for extracting text and tables, creating new PDFs, merging/splitting documents, and handling forms. When Claude needs to fill in a PDF form or programmatically process, generate, or analyze PDF documents at scale.",
    "body": "# PDF Processing Guide\n\n## Overview\n\nThis guide covers essential PDF processing operations using Python libraries and command-line tools. For advanced features, JavaScript libraries, and detailed examples, see reference.md. If you need to fill out a PDF form, read forms.md and follow its instructions.\n\n## Quick Start\n\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Read a PDF\nreader = PdfReader(\"document.pdf\")\nprint(f\"Pages: {len(reader.pages)}\")\n\n# Extract text\ntext = \"\"\nfor page in reader.pages:\n    text += page.extract_text()\n```\n\n## Python Libraries\n\n### pypdf - Basic Operations\n\n#### Merge PDFs\n```python\nfrom pypdf import PdfWriter, PdfReader\n\nwriter = PdfWriter()\nfor pdf_file in [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]:\n    reader = PdfReader(pdf_file)\n    for page in reader.pages:\n        writer.add_page(page)\n\nwith open(\"merged.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n#### Split PDF\n```python\nreader = PdfReader(\"input.pdf\")\nfor i, page in enumerate(reader.pages):\n    writer = PdfWriter()\n    writer.add_page(page)\n    with open(f\"page_{i+1}.pdf\", \"wb\") as output:\n        writer.write(output)\n```\n\n#### Extract Metadata\n```python\nreader = PdfReader(\"document.pdf\")\nmeta = reader.metadata\nprint(f\"Title: {meta.title}\")\nprint(f\"Author: {meta.author}\")\nprint(f\"Subject: {meta.subject}\")\nprint(f\"Creator: {meta.creator}\")\n```\n\n#### Rotate Pages\n```python\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\npage = reader.pages[0]\npage.rotate(90)  # Rotate 90 degrees clockwise\nwriter.add_page(page)\n\nwith open(\"rotated.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### pdfplumber - Text and Table Extraction\n\n#### Extract Text with Layout\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for page in pdf.pages:\n        text = page.extract_text()\n        print(text)\n```\n\n#### Extract Tables\n```python\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for i, page in enumerate(pdf.pages):\n        tables = page.extract_tables()\n        for j, table in enumerate(tables):\n            print(f\"Table {j+1} on page {i+1}:\")\n            for row in table:\n                print(row)\n```\n\n#### Advanced Table Extraction\n```python\nimport pandas as pd\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    all_tables = []\n    for page in pdf.pages:\n        tables = page.extract_tables()\n        for table in tables:\n            if table:  # Check if table is not empty\n                df = pd.DataFrame(table[1:], columns=table[0])\n                all_tables.append(df)\n\n# Combine all tables\nif all_tables:\n    combined_df = pd.concat(all_tables, ignore_index=True)\n    combined_df.to_excel(\"extracted_tables.xlsx\", index=False)\n```\n\n### reportlab - Create PDFs\n\n#### Basic PDF Creation\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\n\nc = canvas.Canvas(\"hello.pdf\", pagesize=letter)\nwidth, height = letter\n\n# Add text\nc.drawString(100, height - 100, \"Hello World!\")\nc.drawString(100, height - 120, \"This is a PDF created with reportlab\")\n\n# Add a line\nc.line(100, height - 140, 400, height - 140)\n\n# Save\nc.save()\n```\n\n#### Create PDF with Multiple Pages\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak\nfrom reportlab.lib.styles import getSampleStyleSheet\n\ndoc = SimpleDocTemplate(\"report.pdf\", pagesize=letter)\nstyles = getSampleStyleSheet()\nstory = []\n\n# Add content\ntitle = Paragraph(\"Report Title\", styles['Title'])\nstory.append(title)\nstory.append(Spacer(1, 12))\n\nbody = Paragraph(\"This is the body of the report. \" * 20, styles['Normal'])\nstory.append(body)\nstory.append(PageBreak())\n\n# Page 2\nstory.append(Paragraph(\"Page 2\", styles['Heading1']))\nstory.append(Paragraph(\"Content for page 2\", styles['Normal']))\n\n# Build PDF\ndoc.build(story)\n```\n\n## Command-Line Tools\n\n### pdftotext (poppler-utils)\n```bash\n# Extract text\npdftotext input.pdf output.txt\n\n# Extract text preserving layout\npdftotext -layout input.pdf output.txt\n\n# Extract specific pages\npdftotext -f 1 -l 5 input.pdf output.txt  # Pages 1-5\n```\n\n### qpdf\n```bash\n# Merge PDFs\nqpdf --empty --pages file1.pdf file2.pdf -- merged.pdf\n\n# Split pages\nqpdf input.pdf --pages . 1-5 -- pages1-5.pdf\nqpdf input.pdf --pages . 6-10 -- pages6-10.pdf\n\n# Rotate pages\nqpdf input.pdf output.pdf --rotate=+90:1  # Rotate page 1 by 90 degrees\n\n# Remove password\nqpdf --password=mypassword --decrypt encrypted.pdf decrypted.pdf\n```\n\n### pdftk (if available)\n```bash\n# Merge\npdftk file1.pdf file2.pdf cat output merged.pdf\n\n# Split\npdftk input.pdf burst\n\n# Rotate\npdftk input.pdf rotate 1east output rotated.pdf\n```\n\n## Common Tasks\n\n### Extract Text from Scanned PDFs\n```python\n# Requires: pip install pytesseract pdf2image\nimport pytesseract\nfrom pdf2image import convert_from_path\n\n# Convert PDF to images\nimages = convert_from_path('scanned.pdf')\n\n# OCR each page\ntext = \"\"\nfor i, image in enumerate(images):\n    text += f\"Page {i+1}:\\n\"\n    text += pytesseract.image_to_string(image)\n    text += \"\\n\\n\"\n\nprint(text)\n```\n\n### Add Watermark\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Create watermark (or load existing)\nwatermark = PdfReader(\"watermark.pdf\").pages[0]\n\n# Apply to all pages\nreader = PdfReader(\"document.pdf\")\nwriter = PdfWriter()\n\nfor page in reader.pages:\n    page.merge_page(watermark)\n    writer.add_page(page)\n\nwith open(\"watermarked.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### Extract Images\n```bash\n# Using pdfimages (poppler-utils)\npdfimages -j input.pdf output_prefix\n\n# This extracts all images as output_prefix-000.jpg, output_prefix-001.jpg, etc.\n```\n\n### Password Protection\n```python\nfrom pypdf import PdfReader, PdfWriter\n\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\nfor page in reader.pages:\n    writer.add_page(page)\n\n# Add password\nwriter.encrypt(\"userpassword\", \"ownerpassword\")\n\nwith open(\"encrypted.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n## Quick Reference\n\n| Task | Best Tool | Command/Code |\n|------|-----------|--------------|\n| Merge PDFs | pypdf | `writer.add_page(page)` |\n| Split PDFs | pypdf | One page per file |\n| Extract text | pdfplumber | `page.extract_text()` |\n| Extract tables | pdfplumber | `page.extract_tables()` |\n| Create PDFs | reportlab | Canvas or Platypus |\n| Command line merge | qpdf | `qpdf --empty --pages ...` |\n| OCR scanned PDFs | pytesseract | Convert to image first |\n| Fill PDF forms | pdf-lib or pypdf (see forms.md) | See forms.md |\n\n## Next Steps\n\n- For advanced pypdfium2 usage, see reference.md\n- For JavaScript libraries (pdf-lib), see reference.md\n- If you need to fill out a PDF form, follow the instructions in forms.md\n- For troubleshooting guides, see reference.md",
    "id": "pdf",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/pdf",
    "name_zh": "PDF Â§ÑÁêÜ",
    "description_zh": "Comprehensive PDF manipulation toolkit for extracting text and tables, creating new PDFs, merging/splitting documents, and handling forms. When Claude needs to fill in a PDF form or programmatically process, generate, or analyze PDF documents at scale.",
    "body_zh": "# PDF Processing Guide\n\n## Overview\n\nThis guide covers essential PDF processing operations using Python libraries and command-line tools. For advanced features, JavaScript libraries, and detailed examples, see reference.md. If you need to fill out a PDF form, read forms.md and follow its instructions.\n\n## Quick Start\n\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Read a PDF\nreader = PdfReader(\"document.pdf\")\nprint(f\"Pages: {len(reader.pages)}\")\n\n# Extract text\ntext = \"\"\nfor page in reader.pages:\n    text += page.extract_text()\n```\n\n## Python Libraries\n\n### pypdf - Basic Operations\n\n#### Merge PDFs\n```python\nfrom pypdf import PdfWriter, PdfReader\n\nwriter = PdfWriter()\nfor pdf_file in [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]:\n    reader = PdfReader(pdf_file)\n    for page in reader.pages:\n        writer.add_page(page)\n\nwith open(\"merged.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n#### Split PDF\n```python\nreader = PdfReader(\"input.pdf\")\nfor i, page in enumerate(reader.pages):\n    writer = PdfWriter()\n    writer.add_page(page)\n    with open(f\"page_{i+1}.pdf\", \"wb\") as output:\n        writer.write(output)\n```\n\n#### Extract Metadata\n```python\nreader = PdfReader(\"document.pdf\")\nmeta = reader.metadata\nprint(f\"Title: {meta.title}\")\nprint(f\"Author: {meta.author}\")\nprint(f\"Subject: {meta.subject}\")\nprint(f\"Creator: {meta.creator}\")\n```\n\n#### Rotate Pages\n```python\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\npage = reader.pages[0]\npage.rotate(90)  # Rotate 90 degrees clockwise\nwriter.add_page(page)\n\nwith open(\"rotated.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### pdfplumber - Text and Table Extraction\n\n#### Extract Text with Layout\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for page in pdf.pages:\n        text = page.extract_text()\n        print(text)\n```\n\n#### Extract Tables\n```python\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for i, page in enumerate(pdf.pages):\n        tables = page.extract_tables()\n        for j, table in enumerate(tables):\n            print(f\"Table {j+1} on page {i+1}:\")\n            for row in table:\n                print(row)\n```\n\n#### Advanced Table Extraction\n```python\nimport pandas as pd\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    all_tables = []\n    for page in pdf.pages:\n        tables = page.extract_tables()\n        for table in tables:\n            if table:  # Check if table is not empty\n                df = pd.DataFrame(table[1:], columns=table[0])\n                all_tables.append(df)\n\n# Combine all tables\nif all_tables:\n    combined_df = pd.concat(all_tables, ignore_index=True)\n    combined_df.to_excel(\"extracted_tables.xlsx\", index=False)\n```\n\n### reportlab - Create PDFs\n\n#### Basic PDF Creation\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\n\nc = canvas.Canvas(\"hello.pdf\", pagesize=letter)\nwidth, height = letter\n\n# Add text\nc.drawString(100, height - 100, \"Hello World!\")\nc.drawString(100, height - 120, \"This is a PDF created with reportlab\")\n\n# Add a line\nc.line(100, height - 140, 400, height - 140)\n\n# Save\nc.save()\n```\n\n#### Create PDF with Multiple Pages\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak\nfrom reportlab.lib.styles import getSampleStyleSheet\n\ndoc = SimpleDocTemplate(\"report.pdf\", pagesize=letter)\nstyles = getSampleStyleSheet()\nstory = []\n\n# Add content\ntitle = Paragraph(\"Report Title\", styles['Title'])\nstory.append(title)\nstory.append(Spacer(1, 12))\n\nbody = Paragraph(\"This is the body of the report. \" * 20, styles['Normal'])\nstory.append(body)\nstory.append(PageBreak())\n\n# Page 2\nstory.append(Paragraph(\"Page 2\", styles['Heading1']))\nstory.append(Paragraph(\"Content for page 2\", styles['Normal']))\n\n# Build PDF\ndoc.build(story)\n```\n\n## Command-Line Tools\n\n### pdftotext (poppler-utils)\n```bash\n# Extract text\npdftotext input.pdf output.txt\n\n# Extract text preserving layout\npdftotext -layout input.pdf output.txt\n\n# Extract specific pages\npdftotext -f 1 -l 5 input.pdf output.txt  # Pages 1-5\n```\n\n### qpdf\n```bash\n# Merge PDFs\nqpdf --empty --pages file1.pdf file2.pdf -- merged.pdf\n\n# Split pages\nqpdf input.pdf --pages . 1-5 -- pages1-5.pdf\nqpdf input.pdf --pages . 6-10 -- pages6-10.pdf\n\n# Rotate pages\nqpdf input.pdf output.pdf --rotate=+90:1  # Rotate page 1 by 90 degrees\n\n# Remove password\nqpdf --password=mypassword --decrypt encrypted.pdf decrypted.pdf\n```\n\n### pdftk (if available)\n```bash\n# Merge\npdftk file1.pdf file2.pdf cat output merged.pdf\n\n# Split\npdftk input.pdf burst\n\n# Rotate\npdftk input.pdf rotate 1east output rotated.pdf\n```\n\n## Common Tasks\n\n### Extract Text from Scanned PDFs\n```python\n# Requires: pip install pytesseract pdf2image\nimport pytesseract\nfrom pdf2image import convert_from_path\n\n# Convert PDF to images\nimages = convert_from_path('scanned.pdf')\n\n# OCR each page\ntext = \"\"\nfor i, image in enumerate(images):\n    text += f\"Page {i+1}:\\n\"\n    text += pytesseract.image_to_string(image)\n    text += \"\\n\\n\"\n\nprint(text)\n```\n\n### Add Watermark\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Create watermark (or load existing)\nwatermark = PdfReader(\"watermark.pdf\").pages[0]\n\n# Apply to all pages\nreader = PdfReader(\"document.pdf\")\nwriter = PdfWriter()\n\nfor page in reader.pages:\n    page.merge_page(watermark)\n    writer.add_page(page)\n\nwith open(\"watermarked.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### Extract Images\n```bash\n# Using pdfimages (poppler-utils)\npdfimages -j input.pdf output_prefix\n\n# This extracts all images as output_prefix-000.jpg, output_prefix-001.jpg, etc.\n```\n\n### Password Protection\n```python\nfrom pypdf import PdfReader, PdfWriter\n\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\nfor page in reader.pages:\n    writer.add_page(page)\n\n# Add password\nwriter.encrypt(\"userpassword\", \"ownerpassword\")\n\nwith open(\"encrypted.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n## Quick Reference\n\n| Task | Best Tool | Command/Code |\n|------|-----------|--------------|\n| Merge PDFs | pypdf | `writer.add_page(page)` |\n| Split PDFs | pypdf | One page per file |\n| Extract text | pdfplumber | `page.extract_text()` |\n| Extract tables | pdfplumber | `page.extract_tables()` |\n| Create PDFs | reportlab | Canvas or Platypus |\n| Command line merge | qpdf | `qpdf --empty --pages ...` |\n| OCR scanned PDFs | pytesseract | Convert to image first |\n| Fill PDF forms | pdf-lib or pypdf (see forms.md) | See forms.md |\n\n## Next Steps\n\n- For advanced pypdfium2 usage, see reference.md\n- For JavaScript libraries (pdf-lib), see reference.md\n- If you need to fill out a PDF form, follow the instructions in forms.md\n- For troubleshooting guides, see reference.md"
  },
  {
    "name": "pptx",
    "description": "Presentation creation, editing, and analysis. When Claude needs to work with presentations (.pptx files) for: (1) Creating new presentations, (2) Modifying or editing content, (3) Working with layouts, (4) Adding comments or speaker notes, or any other presentation tasks",
    "body": "# PPTX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .pptx file. A .pptx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a presentation, you should convert the document to markdown:\n\n```bash\n# Convert document to markdown\npython -m markitdown path-to-file.pptx\n```\n\n### Raw XML access\nYou need raw XML access for: comments, speaker notes, slide layouts, animations, design elements, and complex formatting. For any of these features, you'll need to unpack a presentation and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_dir>`\n\n**Note**: The unpack.py script is located at `skills/pptx/ooxml/scripts/unpack.py` relative to the project root. If the script doesn't exist at this path, use `find . -name \"unpack.py\"` to locate it.\n\n#### Key file structures\n* `ppt/presentation.xml` - Main presentation metadata and slide references\n* `ppt/slides/slide{N}.xml` - Individual slide contents (slide1.xml, slide2.xml, etc.)\n* `ppt/notesSlides/notesSlide{N}.xml` - Speaker notes for each slide\n* `ppt/comments/modernComment_*.xml` - Comments for specific slides\n* `ppt/slideLayouts/` - Layout templates for slides\n* `ppt/slideMasters/` - Master slide templates\n* `ppt/theme/` - Theme and styling information\n* `ppt/media/` - Images and other media files\n\n#### Typography and color extraction\n**When given an example design to emulate**: Always analyze the presentation's typography and colors first using the methods below:\n1. **Read theme file**: Check `ppt/theme/theme1.xml` for colors (`<a:clrScheme>`) and fonts (`<a:fontScheme>`)\n2. **Sample slide content**: Examine `ppt/slides/slide1.xml` for actual font usage (`<a:rPr>`) and colors\n3. **Search for patterns**: Use grep to find color (`<a:solidFill>`, `<a:srgbClr>`) and font references across all XML files\n\n## Creating a new PowerPoint presentation **without a template**\n\nWhen creating a new PowerPoint presentation from scratch, use the **html2pptx** workflow to convert HTML slides to PowerPoint with accurate positioning.\n\n### Design Principles\n\n**CRITICAL**: Before creating any presentation, analyze the content and choose appropriate design elements:\n1. **Consider the subject matter**: What is this presentation about? What tone, industry, or mood does it suggest?\n2. **Check for branding**: If the user mentions a company/organization, consider their brand colors and identity\n3. **Match palette to content**: Select colors that reflect the subject\n4. **State your approach**: Explain your design choices before writing code\n\n**Requirements**:\n- ‚úÖ State your content-informed design approach BEFORE writing code\n- ‚úÖ Use web-safe fonts only: Arial, Helvetica, Times New Roman, Georgia, Courier New, Verdana, Tahoma, Trebuchet MS, Impact\n- ‚úÖ Create clear visual hierarchy through size, weight, and color\n- ‚úÖ Ensure readability: strong contrast, appropriately sized text, clean alignment\n- ‚úÖ Be consistent: repeat patterns, spacing, and visual language across slides\n\n#### Color Palette Selection\n\n**Choosing colors creatively**:\n- **Think beyond defaults**: What colors genuinely match this specific topic? Avoid autopilot choices.\n- **Consider multiple angles**: Topic, industry, mood, energy level, target audience, brand identity (if mentioned)\n- **Be adventurous**: Try unexpected combinations - a healthcare presentation doesn't have to be green, finance doesn't have to be navy\n- **Build your palette**: Pick 3-5 colors that work together (dominant colors + supporting tones + accent)\n- **Ensure contrast**: Text must be clearly readable on backgrounds\n\n**Example color palettes** (use these to spark creativity - choose one, adapt it, or create your own):\n\n1. **Classic Blue**: Deep navy (#1C2833), slate gray (#2E4053), silver (#AAB7B8), off-white (#F4F6F6)\n2. **Teal & Coral**: Teal (#5EA8A7), deep teal (#277884), coral (#FE4447), white (#FFFFFF)\n3. **Bold Red**: Red (#C0392B), bright red (#E74C3C), orange (#F39C12), yellow (#F1C40F), green (#2ECC71)\n4. **Warm Blush**: Mauve (#A49393), blush (#EED6D3), rose (#E8B4B8), cream (#FAF7F2)\n5. **Burgundy Luxury**: Burgundy (#5D1D2E), crimson (#951233), rust (#C15937), gold (#997929)\n6. **Deep Purple & Emerald**: Purple (#B165FB), dark blue (#181B24), emerald (#40695B), white (#FFFFFF)\n7. **Cream & Forest Green**: Cream (#FFE1C7), forest green (#40695B), white (#FCFCFC)\n8. **Pink & Purple**: Pink (#F8275B), coral (#FF574A), rose (#FF737D), purple (#3D2F68)\n9. **Lime & Plum**: Lime (#C5DE82), plum (#7C3A5F), coral (#FD8C6E), blue-gray (#98ACB5)\n10. **Black & Gold**: Gold (#BF9A4A), black (#000000), cream (#F4F6F6)\n11. **Sage & Terracotta**: Sage (#87A96B), terracotta (#E07A5F), cream (#F4F1DE), charcoal (#2C2C2C)\n12. **Charcoal & Red**: Charcoal (#292929), red (#E33737), light gray (#CCCBCB)\n13. **Vibrant Orange**: Orange (#F96D00), light gray (#F2F2F2), charcoal (#222831)\n14. **Forest Green**: Black (#191A19), green (#4E9F3D), dark green (#1E5128), white (#FFFFFF)\n15. **Retro Rainbow**: Purple (#722880), pink (#D72D51), orange (#EB5C18), amber (#F08800), gold (#DEB600)\n16. **Vintage Earthy**: Mustard (#E3B448), sage (#CBD18F), forest green (#3A6B35), cream (#F4F1DE)\n17. **Coastal Rose**: Old rose (#AD7670), beaver (#B49886), eggshell (#F3ECDC), ash gray (#BFD5BE)\n18. **Orange & Turquoise**: Light orange (#FC993E), grayish turquoise (#667C6F), white (#FCFCFC)\n\n#### Visual Details Options\n\n**Geometric Patterns**:\n- Diagonal section dividers instead of horizontal\n- Asymmetric column widths (30/70, 40/60, 25/75)\n- Rotated text headers at 90¬∞ or 270¬∞\n- Circular/hexagonal frames for images\n- Triangular accent shapes in corners\n- Overlapping shapes for depth\n\n**Border & Frame Treatments**:\n- Thick single-color borders (10-20pt) on one side only\n- Double-line borders with contrasting colors\n- Corner brackets instead of full frames\n- L-shaped borders (top+left or bottom+right)\n- Underline accents beneath headers (3-5pt thick)\n\n**Typography Treatments**:\n- Extreme size contrast (72pt headlines vs 11pt body)\n- All-caps headers with wide letter spacing\n- Numbered sections in oversized display type\n- Monospace (Courier New) for data/stats/technical content\n- Condensed fonts (Arial Narrow) for dense information\n- Outlined text for emphasis\n\n**Chart & Data Styling**:\n- Monochrome charts with single accent color for key data\n- Horizontal bar charts instead of vertical\n- Dot plots instead of bar charts\n- Minimal gridlines or none at all\n- Data labels directly on elements (no legends)\n- Oversized numbers for key metrics\n\n**Layout Innovations**:\n- Full-bleed images with text overlays\n- Sidebar column (20-30% width) for navigation/context\n- Modular grid systems (3√ó3, 4√ó4 blocks)\n- Z-pattern or F-pattern content flow\n- Floating text boxes over colored shapes\n- Magazine-style multi-column layouts\n\n**Background Treatments**:\n- Solid color blocks occupying 40-60% of slide\n- Gradient fills (vertical or diagonal only)\n- Split backgrounds (two colors, diagonal or vertical)\n- Edge-to-edge color bands\n- Negative space as a design element\n\n### Layout Tips\n**When creating slides with charts or tables:**\n- **Two-column layout (PREFERRED)**: Use a header spanning the full width, then two columns below - text/bullets in one column and the featured content in the other. This provides better balance and makes charts/tables more readable. Use flexbox with unequal column widths (e.g., 40%/60% split) to optimize space for each content type.\n- **Full-slide layout**: Let the featured content (chart/table) take up the entire slide for maximum impact and readability\n- **NEVER vertically stack**: Do not place charts/tables below text in a single column - this causes poor readability and layout issues\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`html2pptx.md`](html2pptx.md) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for detailed syntax, critical formatting rules, and best practices before proceeding with presentation creation.\n2. Create an HTML file for each slide with proper dimensions (e.g., 720pt √ó 405pt for 16:9)\n   - Use `<p>`, `<h1>`-`<h6>`, `<ul>`, `<ol>` for all text content\n   - Use `class=\"placeholder\"` for areas where charts/tables will be added (render with gray background for visibility)\n   - **CRITICAL**: Rasterize gradients and icons as PNG images FIRST using Sharp, then reference in HTML\n   - **LAYOUT**: For slides with charts/tables/images, use either full-slide layout or two-column layout for better readability\n3. Create and run a JavaScript file using the [`html2pptx.js`](scripts/html2pptx.js) library to convert HTML slides to PowerPoint and save the presentation\n   - Use the `html2pptx()` function to process each HTML file\n   - Add charts and tables to placeholder areas using PptxGenJS API\n   - Save the presentation using `pptx.writeFile()`\n4. **Visual validation**: Generate thumbnails and inspect for layout issues\n   - Create thumbnail grid: `python scripts/thumbnail.py output.pptx workspace/thumbnails --cols 4`\n   - Read and carefully examine the thumbnail image for:\n     - **Text cutoff**: Text being cut off by header bars, shapes, or slide edges\n     - **Text overlap**: Text overlapping with other text or shapes\n     - **Positioning issues**: Content too close to slide boundaries or other elements\n     - **Contrast issues**: Insufficient contrast between text and backgrounds\n   - If issues found, adjust HTML margins/spacing/colors and regenerate the presentation\n   - Repeat until all slides are visually correct\n\n## Editing an existing PowerPoint presentation\n\nWhen edit slides in an existing PowerPoint presentation, you need to work with the raw Office Open XML (OOXML) format. This involves unpacking the .pptx file, editing the XML content, and repacking it.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~500 lines) completely from start to finish.  **NEVER set any range limits when reading this file.**  Read the full file content for detailed guidance on OOXML structure and editing workflows before any presentation editing.\n2. Unpack the presentation: `python ooxml/scripts/unpack.py <office_file> <output_dir>`\n3. Edit the XML files (primarily `ppt/slides/slide{N}.xml` and related files)\n4. **CRITICAL**: Validate immediately after each edit and fix any validation errors before proceeding: `python ooxml/scripts/validate.py <dir> --original <file>`\n5. Pack the final presentation: `python ooxml/scripts/pack.py <input_directory> <office_file>`\n\n## Creating a new PowerPoint presentation **using a template**\n\nWhen you need to create a presentation that follows an existing template's design, you'll need to duplicate and re-arrange template slides before then replacing placeholder context.\n\n### Workflow\n1. **Extract template text AND create visual thumbnail grid**:\n   * Extract text: `python -m markitdown template.pptx > template-content.md`\n   * Read `template-content.md`: Read the entire file to understand the contents of the template presentation. **NEVER set any range limits when reading this file.**\n   * Create thumbnail grids: `python scripts/thumbnail.py template.pptx`\n   * See [Creating Thumbnail Grids](#creating-thumbnail-grids) section for more details\n\n2. **Analyze template and save inventory to a file**:\n   * **Visual Analysis**: Review thumbnail grid(s) to understand slide layouts, design patterns, and visual structure\n   * Create and save a template inventory file at `template-inventory.md` containing:\n     ```markdown\n     # Template Inventory Analysis\n     **Total Slides: [count]**\n     **IMPORTANT: Slides are 0-indexed (first slide = 0, last slide = count-1)**\n\n     ## [Category Name]\n     - Slide 0: [Layout code if available] - Description/purpose\n     - Slide 1: [Layout code] - Description/purpose\n     - Slide 2: [Layout code] - Description/purpose\n     [... EVERY slide must be listed individually with its index ...]\n     ```\n   * **Using the thumbnail grid**: Reference the visual thumbnails to identify:\n     - Layout patterns (title slides, content layouts, section dividers)\n     - Image placeholder locations and counts\n     - Design consistency across slide groups\n     - Visual hierarchy and structure\n   * This inventory file is REQUIRED for selecting appropriate templates in the next step\n\n3. **Create presentation outline based on template inventory**:\n   * Review available templates from step 2.\n   * Choose an intro or title template for the first slide. This should be one of the first templates.\n   * Choose safe, text-based layouts for the other slides.\n   * **CRITICAL: Match layout structure to actual content**:\n     - Single-column layouts: Use for unified narrative or single topic\n     - Two-column layouts: Use ONLY when you have exactly 2 distinct items/concepts\n     - Three-column layouts: Use ONLY when you have exactly 3 distinct items/concepts\n     - Image + text layouts: Use ONLY when you have actual images to insert\n     - Quote layouts: Use ONLY for actual quotes from people (with attribution), never for emphasis\n     - Never use layouts with more placeholders than you have content\n     - If you have 2 items, don't force them into a 3-column layout\n     - If you have 4+ items, consider breaking into multiple slides or using a list format\n   * Count your actual content pieces BEFORE selecting the layout\n   * Verify each placeholder in the chosen layout will be filled with meaningful content\n   * Select one option representing the **best** layout for each content section.\n   * Save `outline.md` with content AND template mapping that leverages available designs\n   * Example template mapping:\n      ```\n      # Template slides to use (0-based indexing)\n      # WARNING: Verify indices are within range! Template with 73 slides has indices 0-72\n      # Mapping: slide numbers from outline -> template slide indices\n      template_mapping = [\n          0,   # Use slide 0 (Title/Cover)\n          34,  # Use slide 34 (B1: Title and body)\n          34,  # Use slide 34 again (duplicate for second B1)\n          50,  # Use slide 50 (E1: Quote)\n          54,  # Use slide 54 (F2: Closing + Text)\n      ]\n      ```\n\n4. **Duplicate, reorder, and delete slides using `rearrange.py`**:\n   * Use the `scripts/rearrange.py` script to create a new presentation with slides in the desired order:\n     ```bash\n     python scripts/rearrange.py template.pptx working.pptx 0,34,34,50,52\n     ```\n   * The script handles duplicating repeated slides, deleting unused slides, and reordering automatically\n   * Slide indices are 0-based (first slide is 0, second is 1, etc.)\n   * The same slide index can appear multiple times to duplicate that slide\n\n5. **Extract ALL text using the `inventory.py` script**:\n   * **Run inventory extraction**:\n     ```bash\n     python scripts/inventory.py working.pptx text-inventory.json\n     ```\n   * **Read text-inventory.json**: Read the entire text-inventory.json file to understand all shapes and their properties. **NEVER set any range limits when reading this file.**\n\n   * The inventory JSON structure:\n      ```json\n        {\n          \"slide-0\": {\n            \"shape-0\": {\n              \"placeholder_type\": \"TITLE\",  // or null for non-placeholders\n              \"left\": 1.5,                  // position in inches\n              \"top\": 2.0,\n              \"width\": 7.5,\n              \"height\": 1.2,\n              \"paragraphs\": [\n                {\n                  \"text\": \"Paragraph text\",\n                  // Optional properties (only included when non-default):\n                  \"bullet\": true,           // explicit bullet detected\n                  \"level\": 0,               // only included when bullet is true\n                  \"alignment\": \"CENTER\",    // CENTER, RIGHT (not LEFT)\n                  \"space_before\": 10.0,     // space before paragraph in points\n                  \"space_after\": 6.0,       // space after paragraph in points\n                  \"line_spacing\": 22.4,     // line spacing in points\n                  \"font_name\": \"Arial\",     // from first run\n                  \"font_size\": 14.0,        // in points\n                  \"bold\": true,\n                  \"italic\": false,\n                  \"underline\": false,\n                  \"color\": \"FF0000\"         // RGB color\n                }\n              ]\n            }\n          }\n        }\n      ```\n\n   * Key features:\n     - **Slides**: Named as \"slide-0\", \"slide-1\", etc.\n     - **Shapes**: Ordered by visual position (top-to-bottom, left-to-right) as \"shape-0\", \"shape-1\", etc.\n     - **Placeholder types**: TITLE, CENTER_TITLE, SUBTITLE, BODY, OBJECT, or null\n     - **Default font size**: `default_font_size` in points extracted from layout placeholders (when available)\n     - **Slide numbers are filtered**: Shapes with SLIDE_NUMBER placeholder type are automatically excluded from inventory\n     - **Bullets**: When `bullet: true`, `level` is always included (even if 0)\n     - **Spacing**: `space_before`, `space_after`, and `line_spacing` in points (only included when set)\n     - **Colors**: `color` for RGB (e.g., \"FF0000\"), `theme_color` for theme colors (e.g., \"DARK_1\")\n     - **Properties**: Only non-default values are included in the output\n\n6. **Generate replacement text and save the data to a JSON file**\n   Based on the text inventory from the previous step:\n   - **CRITICAL**: First verify which shapes exist in the inventory - only reference shapes that are actually present\n   - **VALIDATION**: The replace.py script will validate that all shapes in your replacement JSON exist in the inventory\n     - If you reference a non-existent shape, you'll get an error showing available shapes\n     - If you reference a non-existent slide, you'll get an error indicating the slide doesn't exist\n     - All validation errors are shown at once before the script exits\n   - **IMPORTANT**: The replace.py script uses inventory.py internally to identify ALL text shapes\n   - **AUTOMATIC CLEARING**: ALL text shapes from the inventory will be cleared unless you provide \"paragraphs\" for them\n   - Add a \"paragraphs\" field to shapes that need content (not \"replacement_paragraphs\")\n   - Shapes without \"paragraphs\" in the replacement JSON will have their text cleared automatically\n   - Paragraphs with bullets will be automatically left aligned. Don't set the `alignment` property on when `\"bullet\": true`\n   - Generate appropriate replacement content for placeholder text\n   - Use shape size to determine appropriate content length\n   - **CRITICAL**: Include paragraph properties from the original inventory - don't just provide text\n   - **IMPORTANT**: When bullet: true, do NOT include bullet symbols (‚Ä¢, -, *) in text - they're added automatically\n   - **ESSENTIAL FORMATTING RULES**:\n     - Headers/titles should typically have `\"bold\": true`\n     - List items should have `\"bullet\": true, \"level\": 0` (level is required when bullet is true)\n     - Preserve any alignment properties (e.g., `\"alignment\": \"CENTER\"` for centered text)\n     - Include font properties when different from default (e.g., `\"font_size\": 14.0`, `\"font_name\": \"Lora\"`)\n     - Colors: Use `\"color\": \"FF0000\"` for RGB or `\"theme_color\": \"DARK_1\"` for theme colors\n     - The replacement script expects **properly formatted paragraphs**, not just text strings\n     - **Overlapping shapes**: Prefer shapes with larger default_font_size or more appropriate placeholder_type\n   - Save the updated inventory with replacements to `replacement-text.json`\n   - **WARNING**: Different template layouts have different shape counts - always check the actual inventory before creating replacements\n\n   Example paragraphs field showing proper formatting:\n   ```json\n   \"paragraphs\": [\n     {\n       \"text\": \"New presentation title text\",\n       \"alignment\": \"CENTER\",\n       \"bold\": true\n     },\n     {\n       \"text\": \"Section Header\",\n       \"bold\": true\n     },\n     {\n       \"text\": \"First bullet point without bullet symbol\",\n       \"bullet\": true,\n       \"level\": 0\n     },\n     {\n       \"text\": \"Red colored text\",\n       \"color\": \"FF0000\"\n     },\n     {\n       \"text\": \"Theme colored text\",\n       \"theme_color\": \"DARK_1\"\n     },\n     {\n       \"text\": \"Regular paragraph text without special formatting\"\n     }\n   ]\n   ```\n\n   **Shapes not listed in the replacement JSON are automatically cleared**:\n   ```json\n   {\n     \"slide-0\": {\n       \"shape-0\": {\n         \"paragraphs\": [...] // This shape gets new text\n       }\n       // shape-1 and shape-2 from inventory will be cleared automatically\n     }\n   }\n   ```\n\n   **Common formatting patterns for presentations**:\n   - Title slides: Bold text, sometimes centered\n   - Section headers within slides: Bold text\n   - Bullet lists: Each item needs `\"bullet\": true, \"level\": 0`\n   - Body text: Usually no special properties needed\n   - Quotes: May have special alignment or font properties\n\n7. **Apply replacements using the `replace.py` script**\n   ```bash\n   python scripts/replace.py working.pptx replacement-text.json output.pptx\n   ```\n\n   The script will:\n   - First extract the inventory of ALL text shapes using functions from inventory.py\n   - Validate that all shapes in the replacement JSON exist in the inventory\n   - Clear text from ALL shapes identified in the inventory\n   - Apply new text only to shapes with \"paragraphs\" defined in the replacement JSON\n   - Preserve formatting by applying paragraph properties from the JSON\n   - Handle bullets, alignment, font properties, and colors automatically\n   - Save the updated presentation\n\n   Example validation errors:\n   ```\n   ERROR: Invalid shapes in replacement JSON:\n     - Shape 'shape-99' not found on 'slide-0'. Available shapes: shape-0, shape-1, shape-4\n     - Slide 'slide-999' not found in inventory\n   ```\n\n   ```\n   ERROR: Replacement text made overflow worse in these shapes:\n     - slide-0/shape-2: overflow worsened by 1.25\" (was 0.00\", now 1.25\")\n   ```\n\n## Creating Thumbnail Grids\n\nTo create visual thumbnail grids of PowerPoint slides for quick analysis and reference:\n\n```bash\npython scripts/thumbnail.py template.pptx [output_prefix]\n```\n\n**Features**:\n- Creates: `thumbnails.jpg` (or `thumbnails-1.jpg`, `thumbnails-2.jpg`, etc. for large decks)\n- Default: 5 columns, max 30 slides per grid (5√ó6)\n- Custom prefix: `python scripts/thumbnail.py template.pptx my-grid`\n  - Note: The output prefix should include the path if you want output in a specific directory (e.g., `workspace/my-grid`)\n- Adjust columns: `--cols 4` (range: 3-6, affects slides per grid)\n- Grid limits: 3 cols = 12 slides/grid, 4 cols = 20, 5 cols = 30, 6 cols = 42\n- Slides are zero-indexed (Slide 0, Slide 1, etc.)\n\n**Use cases**:\n- Template analysis: Quickly understand slide layouts and design patterns\n- Content review: Visual overview of entire presentation\n- Navigation reference: Find specific slides by their visual appearance\n- Quality check: Verify all slides are properly formatted\n\n**Examples**:\n```bash\n# Basic usage\npython scripts/thumbnail.py presentation.pptx\n\n# Combine options: custom name, columns\npython scripts/thumbnail.py template.pptx analysis --cols 4\n```\n\n## Converting Slides to Images\n\nTo visually analyze PowerPoint slides, convert them to images using a two-step process:\n\n1. **Convert PPTX to PDF**:\n   ```bash\n   soffice --headless --convert-to pdf template.pptx\n   ```\n\n2. **Convert PDF pages to JPEG images**:\n   ```bash\n   pdftoppm -jpeg -r 150 template.pdf slide\n   ```\n   This creates files like `slide-1.jpg`, `slide-2.jpg`, etc.\n\nOptions:\n- `-r 150`: Sets resolution to 150 DPI (adjust for quality/size balance)\n- `-jpeg`: Output JPEG format (use `-png` for PNG if preferred)\n- `-f N`: First page to convert (e.g., `-f 2` starts from page 2)\n- `-l N`: Last page to convert (e.g., `-l 5` stops at page 5)\n- `slide`: Prefix for output files\n\nExample for specific range:\n```bash\npdftoppm -jpeg -r 150 -f 2 -l 5 template.pdf slide  # Converts only pages 2-5\n```\n\n## Code Style Guidelines\n**IMPORTANT**: When generating code for PPTX operations:\n- Write concise code\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n## Dependencies\n\nRequired dependencies (should already be installed):\n\n- **markitdown**: `pip install \"markitdown[pptx]\"` (for text extraction from presentations)\n- **pptxgenjs**: `npm install -g pptxgenjs` (for creating presentations via html2pptx)\n- **playwright**: `npm install -g playwright` (for HTML rendering in html2pptx)\n- **react-icons**: `npm install -g react-icons react react-dom` (for icons)\n- **sharp**: `npm install -g sharp` (for SVG rasterization and image processing)\n- **LibreOffice**: `sudo apt-get install libreoffice` (for PDF conversion)\n- **Poppler**: `sudo apt-get install poppler-utils` (for pdftoppm to convert PDF to images)\n- **defusedxml**: `pip install defusedxml` (for secure XML parsing)",
    "id": "pptx",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/pptx",
    "name_zh": "PPT Â§ÑÁêÜ",
    "description_zh": "Presentation creation, editing, and analysis. When Claude needs to work with presentations (.pptx files) for: (1) ÂàõÂª∫ new presentations, (2) Modifying or editing content, (3) Working with layouts, (4) Adding comments or speaker notes, or any other presentation tasks",
    "body_zh": "# PPTX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .pptx file. A .pptx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a presentation, you should convert the document to markdown:\n\n```bash\n# Convert document to markdown\npython -m markitdown path-to-file.pptx\n```\n\n### Raw XML access\nYou need raw XML access for: comments, speaker notes, slide layouts, animations, design elements, and complex formatting. For any of these features, you'll need to unpack a presentation and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_dir>`\n\n**Note**: The unpack.py script is located at `skills/pptx/ooxml/scripts/unpack.py` relative to the project root. If the script doesn't exist at this path, use `find . -name \"unpack.py\"` to locate it.\n\n#### Key file structures\n* `ppt/presentation.xml` - Main presentation metadata and slide references\n* `ppt/slides/slide{N}.xml` - Individual slide contents (slide1.xml, slide2.xml, etc.)\n* `ppt/notesSlides/notesSlide{N}.xml` - Speaker notes for each slide\n* `ppt/comments/modernComment_*.xml` - Comments for specific slides\n* `ppt/slideLayouts/` - Layout templates for slides\n* `ppt/slideMasters/` - Master slide templates\n* `ppt/theme/` - Theme and styling information\n* `ppt/media/` - Images and other media files\n\n#### Typography and color extraction\n**When given an example design to emulate**: Always analyze the presentation's typography and colors first using the methods below:\n1. **Read theme file**: Check `ppt/theme/theme1.xml` for colors (`<a:clrScheme>`) and fonts (`<a:fontScheme>`)\n2. **Sample slide content**: Examine `ppt/slides/slide1.xml` for actual font usage (`<a:rPr>`) and colors\n3. **Search for patterns**: Use grep to find color (`<a:solidFill>`, `<a:srgbClr>`) and font references across all XML files\n\n## Creating a new PowerPoint presentation **without a template**\n\nWhen creating a new PowerPoint presentation from scratch, use the **html2pptx** workflow to convert HTML slides to PowerPoint with accurate positioning.\n\n### Design Principles\n\n**CRITICAL**: Before creating any presentation, analyze the content and choose appropriate design elements:\n1. **Consider the subject matter**: What is this presentation about? What tone, industry, or mood does it suggest?\n2. **Check for branding**: If the user mentions a company/organization, consider their brand colors and identity\n3. **Match palette to content**: Select colors that reflect the subject\n4. **State your approach**: Explain your design choices before writing code\n\n**Requirements**:\n- ‚úÖ State your content-informed design approach BEFORE writing code\n- ‚úÖ Use web-safe fonts only: Arial, Helvetica, Times New Roman, Georgia, Courier New, Verdana, Tahoma, Trebuchet MS, Impact\n- ‚úÖ Create clear visual hierarchy through size, weight, and color\n- ‚úÖ Ensure readability: strong contrast, appropriately sized text, clean alignment\n- ‚úÖ Be consistent: repeat patterns, spacing, and visual language across slides\n\n#### Color Palette Selection\n\n**Choosing colors creatively**:\n- **Think beyond defaults**: What colors genuinely match this specific topic? Avoid autopilot choices.\n- **Consider multiple angles**: Topic, industry, mood, energy level, target audience, brand identity (if mentioned)\n- **Be adventurous**: Try unexpected combinations - a healthcare presentation doesn't have to be green, finance doesn't have to be navy\n- **Build your palette**: Pick 3-5 colors that work together (dominant colors + supporting tones + accent)\n- **Ensure contrast**: Text must be clearly readable on backgrounds\n\n**Example color palettes** (use these to spark creativity - choose one, adapt it, or create your own):\n\n1. **Classic Blue**: Deep navy (#1C2833), slate gray (#2E4053), silver (#AAB7B8), off-white (#F4F6F6)\n2. **Teal & Coral**: Teal (#5EA8A7), deep teal (#277884), coral (#FE4447), white (#FFFFFF)\n3. **Bold Red**: Red (#C0392B), bright red (#E74C3C), orange (#F39C12), yellow (#F1C40F), green (#2ECC71)\n4. **Warm Blush**: Mauve (#A49393), blush (#EED6D3), rose (#E8B4B8), cream (#FAF7F2)\n5. **Burgundy Luxury**: Burgundy (#5D1D2E), crimson (#951233), rust (#C15937), gold (#997929)\n6. **Deep Purple & Emerald**: Purple (#B165FB), dark blue (#181B24), emerald (#40695B), white (#FFFFFF)\n7. **Cream & Forest Green**: Cream (#FFE1C7), forest green (#40695B), white (#FCFCFC)\n8. **Pink & Purple**: Pink (#F8275B), coral (#FF574A), rose (#FF737D), purple (#3D2F68)\n9. **Lime & Plum**: Lime (#C5DE82), plum (#7C3A5F), coral (#FD8C6E), blue-gray (#98ACB5)\n10. **Black & Gold**: Gold (#BF9A4A), black (#000000), cream (#F4F6F6)\n11. **Sage & Terracotta**: Sage (#87A96B), terracotta (#E07A5F), cream (#F4F1DE), charcoal (#2C2C2C)\n12. **Charcoal & Red**: Charcoal (#292929), red (#E33737), light gray (#CCCBCB)\n13. **Vibrant Orange**: Orange (#F96D00), light gray (#F2F2F2), charcoal (#222831)\n14. **Forest Green**: Black (#191A19), green (#4E9F3D), dark green (#1E5128), white (#FFFFFF)\n15. **Retro Rainbow**: Purple (#722880), pink (#D72D51), orange (#EB5C18), amber (#F08800), gold (#DEB600)\n16. **Vintage Earthy**: Mustard (#E3B448), sage (#CBD18F), forest green (#3A6B35), cream (#F4F1DE)\n17. **Coastal Rose**: Old rose (#AD7670), beaver (#B49886), eggshell (#F3ECDC), ash gray (#BFD5BE)\n18. **Orange & Turquoise**: Light orange (#FC993E), grayish turquoise (#667C6F), white (#FCFCFC)\n\n#### Visual Details Options\n\n**Geometric Patterns**:\n- Diagonal section dividers instead of horizontal\n- Asymmetric column widths (30/70, 40/60, 25/75)\n- Rotated text headers at 90¬∞ or 270¬∞\n- Circular/hexagonal frames for images\n- Triangular accent shapes in corners\n- Overlapping shapes for depth\n\n**Border & Frame Treatments**:\n- Thick single-color borders (10-20pt) on one side only\n- Double-line borders with contrasting colors\n- Corner brackets instead of full frames\n- L-shaped borders (top+left or bottom+right)\n- Underline accents beneath headers (3-5pt thick)\n\n**Typography Treatments**:\n- Extreme size contrast (72pt headlines vs 11pt body)\n- All-caps headers with wide letter spacing\n- Numbered sections in oversized display type\n- Monospace (Courier New) for data/stats/technical content\n- Condensed fonts (Arial Narrow) for dense information\n- Outlined text for emphasis\n\n**Chart & Data Styling**:\n- Monochrome charts with single accent color for key data\n- Horizontal bar charts instead of vertical\n- Dot plots instead of bar charts\n- Minimal gridlines or none at all\n- Data labels directly on elements (no legends)\n- Oversized numbers for key metrics\n\n**Layout Innovations**:\n- Full-bleed images with text overlays\n- Sidebar column (20-30% width) for navigation/context\n- Modular grid systems (3√ó3, 4√ó4 blocks)\n- Z-pattern or F-pattern content flow\n- Floating text boxes over colored shapes\n- Magazine-style multi-column layouts\n\n**Background Treatments**:\n- Solid color blocks occupying 40-60% of slide\n- Gradient fills (vertical or diagonal only)\n- Split backgrounds (two colors, diagonal or vertical)\n- Edge-to-edge color bands\n- Negative space as a design element\n\n### Layout Tips\n**When creating slides with charts or tables:**\n- **Two-column layout (PREFERRED)**: Use a header spanning the full width, then two columns below - text/bullets in one column and the featured content in the other. This provides better balance and makes charts/tables more readable. Use flexbox with unequal column widths (e.g., 40%/60% split) to optimize space for each content type.\n- **Full-slide layout**: Let the featured content (chart/table) take up the entire slide for maximum impact and readability\n- **NEVER vertically stack**: Do not place charts/tables below text in a single column - this causes poor readability and layout issues\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`html2pptx.md`](html2pptx.md) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for detailed syntax, critical formatting rules, and best practices before proceeding with presentation creation.\n2. Create an HTML file for each slide with proper dimensions (e.g., 720pt √ó 405pt for 16:9)\n   - Use `<p>`, `<h1>`-`<h6>`, `<ul>`, `<ol>` for all text content\n   - Use `class=\"placeholder\"` for areas where charts/tables will be added (render with gray background for visibility)\n   - **CRITICAL**: Rasterize gradients and icons as PNG images FIRST using Sharp, then reference in HTML\n   - **LAYOUT**: For slides with charts/tables/images, use either full-slide layout or two-column layout for better readability\n3. Create and run a JavaScript file using the [`html2pptx.js`](scripts/html2pptx.js) library to convert HTML slides to PowerPoint and save the presentation\n   - Use the `html2pptx()` function to process each HTML file\n   - Add charts and tables to placeholder areas using PptxGenJS API\n   - Save the presentation using `pptx.writeFile()`\n4. **Visual validation**: Generate thumbnails and inspect for layout issues\n   - Create thumbnail grid: `python scripts/thumbnail.py output.pptx workspace/thumbnails --cols 4`\n   - Read and carefully examine the thumbnail image for:\n     - **Text cutoff**: Text being cut off by header bars, shapes, or slide edges\n     - **Text overlap**: Text overlapping with other text or shapes\n     - **Positioning issues**: Content too close to slide boundaries or other elements\n     - **Contrast issues**: Insufficient contrast between text and backgrounds\n   - If issues found, adjust HTML margins/spacing/colors and regenerate the presentation\n   - Repeat until all slides are visually correct\n\n## Editing an existing PowerPoint presentation\n\nWhen edit slides in an existing PowerPoint presentation, you need to work with the raw Office Open XML (OOXML) format. This involves unpacking the .pptx file, editing the XML content, and repacking it.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~500 lines) completely from start to finish.  **NEVER set any range limits when reading this file.**  Read the full file content for detailed guidance on OOXML structure and editing workflows before any presentation editing.\n2. Unpack the presentation: `python ooxml/scripts/unpack.py <office_file> <output_dir>`\n3. Edit the XML files (primarily `ppt/slides/slide{N}.xml` and related files)\n4. **CRITICAL**: Validate immediately after each edit and fix any validation errors before proceeding: `python ooxml/scripts/validate.py <dir> --original <file>`\n5. Pack the final presentation: `python ooxml/scripts/pack.py <input_directory> <office_file>`\n\n## Creating a new PowerPoint presentation **using a template**\n\nWhen you need to create a presentation that follows an existing template's design, you'll need to duplicate and re-arrange template slides before then replacing placeholder context.\n\n### Workflow\n1. **Extract template text AND create visual thumbnail grid**:\n   * Extract text: `python -m markitdown template.pptx > template-content.md`\n   * Read `template-content.md`: Read the entire file to understand the contents of the template presentation. **NEVER set any range limits when reading this file.**\n   * Create thumbnail grids: `python scripts/thumbnail.py template.pptx`\n   * See [Creating Thumbnail Grids](#creating-thumbnail-grids) section for more details\n\n2. **Analyze template and save inventory to a file**:\n   * **Visual Analysis**: Review thumbnail grid(s) to understand slide layouts, design patterns, and visual structure\n   * Create and save a template inventory file at `template-inventory.md` containing:\n     ```markdown\n     # Template Inventory Analysis\n     **Total Slides: [count]**\n     **IMPORTANT: Slides are 0-indexed (first slide = 0, last slide = count-1)**\n\n     ## [Category Name]\n     - Slide 0: [Layout code if available] - Description/purpose\n     - Slide 1: [Layout code] - Description/purpose\n     - Slide 2: [Layout code] - Description/purpose\n     [... EVERY slide must be listed individually with its index ...]\n     ```\n   * **Using the thumbnail grid**: Reference the visual thumbnails to identify:\n     - Layout patterns (title slides, content layouts, section dividers)\n     - Image placeholder locations and counts\n     - Design consistency across slide groups\n     - Visual hierarchy and structure\n   * This inventory file is REQUIRED for selecting appropriate templates in the next step\n\n3. **Create presentation outline based on template inventory**:\n   * Review available templates from step 2.\n   * Choose an intro or title template for the first slide. This should be one of the first templates.\n   * Choose safe, text-based layouts for the other slides.\n   * **CRITICAL: Match layout structure to actual content**:\n     - Single-column layouts: Use for unified narrative or single topic\n     - Two-column layouts: Use ONLY when you have exactly 2 distinct items/concepts\n     - Three-column layouts: Use ONLY when you have exactly 3 distinct items/concepts\n     - Image + text layouts: Use ONLY when you have actual images to insert\n     - Quote layouts: Use ONLY for actual quotes from people (with attribution), never for emphasis\n     - Never use layouts with more placeholders than you have content\n     - If you have 2 items, don't force them into a 3-column layout\n     - If you have 4+ items, consider breaking into multiple slides or using a list format\n   * Count your actual content pieces BEFORE selecting the layout\n   * Verify each placeholder in the chosen layout will be filled with meaningful content\n   * Select one option representing the **best** layout for each content section.\n   * Save `outline.md` with content AND template mapping that leverages available designs\n   * Example template mapping:\n      ```\n      # Template slides to use (0-based indexing)\n      # WARNING: Verify indices are within range! Template with 73 slides has indices 0-72\n      # Mapping: slide numbers from outline -> template slide indices\n      template_mapping = [\n          0,   # Use slide 0 (Title/Cover)\n          34,  # Use slide 34 (B1: Title and body)\n          34,  # Use slide 34 again (duplicate for second B1)\n          50,  # Use slide 50 (E1: Quote)\n          54,  # Use slide 54 (F2: Closing + Text)\n      ]\n      ```\n\n4. **Duplicate, reorder, and delete slides using `rearrange.py`**:\n   * Use the `scripts/rearrange.py` script to create a new presentation with slides in the desired order:\n     ```bash\n     python scripts/rearrange.py template.pptx working.pptx 0,34,34,50,52\n     ```\n   * The script handles duplicating repeated slides, deleting unused slides, and reordering automatically\n   * Slide indices are 0-based (first slide is 0, second is 1, etc.)\n   * The same slide index can appear multiple times to duplicate that slide\n\n5. **Extract ALL text using the `inventory.py` script**:\n   * **Run inventory extraction**:\n     ```bash\n     python scripts/inventory.py working.pptx text-inventory.json\n     ```\n   * **Read text-inventory.json**: Read the entire text-inventory.json file to understand all shapes and their properties. **NEVER set any range limits when reading this file.**\n\n   * The inventory JSON structure:\n      ```json\n        {\n          \"slide-0\": {\n            \"shape-0\": {\n              \"placeholder_type\": \"TITLE\",  // or null for non-placeholders\n              \"left\": 1.5,                  // position in inches\n              \"top\": 2.0,\n              \"width\": 7.5,\n              \"height\": 1.2,\n              \"paragraphs\": [\n                {\n                  \"text\": \"Paragraph text\",\n                  // Optional properties (only included when non-default):\n                  \"bullet\": true,           // explicit bullet detected\n                  \"level\": 0,               // only included when bullet is true\n                  \"alignment\": \"CENTER\",    // CENTER, RIGHT (not LEFT)\n                  \"space_before\": 10.0,     // space before paragraph in points\n                  \"space_after\": 6.0,       // space after paragraph in points\n                  \"line_spacing\": 22.4,     // line spacing in points\n                  \"font_name\": \"Arial\",     // from first run\n                  \"font_size\": 14.0,        // in points\n                  \"bold\": true,\n                  \"italic\": false,\n                  \"underline\": false,\n                  \"color\": \"FF0000\"         // RGB color\n                }\n              ]\n            }\n          }\n        }\n      ```\n\n   * Key features:\n     - **Slides**: Named as \"slide-0\", \"slide-1\", etc.\n     - **Shapes**: Ordered by visual position (top-to-bottom, left-to-right) as \"shape-0\", \"shape-1\", etc.\n     - **Placeholder types**: TITLE, CENTER_TITLE, SUBTITLE, BODY, OBJECT, or null\n     - **Default font size**: `default_font_size` in points extracted from layout placeholders (when available)\n     - **Slide numbers are filtered**: Shapes with SLIDE_NUMBER placeholder type are automatically excluded from inventory\n     - **Bullets**: When `bullet: true`, `level` is always included (even if 0)\n     - **Spacing**: `space_before`, `space_after`, and `line_spacing` in points (only included when set)\n     - **Colors**: `color` for RGB (e.g., \"FF0000\"), `theme_color` for theme colors (e.g., \"DARK_1\")\n     - **Properties**: Only non-default values are included in the output\n\n6. **Generate replacement text and save the data to a JSON file**\n   Based on the text inventory from the previous step:\n   - **CRITICAL**: First verify which shapes exist in the inventory - only reference shapes that are actually present\n   - **VALIDATION**: The replace.py script will validate that all shapes in your replacement JSON exist in the inventory\n     - If you reference a non-existent shape, you'll get an error showing available shapes\n     - If you reference a non-existent slide, you'll get an error indicating the slide doesn't exist\n     - All validation errors are shown at once before the script exits\n   - **IMPORTANT**: The replace.py script uses inventory.py internally to identify ALL text shapes\n   - **AUTOMATIC CLEARING**: ALL text shapes from the inventory will be cleared unless you provide \"paragraphs\" for them\n   - Add a \"paragraphs\" field to shapes that need content (not \"replacement_paragraphs\")\n   - Shapes without \"paragraphs\" in the replacement JSON will have their text cleared automatically\n   - Paragraphs with bullets will be automatically left aligned. Don't set the `alignment` property on when `\"bullet\": true`\n   - Generate appropriate replacement content for placeholder text\n   - Use shape size to determine appropriate content length\n   - **CRITICAL**: Include paragraph properties from the original inventory - don't just provide text\n   - **IMPORTANT**: When bullet: true, do NOT include bullet symbols (‚Ä¢, -, *) in text - they're added automatically\n   - **ESSENTIAL FORMATTING RULES**:\n     - Headers/titles should typically have `\"bold\": true`\n     - List items should have `\"bullet\": true, \"level\": 0` (level is required when bullet is true)\n     - Preserve any alignment properties (e.g., `\"alignment\": \"CENTER\"` for centered text)\n     - Include font properties when different from default (e.g., `\"font_size\": 14.0`, `\"font_name\": \"Lora\"`)\n     - Colors: Use `\"color\": \"FF0000\"` for RGB or `\"theme_color\": \"DARK_1\"` for theme colors\n     - The replacement script expects **properly formatted paragraphs**, not just text strings\n     - **Overlapping shapes**: Prefer shapes with larger default_font_size or more appropriate placeholder_type\n   - Save the updated inventory with replacements to `replacement-text.json`\n   - **WARNING**: Different template layouts have different shape counts - always check the actual inventory before creating replacements\n\n   Example paragraphs field showing proper formatting:\n   ```json\n   \"paragraphs\": [\n     {\n       \"text\": \"New presentation title text\",\n       \"alignment\": \"CENTER\",\n       \"bold\": true\n     },\n     {\n       \"text\": \"Section Header\",\n       \"bold\": true\n     },\n     {\n       \"text\": \"First bullet point without bullet symbol\",\n       \"bullet\": true,\n       \"level\": 0\n     },\n     {\n       \"text\": \"Red colored text\",\n       \"color\": \"FF0000\"\n     },\n     {\n       \"text\": \"Theme colored text\",\n       \"theme_color\": \"DARK_1\"\n     },\n     {\n       \"text\": \"Regular paragraph text without special formatting\"\n     }\n   ]\n   ```\n\n   **Shapes not listed in the replacement JSON are automatically cleared**:\n   ```json\n   {\n     \"slide-0\": {\n       \"shape-0\": {\n         \"paragraphs\": [...] // This shape gets new text\n       }\n       // shape-1 and shape-2 from inventory will be cleared automatically\n     }\n   }\n   ```\n\n   **Common formatting patterns for presentations**:\n   - Title slides: Bold text, sometimes centered\n   - Section headers within slides: Bold text\n   - Bullet lists: Each item needs `\"bullet\": true, \"level\": 0`\n   - Body text: Usually no special properties needed\n   - Quotes: May have special alignment or font properties\n\n7. **Apply replacements using the `replace.py` script**\n   ```bash\n   python scripts/replace.py working.pptx replacement-text.json output.pptx\n   ```\n\n   The script will:\n   - First extract the inventory of ALL text shapes using functions from inventory.py\n   - Validate that all shapes in the replacement JSON exist in the inventory\n   - Clear text from ALL shapes identified in the inventory\n   - Apply new text only to shapes with \"paragraphs\" defined in the replacement JSON\n   - Preserve formatting by applying paragraph properties from the JSON\n   - Handle bullets, alignment, font properties, and colors automatically\n   - Save the updated presentation\n\n   Example validation errors:\n   ```\n   ERROR: Invalid shapes in replacement JSON:\n     - Shape 'shape-99' not found on 'slide-0'. Available shapes: shape-0, shape-1, shape-4\n     - Slide 'slide-999' not found in inventory\n   ```\n\n   ```\n   ERROR: Replacement text made overflow worse in these shapes:\n     - slide-0/shape-2: overflow worsened by 1.25\" (was 0.00\", now 1.25\")\n   ```\n\n## Creating Thumbnail Grids\n\nTo create visual thumbnail grids of PowerPoint slides for quick analysis and reference:\n\n```bash\npython scripts/thumbnail.py template.pptx [output_prefix]\n```\n\n**Features**:\n- Creates: `thumbnails.jpg` (or `thumbnails-1.jpg`, `thumbnails-2.jpg`, etc. for large decks)\n- Default: 5 columns, max 30 slides per grid (5√ó6)\n- Custom prefix: `python scripts/thumbnail.py template.pptx my-grid`\n  - Note: The output prefix should include the path if you want output in a specific directory (e.g., `workspace/my-grid`)\n- Adjust columns: `--cols 4` (range: 3-6, affects slides per grid)\n- Grid limits: 3 cols = 12 slides/grid, 4 cols = 20, 5 cols = 30, 6 cols = 42\n- Slides are zero-indexed (Slide 0, Slide 1, etc.)\n\n**Use cases**:\n- Template analysis: Quickly understand slide layouts and design patterns\n- Content review: Visual overview of entire presentation\n- Navigation reference: Find specific slides by their visual appearance\n- Quality check: Verify all slides are properly formatted\n\n**Examples**:\n```bash\n# Basic usage\npython scripts/thumbnail.py presentation.pptx\n\n# Combine options: custom name, columns\npython scripts/thumbnail.py template.pptx analysis --cols 4\n```\n\n## Converting Slides to Images\n\nTo visually analyze PowerPoint slides, convert them to images using a two-step process:\n\n1. **Convert PPTX to PDF**:\n   ```bash\n   soffice --headless --convert-to pdf template.pptx\n   ```\n\n2. **Convert PDF pages to JPEG images**:\n   ```bash\n   pdftoppm -jpeg -r 150 template.pdf slide\n   ```\n   This creates files like `slide-1.jpg`, `slide-2.jpg`, etc.\n\nOptions:\n- `-r 150`: Sets resolution to 150 DPI (adjust for quality/size balance)\n- `-jpeg`: Output JPEG format (use `-png` for PNG if preferred)\n- `-f N`: First page to convert (e.g., `-f 2` starts from page 2)\n- `-l N`: Last page to convert (e.g., `-l 5` stops at page 5)\n- `slide`: Prefix for output files\n\nExample for specific range:\n```bash\npdftoppm -jpeg -r 150 -f 2 -l 5 template.pdf slide  # Converts only pages 2-5\n```\n\n## Code Style Guidelines\n**IMPORTANT**: When generating code for PPTX operations:\n- Write concise code\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n## Dependencies\n\nRequired dependencies (should already be installed):\n\n- **markitdown**: `pip install \"markitdown[pptx]\"` (for text extraction from presentations)\n- **pptxgenjs**: `npm install -g pptxgenjs` (for creating presentations via html2pptx)\n- **playwright**: `npm install -g playwright` (for HTML rendering in html2pptx)\n- **react-icons**: `npm install -g react-icons react react-dom` (for icons)\n- **sharp**: `npm install -g sharp` (for SVG rasterization and image processing)\n- **LibreOffice**: `sudo apt-get install libreoffice` (for PDF conversion)\n- **Poppler**: `sudo apt-get install poppler-utils` (for pdftoppm to convert PDF to images)\n- **defusedxml**: `pip install defusedxml` (for secure XML parsing)"
  },
  {
    "name": "skill-creator",
    "description": "Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
    "body": "# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasks‚Äîthey transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n## Core Principles\n\n### Concise is Key\n\nThe context window is a public good. Skills share the context window with everything else Claude needs: system prompt, conversation history, other Skills' metadata, and the actual user request.\n\n**Default assumption: Claude is already very smart.** Only add context Claude doesn't already have. Challenge each piece of information: \"Does Claude really need this explanation?\" and \"Does this paragraph justify its token cost?\"\n\nPrefer concise examples over verbose explanations.\n\n### Set Appropriate Degrees of Freedom\n\nMatch the level of specificity to the task's fragility and variability:\n\n**High freedom (text-based instructions)**: Use when multiple approaches are valid, decisions depend on context, or heuristics guide the approach.\n\n**Medium freedom (pseudocode or scripts with parameters)**: Use when a preferred pattern exists, some variation is acceptable, or configuration affects behavior.\n\n**Low freedom (specific scripts, few parameters)**: Use when operations are fragile and error-prone, consistency is critical, or a specific sequence must be followed.\n\nThink of Claude as exploring a path: a narrow bridge with cliffs needs specific guardrails (low freedom), while an open field allows many routes (high freedom).\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\n‚îú‚îÄ‚îÄ SKILL.md (required)\n‚îÇ   ‚îú‚îÄ‚îÄ YAML frontmatter metadata (required)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ name: (required)\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ description: (required)\n‚îÇ   ‚îî‚îÄ‚îÄ Markdown instructions (required)\n‚îî‚îÄ‚îÄ Bundled Resources (optional)\n    ‚îú‚îÄ‚îÄ scripts/          - Executable code (Python/Bash/etc.)\n    ‚îú‚îÄ‚îÄ references/       - Documentation intended to be loaded into context as needed\n    ‚îî‚îÄ‚îÄ assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\nEvery SKILL.md consists of:\n\n- **Frontmatter** (YAML): Contains `name` and `description` fields. These are the only fields that Claude reads to determine when the skill gets used, thus it is very important to be clear and comprehensive in describing what the skill is, and when it should be used.\n- **Body** (Markdown): Instructions and guidance for using the skill. Only loaded AFTER the skill triggers (if at all).\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill‚Äîthis keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n#### What to Not Include in a Skill\n\nA skill should only contain essential files that directly support its functionality. Do NOT create extraneous documentation or auxiliary files, including:\n\n- README.md\n- INSTALLATION_GUIDE.md\n- QUICK_REFERENCE.md\n- CHANGELOG.md\n- etc.\n\nThe skill should only contain the information needed for an AI agent to do the job at hand. It should not contain auxilary context about the process that went into creating it, setup and testing procedures, user-facing documentation, etc. Creating additional documentation files just adds clutter and confusion.\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited because scripts can be executed without reading into context window)\n\n#### Progressive Disclosure Patterns\n\nKeep SKILL.md body to the essentials and under 500 lines to minimize context bloat. Split content into separate files when approaching this limit. When splitting out content into other files, it is very important to reference them from SKILL.md and describe clearly when to read them, to ensure the reader of the skill knows they exist and when to use them.\n\n**Key principle:** When a skill supports multiple variations, frameworks, or options, keep only the core workflow and selection guidance in SKILL.md. Move variant-specific details (patterns, examples, configuration) into separate reference files.\n\n**Pattern 1: High-level guide with references**\n\n```markdown\n# PDF Processing\n\n## Quick start\n\nExtract text with pdfplumber:\n[code example]\n\n## Advanced features\n\n- **Form filling**: See [FORMS.md](FORMS.md) for complete guide\n- **API reference**: See [REFERENCE.md](REFERENCE.md) for all methods\n- **Examples**: See [EXAMPLES.md](EXAMPLES.md) for common patterns\n```\n\nClaude loads FORMS.md, REFERENCE.md, or EXAMPLES.md only when needed.\n\n**Pattern 2: Domain-specific organization**\n\nFor Skills with multiple domains, organize content by domain to avoid loading irrelevant context:\n\n```\nbigquery-skill/\n‚îú‚îÄ‚îÄ SKILL.md (overview and navigation)\n‚îî‚îÄ‚îÄ reference/\n    ‚îú‚îÄ‚îÄ finance.md (revenue, billing metrics)\n    ‚îú‚îÄ‚îÄ sales.md (opportunities, pipeline)\n    ‚îú‚îÄ‚îÄ product.md (API usage, features)\n    ‚îî‚îÄ‚îÄ marketing.md (campaigns, attribution)\n```\n\nWhen a user asks about sales metrics, Claude only reads sales.md.\n\nSimilarly, for skills supporting multiple frameworks or variants, organize by variant:\n\n```\ncloud-deploy/\n‚îú‚îÄ‚îÄ SKILL.md (workflow + provider selection)\n‚îî‚îÄ‚îÄ references/\n    ‚îú‚îÄ‚îÄ aws.md (AWS deployment patterns)\n    ‚îú‚îÄ‚îÄ gcp.md (GCP deployment patterns)\n    ‚îî‚îÄ‚îÄ azure.md (Azure deployment patterns)\n```\n\nWhen the user chooses AWS, Claude only reads aws.md.\n\n**Pattern 3: Conditional details**\n\nShow basic content, link to advanced content:\n\n```markdown\n# DOCX Processing\n\n## Creating documents\n\nUse docx-js for new documents. See [DOCX-JS.md](DOCX-JS.md).\n\n## Editing documents\n\nFor simple edits, modify the XML directly.\n\n**For tracked changes**: See [REDLINING.md](REDLINING.md)\n**For OOXML details**: See [OOXML.md](OOXML.md)\n```\n\nClaude reads REDLINING.md or OOXML.md only when the user needs those features.\n\n**Important guidelines:**\n\n- **Avoid deeply nested references** - Keep references one level deep from SKILL.md. All reference files should link directly from SKILL.md.\n- **Structure longer reference files** - For files longer than 100 lines, include a table of contents at the top so Claude can see the full scope when previewing.\n\n## Skill Creation Process\n\nSkill creation involves these steps:\n\n1. Understand the skill with concrete examples\n2. Plan reusable skill contents (scripts, references, assets)\n3. Initialize the skill (run init_skill.py)\n4. Edit the skill (implement resources and write SKILL.md)\n5. Package the skill (run package_skill.py)\n6. Iterate based on real usage\n\nFollow these steps in order, skipping only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Initializing the Skill\n\nAt this point, it is time to actually create the skill.\n\nSkip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.\n\nWhen creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.\n\nUsage:\n\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory>\n```\n\nThe script:\n\n- Creates the skill directory at the specified path\n- Generates a SKILL.md template with proper frontmatter and TODO placeholders\n- Creates example resource directories: `scripts/`, `references/`, and `assets/`\n- Adds example files in each directory that can be customized or deleted\n\nAfter initialization, customize or remove the generated SKILL.md and example files as needed.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Include information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Learn Proven Design Patterns\n\nConsult these helpful guides based on your skill's needs:\n\n- **Multi-step processes**: See references/workflows.md for sequential workflows and conditional logic\n- **Specific output formats or quality standards**: See references/output-patterns.md for template and example patterns\n\nThese files contain established best practices for effective skill design.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAdded scripts must be tested by actually running them to ensure there are no bugs and that the output matches what is expected. If there are many similar scripts, only a representative sample needs to be tested to ensure confidence that they all work while balancing time to completion.\n\nAny example files and directories not needed for the skill should be deleted. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.\n\n#### Update SKILL.md\n\n**Writing Guidelines:** Always use imperative/infinitive form.\n\n##### Frontmatter\n\nWrite the YAML frontmatter with `name` and `description`:\n\n- `name`: The skill name\n- `description`: This is the primary triggering mechanism for your skill, and helps Claude understand when to use the skill.\n  - Include both what the Skill does and specific triggers/contexts for when to use it.\n  - Include all \"when to use\" information here - Not in the body. The body is only loaded after triggering, so \"When to Use This Skill\" sections in the body are not helpful to Claude.\n  - Example description for a `docx` skill: \"Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. Use when Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks\"\n\nDo not include any other fields in YAML frontmatter.\n\n##### Body\n\nWrite instructions for using the skill and its bundled resources.\n\n### Step 5: Packaging a Skill\n\nOnce development of the skill is complete, it must be packaged into a distributable .skill file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder>\n```\n\nOptional output directory specification:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder> ./dist\n```\n\nThe packaging script will:\n\n1. **Validate** the skill automatically, checking:\n\n   - YAML frontmatter format and required fields\n   - Skill naming conventions and directory structure\n   - Description completeness and quality\n   - File organization and resource references\n\n2. **Package** the skill if validation passes, creating a .skill file named after the skill (e.g., `my-skill.skill`) that includes all files and maintains the proper directory structure for distribution. The .skill file is a zip file with a .skill extension.\n\nIf validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again",
    "id": "skill-creator",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/skill-creator",
    "name_zh": "ÊäÄËÉΩÂàõÂª∫Âô®",
    "description_zh": "Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
    "body_zh": "# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasks‚Äîthey transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n## Core Principles\n\n### Concise is Key\n\nThe context window is a public good. Skills share the context window with everything else Claude needs: system prompt, conversation history, other Skills' metadata, and the actual user request.\n\n**Default assumption: Claude is already very smart.** Only add context Claude doesn't already have. Challenge each piece of information: \"Does Claude really need this explanation?\" and \"Does this paragraph justify its token cost?\"\n\nPrefer concise examples over verbose explanations.\n\n### Set Appropriate Degrees of Freedom\n\nMatch the level of specificity to the task's fragility and variability:\n\n**High freedom (text-based instructions)**: Use when multiple approaches are valid, decisions depend on context, or heuristics guide the approach.\n\n**Medium freedom (pseudocode or scripts with parameters)**: Use when a preferred pattern exists, some variation is acceptable, or configuration affects behavior.\n\n**Low freedom (specific scripts, few parameters)**: Use when operations are fragile and error-prone, consistency is critical, or a specific sequence must be followed.\n\nThink of Claude as exploring a path: a narrow bridge with cliffs needs specific guardrails (low freedom), while an open field allows many routes (high freedom).\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\n‚îú‚îÄ‚îÄ SKILL.md (required)\n‚îÇ   ‚îú‚îÄ‚îÄ YAML frontmatter metadata (required)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ name: (required)\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ description: (required)\n‚îÇ   ‚îî‚îÄ‚îÄ Markdown instructions (required)\n‚îî‚îÄ‚îÄ Bundled Resources (optional)\n    ‚îú‚îÄ‚îÄ scripts/          - Executable code (Python/Bash/etc.)\n    ‚îú‚îÄ‚îÄ references/       - Documentation intended to be loaded into context as needed\n    ‚îî‚îÄ‚îÄ assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\nEvery SKILL.md consists of:\n\n- **Frontmatter** (YAML): Contains `name` and `description` fields. These are the only fields that Claude reads to determine when the skill gets used, thus it is very important to be clear and comprehensive in describing what the skill is, and when it should be used.\n- **Body** (Markdown): Instructions and guidance for using the skill. Only loaded AFTER the skill triggers (if at all).\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill‚Äîthis keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n#### What to Not Include in a Skill\n\nA skill should only contain essential files that directly support its functionality. Do NOT create extraneous documentation or auxiliary files, including:\n\n- README.md\n- INSTALLATION_GUIDE.md\n- QUICK_REFERENCE.md\n- CHANGELOG.md\n- etc.\n\nThe skill should only contain the information needed for an AI agent to do the job at hand. It should not contain auxilary context about the process that went into creating it, setup and testing procedures, user-facing documentation, etc. Creating additional documentation files just adds clutter and confusion.\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited because scripts can be executed without reading into context window)\n\n#### Progressive Disclosure Patterns\n\nKeep SKILL.md body to the essentials and under 500 lines to minimize context bloat. Split content into separate files when approaching this limit. When splitting out content into other files, it is very important to reference them from SKILL.md and describe clearly when to read them, to ensure the reader of the skill knows they exist and when to use them.\n\n**Key principle:** When a skill supports multiple variations, frameworks, or options, keep only the core workflow and selection guidance in SKILL.md. Move variant-specific details (patterns, examples, configuration) into separate reference files.\n\n**Pattern 1: High-level guide with references**\n\n```markdown\n# PDF Processing\n\n## Quick start\n\nExtract text with pdfplumber:\n[code example]\n\n## Advanced features\n\n- **Form filling**: See [FORMS.md](FORMS.md) for complete guide\n- **API reference**: See [REFERENCE.md](REFERENCE.md) for all methods\n- **Examples**: See [EXAMPLES.md](EXAMPLES.md) for common patterns\n```\n\nClaude loads FORMS.md, REFERENCE.md, or EXAMPLES.md only when needed.\n\n**Pattern 2: Domain-specific organization**\n\nFor Skills with multiple domains, organize content by domain to avoid loading irrelevant context:\n\n```\nbigquery-skill/\n‚îú‚îÄ‚îÄ SKILL.md (overview and navigation)\n‚îî‚îÄ‚îÄ reference/\n    ‚îú‚îÄ‚îÄ finance.md (revenue, billing metrics)\n    ‚îú‚îÄ‚îÄ sales.md (opportunities, pipeline)\n    ‚îú‚îÄ‚îÄ product.md (API usage, features)\n    ‚îî‚îÄ‚îÄ marketing.md (campaigns, attribution)\n```\n\nWhen a user asks about sales metrics, Claude only reads sales.md.\n\nSimilarly, for skills supporting multiple frameworks or variants, organize by variant:\n\n```\ncloud-deploy/\n‚îú‚îÄ‚îÄ SKILL.md (workflow + provider selection)\n‚îî‚îÄ‚îÄ references/\n    ‚îú‚îÄ‚îÄ aws.md (AWS deployment patterns)\n    ‚îú‚îÄ‚îÄ gcp.md (GCP deployment patterns)\n    ‚îî‚îÄ‚îÄ azure.md (Azure deployment patterns)\n```\n\nWhen the user chooses AWS, Claude only reads aws.md.\n\n**Pattern 3: Conditional details**\n\nShow basic content, link to advanced content:\n\n```markdown\n# DOCX Processing\n\n## Creating documents\n\nUse docx-js for new documents. See [DOCX-JS.md](DOCX-JS.md).\n\n## Editing documents\n\nFor simple edits, modify the XML directly.\n\n**For tracked changes**: See [REDLINING.md](REDLINING.md)\n**For OOXML details**: See [OOXML.md](OOXML.md)\n```\n\nClaude reads REDLINING.md or OOXML.md only when the user needs those features.\n\n**Important guidelines:**\n\n- **Avoid deeply nested references** - Keep references one level deep from SKILL.md. All reference files should link directly from SKILL.md.\n- **Structure longer reference files** - For files longer than 100 lines, include a table of contents at the top so Claude can see the full scope when previewing.\n\n## Skill Creation Process\n\nSkill creation involves these steps:\n\n1. Understand the skill with concrete examples\n2. Plan reusable skill contents (scripts, references, assets)\n3. Initialize the skill (run init_skill.py)\n4. Edit the skill (implement resources and write SKILL.md)\n5. Package the skill (run package_skill.py)\n6. Iterate based on real usage\n\nFollow these steps in order, skipping only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Initializing the Skill\n\nAt this point, it is time to actually create the skill.\n\nSkip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.\n\nWhen creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.\n\nUsage:\n\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory>\n```\n\nThe script:\n\n- Creates the skill directory at the specified path\n- Generates a SKILL.md template with proper frontmatter and TODO placeholders\n- Creates example resource directories: `scripts/`, `references/`, and `assets/`\n- Adds example files in each directory that can be customized or deleted\n\nAfter initialization, customize or remove the generated SKILL.md and example files as needed.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Include information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Learn Proven Design Patterns\n\nConsult these helpful guides based on your skill's needs:\n\n- **Multi-step processes**: See references/workflows.md for sequential workflows and conditional logic\n- **Specific output formats or quality standards**: See references/output-patterns.md for template and example patterns\n\nThese files contain established best practices for effective skill design.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAdded scripts must be tested by actually running them to ensure there are no bugs and that the output matches what is expected. If there are many similar scripts, only a representative sample needs to be tested to ensure confidence that they all work while balancing time to completion.\n\nAny example files and directories not needed for the skill should be deleted. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.\n\n#### Update SKILL.md\n\n**Writing Guidelines:** Always use imperative/infinitive form.\n\n##### Frontmatter\n\nWrite the YAML frontmatter with `name` and `description`:\n\n- `name`: The skill name\n- `description`: This is the primary triggering mechanism for your skill, and helps Claude understand when to use the skill.\n  - Include both what the Skill does and specific triggers/contexts for when to use it.\n  - Include all \"when to use\" information here - Not in the body. The body is only loaded after triggering, so \"When to Use This Skill\" sections in the body are not helpful to Claude.\n  - Example description for a `docx` skill: \"Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. Use when Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks\"\n\nDo not include any other fields in YAML frontmatter.\n\n##### Body\n\nWrite instructions for using the skill and its bundled resources.\n\n### Step 5: Packaging a Skill\n\nOnce development of the skill is complete, it must be packaged into a distributable .skill file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder>\n```\n\nOptional output directory specification:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder> ./dist\n```\n\nThe packaging script will:\n\n1. **Validate** the skill automatically, checking:\n\n   - YAML frontmatter format and required fields\n   - Skill naming conventions and directory structure\n   - Description completeness and quality\n   - File organization and resource references\n\n2. **Package** the skill if validation passes, creating a .skill file named after the skill (e.g., `my-skill.skill`) that includes all files and maintains the proper directory structure for distribution. The .skill file is a zip file with a .skill extension.\n\nIf validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again"
  },
  {
    "name": "slack-gif-creator",
    "description": "Knowledge and utilities for creating animated GIFs optimized for Slack. Provides constraints, validation tools, and animation concepts. Use when users request animated GIFs for Slack like \"make me a GIF of X doing Y for Slack.\"",
    "body": "# Slack GIF Creator\n\nA toolkit providing utilities and knowledge for creating animated GIFs optimized for Slack.\n\n## Slack Requirements\n\n**Dimensions:**\n- Emoji GIFs: 128x128 (recommended)\n- Message GIFs: 480x480\n\n**Parameters:**\n- FPS: 10-30 (lower is smaller file size)\n- Colors: 48-128 (fewer = smaller file size)\n- Duration: Keep under 3 seconds for emoji GIFs\n\n## Core Workflow\n\n```python\nfrom core.gif_builder import GIFBuilder\nfrom PIL import Image, ImageDraw\n\n# 1. Create builder\nbuilder = GIFBuilder(width=128, height=128, fps=10)\n\n# 2. Generate frames\nfor i in range(12):\n    frame = Image.new('RGB', (128, 128), (240, 248, 255))\n    draw = ImageDraw.Draw(frame)\n\n    # Draw your animation using PIL primitives\n    # (circles, polygons, lines, etc.)\n\n    builder.add_frame(frame)\n\n# 3. Save with optimization\nbuilder.save('output.gif', num_colors=48, optimize_for_emoji=True)\n```\n\n## Drawing Graphics\n\n### Working with User-Uploaded Images\nIf a user uploads an image, consider whether they want to:\n- **Use it directly** (e.g., \"animate this\", \"split this into frames\")\n- **Use it as inspiration** (e.g., \"make something like this\")\n\nLoad and work with images using PIL:\n```python\nfrom PIL import Image\n\nuploaded = Image.open('file.png')\n# Use directly, or just as reference for colors/style\n```\n\n### Drawing from Scratch\nWhen drawing graphics from scratch, use PIL ImageDraw primitives:\n\n```python\nfrom PIL import ImageDraw\n\ndraw = ImageDraw.Draw(frame)\n\n# Circles/ovals\ndraw.ellipse([x1, y1, x2, y2], fill=(r, g, b), outline=(r, g, b), width=3)\n\n# Stars, triangles, any polygon\npoints = [(x1, y1), (x2, y2), (x3, y3), ...]\ndraw.polygon(points, fill=(r, g, b), outline=(r, g, b), width=3)\n\n# Lines\ndraw.line([(x1, y1), (x2, y2)], fill=(r, g, b), width=5)\n\n# Rectangles\ndraw.rectangle([x1, y1, x2, y2], fill=(r, g, b), outline=(r, g, b), width=3)\n```\n\n**Don't use:** Emoji fonts (unreliable across platforms) or assume pre-packaged graphics exist in this skill.\n\n### Making Graphics Look Good\n\nGraphics should look polished and creative, not basic. Here's how:\n\n**Use thicker lines** - Always set `width=2` or higher for outlines and lines. Thin lines (width=1) look choppy and amateurish.\n\n**Add visual depth**:\n- Use gradients for backgrounds (`create_gradient_background`)\n- Layer multiple shapes for complexity (e.g., a star with a smaller star inside)\n\n**Make shapes more interesting**:\n- Don't just draw a plain circle - add highlights, rings, or patterns\n- Stars can have glows (draw larger, semi-transparent versions behind)\n- Combine multiple shapes (stars + sparkles, circles + rings)\n\n**Pay attention to colors**:\n- Use vibrant, complementary colors\n- Add contrast (dark outlines on light shapes, light outlines on dark shapes)\n- Consider the overall composition\n\n**For complex shapes** (hearts, snowflakes, etc.):\n- Use combinations of polygons and ellipses\n- Calculate points carefully for symmetry\n- Add details (a heart can have a highlight curve, snowflakes have intricate branches)\n\nBe creative and detailed! A good Slack GIF should look polished, not like placeholder graphics.\n\n## Available Utilities\n\n### GIFBuilder (`core.gif_builder`)\nAssembles frames and optimizes for Slack:\n```python\nbuilder = GIFBuilder(width=128, height=128, fps=10)\nbuilder.add_frame(frame)  # Add PIL Image\nbuilder.add_frames(frames)  # Add list of frames\nbuilder.save('out.gif', num_colors=48, optimize_for_emoji=True, remove_duplicates=True)\n```\n\n### Validators (`core.validators`)\nCheck if GIF meets Slack requirements:\n```python\nfrom core.validators import validate_gif, is_slack_ready\n\n# Detailed validation\npasses, info = validate_gif('my.gif', is_emoji=True, verbose=True)\n\n# Quick check\nif is_slack_ready('my.gif'):\n    print(\"Ready!\")\n```\n\n### Easing Functions (`core.easing`)\nSmooth motion instead of linear:\n```python\nfrom core.easing import interpolate\n\n# Progress from 0.0 to 1.0\nt = i / (num_frames - 1)\n\n# Apply easing\ny = interpolate(start=0, end=400, t=t, easing='ease_out')\n\n# Available: linear, ease_in, ease_out, ease_in_out,\n#           bounce_out, elastic_out, back_out\n```\n\n### Frame Helpers (`core.frame_composer`)\nConvenience functions for common needs:\n```python\nfrom core.frame_composer import (\n    create_blank_frame,         # Solid color background\n    create_gradient_background,  # Vertical gradient\n    draw_circle,                # Helper for circles\n    draw_text,                  # Simple text rendering\n    draw_star                   # 5-pointed star\n)\n```\n\n## Animation Concepts\n\n### Shake/Vibrate\nOffset object position with oscillation:\n- Use `math.sin()` or `math.cos()` with frame index\n- Add small random variations for natural feel\n- Apply to x and/or y position\n\n### Pulse/Heartbeat\nScale object size rhythmically:\n- Use `math.sin(t * frequency * 2 * math.pi)` for smooth pulse\n- For heartbeat: two quick pulses then pause (adjust sine wave)\n- Scale between 0.8 and 1.2 of base size\n\n### Bounce\nObject falls and bounces:\n- Use `interpolate()` with `easing='bounce_out'` for landing\n- Use `easing='ease_in'` for falling (accelerating)\n- Apply gravity by increasing y velocity each frame\n\n### Spin/Rotate\nRotate object around center:\n- PIL: `image.rotate(angle, resample=Image.BICUBIC)`\n- For wobble: use sine wave for angle instead of linear\n\n### Fade In/Out\nGradually appear or disappear:\n- Create RGBA image, adjust alpha channel\n- Or use `Image.blend(image1, image2, alpha)`\n- Fade in: alpha from 0 to 1\n- Fade out: alpha from 1 to 0\n\n### Slide\nMove object from off-screen to position:\n- Start position: outside frame bounds\n- End position: target location\n- Use `interpolate()` with `easing='ease_out'` for smooth stop\n- For overshoot: use `easing='back_out'`\n\n### Zoom\nScale and position for zoom effect:\n- Zoom in: scale from 0.1 to 2.0, crop center\n- Zoom out: scale from 2.0 to 1.0\n- Can add motion blur for drama (PIL filter)\n\n### Explode/Particle Burst\nCreate particles radiating outward:\n- Generate particles with random angles and velocities\n- Update each particle: `x += vx`, `y += vy`\n- Add gravity: `vy += gravity_constant`\n- Fade out particles over time (reduce alpha)\n\n## Optimization Strategies\n\nOnly when asked to make the file size smaller, implement a few of the following methods:\n\n1. **Fewer frames** - Lower FPS (10 instead of 20) or shorter duration\n2. **Fewer colors** - `num_colors=48` instead of 128\n3. **Smaller dimensions** - 128x128 instead of 480x480\n4. **Remove duplicates** - `remove_duplicates=True` in save()\n5. **Emoji mode** - `optimize_for_emoji=True` auto-optimizes\n\n```python\n# Maximum optimization for emoji\nbuilder.save(\n    'emoji.gif',\n    num_colors=48,\n    optimize_for_emoji=True,\n    remove_duplicates=True\n)\n```\n\n## Philosophy\n\nThis skill provides:\n- **Knowledge**: Slack's requirements and animation concepts\n- **Utilities**: GIFBuilder, validators, easing functions\n- **Flexibility**: Create the animation logic using PIL primitives\n\nIt does NOT provide:\n- Rigid animation templates or pre-made functions\n- Emoji font rendering (unreliable across platforms)\n- A library of pre-packaged graphics built into the skill\n\n**Note on user uploads**: This skill doesn't include pre-built graphics, but if a user uploads an image, use PIL to load and work with it - interpret based on their request whether they want it used directly or just as inspiration.\n\nBe creative! Combine concepts (bouncing + rotating, pulsing + sliding, etc.) and use PIL's full capabilities.\n\n## Dependencies\n\n```bash\npip install pillow imageio numpy\n```",
    "id": "slack-gif-creator",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/slack-gif-creator",
    "name_zh": "Slack GIF Âà∂‰Ωú",
    "description_zh": "Knowledge and utilities for creating animated GIFs optimized for Slack. Provides constraints, validation tools, and animation concepts. ÈÄÇÁî®‰∫é Áî®Êà∑ËØ∑Ê±Ç animated GIFs for Slack like \"make me a GIF of X doing Y for Slack.\"",
    "body_zh": "# Slack GIF Creator\n\nA toolkit providing utilities and knowledge for creating animated GIFs optimized for Slack.\n\n## Slack Requirements\n\n**Dimensions:**\n- Emoji GIFs: 128x128 (recommended)\n- Message GIFs: 480x480\n\n**Parameters:**\n- FPS: 10-30 (lower is smaller file size)\n- Colors: 48-128 (fewer = smaller file size)\n- Duration: Keep under 3 seconds for emoji GIFs\n\n## Core Workflow\n\n```python\nfrom core.gif_builder import GIFBuilder\nfrom PIL import Image, ImageDraw\n\n# 1. Create builder\nbuilder = GIFBuilder(width=128, height=128, fps=10)\n\n# 2. Generate frames\nfor i in range(12):\n    frame = Image.new('RGB', (128, 128), (240, 248, 255))\n    draw = ImageDraw.Draw(frame)\n\n    # Draw your animation using PIL primitives\n    # (circles, polygons, lines, etc.)\n\n    builder.add_frame(frame)\n\n# 3. Save with optimization\nbuilder.save('output.gif', num_colors=48, optimize_for_emoji=True)\n```\n\n## Drawing Graphics\n\n### Working with User-Uploaded Images\nIf a user uploads an image, consider whether they want to:\n- **Use it directly** (e.g., \"animate this\", \"split this into frames\")\n- **Use it as inspiration** (e.g., \"make something like this\")\n\nLoad and work with images using PIL:\n```python\nfrom PIL import Image\n\nuploaded = Image.open('file.png')\n# Use directly, or just as reference for colors/style\n```\n\n### Drawing from Scratch\nWhen drawing graphics from scratch, use PIL ImageDraw primitives:\n\n```python\nfrom PIL import ImageDraw\n\ndraw = ImageDraw.Draw(frame)\n\n# Circles/ovals\ndraw.ellipse([x1, y1, x2, y2], fill=(r, g, b), outline=(r, g, b), width=3)\n\n# Stars, triangles, any polygon\npoints = [(x1, y1), (x2, y2), (x3, y3), ...]\ndraw.polygon(points, fill=(r, g, b), outline=(r, g, b), width=3)\n\n# Lines\ndraw.line([(x1, y1), (x2, y2)], fill=(r, g, b), width=5)\n\n# Rectangles\ndraw.rectangle([x1, y1, x2, y2], fill=(r, g, b), outline=(r, g, b), width=3)\n```\n\n**Don't use:** Emoji fonts (unreliable across platforms) or assume pre-packaged graphics exist in this skill.\n\n### Making Graphics Look Good\n\nGraphics should look polished and creative, not basic. Here's how:\n\n**Use thicker lines** - Always set `width=2` or higher for outlines and lines. Thin lines (width=1) look choppy and amateurish.\n\n**Add visual depth**:\n- Use gradients for backgrounds (`create_gradient_background`)\n- Layer multiple shapes for complexity (e.g., a star with a smaller star inside)\n\n**Make shapes more interesting**:\n- Don't just draw a plain circle - add highlights, rings, or patterns\n- Stars can have glows (draw larger, semi-transparent versions behind)\n- Combine multiple shapes (stars + sparkles, circles + rings)\n\n**Pay attention to colors**:\n- Use vibrant, complementary colors\n- Add contrast (dark outlines on light shapes, light outlines on dark shapes)\n- Consider the overall composition\n\n**For complex shapes** (hearts, snowflakes, etc.):\n- Use combinations of polygons and ellipses\n- Calculate points carefully for symmetry\n- Add details (a heart can have a highlight curve, snowflakes have intricate branches)\n\nBe creative and detailed! A good Slack GIF should look polished, not like placeholder graphics.\n\n## Available Utilities\n\n### GIFBuilder (`core.gif_builder`)\nAssembles frames and optimizes for Slack:\n```python\nbuilder = GIFBuilder(width=128, height=128, fps=10)\nbuilder.add_frame(frame)  # Add PIL Image\nbuilder.add_frames(frames)  # Add list of frames\nbuilder.save('out.gif', num_colors=48, optimize_for_emoji=True, remove_duplicates=True)\n```\n\n### Validators (`core.validators`)\nCheck if GIF meets Slack requirements:\n```python\nfrom core.validators import validate_gif, is_slack_ready\n\n# Detailed validation\npasses, info = validate_gif('my.gif', is_emoji=True, verbose=True)\n\n# Quick check\nif is_slack_ready('my.gif'):\n    print(\"Ready!\")\n```\n\n### Easing Functions (`core.easing`)\nSmooth motion instead of linear:\n```python\nfrom core.easing import interpolate\n\n# Progress from 0.0 to 1.0\nt = i / (num_frames - 1)\n\n# Apply easing\ny = interpolate(start=0, end=400, t=t, easing='ease_out')\n\n# Available: linear, ease_in, ease_out, ease_in_out,\n#           bounce_out, elastic_out, back_out\n```\n\n### Frame Helpers (`core.frame_composer`)\nConvenience functions for common needs:\n```python\nfrom core.frame_composer import (\n    create_blank_frame,         # Solid color background\n    create_gradient_background,  # Vertical gradient\n    draw_circle,                # Helper for circles\n    draw_text,                  # Simple text rendering\n    draw_star                   # 5-pointed star\n)\n```\n\n## Animation Concepts\n\n### Shake/Vibrate\nOffset object position with oscillation:\n- Use `math.sin()` or `math.cos()` with frame index\n- Add small random variations for natural feel\n- Apply to x and/or y position\n\n### Pulse/Heartbeat\nScale object size rhythmically:\n- Use `math.sin(t * frequency * 2 * math.pi)` for smooth pulse\n- For heartbeat: two quick pulses then pause (adjust sine wave)\n- Scale between 0.8 and 1.2 of base size\n\n### Bounce\nObject falls and bounces:\n- Use `interpolate()` with `easing='bounce_out'` for landing\n- Use `easing='ease_in'` for falling (accelerating)\n- Apply gravity by increasing y velocity each frame\n\n### Spin/Rotate\nRotate object around center:\n- PIL: `image.rotate(angle, resample=Image.BICUBIC)`\n- For wobble: use sine wave for angle instead of linear\n\n### Fade In/Out\nGradually appear or disappear:\n- Create RGBA image, adjust alpha channel\n- Or use `Image.blend(image1, image2, alpha)`\n- Fade in: alpha from 0 to 1\n- Fade out: alpha from 1 to 0\n\n### Slide\nMove object from off-screen to position:\n- Start position: outside frame bounds\n- End position: target location\n- Use `interpolate()` with `easing='ease_out'` for smooth stop\n- For overshoot: use `easing='back_out'`\n\n### Zoom\nScale and position for zoom effect:\n- Zoom in: scale from 0.1 to 2.0, crop center\n- Zoom out: scale from 2.0 to 1.0\n- Can add motion blur for drama (PIL filter)\n\n### Explode/Particle Burst\nCreate particles radiating outward:\n- Generate particles with random angles and velocities\n- Update each particle: `x += vx`, `y += vy`\n- Add gravity: `vy += gravity_constant`\n- Fade out particles over time (reduce alpha)\n\n## Optimization Strategies\n\nOnly when asked to make the file size smaller, implement a few of the following methods:\n\n1. **Fewer frames** - Lower FPS (10 instead of 20) or shorter duration\n2. **Fewer colors** - `num_colors=48` instead of 128\n3. **Smaller dimensions** - 128x128 instead of 480x480\n4. **Remove duplicates** - `remove_duplicates=True` in save()\n5. **Emoji mode** - `optimize_for_emoji=True` auto-optimizes\n\n```python\n# Maximum optimization for emoji\nbuilder.save(\n    'emoji.gif',\n    num_colors=48,\n    optimize_for_emoji=True,\n    remove_duplicates=True\n)\n```\n\n## Philosophy\n\nThis skill provides:\n- **Knowledge**: Slack's requirements and animation concepts\n- **Utilities**: GIFBuilder, validators, easing functions\n- **Flexibility**: Create the animation logic using PIL primitives\n\nIt does NOT provide:\n- Rigid animation templates or pre-made functions\n- Emoji font rendering (unreliable across platforms)\n- A library of pre-packaged graphics built into the skill\n\n**Note on user uploads**: This skill doesn't include pre-built graphics, but if a user uploads an image, use PIL to load and work with it - interpret based on their request whether they want it used directly or just as inspiration.\n\nBe creative! Combine concepts (bouncing + rotating, pulsing + sliding, etc.) and use PIL's full capabilities.\n\n## Dependencies\n\n```bash\npip install pillow imageio numpy\n```"
  },
  {
    "name": "theme-factory",
    "description": "Toolkit for styling artifacts with a theme. These artifacts can be slides, docs, reportings, HTML landing pages, etc. There are 10 pre-set themes with colors/fonts that you can apply to any artifact that has been creating, or can generate a new theme on-the-fly.",
    "body": "# Theme Factory Skill\n\nThis skill provides a curated collection of professional font and color themes themes, each with carefully selected color palettes and font pairings. Once a theme is chosen, it can be applied to any artifact.\n\n## Purpose\n\nTo apply consistent, professional styling to presentation slide decks, use this skill. Each theme includes:\n- A cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- A distinct visual identity suitable for different contexts and audiences\n\n## Usage Instructions\n\nTo apply styling to a slide deck or other artifact:\n\n1. **Show the theme showcase**: Display the `theme-showcase.pdf` file to allow users to see all available themes visually. Do not make any modifications to it; simply show the file for viewing.\n2. **Ask for their choice**: Ask which theme to apply to the deck\n3. **Wait for selection**: Get explicit confirmation about the chosen theme\n4. **Apply the theme**: Once a theme has been chosen, apply the selected theme's colors and fonts to the deck/artifact\n\n## Themes Available\n\nThe following 10 themes are available, each showcased in `theme-showcase.pdf`:\n\n1. **Ocean Depths** - Professional and calming maritime theme\n2. **Sunset Boulevard** - Warm and vibrant sunset colors\n3. **Forest Canopy** - Natural and grounded earth tones\n4. **Modern Minimalist** - Clean and contemporary grayscale\n5. **Golden Hour** - Rich and warm autumnal palette\n6. **Arctic Frost** - Cool and crisp winter-inspired theme\n7. **Desert Rose** - Soft and sophisticated dusty tones\n8. **Tech Innovation** - Bold and modern tech aesthetic\n9. **Botanical Garden** - Fresh and organic garden colors\n10. **Midnight Galaxy** - Dramatic and cosmic deep tones\n\n## Theme Details\n\nEach theme is defined in the `themes/` directory with complete specifications including:\n- Cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- Distinct visual identity suitable for different contexts and audiences\n\n## Application Process\n\nAfter a preferred theme is selected:\n1. Read the corresponding theme file from the `themes/` directory\n2. Apply the specified colors and fonts consistently throughout the deck\n3. Ensure proper contrast and readability\n4. Maintain the theme's visual identity across all slides\n\n## Create your Own Theme\nTo handle cases where none of the existing themes work for an artifact, create a custom theme. Based on provided inputs, generate a new theme similar to the ones above. Give the theme a similar name describing what the font/color combinations represent. Use any basic description provided to choose appropriate colors/fonts. After generating the theme, show it for review and verification. Following that, apply the theme as described above.",
    "id": "theme-factory",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/theme-factory",
    "name_zh": "‰∏ªÈ¢òÂ∑•ÂéÇ",
    "description_zh": "Toolkit for styling artifacts with a theme. These artifacts can be slides, docs, reportings, HTML landing pages, etc. There are 10 pre-set themes with colors/fonts that you can apply to any artifact that has been creating, or can generate a new theme on-the-fly.",
    "body_zh": "# Theme Factory Skill\n\nThis skill provides a curated collection of professional font and color themes themes, each with carefully selected color palettes and font pairings. Once a theme is chosen, it can be applied to any artifact.\n\n## Purpose\n\nTo apply consistent, professional styling to presentation slide decks, use this skill. Each theme includes:\n- A cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- A distinct visual identity suitable for different contexts and audiences\n\n## Usage Instructions\n\nTo apply styling to a slide deck or other artifact:\n\n1. **Show the theme showcase**: Display the `theme-showcase.pdf` file to allow users to see all available themes visually. Do not make any modifications to it; simply show the file for viewing.\n2. **Ask for their choice**: Ask which theme to apply to the deck\n3. **Wait for selection**: Get explicit confirmation about the chosen theme\n4. **Apply the theme**: Once a theme has been chosen, apply the selected theme's colors and fonts to the deck/artifact\n\n## Themes Available\n\nThe following 10 themes are available, each showcased in `theme-showcase.pdf`:\n\n1. **Ocean Depths** - Professional and calming maritime theme\n2. **Sunset Boulevard** - Warm and vibrant sunset colors\n3. **Forest Canopy** - Natural and grounded earth tones\n4. **Modern Minimalist** - Clean and contemporary grayscale\n5. **Golden Hour** - Rich and warm autumnal palette\n6. **Arctic Frost** - Cool and crisp winter-inspired theme\n7. **Desert Rose** - Soft and sophisticated dusty tones\n8. **Tech Innovation** - Bold and modern tech aesthetic\n9. **Botanical Garden** - Fresh and organic garden colors\n10. **Midnight Galaxy** - Dramatic and cosmic deep tones\n\n## Theme Details\n\nEach theme is defined in the `themes/` directory with complete specifications including:\n- Cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- Distinct visual identity suitable for different contexts and audiences\n\n## Application Process\n\nAfter a preferred theme is selected:\n1. Read the corresponding theme file from the `themes/` directory\n2. Apply the specified colors and fonts consistently throughout the deck\n3. Ensure proper contrast and readability\n4. Maintain the theme's visual identity across all slides\n\n## Create your Own Theme\nTo handle cases where none of the existing themes work for an artifact, create a custom theme. Based on provided inputs, generate a new theme similar to the ones above. Give the theme a similar name describing what the font/color combinations represent. Use any basic description provided to choose appropriate colors/fonts. After generating the theme, show it for review and verification. Following that, apply the theme as described above."
  },
  {
    "name": "web-artifacts-builder",
    "description": "Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui). Use for complex artifacts requiring state management, routing, or shadcn/ui components - not for simple single-file HTML/JSX artifacts.",
    "body": "# Web Artifacts Builder\n\nTo build powerful frontend claude.ai artifacts, follow these steps:\n1. Initialize the frontend repo using `scripts/init-artifact.sh`\n2. Develop your artifact by editing the generated code\n3. Bundle all code into a single HTML file using `scripts/bundle-artifact.sh`\n4. Display artifact to user\n5. (Optional) Test the artifact\n\n**Stack**: React 18 + TypeScript + Vite + Parcel (bundling) + Tailwind CSS + shadcn/ui\n\n## Design & Style Guidelines\n\nVERY IMPORTANT: To avoid what is often referred to as \"AI slop\", avoid using excessive centered layouts, purple gradients, uniform rounded corners, and Inter font.\n\n## Quick Start\n\n### Step 1: Initialize Project\n\nRun the initialization script to create a new React project:\n```bash\nbash scripts/init-artifact.sh <project-name>\ncd <project-name>\n```\n\nThis creates a fully configured project with:\n- ‚úÖ React + TypeScript (via Vite)\n- ‚úÖ Tailwind CSS 3.4.1 with shadcn/ui theming system\n- ‚úÖ Path aliases (`@/`) configured\n- ‚úÖ 40+ shadcn/ui components pre-installed\n- ‚úÖ All Radix UI dependencies included\n- ‚úÖ Parcel configured for bundling (via .parcelrc)\n- ‚úÖ Node 18+ compatibility (auto-detects and pins Vite version)\n\n### Step 2: Develop Your Artifact\n\nTo build the artifact, edit the generated files. See **Common Development Tasks** below for guidance.\n\n### Step 3: Bundle to Single HTML File\n\nTo bundle the React app into a single HTML artifact:\n```bash\nbash scripts/bundle-artifact.sh\n```\n\nThis creates `bundle.html` - a self-contained artifact with all JavaScript, CSS, and dependencies inlined. This file can be directly shared in Claude conversations as an artifact.\n\n**Requirements**: Your project must have an `index.html` in the root directory.\n\n**What the script does**:\n- Installs bundling dependencies (parcel, @parcel/config-default, parcel-resolver-tspaths, html-inline)\n- Creates `.parcelrc` config with path alias support\n- Builds with Parcel (no source maps)\n- Inlines all assets into single HTML using html-inline\n\n### Step 4: Share Artifact with User\n\nFinally, share the bundled HTML file in conversation with the user so they can view it as an artifact.\n\n### Step 5: Testing/Visualizing the Artifact (Optional)\n\nNote: This is a completely optional step. Only perform if necessary or requested.\n\nTo test/visualize the artifact, use available tools (including other Skills or built-in tools like Playwright or Puppeteer). In general, avoid testing the artifact upfront as it adds latency between the request and when the finished artifact can be seen. Test later, after presenting the artifact, if requested or if issues arise.\n\n## Reference\n\n- **shadcn/ui components**: https://ui.shadcn.com/docs/components",
    "id": "web-artifacts-builder",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/web-artifacts-builder",
    "name_zh": "Web Artifacts ÊûÑÂª∫Âô®",
    "description_zh": "Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui). Use for complex artifacts requiring state management, routing, or shadcn/ui components - not for simple single-file HTML/JSX artifacts.",
    "body_zh": "# Web Artifacts Builder\n\nTo build powerful frontend claude.ai artifacts, follow these steps:\n1. Initialize the frontend repo using `scripts/init-artifact.sh`\n2. Develop your artifact by editing the generated code\n3. Bundle all code into a single HTML file using `scripts/bundle-artifact.sh`\n4. Display artifact to user\n5. (Optional) Test the artifact\n\n**Stack**: React 18 + TypeScript + Vite + Parcel (bundling) + Tailwind CSS + shadcn/ui\n\n## Design & Style Guidelines\n\nVERY IMPORTANT: To avoid what is often referred to as \"AI slop\", avoid using excessive centered layouts, purple gradients, uniform rounded corners, and Inter font.\n\n## Quick Start\n\n### Step 1: Initialize Project\n\nRun the initialization script to create a new React project:\n```bash\nbash scripts/init-artifact.sh <project-name>\ncd <project-name>\n```\n\nThis creates a fully configured project with:\n- ‚úÖ React + TypeScript (via Vite)\n- ‚úÖ Tailwind CSS 3.4.1 with shadcn/ui theming system\n- ‚úÖ Path aliases (`@/`) configured\n- ‚úÖ 40+ shadcn/ui components pre-installed\n- ‚úÖ All Radix UI dependencies included\n- ‚úÖ Parcel configured for bundling (via .parcelrc)\n- ‚úÖ Node 18+ compatibility (auto-detects and pins Vite version)\n\n### Step 2: Develop Your Artifact\n\nTo build the artifact, edit the generated files. See **Common Development Tasks** below for guidance.\n\n### Step 3: Bundle to Single HTML File\n\nTo bundle the React app into a single HTML artifact:\n```bash\nbash scripts/bundle-artifact.sh\n```\n\nThis creates `bundle.html` - a self-contained artifact with all JavaScript, CSS, and dependencies inlined. This file can be directly shared in Claude conversations as an artifact.\n\n**Requirements**: Your project must have an `index.html` in the root directory.\n\n**What the script does**:\n- Installs bundling dependencies (parcel, @parcel/config-default, parcel-resolver-tspaths, html-inline)\n- Creates `.parcelrc` config with path alias support\n- Builds with Parcel (no source maps)\n- Inlines all assets into single HTML using html-inline\n\n### Step 4: Share Artifact with User\n\nFinally, share the bundled HTML file in conversation with the user so they can view it as an artifact.\n\n### Step 5: Testing/Visualizing the Artifact (Optional)\n\nNote: This is a completely optional step. Only perform if necessary or requested.\n\nTo test/visualize the artifact, use available tools (including other Skills or built-in tools like Playwright or Puppeteer). In general, avoid testing the artifact upfront as it adds latency between the request and when the finished artifact can be seen. Test later, after presenting the artifact, if requested or if issues arise.\n\n## Reference\n\n- **shadcn/ui components**: https://ui.shadcn.com/docs/components"
  },
  {
    "name": "webapp-testing",
    "description": "Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs.",
    "body": "# Web Application Testing\n\nTo test local web applications, write native Python Playwright scripts.\n\n**Helper Scripts Available**:\n- `scripts/with_server.py` - Manages server lifecycle (supports multiple servers)\n\n**Always run scripts with `--help` first** to see usage. DO NOT read the source until you try running the script first and find that a customized solution is abslutely necessary. These scripts can be very large and thus pollute your context window. They exist to be called directly as black-box scripts rather than ingested into your context window.\n\n## Decision Tree: Choosing Your Approach\n\n```\nUser task ‚Üí Is it static HTML?\n    ‚îú‚îÄ Yes ‚Üí Read HTML file directly to identify selectors\n    ‚îÇ         ‚îú‚îÄ Success ‚Üí Write Playwright script using selectors\n    ‚îÇ         ‚îî‚îÄ Fails/Incomplete ‚Üí Treat as dynamic (below)\n    ‚îÇ\n    ‚îî‚îÄ No (dynamic webapp) ‚Üí Is the server already running?\n        ‚îú‚îÄ No ‚Üí Run: python scripts/with_server.py --help\n        ‚îÇ        Then use the helper + write simplified Playwright script\n        ‚îÇ\n        ‚îî‚îÄ Yes ‚Üí Reconnaissance-then-action:\n            1. Navigate and wait for networkidle\n            2. Take screenshot or inspect DOM\n            3. Identify selectors from rendered state\n            4. Execute actions with discovered selectors\n```\n\n## Example: Using with_server.py\n\nTo start a server, run `--help` first, then use the helper:\n\n**Single server:**\n```bash\npython scripts/with_server.py --server \"npm run dev\" --port 5173 -- python your_automation.py\n```\n\n**Multiple servers (e.g., backend + frontend):**\n```bash\npython scripts/with_server.py \\\n  --server \"cd backend && python server.py\" --port 3000 \\\n  --server \"cd frontend && npm run dev\" --port 5173 \\\n  -- python your_automation.py\n```\n\nTo create an automation script, include only Playwright logic (servers are managed automatically):\n```python\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    browser = p.chromium.launch(headless=True) # Always launch chromium in headless mode\n    page = browser.new_page()\n    page.goto('http://localhost:5173') # Server already running and ready\n    page.wait_for_load_state('networkidle') # CRITICAL: Wait for JS to execute\n    # ... your automation logic\n    browser.close()\n```\n\n## Reconnaissance-Then-Action Pattern\n\n1. **Inspect rendered DOM**:\n   ```python\n   page.screenshot(path='/tmp/inspect.png', full_page=True)\n   content = page.content()\n   page.locator('button').all()\n   ```\n\n2. **Identify selectors** from inspection results\n\n3. **Execute actions** using discovered selectors\n\n## Common Pitfall\n\n‚ùå **Don't** inspect the DOM before waiting for `networkidle` on dynamic apps\n‚úÖ **Do** wait for `page.wait_for_load_state('networkidle')` before inspection\n\n## Best Practices\n\n- **Use bundled scripts as black boxes** - To accomplish a task, consider whether one of the scripts available in `scripts/` can help. These scripts handle common, complex workflows reliably without cluttering the context window. Use `--help` to see usage, then invoke directly. \n- Use `sync_playwright()` for synchronous scripts\n- Always close the browser when done\n- Use descriptive selectors: `text=`, `role=`, CSS selectors, or IDs\n- Add appropriate waits: `page.wait_for_selector()` or `page.wait_for_timeout()`\n\n## Reference Files\n\n- **examples/** - Examples showing common patterns:\n  - `element_discovery.py` - Discovering buttons, links, and inputs on a page\n  - `static_html_automation.py` - Using file:// URLs for local HTML\n  - `console_logging.py` - Capturing console logs during automation",
    "id": "webapp-testing",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/webapp-testing",
    "name_zh": "Web Â∫îÁî®ÊµãËØï",
    "description_zh": "Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs.",
    "body_zh": "# Web Application Testing\n\nTo test local web applications, write native Python Playwright scripts.\n\n**Helper Scripts Available**:\n- `scripts/with_server.py` - Manages server lifecycle (supports multiple servers)\n\n**Always run scripts with `--help` first** to see usage. DO NOT read the source until you try running the script first and find that a customized solution is abslutely necessary. These scripts can be very large and thus pollute your context window. They exist to be called directly as black-box scripts rather than ingested into your context window.\n\n## Decision Tree: Choosing Your Approach\n\n```\nUser task ‚Üí Is it static HTML?\n    ‚îú‚îÄ Yes ‚Üí Read HTML file directly to identify selectors\n    ‚îÇ         ‚îú‚îÄ Success ‚Üí Write Playwright script using selectors\n    ‚îÇ         ‚îî‚îÄ Fails/Incomplete ‚Üí Treat as dynamic (below)\n    ‚îÇ\n    ‚îî‚îÄ No (dynamic webapp) ‚Üí Is the server already running?\n        ‚îú‚îÄ No ‚Üí Run: python scripts/with_server.py --help\n        ‚îÇ        Then use the helper + write simplified Playwright script\n        ‚îÇ\n        ‚îî‚îÄ Yes ‚Üí Reconnaissance-then-action:\n            1. Navigate and wait for networkidle\n            2. Take screenshot or inspect DOM\n            3. Identify selectors from rendered state\n            4. Execute actions with discovered selectors\n```\n\n## Example: Using with_server.py\n\nTo start a server, run `--help` first, then use the helper:\n\n**Single server:**\n```bash\npython scripts/with_server.py --server \"npm run dev\" --port 5173 -- python your_automation.py\n```\n\n**Multiple servers (e.g., backend + frontend):**\n```bash\npython scripts/with_server.py \\\n  --server \"cd backend && python server.py\" --port 3000 \\\n  --server \"cd frontend && npm run dev\" --port 5173 \\\n  -- python your_automation.py\n```\n\nTo create an automation script, include only Playwright logic (servers are managed automatically):\n```python\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    browser = p.chromium.launch(headless=True) # Always launch chromium in headless mode\n    page = browser.new_page()\n    page.goto('http://localhost:5173') # Server already running and ready\n    page.wait_for_load_state('networkidle') # CRITICAL: Wait for JS to execute\n    # ... your automation logic\n    browser.close()\n```\n\n## Reconnaissance-Then-Action Pattern\n\n1. **Inspect rendered DOM**:\n   ```python\n   page.screenshot(path='/tmp/inspect.png', full_page=True)\n   content = page.content()\n   page.locator('button').all()\n   ```\n\n2. **Identify selectors** from inspection results\n\n3. **Execute actions** using discovered selectors\n\n## Common Pitfall\n\n‚ùå **Don't** inspect the DOM before waiting for `networkidle` on dynamic apps\n‚úÖ **Do** wait for `page.wait_for_load_state('networkidle')` before inspection\n\n## Best Practices\n\n- **Use bundled scripts as black boxes** - To accomplish a task, consider whether one of the scripts available in `scripts/` can help. These scripts handle common, complex workflows reliably without cluttering the context window. Use `--help` to see usage, then invoke directly. \n- Use `sync_playwright()` for synchronous scripts\n- Always close the browser when done\n- Use descriptive selectors: `text=`, `role=`, CSS selectors, or IDs\n- Add appropriate waits: `page.wait_for_selector()` or `page.wait_for_timeout()`\n\n## Reference Files\n\n- **examples/** - Examples showing common patterns:\n  - `element_discovery.py` - Discovering buttons, links, and inputs on a page\n  - `static_html_automation.py` - Using file:// URLs for local HTML\n  - `console_logging.py` - Capturing console logs during automation"
  },
  {
    "name": "xlsx",
    "description": "Comprehensive spreadsheet creation, editing, and analysis with support for formulas, formatting, data analysis, and visualization. When Claude needs to work with spreadsheets (.xlsx, .xlsm, .csv, .tsv, etc) for: (1) Creating new spreadsheets with formulas and formatting, (2) Reading or analyzing data, (3) Modify existing spreadsheets while preserving formulas, (4) Data analysis and visualization in spreadsheets, or (5) Recalculating formulas",
    "body": "# Requirements for Outputs\n\n## All Excel files\n\n### Zero Formula Errors\n- Every Excel model MUST be delivered with ZERO formula errors (#REF!, #DIV/0!, #VALUE!, #N/A, #NAME?)\n\n### Preserve Existing Templates (when updating templates)\n- Study and EXACTLY match existing format, style, and conventions when modifying files\n- Never impose standardized formatting on files with established patterns\n- Existing template conventions ALWAYS override these guidelines\n\n## Financial models\n\n### Color Coding Standards\nUnless otherwise stated by the user or existing template\n\n#### Industry-Standard Color Conventions\n- **Blue text (RGB: 0,0,255)**: Hardcoded inputs, and numbers users will change for scenarios\n- **Black text (RGB: 0,0,0)**: ALL formulas and calculations\n- **Green text (RGB: 0,128,0)**: Links pulling from other worksheets within same workbook\n- **Red text (RGB: 255,0,0)**: External links to other files\n- **Yellow background (RGB: 255,255,0)**: Key assumptions needing attention or cells that need to be updated\n\n### Number Formatting Standards\n\n#### Required Format Rules\n- **Years**: Format as text strings (e.g., \"2024\" not \"2,024\")\n- **Currency**: Use $#,##0 format; ALWAYS specify units in headers (\"Revenue ($mm)\")\n- **Zeros**: Use number formatting to make all zeros \"-\", including percentages (e.g., \"$#,##0;($#,##0);-\")\n- **Percentages**: Default to 0.0% format (one decimal)\n- **Multiples**: Format as 0.0x for valuation multiples (EV/EBITDA, P/E)\n- **Negative numbers**: Use parentheses (123) not minus -123\n\n### Formula Construction Rules\n\n#### Assumptions Placement\n- Place ALL assumptions (growth rates, margins, multiples, etc.) in separate assumption cells\n- Use cell references instead of hardcoded values in formulas\n- Example: Use =B5*(1+$B$6) instead of =B5*1.05\n\n#### Formula Error Prevention\n- Verify all cell references are correct\n- Check for off-by-one errors in ranges\n- Ensure consistent formulas across all projection periods\n- Test with edge cases (zero values, negative numbers)\n- Verify no unintended circular references\n\n#### Documentation Requirements for Hardcodes\n- Comment or in cells beside (if end of table). Format: \"Source: [System/Document], [Date], [Specific Reference], [URL if applicable]\"\n- Examples:\n  - \"Source: Company 10-K, FY2024, Page 45, Revenue Note, [SEC EDGAR URL]\"\n  - \"Source: Company 10-Q, Q2 2025, Exhibit 99.1, [SEC EDGAR URL]\"\n  - \"Source: Bloomberg Terminal, 8/15/2025, AAPL US Equity\"\n  - \"Source: FactSet, 8/20/2025, Consensus Estimates Screen\"\n\n# XLSX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of an .xlsx file. You have different tools and workflows available for different tasks.\n\n## Important Requirements\n\n**LibreOffice Required for Formula Recalculation**: You can assume LibreOffice is installed for recalculating formula values using the `recalc.py` script. The script automatically configures LibreOffice on first run\n\n## Reading and analyzing data\n\n### Data analysis with pandas\nFor data analysis, visualization, and basic operations, use **pandas** which provides powerful data manipulation capabilities:\n\n```python\nimport pandas as pd\n\n# Read Excel\ndf = pd.read_excel('file.xlsx')  # Default: first sheet\nall_sheets = pd.read_excel('file.xlsx', sheet_name=None)  # All sheets as dict\n\n# Analyze\ndf.head()      # Preview data\ndf.info()      # Column info\ndf.describe()  # Statistics\n\n# Write Excel\ndf.to_excel('output.xlsx', index=False)\n```\n\n## Excel File Workflows\n\n## CRITICAL: Use Formulas, Not Hardcoded Values\n\n**Always use Excel formulas instead of calculating values in Python and hardcoding them.** This ensures the spreadsheet remains dynamic and updateable.\n\n### ‚ùå WRONG - Hardcoding Calculated Values\n```python\n# Bad: Calculating in Python and hardcoding result\ntotal = df['Sales'].sum()\nsheet['B10'] = total  # Hardcodes 5000\n\n# Bad: Computing growth rate in Python\ngrowth = (df.iloc[-1]['Revenue'] - df.iloc[0]['Revenue']) / df.iloc[0]['Revenue']\nsheet['C5'] = growth  # Hardcodes 0.15\n\n# Bad: Python calculation for average\navg = sum(values) / len(values)\nsheet['D20'] = avg  # Hardcodes 42.5\n```\n\n### ‚úÖ CORRECT - Using Excel Formulas\n```python\n# Good: Let Excel calculate the sum\nsheet['B10'] = '=SUM(B2:B9)'\n\n# Good: Growth rate as Excel formula\nsheet['C5'] = '=(C4-C2)/C2'\n\n# Good: Average using Excel function\nsheet['D20'] = '=AVERAGE(D2:D19)'\n```\n\nThis applies to ALL calculations - totals, percentages, ratios, differences, etc. The spreadsheet should be able to recalculate when source data changes.\n\n## Common Workflow\n1. **Choose tool**: pandas for data, openpyxl for formulas/formatting\n2. **Create/Load**: Create new workbook or load existing file\n3. **Modify**: Add/edit data, formulas, and formatting\n4. **Save**: Write to file\n5. **Recalculate formulas (MANDATORY IF USING FORMULAS)**: Use the recalc.py script\n   ```bash\n   python recalc.py output.xlsx\n   ```\n6. **Verify and fix any errors**: \n   - The script returns JSON with error details\n   - If `status` is `errors_found`, check `error_summary` for specific error types and locations\n   - Fix the identified errors and recalculate again\n   - Common errors to fix:\n     - `#REF!`: Invalid cell references\n     - `#DIV/0!`: Division by zero\n     - `#VALUE!`: Wrong data type in formula\n     - `#NAME?`: Unrecognized formula name\n\n### Creating new Excel files\n\n```python\n# Using openpyxl for formulas and formatting\nfrom openpyxl import Workbook\nfrom openpyxl.styles import Font, PatternFill, Alignment\n\nwb = Workbook()\nsheet = wb.active\n\n# Add data\nsheet['A1'] = 'Hello'\nsheet['B1'] = 'World'\nsheet.append(['Row', 'of', 'data'])\n\n# Add formula\nsheet['B2'] = '=SUM(A1:A10)'\n\n# Formatting\nsheet['A1'].font = Font(bold=True, color='FF0000')\nsheet['A1'].fill = PatternFill('solid', start_color='FFFF00')\nsheet['A1'].alignment = Alignment(horizontal='center')\n\n# Column width\nsheet.column_dimensions['A'].width = 20\n\nwb.save('output.xlsx')\n```\n\n### Editing existing Excel files\n\n```python\n# Using openpyxl to preserve formulas and formatting\nfrom openpyxl import load_workbook\n\n# Load existing file\nwb = load_workbook('existing.xlsx')\nsheet = wb.active  # or wb['SheetName'] for specific sheet\n\n# Working with multiple sheets\nfor sheet_name in wb.sheetnames:\n    sheet = wb[sheet_name]\n    print(f\"Sheet: {sheet_name}\")\n\n# Modify cells\nsheet['A1'] = 'New Value'\nsheet.insert_rows(2)  # Insert row at position 2\nsheet.delete_cols(3)  # Delete column 3\n\n# Add new sheet\nnew_sheet = wb.create_sheet('NewSheet')\nnew_sheet['A1'] = 'Data'\n\nwb.save('modified.xlsx')\n```\n\n## Recalculating formulas\n\nExcel files created or modified by openpyxl contain formulas as strings but not calculated values. Use the provided `recalc.py` script to recalculate formulas:\n\n```bash\npython recalc.py <excel_file> [timeout_seconds]\n```\n\nExample:\n```bash\npython recalc.py output.xlsx 30\n```\n\nThe script:\n- Automatically sets up LibreOffice macro on first run\n- Recalculates all formulas in all sheets\n- Scans ALL cells for Excel errors (#REF!, #DIV/0!, etc.)\n- Returns JSON with detailed error locations and counts\n- Works on both Linux and macOS\n\n## Formula Verification Checklist\n\nQuick checks to ensure formulas work correctly:\n\n### Essential Verification\n- [ ] **Test 2-3 sample references**: Verify they pull correct values before building full model\n- [ ] **Column mapping**: Confirm Excel columns match (e.g., column 64 = BL, not BK)\n- [ ] **Row offset**: Remember Excel rows are 1-indexed (DataFrame row 5 = Excel row 6)\n\n### Common Pitfalls\n- [ ] **NaN handling**: Check for null values with `pd.notna()`\n- [ ] **Far-right columns**: FY data often in columns 50+ \n- [ ] **Multiple matches**: Search all occurrences, not just first\n- [ ] **Division by zero**: Check denominators before using `/` in formulas (#DIV/0!)\n- [ ] **Wrong references**: Verify all cell references point to intended cells (#REF!)\n- [ ] **Cross-sheet references**: Use correct format (Sheet1!A1) for linking sheets\n\n### Formula Testing Strategy\n- [ ] **Start small**: Test formulas on 2-3 cells before applying broadly\n- [ ] **Verify dependencies**: Check all cells referenced in formulas exist\n- [ ] **Test edge cases**: Include zero, negative, and very large values\n\n### Interpreting recalc.py Output\nThe script returns JSON with error details:\n```json\n{\n  \"status\": \"success\",           // or \"errors_found\"\n  \"total_errors\": 0,              // Total error count\n  \"total_formulas\": 42,           // Number of formulas in file\n  \"error_summary\": {              // Only present if errors found\n    \"#REF!\": {\n      \"count\": 2,\n      \"locations\": [\"Sheet1!B5\", \"Sheet1!C10\"]\n    }\n  }\n}\n```\n\n## Best Practices\n\n### Library Selection\n- **pandas**: Best for data analysis, bulk operations, and simple data export\n- **openpyxl**: Best for complex formatting, formulas, and Excel-specific features\n\n### Working with openpyxl\n- Cell indices are 1-based (row=1, column=1 refers to cell A1)\n- Use `data_only=True` to read calculated values: `load_workbook('file.xlsx', data_only=True)`\n- **Warning**: If opened with `data_only=True` and saved, formulas are replaced with values and permanently lost\n- For large files: Use `read_only=True` for reading or `write_only=True` for writing\n- Formulas are preserved but not evaluated - use recalc.py to update values\n\n### Working with pandas\n- Specify data types to avoid inference issues: `pd.read_excel('file.xlsx', dtype={'id': str})`\n- For large files, read specific columns: `pd.read_excel('file.xlsx', usecols=['A', 'C', 'E'])`\n- Handle dates properly: `pd.read_excel('file.xlsx', parse_dates=['date_column'])`\n\n## Code Style Guidelines\n**IMPORTANT**: When generating Python code for Excel operations:\n- Write minimal, concise Python code without unnecessary comments\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n**For Excel files themselves**:\n- Add comments to cells with complex formulas or important assumptions\n- Document data sources for hardcoded values\n- Include notes for key calculations and model sections",
    "id": "xlsx",
    "source": "anthropics-skills",
    "html_url": "https://github.com/anthropics/skills/tree/main/skills/xlsx",
    "name_zh": "Excel Â§ÑÁêÜ",
    "description_zh": "Comprehensive spreadsheet creation, editing, and analysis with support for formulas, formatting, data analysis, and visualization. When Claude needs to work with spreadsheets (.xlsx, .xlsm, .csv, .tsv, etc) for: (1) ÂàõÂª∫ new spreadsheets with formulas and formatting, (2) Reading or analyzing data, (3) Modify existing spreadsheets while preserving formulas, (4) Data analysis and visualization in spreadsheets, or (5) Recalculating formulas",
    "body_zh": "# Requirements for Outputs\n\n## All Excel files\n\n### Zero Formula Errors\n- Every Excel model MUST be delivered with ZERO formula errors (#REF!, #DIV/0!, #VALUE!, #N/A, #NAME?)\n\n### Preserve Existing Templates (when updating templates)\n- Study and EXACTLY match existing format, style, and conventions when modifying files\n- Never impose standardized formatting on files with established patterns\n- Existing template conventions ALWAYS override these guidelines\n\n## Financial models\n\n### Color Coding Standards\nUnless otherwise stated by the user or existing template\n\n#### Industry-Standard Color Conventions\n- **Blue text (RGB: 0,0,255)**: Hardcoded inputs, and numbers users will change for scenarios\n- **Black text (RGB: 0,0,0)**: ALL formulas and calculations\n- **Green text (RGB: 0,128,0)**: Links pulling from other worksheets within same workbook\n- **Red text (RGB: 255,0,0)**: External links to other files\n- **Yellow background (RGB: 255,255,0)**: Key assumptions needing attention or cells that need to be updated\n\n### Number Formatting Standards\n\n#### Required Format Rules\n- **Years**: Format as text strings (e.g., \"2024\" not \"2,024\")\n- **Currency**: Use $#,##0 format; ALWAYS specify units in headers (\"Revenue ($mm)\")\n- **Zeros**: Use number formatting to make all zeros \"-\", including percentages (e.g., \"$#,##0;($#,##0);-\")\n- **Percentages**: Default to 0.0% format (one decimal)\n- **Multiples**: Format as 0.0x for valuation multiples (EV/EBITDA, P/E)\n- **Negative numbers**: Use parentheses (123) not minus -123\n\n### Formula Construction Rules\n\n#### Assumptions Placement\n- Place ALL assumptions (growth rates, margins, multiples, etc.) in separate assumption cells\n- Use cell references instead of hardcoded values in formulas\n- Example: Use =B5*(1+$B$6) instead of =B5*1.05\n\n#### Formula Error Prevention\n- Verify all cell references are correct\n- Check for off-by-one errors in ranges\n- Ensure consistent formulas across all projection periods\n- Test with edge cases (zero values, negative numbers)\n- Verify no unintended circular references\n\n#### Documentation Requirements for Hardcodes\n- Comment or in cells beside (if end of table). Format: \"Source: [System/Document], [Date], [Specific Reference], [URL if applicable]\"\n- Examples:\n  - \"Source: Company 10-K, FY2024, Page 45, Revenue Note, [SEC EDGAR URL]\"\n  - \"Source: Company 10-Q, Q2 2025, Exhibit 99.1, [SEC EDGAR URL]\"\n  - \"Source: Bloomberg Terminal, 8/15/2025, AAPL US Equity\"\n  - \"Source: FactSet, 8/20/2025, Consensus Estimates Screen\"\n\n# XLSX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of an .xlsx file. You have different tools and workflows available for different tasks.\n\n## Important Requirements\n\n**LibreOffice Required for Formula Recalculation**: You can assume LibreOffice is installed for recalculating formula values using the `recalc.py` script. The script automatically configures LibreOffice on first run\n\n## Reading and analyzing data\n\n### Data analysis with pandas\nFor data analysis, visualization, and basic operations, use **pandas** which provides powerful data manipulation capabilities:\n\n```python\nimport pandas as pd\n\n# Read Excel\ndf = pd.read_excel('file.xlsx')  # Default: first sheet\nall_sheets = pd.read_excel('file.xlsx', sheet_name=None)  # All sheets as dict\n\n# Analyze\ndf.head()      # Preview data\ndf.info()      # Column info\ndf.describe()  # Statistics\n\n# Write Excel\ndf.to_excel('output.xlsx', index=False)\n```\n\n## Excel File Workflows\n\n## CRITICAL: Use Formulas, Not Hardcoded Values\n\n**Always use Excel formulas instead of calculating values in Python and hardcoding them.** This ensures the spreadsheet remains dynamic and updateable.\n\n### ‚ùå WRONG - Hardcoding Calculated Values\n```python\n# Bad: Calculating in Python and hardcoding result\ntotal = df['Sales'].sum()\nsheet['B10'] = total  # Hardcodes 5000\n\n# Bad: Computing growth rate in Python\ngrowth = (df.iloc[-1]['Revenue'] - df.iloc[0]['Revenue']) / df.iloc[0]['Revenue']\nsheet['C5'] = growth  # Hardcodes 0.15\n\n# Bad: Python calculation for average\navg = sum(values) / len(values)\nsheet['D20'] = avg  # Hardcodes 42.5\n```\n\n### ‚úÖ CORRECT - Using Excel Formulas\n```python\n# Good: Let Excel calculate the sum\nsheet['B10'] = '=SUM(B2:B9)'\n\n# Good: Growth rate as Excel formula\nsheet['C5'] = '=(C4-C2)/C2'\n\n# Good: Average using Excel function\nsheet['D20'] = '=AVERAGE(D2:D19)'\n```\n\nThis applies to ALL calculations - totals, percentages, ratios, differences, etc. The spreadsheet should be able to recalculate when source data changes.\n\n## Common Workflow\n1. **Choose tool**: pandas for data, openpyxl for formulas/formatting\n2. **Create/Load**: Create new workbook or load existing file\n3. **Modify**: Add/edit data, formulas, and formatting\n4. **Save**: Write to file\n5. **Recalculate formulas (MANDATORY IF USING FORMULAS)**: Use the recalc.py script\n   ```bash\n   python recalc.py output.xlsx\n   ```\n6. **Verify and fix any errors**: \n   - The script returns JSON with error details\n   - If `status` is `errors_found`, check `error_summary` for specific error types and locations\n   - Fix the identified errors and recalculate again\n   - Common errors to fix:\n     - `#REF!`: Invalid cell references\n     - `#DIV/0!`: Division by zero\n     - `#VALUE!`: Wrong data type in formula\n     - `#NAME?`: Unrecognized formula name\n\n### Creating new Excel files\n\n```python\n# Using openpyxl for formulas and formatting\nfrom openpyxl import Workbook\nfrom openpyxl.styles import Font, PatternFill, Alignment\n\nwb = Workbook()\nsheet = wb.active\n\n# Add data\nsheet['A1'] = 'Hello'\nsheet['B1'] = 'World'\nsheet.append(['Row', 'of', 'data'])\n\n# Add formula\nsheet['B2'] = '=SUM(A1:A10)'\n\n# Formatting\nsheet['A1'].font = Font(bold=True, color='FF0000')\nsheet['A1'].fill = PatternFill('solid', start_color='FFFF00')\nsheet['A1'].alignment = Alignment(horizontal='center')\n\n# Column width\nsheet.column_dimensions['A'].width = 20\n\nwb.save('output.xlsx')\n```\n\n### Editing existing Excel files\n\n```python\n# Using openpyxl to preserve formulas and formatting\nfrom openpyxl import load_workbook\n\n# Load existing file\nwb = load_workbook('existing.xlsx')\nsheet = wb.active  # or wb['SheetName'] for specific sheet\n\n# Working with multiple sheets\nfor sheet_name in wb.sheetnames:\n    sheet = wb[sheet_name]\n    print(f\"Sheet: {sheet_name}\")\n\n# Modify cells\nsheet['A1'] = 'New Value'\nsheet.insert_rows(2)  # Insert row at position 2\nsheet.delete_cols(3)  # Delete column 3\n\n# Add new sheet\nnew_sheet = wb.create_sheet('NewSheet')\nnew_sheet['A1'] = 'Data'\n\nwb.save('modified.xlsx')\n```\n\n## Recalculating formulas\n\nExcel files created or modified by openpyxl contain formulas as strings but not calculated values. Use the provided `recalc.py` script to recalculate formulas:\n\n```bash\npython recalc.py <excel_file> [timeout_seconds]\n```\n\nExample:\n```bash\npython recalc.py output.xlsx 30\n```\n\nThe script:\n- Automatically sets up LibreOffice macro on first run\n- Recalculates all formulas in all sheets\n- Scans ALL cells for Excel errors (#REF!, #DIV/0!, etc.)\n- Returns JSON with detailed error locations and counts\n- Works on both Linux and macOS\n\n## Formula Verification Checklist\n\nQuick checks to ensure formulas work correctly:\n\n### Essential Verification\n- [ ] **Test 2-3 sample references**: Verify they pull correct values before building full model\n- [ ] **Column mapping**: Confirm Excel columns match (e.g., column 64 = BL, not BK)\n- [ ] **Row offset**: Remember Excel rows are 1-indexed (DataFrame row 5 = Excel row 6)\n\n### Common Pitfalls\n- [ ] **NaN handling**: Check for null values with `pd.notna()`\n- [ ] **Far-right columns**: FY data often in columns 50+ \n- [ ] **Multiple matches**: Search all occurrences, not just first\n- [ ] **Division by zero**: Check denominators before using `/` in formulas (#DIV/0!)\n- [ ] **Wrong references**: Verify all cell references point to intended cells (#REF!)\n- [ ] **Cross-sheet references**: Use correct format (Sheet1!A1) for linking sheets\n\n### Formula Testing Strategy\n- [ ] **Start small**: Test formulas on 2-3 cells before applying broadly\n- [ ] **Verify dependencies**: Check all cells referenced in formulas exist\n- [ ] **Test edge cases**: Include zero, negative, and very large values\n\n### Interpreting recalc.py Output\nThe script returns JSON with error details:\n```json\n{\n  \"status\": \"success\",           // or \"errors_found\"\n  \"total_errors\": 0,              // Total error count\n  \"total_formulas\": 42,           // Number of formulas in file\n  \"error_summary\": {              // Only present if errors found\n    \"#REF!\": {\n      \"count\": 2,\n      \"locations\": [\"Sheet1!B5\", \"Sheet1!C10\"]\n    }\n  }\n}\n```\n\n## Best Practices\n\n### Library Selection\n- **pandas**: Best for data analysis, bulk operations, and simple data export\n- **openpyxl**: Best for complex formatting, formulas, and Excel-specific features\n\n### Working with openpyxl\n- Cell indices are 1-based (row=1, column=1 refers to cell A1)\n- Use `data_only=True` to read calculated values: `load_workbook('file.xlsx', data_only=True)`\n- **Warning**: If opened with `data_only=True` and saved, formulas are replaced with values and permanently lost\n- For large files: Use `read_only=True` for reading or `write_only=True` for writing\n- Formulas are preserved but not evaluated - use recalc.py to update values\n\n### Working with pandas\n- Specify data types to avoid inference issues: `pd.read_excel('file.xlsx', dtype={'id': str})`\n- For large files, read specific columns: `pd.read_excel('file.xlsx', usecols=['A', 'C', 'E'])`\n- Handle dates properly: `pd.read_excel('file.xlsx', parse_dates=['date_column'])`\n\n## Code Style Guidelines\n**IMPORTANT**: When generating Python code for Excel operations:\n- Write minimal, concise Python code without unnecessary comments\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n**For Excel files themselves**:\n- Add comments to cells with complex formulas or important assumptions\n- Document data sources for hardcoded values\n- Include notes for key calculations and model sections"
  }
]